{"meta":{"title":"宵晓咲","subtitle":"且听风吟","description":"心情、思考、时光","author":"aisaka","url":"https://aisaka.cloud","root":"/"},"pages":[{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2021-01-17T16:38:44.000Z","comments":false,"path":"bangumi/index.html","permalink":"https://aisaka.cloud/bangumi/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-03-27T06:23:52.000Z","updated":"2019-03-28T04:48:16.000Z","comments":false,"path":"categories/index.html","permalink":"https://aisaka.cloud/categories/index.html","excerpt":"","text":""},{"title":"我","date":"2019-03-27T06:49:10.000Z","updated":"2021-01-19T05:31:58.000Z","comments":false,"path":"about/index.html","permalink":"https://aisaka.cloud/about/index.html","excerpt":"","text":"关于这个网站这个网站是我大二建的个人网站，建立起来只是好玩，像当自己的小窝一样。最开始框架用的是wordpress，直到上学期换成了较为轻便的hexo。同时把以前写的大部分日记和随笔都迁移到其他地方去了。这个网站大概是个人的记录，随缘更新~ 2018年9月 关于我 坐标帝都，在校学生 aisaka/宵晓咲/小Y 喜欢动画，游戏，阅读，算法，代码 高中入宅，本命夏娜，最喜欢的番剧是《龙与虎》，最喜欢的Gal是《LittleBusters》(Refrain线) 热爱游戏，核心玩家，最喜欢的游戏是《超级弹丸论破2》，喜欢七海千秋 过去与现在是一个理想主义者，未来也希望自己能一直坚持下去"},{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2021-01-17T13:45:22.000Z","comments":true,"path":"comment/index.html","permalink":"https://aisaka.cloud/comment/index.html","excerpt":"","text":"Notes.. できないことが、できるって、最高だ。"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2021-01-19T04:03:16.000Z","comments":true,"path":"musicLibrary/index.html","permalink":"https://aisaka.cloud/musicLibrary/index.html","excerpt":"","text":""},{"title":"links","date":"2021-01-18T15:11:06.000Z","updated":"2021-01-17T16:30:39.000Z","comments":true,"path":"links/index.html","permalink":"https://aisaka.cloud/links/index.html","excerpt":"","text":""},{"title":"示例页面","date":"2016-09-30T15:59:59.000Z","updated":"2018-11-05T10:43:31.000Z","comments":false,"path":"sample-page/index.html","permalink":"https://aisaka.cloud/sample-page/index.html","excerpt":"","text":"这是一个范例页面。它和博客文章不同，因为它的页面位置是固定的，同时会显示于您的博客导航栏（大多数主题中）。大多数人会新增一个“关于”页面向访客介绍自己。它可能类似下面这样： 我是一个很有趣的人，我创建了工厂和庄园。并且，顺便提一下，我的妻子也很好。 ……或下面这样： XYZ装置公司成立于1971年，公司成立以来，我们一直向市民提供高品质的装置。我们位于北京市，有超过2,000名员工，对北京市有着相当大的贡献。 作为一个新的WordPress用户，您可以前往您的仪表盘删除这个页面，并建立属于您的全新内容。祝您使用愉快！"},{"title":"[object Object]","date":"2021-07-20T12:19:01.963Z","updated":"2021-01-17T09:18:25.000Z","comments":true,"path":"scaffolds/draft.html","permalink":"https://aisaka.cloud/scaffolds/draft.html","excerpt":"","text":""},{"title":"[object Object]","date":"2021-07-20T12:19:01.964Z","updated":"2021-01-18T01:43:34.000Z","comments":true,"path":"scaffolds/post.html","permalink":"https://aisaka.cloud/scaffolds/post.html","excerpt":"","text":""},{"title":"[object Object]","date":"2021-07-20T12:19:01.964Z","updated":"2021-01-17T09:18:25.000Z","comments":true,"path":"scaffolds/page.html","permalink":"https://aisaka.cloud/scaffolds/page.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-20T15:14:28.000Z","updated":"2021-01-18T03:05:59.000Z","comments":true,"path":"tags/图集/index.html","permalink":"https://aisaka.cloud/tags/%E5%9B%BE%E9%9B%86/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-20T15:14:28.000Z","updated":"2021-01-18T03:05:52.000Z","comments":true,"path":"tags/悦读/index.html","permalink":"https://aisaka.cloud/tags/%E6%82%A6%E8%AF%BB/index.html","excerpt":"","text":""},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-03-16T10:41:30.000Z","comments":false,"path":"video/index.html","permalink":"https://aisaka.cloud/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }"}],"posts":[{"title":"Linux存储栈大略&存储加速","slug":"存储/Linux存储栈大略","date":"2021-07-20T11:12:37.000Z","updated":"2021-07-20T23:59:09.442Z","comments":true,"path":"存储/Linux存储栈大略/","link":"","permalink":"https://aisaka.cloud/%E5%AD%98%E5%82%A8/Linux%E5%AD%98%E5%82%A8%E6%A0%88%E5%A4%A7%E7%95%A5/","excerpt":"","text":"linux存储栈用户请求（流数据）-文件系统转换成块设备需要的块（块数据）（在内存中进行）-发送到设备（BIO方式） =&gt;完成将数据写到磁盘 内存在这个过程中扮演磁盘缓存，将这一流程分为上下两个异步过程 流 Stream；块 Block 【Pic：The Linux Storage Stack Diagram】 此图为关键，包含linux存储栈所有内容 内存区域中，低位地址是用户态应用，高位地址给内核态应用（32位支持4G内存，低位3G用户态，高位1G内核态） pmap：查看进程的地址空间分布（or /proc/&lt;pid&gt;/maps查看） mmap/mmap2：将文件中指定长度的一段数据映射到指定内存区域，从而可以通过访问内存的方式访问文件；且设置参数可支持贡献映射，私有映射，匿名映射等） 使用mmap访问内存，相比read/write，减少了一次用户空间到内核空间的映射（即直接访问内存来访问文件），提升性能 （lab） 用户态与内核态，是权限的差别 凡是与硬件有关的（比如内存），以及操作系统级别的，都是属于很高的权限，都是系统调用 系统调用从执行的时候就进入内核态，返回的时候才回到用户态 文件系统VFS(Virtual File System)虚拟文件系统向用户提供统一的抽象系统调用供用户使用，屏蔽真实文件系统细节；各个真实文件系统需要遵循VFS提供的规范才能兼容，常见的真实文件系统有Ext3、NFS、ISOFS等。 VFS主要有四个对象类型： 超级块：存储文件系统相关信息 inode：存储文件（含目录）的元数据，一个文件对应一个inode，包含指向文件（目录项）数据的指针（或文本数据） 目录项（也是文件，一种特殊的文件）：描述了文件系统的层次结构，主要格式为[目录—-文件名（含目录项）—-inode] 文件 linux一切皆文件，一切文件皆有一个对应的inode结点，后面就不特意强调目录项也是文件了 Btrfs特性 BTree Ext3额外使用BTree，当同一目录下文件容量超过2KB，这个目录的inode的i_data域（i_data域用于存放数据，目录的i_data域原来是没数据的，文本数据会直接存在其inode的i_data域（？））会指向一个BTree结构的目录索引，通过检索这个BTree可以快速找到目标文件的inode编号 Btrfs就是更进一步进化，其所有inode结点都是只通过BTree索引 一切文件的索引从超级块开始 对于文件系统来说，假设用树结构进行索引，树的每个结点就是一页，在搜索树的时候，每访问一个结点，实际上都要进行一次IO，从磁盘读数据到内存，所以树越高，IO越多，所以我们用BTree，很扁平，IO很少（还有局部预读优势） extent inode中保存有指向数据块的指针，现代文件系统（如ext4、Btrfs）通常用extent来取代block（块），一个extent由很多连续的block组成，减小元数据的开销。 动态索引节点分配 ext234的索引节点数量都是固定的，存在索引节点用完但磁盘空间没用完的情况，Btrfs则是动态分配 SSD优化（？） 支持元数据和数据的校验 支持写时复制 子分区subvolume 软件磁盘阵列 压缩 page cache计算机存储结构：扇区-&gt;块(簇,block)-&gt;页 扇区：磁盘上的最小寻址单位，通常为512B 块：文件系统读写数据的最小单位，也叫磁盘簇，Block。操作系统内核不能对磁盘扇区直接寻址，而是对块进行寻址 页：内存的最小存储单位 块由扇区组成，页由块组成 page cache，文件缓存，属于内核缓冲区，缓存页，在内存中；（注意与MMU管理的page table的区别，而TLB在CPU缓存中，这俩存的都是地址转换表，而page cache在内存中缓存的是page/block）在2.4.10版本内核之前有个buffer cache，用来缓存块，现在已经被包含在page cache里了；其主要作用是内核将闲余的内存空间利用起来对磁盘文件进行缓存（预读） 【更深入了解】 DDIO(Data Direct IO)跳过page cache，不经过内存直接进行块设备与CPU之间的数据传输 见下面“关于SPDK&amp;DPDK”一节 所以IO也分为Direct IO和Buffered IO 块层(Block Layer)块设备复杂程度高，且块设备访问性能对系统影响很大，所以内核专门提供了一个子系统来管理块设备，叫Block Layer 块层属于真实磁盘文件系统与IO调度层之间 内核设备IO流程： 【虚拟文件系统】—-【(page cache)】—-【真实文件系统】—-【通用块层】—-【IO调度层】—-【块设备驱动】—-【块设备】 通用块层：通用块层通过bio结构向IO调度层描述IO请求，这里已经到达了物理磁盘领域 IO调度层：对通用块层的请求进行优化调度处理（如合并等），再使用request结构体向下层块设备驱动发出请求 bio结构描述了真实操作位置（块设备上）的块与Page Cache（内存中）中块的映射关系，一个bio在磁盘中对应一块连续的位置，但其对应的内存中的数据可以不连续，由若干bio_vec来描述（一个bio对应多个bio_vec，一个bio_vec描述一个块在哪个page中的哪个位置） 多个bio在块层被合并（蓄流-&gt;泄流）为一个request结构，request组成request队列，调用设备驱动程序接口将request移动到设备驱动层进行处理；一个块设备有若干request队列与之对应（一个队列一个CPU处理） IO调度有多种算法，如noop（FIFO）、deadline（电梯+最大等待时间防饥饿）、CFQ（多请求队列、时间片；默认） LVM(Logic Volume Manager)逻辑卷管理 LVM解决传统磁盘分区不方便管理的问题（需要重新进行系统引导） LVM通过device mapper建立逻辑设备到物理设备的映射，它对IO请求进行过滤或重定向等工作 LVM是可选的，见上面大图中Block Layer上面那个矩形框，就是LVM层，它在Block Layer（块设备）之前，被注册为一个块设备驱动 device mapper机制由内核空间的device mapper块设备驱动（提供映射机制）和用户空间的device mapper库（用户空间可以决定如何建立映射）组成 derive mapper块设备驱动则有三个重要对象概念：mapper device、target device、mapping table LVM可以嵌套，即多层逻辑设备 bcachelinux内核的块层缓存，使用固态硬盘作为硬盘驱动器缓存 三种缓存策略：writeback、writethrough(default)、writearoud bcache可以将固态硬盘池化，一个固态硬盘形成一个缓存池，对应多块硬盘驱动器，并且支持从缓存池中划分出瘦分配的纯Flash卷（thin-Flash LUN）单独使用。LUN是存储设备上可以被应用服务器识别的独立存储单元。 bcache被划分为很多bucket，使用LRU策略缓存，计数周期减少；需要GC，压缩无效bucket 块层缓存还有flashcache、dm-cache、enhanceIO等，前两者通过device mapper机制实现 DRBD(Distributed Relicated Block Device)分布式块设备复制，用于通过网络在服务器之间对块设备进行镜像，以解决磁盘单点故障问题 类似于HA集群 两种工作模式：主从、双主 存储加速关于syscall：read+syscall：write操作read+write连续调用的场景是网络读盘：即读取互联网一台计算机的磁盘数据，需要先read从磁盘到服务端[内核缓冲区]，再由服务端程序write从用户程序到网卡[套接字缓冲区] 磁盘缓冲—-(copy)—内存—(copy)—-用户程序缓冲区 CPU Direct：在原来的存储栈中，read操作是 数据先从磁盘拷贝到磁盘缓冲区，再由CPU从磁盘缓冲区拷贝到内核缓冲区（在内存中-内核态，高位），再由CPU从内核缓冲区拷贝到应用程序缓冲区（也在内存中，但是状态不同-用户态，低位）；然后write则是将数据从应用程序缓冲区拷贝到套接字缓冲区，再从套接字缓冲区拷贝到网卡，这个过程全由CPU负责 一次syscall两次拷贝：指的是内存与用户之间往返的两次（内核缓冲区-用户缓冲区） 一次syscall两次状态切换：syscall进入与返回两次 read+write则是四次拷贝（CPU Direct全由CPU负责）、四次状态切换 CPU&amp;DMA：这个方式下CPU不再与磁盘直接交互，而是CPU命令DMA去与磁盘交互（DMA负责磁盘与内存之间的数据拷贝，这是在内核态，CPU只负责用户程序与内存之间数据的拷贝），CPU就解放了一部分。但是这个方式下，还是存在2次DMA拷贝，2次CPU拷贝，4次状态切换（进出read、write）。 zero-copy 零拷贝技术：不进行两次两次拷贝，而是直接 mmap+write、sendfile、sendfile+DMA收集、splice、dpdk、spdk、rdma、NVMe Direct等 mmap可以做到共享内核缓冲区与用户空间缓冲区，减少了一次CPU拷贝（不需要内核缓冲区-&gt;用户空间缓冲区，只需要内核缓冲区-&gt;套接字缓冲区），且有状态切换 mmap小文件可能出现碎片，且多进程环境下可能出现问题 sendfile建立了两个文件之间的传输通道，一个syscall实现了read+write，减少了两次状态切换，数据不经过用户缓冲区。2次CPU拷贝，2次状态切换（进出sendfile） 由于数据不经过用户缓冲区，所以数据无法被修改；且sendfile只能将数据拷贝在socket上 sendfile+DMA 同理，改由DMA直接操作磁盘，2次DMA拷贝，2次状态切换 但需要DMA控制器 splice则是在sendfile+DMA上改进，不需要DMA控制器，且不再限定将数据拷贝到socket上 两个文件描述符参数中有一个必须是管道设备 关于DMA&amp;RDMADMA(Direct Memory Access)，可以把计算机主板上的设备数据直接传送到内存中，不需要CPU参与 RDMA(Remote Direct Memory Access)，允许两台主机的应用程序（存储）在它们的内存空间之间直接进数据传输 RNIC：具有RDMA引擎的网卡（NIC：网卡） 数据传输路径：[host1的应用程序缓冲区]—-[host1的RNIC]—-NETWORK—-[host2的RNIC]—-[host2的应用程序缓冲区] 显然这样就不用经历两次IO缓冲区 RDMA相比传统的TCP/IP有很大优势，RDMA不需要CPU参与，在用户态进行，且数据流将被处理为离散消息进行传输，且可以分散/聚合多个流 RDMA特性：zero-copy，kernel bypass，无CPU干预，消息基于事务，支持分散/聚合条目 支持RDMA的网络协议：IB，RoCE，iWARP；这些协议都要求RDMA专用NIC 关于RDMA&amp;DPDK两者都不使用内核协议栈，都是使用自己的网络协议栈，也就实现了kernel bypass RDMA是将协议栈下沉到网卡硬件，即由具有RDMA引擎的网卡RNIC来单独完成网络协议栈 DPDK是将协议栈上移到用户态软件，在用户态实现了网络协议栈 DPDK是软件层面实现的；RDMA则需要专用RNIC硬件支持 DPDK仍然会消耗CPU资源，并发度取决于CPU的核数；而RDMA的收包速率完全取决于网卡硬件的转发能力 DPDK在低负荷场景下会造成CPU空转；RDMA不会 DPDK用户可以自己定制协议栈；RDMA无法定制协议栈 关于DPDK&amp;SPDKDPDK关键技术：DDIO技术支持以太网控制器将IO流量直接传输到CPU高速缓存，不经过内存，UIO技术直接将设备数据映射拷贝到用户态、大页技术增大分页基本单位大小提高快表TLB访问命中率、利用CPU亲和性绑定网卡和线程到固定的core减少CPU任务切换、无锁队列减少资源竞争 SPDK关键技术： 32位linux系统的页面大小为4KB，DPDK中大页内存可以设置2MB或1GB，大页内存适合在程序占用内存很大的情况下，否则会浪费内存空间（程序占用内存小的话，调用却还是要以页为单位调入内存，页面过大就浪费内存了） SMP&amp;NUMA主要是多核处理器及其内存系统的调度管理技术 SMP/UMA(Uniform Memory Access Architecture)：一致性内存访问结构，所有硬件资源都是共享的，多个处理器没有区别、平等地访问内存和IO外部设备，并且每个处理器访问内存的任何地址所需时间是形同的。 缺点：扩展性有限，当内存访问达到饱和的时候，系统总线成为效率瓶颈，增加处理器也无用，且处理器与内存之间的通信延迟也增大 NUMA(Non-Uniform Memory Access Architecture)：非一致性内存访问技术，设置多个处理器模块(Node)，每个Node具有独立的本地内存、IO设备，处理器模块之间通过高速互联的接口连接起来。NUMA调度器负责将进程尽量在同一Node的CPU之间调度，除非负载太高，才迁移到其他结点。在设计包处理程序时，内存分配上使处理器尽量使用靠近其所在Node的内存，可以水平扩展包处理能力。 CPU加速 超线程技术：OS将一个物理核识别为两个逻辑核，它们有独立的寄存器，但是共用主要的执行单元 优化指令 SIMD(Single Instruction Multiple Data)：单指令流多数据流指令，指拥有多个处理单元的计算机能够用一条指令（执行的流程）同时处理多个数据集；数据层次并行，一个寄存器可以作为完整的64位整数寄存器使用，也可以packed形式作为多个小的整数寄存器，如2个32位、4个16位、8个8位寄存器。 intel提出的AVX指令集就引入了三操作数SIMD指令，如AVX512把指令扩展到了512位，同时定义了32个512位寄存器，利用SIMD就可以操作位宽更大的寄存器，同时进行更多的向量计算 扩展指令（一些在存储上有用的） 如AES-NI指令集、CRC32扩展指令集、SHA-NI指令集 协处理器等其它硬件加速 FPGA：定制化可编程芯片 数据密集计算加速：用FPGA实现纠删码、压缩算法、加密算法 存储协议转换的加速：在RDMA方案中，FPGA替代CPU卸载存储 特殊存储接口加速：用FPGA加速接口 智能网卡加速：将主机CPU上的工作放到网卡上来完成 Intel QAT(Quick Assist Technology)：专注数据安全和压缩的硬件加速器，主要用于数据中心 DVDIMM(Non-Volatile Dual In-Line Memory Module)：一种可以随机访问的非易失内存 ISA-L(智能存储加速库)包含数据保护、数据安全、数据完整性、数据压缩、数据加密等算法函数 ISA-L利用汇编语言编写，利用IA特性，使用高效的SIMD指令和专用指令，最大化利用CPU的微架构来加速存储算法的计算过程 细节略 SPDK(核心)核心是用户态、异步、轮询方式的NVMe驱动，用于加速NVMe SSD SPDK将内核驱动放到用户态，在用户态实现一个完整的存储栈（IO栈，见前面大节），其中一个重要话题就是文件系统，那么常见的文件系统如ext4、Btrfs都不能直接支持了。SPDK目前提供非常简单的文件系统BlobFS，但是并不支持可移植操作系统接口(POSIX,Portable Operating System Interface，是IEEE为要在各种UNIX操作系统上运行软件,而定义API的一系列互相关联的标准的总称)，即由于SPDK的用户态IO栈的FS（File System，文件系统）不支持POSIX，导致应用程序不能直接从其它OS迁移到SPDK的FS上，所以应用程序需要一些代码移植工作来支持SPDK的用户态IO栈FS，或者采用AIO的异步读写方式，不使用POSIX SPDKSPDK NVMe驱动 Linux用户态驱动 UIO(userspace IO)：linux专门提供的一套在用户态开发驱动的框架，它把硬件寄存器的地址用ioremap函数映射到用户态的虚拟地址（原理：UIO框架在内核中的小模块修改了页表），然后在用户态打开这个文件，mmap到内存中，我们就可以在用户态对硬件进行直接IO了，将大部分的内核空间操作放到了用户态 VFIO(Virtual Function IO)：在UIO之上考虑到了安全，把设备IO、中断、DMA暴露到用户空间。引入IOMMU(IO Memory Management Unit)对设备进行限制，设备IO地址需要经过IOMMU重映射为内存物理地址来保证安全，这样物理设备将不能绕过或污染MMU(Memory Management Unit)。 用户态DMA：通过UIO或VFIO，就可以做到用户态驱动，在用户态发起对设备的DMA 用户态DMA三个要考虑问题：①提供设备可以认知的内存地址（设备支持IOMMU解决）②CPU对内存的更新必须对设备可见（CPU之间的缓存一致性来解决）③物理内存必须在位（人工pin解决不让换出解决，大页技术也可以缓解，因为大页可以使得页很少换出；大页技术还可以增大分页基本单位大小提高快表TLB访问命中率） SPDK用户态驱动 SPDK基于UIO、VFIO技术，并引入了其它优化技术来提高用户态驱动对设备的访问效率 异步轮询 由SPDK用户态驱动对设备进行不断轮询，检查状态，判断是否操作完成，而不是让设备发起中断（因为中断由用户态进出处理不合适、给用户态程序引入不确定性） 无锁化 利用CPU亲和性绑定线程和特定CPU核心，并通过轮询的方式占住该核的使用，采用Run To Completion（运行直到完成）的方式，就可以避免资源分配上使用锁，一个核上只会有一个线程 单核上的资源依赖于DPDK的内存管理，不仅提供了核上的专门资源，还提供了高校访问全局资源的数据结构，如mempool、无锁队列、环等 专门为Flash优化 SPDK是专门针对NVMe SSD设备（Flash闪存）的，充分利用设备的高性能（低延时、高带宽），SPDK实现了一组C代码库。 但也支持块设备 SPDK用户态驱动多进程的支持 同一块NVMe SSD给多进程SPDK使用，NVMe SSD可以划分为多个Namespace或在同一个Namespace中划分多个空间分配给不同应用程序进程存储 共享内存（各进程标识）、共享NVMe SSD（数据通道上的隔离：NVMe设备的IO队列）、管理软件完成队列（共享给所有进程） SPDK应用框架SPDK提供了一个指导性的SPDK应用框架，用户可以选择使用SPDK应用框架，也可以自己使用SPDK用户态NVMe驱动提供的函数进行编程 对CPU core和进程的管理 设置绑定进程和CPU core，原则是用最少的core完成最多的任务，一个核上运行一个thread thread在SPDK中封装为Reactor，SPDK为其封装了很多管理，比如Reactor的state没有改变之前，会默认执行while(1)不断轮询，运行直到完成 提供Poller机制为用户定义函数的封装，即thread执行的内容，一个thread可以执行很多poller 线程间的高效通信 放弃锁来进行线程间通信，SPDK提供了事件调用（Event）机制，每个Reactor对应的数据结构维护了一个Event事件的环，这个环是多生产者和单消费者模型（MPSC），每个Reactor thread可以接受来自任何其他Reactor thread的事件消息进行处理 IO的处理模型和数据路径的无锁化机制 包括SPDK用户态存储栈（可以理解为SPDK应用框架的一个应用）的实现也是使用了SPDK应用框架的设计，来达到最高的性能 SPDK用户态块设备层在通用块层引入逻辑上的IO Channel来屏蔽下层的具体实现，IO Channel：Thread：Core=1:1:1 SPDK Bdev（SPDK快设备层）有以下几类核心的数据结构：①通用块设备的数据结构②操作通用设备的函数指针表③块设备IO数据结构 这些核心的数据结构，提供了最基本的功能上的特殊性来支持不同的后端设备，比如通过SPDK用户态NVMe驱动来操作NVMe SSD；通过Linux AIO来操作除NVMe SSD外的其他满速存储设备比如HDD、SATA SSD、SAS SSD等；通过Cpeh RBD来操作远端 Ceph OSD设备；通过GPT在同一设备上创建逻辑分区等等…. SPDK通用块层也使用了SPDK应用框架的优化思想来设计 与linux内核存储栈思想一样，SPDK用户态存储栈也引入IO队列，提供很多功能比如限速流控，IO分发，异常恢复等等 SPDK基于通用块层进行流量控制，好处是和上层各种协议、后端具体设备无关，可以是任何一个通用块设备。 SPDK用户态LVM的核心技术是Blobstore，其本质是一个block的分配管理，是位于SPDK Bdev之上的Blob管理层，用于与用户态文件系统Blobstore Filesystem（BlobFS）集成，代替传统的文件系统 P.S. Blob=Binary Large Object 具体略 【块设备层具体设计细节】 SPDK加速方案举例【略】 SPDK vhost target SPDK iSCSI Target SPDK NVMe-oF Target SPDK RPC P.S. AHCI=Advanced Host Controller Interface NVMe=NVMHCIS=Non Volatile Memory Host Controller Interface Specification","categories":[{"name":"存储","slug":"存储","permalink":"https://aisaka.cloud/categories/%E5%AD%98%E5%82%A8/"}],"tags":[]},{"title":"Ceph","slug":"存储/Ceph","date":"2021-07-20T11:09:21.000Z","updated":"2021-07-20T11:25:20.325Z","comments":true,"path":"存储/Ceph/","link":"","permalink":"https://aisaka.cloud/%E5%AD%98%E5%82%A8/Ceph/","excerpt":"","text":"Ceph体系结构RADOS(Reliable, Autonomous, Distributed Object Storage)，一个可无限扩展的集群，这一层本身是一个完整的对象存储系统，所有存储在Ceph系统中的用户数据最终都是由这一层来存储 RADOS之上直接有librados（提供操作RADOS的基础库，在此基础上可以开放各种存储应用，以及RADOS GW、RBD等），Ceph FS（一个POSIX兼容的分布式FS） RADOS物理上由OSD集群和Monitor集群组成，其逻辑结构为Object——PG——OSD Object—-&gt;PG采用hash映射，PG—-&gt;OSD采用CRUSH映射 RADOS对Object有最大尺寸限定，所以一个File可能被划分为多个Object，作为RADOS的对象，而不是“应用意义上的对象” 一个PG负责组织若干个Object，一个Object只能被映射到一个PG中，即Object和PG是多对一关系 一个PG会被映射到多个OSD（副本，备份），一个OSD承载多个PG，即PG和OSD是多对多关系 存储池由若干PG和OSD构成，也是逻辑结构。 为什么引入PG？因为object潜在的命名空间巨大，如果一个osb出现故障，需要遍历所有object来寻找所有该承载的object。引入一层PG中间层，PG数量是一定的，OSD数量是一定的，那么一个OSD故障了，只需要遍历该OSD承载的PG，对PG进行迁移即可 Ceph客户端（RBD客户端、RADOS客户端、Ceph FS客户端/MDS）可以直接与OSD集群、Monitor集群进行通信 OSD集群向Monitor上报状态信息（满足一些情况即上报，比如增加OSD、异常），Monitor集群负责所有OSD状态的发现与记录，并形成集群运行图的主副本，包括成员、状态、变更、以及ceph存储集群的整体健康状况；随后这份集群运行图被扩散至全体OSD及客户端（OSD使用集群运行图进行数据维护，客户端使用集群运行图进行数据寻址） 注意，信息是OSD主动上报的，图是由Monitor维护再扩散的 集群运行图：Monitor Map、OSD Map、PG Map、CRUSH Map、MDS Map等 CRUSH Map里包含了存储设备列表、故障域树状结构（设备的分组信息，如设备、主机、机架、行、房间等）和存储数据时如何利用此树状结构的规则。根节点是default，所有非叶子结点称为桶（bucket，id为负），叶子结点即为OSD（id为正），选择OSD的时候就是要在这棵树上进行选择，有五种算法进行子节点选择：Uniform、List、Tree、Straw、Straw2 由于Object-&gt;PG采用hash映射，客户端可以直接通过hash得到目标Object所在的PG信息，然后查询OSD Map（由monitor写好扩散到所有OSD了）就可以得到该PG分布信息，然后客户端就可以直接与Primary OSD进行通信了，不需要Monitor干预。仅当客户端需要获取最新OSD Map的时候才与Monitor通信 OSD和Monitor之间存在心跳机制，OSD定时向Monitor上报PG信息、OSD本身信息。 OSD的操作命令（osd scrub/deep scrub、pg/scrub、deep scrub等）是客户端通过Monitor传递给OSD的（注意是OSD操作命令，不包含读写等通信） Ceph的写操作采用Primary-Replica模型，客户端向对应OSD Set发起写请求，Primary收到Object的写请求后将数据发送给set里其它副本，当这个数据被保存到所有OSD上的时候（可以选择到内存缓冲区先第一次确认），Primary才应答Object的写请求，保证副本的一致性。序号最靠前的OSD为Primary。读操作则直接与Primary通信（也可以设置为其它OSD以减轻压力）。 Cache Tiering：ceph设计为分层代理模式，一个缓存层（高速ssd等）、一个storage层（低速hdd等），由一个Objecter（对象管理器，位于osdc即OSD客户端模块）决定往哪里存储对象。Objecter决定何时把缓存内的对象“刷回”Storage层。有以下几种模式：写回模式（写：直接写缓存并应答客户端，缓存再自己写Storage层；读：命中直接在缓存层读，未命中重定向到Storage，且最近有访问可以提升到缓存）、forward模式、readonly模式、readforward模式、readproxy模式、proxy模式。 块存储：ceph在基于RADOS对象存储+librados之上通过RBD提供了一个标准的块设备接口，提供基于块设备的访问模式。ceph中的块设备称为Image，可以在ceph上自由创建块设备并可调整，将数据条带化存储到集群的多个OSD中国。条带化能够将多个磁盘驱动器合并成一个卷，这样读写就比单盘快很多（因为是不同设备并行读写，和RAID一个原理），ceph的块设备就对应于LVM的逻辑卷。建立块设备之后，就可以映射到内核中，成为一个虚拟的块设备；或者通过librdb、librados访问块设备（后者一般是虚拟机场景）。 Ceph FS：兼容POSIX的分布式存储文件系统，需要对应客户端来访问Ceph FS，目前有Ceph FS FUSE（用户空间文件系统）、Ceph FS kernel（集成在内核的Kernel Module，内核空间）两种。Ceph FS FUSE基于libcephfs，而后者又基于librados。Ceph FS要求Ceph集群内至少有一个MDS（元数据服务器），将元数据从OSD分离出来，提高服务性能、减轻存储集群负载。MDS的管理，Multi Active MDS略。 后端存储ObjectStoreObjectStore完成了实际的数据存储，封装了所有对底层存储的IO操作。主要有以下几种ObjectStore MemStore：数据全放内存，主要测试用 KStore：数据全放KVDB FileStore：基于Linux文件系统，每个Object被FileStore看作是一个文件。目前支持的FS有XFS、ext4、Btrfs；通过journal机制支持事物的原子性（一个环形缓冲区），journal是必经路径，是影响性能的瓶颈，也显然导致写数据量增倍，通常用ssd optane等额外的块设备。 BlueStore：直接管理裸设备。在用户态实现了BlockDevice，使用Linux AIO直接对裸设备进行IO，实现了Allocate对裸设备进行空间管理。元数据与数据可以分开存储在不同设备中，元数据以KV的形式保存在KV数据库里（默认RocketDB，基于BlueStore实现的小文件系统BlueFS，不是裸设备）；使用SPDK、PMDK SeaStore：下一代ObjectStore。特点： ①专门为NVMe设计 ②SPDK访问NVMe，不再用Linux AIO ③使用SeaStar编程模型进行优化，以及使用share-nothing机制避免锁竞争 ④网络驱动使用DPDK来实现零拷贝 ⑤Flash设备重写必须先擦除，不知道哪些数据有效，而FS知道，所以垃圾回收功能提到SeaStore来做 CRUSHHash——-&gt;一致性Hash——-&gt;CRUSH 一致性hash组成一个地址环，对服务器地址进行hash，使得服务器固定，环上的数据存储在其右边第一个服务器上，这样就解决了扩容/节点掉线等带来的数据迁移问题 但一致性hash的问题：①所有数据均匀分布，一个结点失效，导致所有用户数据完整性问题②一致性hash无法感知存储节点的实际物理分布能力，无法合理控制数据的失效域 所以提出了CRUSH CRUSH元数据：CRUSH Map保存了OSD的物理组织结构（Tree）、OSD Map保存了各OSD设备的运行时状态 定义桶 默认情况下会创建两种桶（root和主机），所有OSD都放在对应的主机桶中，用户根据自己的物理基础设施部署情况建立对应的桶，比如一个DC、一个机房、一个机架作为一个桶 bucket的type不是自定义的，一定属于某个类型！但name和id可以自定义（即下面的Bucket Class 名称） 要先新建Bucket结构 eg： ceph osd crush add-bucket dc0 datacenter &#x2F;&#x2F;ceph osd crush add-bucket &lt;bucket name&gt; &lt;bucket type&gt; type有：osd(不属于bucket) 、host（服务器）、chassis（机壳）、rack（机架）、row（行）、pdu、pod、room（房间）、datacenter（数据中心）、region（区域）、root（根） 再对该Bucket进行详细描述 &#x2F;&#x2F;Bucket Class的定义 type &lt;Bucket Class ID&gt; &lt;Bucket Class 名称&gt; &#x2F;&#x2F;桶的定义 &lt;Bucket Class 名称&gt; &lt;桶名&gt;&#123; id &lt;负数 id&gt; alg &lt;Bucket Type: Uniform&#x2F;List&#x2F;Straw&#x2F;Straw2&gt; hash &lt;哈希算法:0&#x2F;1&gt; item &lt;子桶名或设备名1&gt; weight &lt;权重1&gt; item &lt;子桶名或设备名2&gt; weight &lt;权重2&gt; ...... &#125; alg 则是核心，其定义了这个Bucket的选择算法，即确定在该bucket的children列表中如何选出一个合适的item。默认用straw2算法。straw类算法的思想就是抽签，让bucket下的每个item随机抽一根签（一个数值），再乘以每个item的权重，然后互相比较选出签最长的那个item。抽签算法的特点是，新增item，新选出的item要么是新item，要么是现在的item，不会是其它item，增强了稳定性，即我们期望集群设备的增删仅影响到必要的结点，不要在正常运行的OSD上做无意义的数据迁移。 #算法实现 def bucket_choose(in_bucket, pgid, trial): for index, item in enumerate(in_bucket.children): draw = crush_hash(item.id, pgid, trial) draw *= item.weight if index == 0 or draw > high_draw: high_item = item high_draw = draw return high_item 在选择的时候还有一个is_avalible来判断指定的item是否可用，如果不可用应该抛弃重选 一个Bucket Class 对应一个失效域（故障域 failure domain），CRUSH确保同一故障域最多只会被选中一次 除了默认CRUSH Rule以外，需要自己定义更精细的Rule rule &lt;规则名称&gt; &#123; ruleset &lt;唯一的规则ID&gt; type &lt;备份策略：replicated&#x2F;erasure&gt; min_size: &lt;规则支持的最少设备数量&gt; max_size: &lt;规则支持的最多设备数量&gt; &#x2F;&#x2F;选择设备范围，确定失效域 step take &lt;桶名称&gt; [class &lt;Device Class&gt;]#通过桶名称来确定规则的选择范围，对应CRUSH Map中的某一棵子树 &#x2F;&#x2F;核心：每一个step choose需要确定一个对应的失效域，以及在当前失效域中选择的子项个数 step &lt;选择方式：choose&#x2F;chosseleaf&gt; &lt;选择备份的策略：firstn&#x2F;indep&gt; &lt;选择个数:n&gt; &#x2F;&#x2F;即要在这个Bucket中选择多少个OSD type &lt;失效域锁对应的Bucket Class&gt; ... step emit #步骤结束，输出选择的位置 &#125; 每一步step choose都配置一个选择区域，直到最后step choose到OSD，最后可以用chooseleaf，会自动递归choose到OSD节点 选择个数n=0的表示选择域备份数量一致的桶；n=负数的时候表示选择备份数量-n个桶；n=正数的时候表示选择n个桶 firstn：适用镜像备份；indep：适用纠删码备份 CRUSH测试工具：crushtool、crush小程序 调整CRUSH算法： ①Tunables ②主OSD设备的亲和性 ③自定义CRUSH Rule，以控制主OSD设备选择范围（即上面的内容） eg: rule ssd-primary&#123; ruleset 5 type replicated min_size 5 max_size 10 &#x2F;&#x2F;从SSD桶中选择一个主OSD step take ssd step chooseleaf firstn 1 type host step emit &#x2F;&#x2F;从platter桶中选出其他OSD step take platter step chooseleaf firstn -1 type host step emit &#125; 这就从两个选择域选出了一个主OSD一个从OSD了 用户可以建立存储池，不同的存储池可以关联不同的CRUSH规则，指定不同的备份数量，以镜像或纠删码的方式保存数据，或是指定不同的存取权限和压缩方式。 一言以蔽之，CRUSH：依赖于Hash实现的纯伪随机算法 计算独立性（每次计算独立，不依赖集群分配情况或选择结果）、稳定性（straw算法）、可预测性（CRUSH map离线计算即可预测出PG分布情形，且与集群内实际使用一致） 也有一些问题：假失败、故障额外迁移、使用率不均衡 来源：CRUSH算法的原理与实现 Ceph可靠性cluster map是一个增量图，每一次OSD状态改变或其它改变都会使得epoch++。cluster map的更新也是增量更新。 Monitor集群通过心跳机制检测OSD是否离线，Monitor集群判断某个OSD节点离线之后，会将最新的OSDMap通过消息机制随机分发给一个OSD，客户端和对等OSD处理 IO请求的时候发现自身OSD版本过低，会向Monitor请求新的OSDMap，经过一段时间的扩散，最终整个集群都会收到OSDMap的更新。 OSD的map在扩散的时候，只与相邻OSD（或Client）通信，属于lazy update，当双方通信谁发现对方版本低就进行update，这样慢慢整个集群就完成了OSDMap更新【问题：这样会不会太慢？见论文Map Propagation有细节】 CRUSH保证稳定性、高可用：数据在集群内自动复制，副本分布到不同的失败域，且映射保证稳定性 Monitor采用集群保证集群结构高可靠性，通过Paxos算法组成一个决策者集群，对关键集群事件作出广播 集群高可用：RBD mirror（两个Ceph集群实时备份，通过主机群开启RDB日志机制，远端集群读RDB日志完成备份）、RBD Snapshot（数据快照到灾备中心）做数据冗余备份 OSD端数据冗余：多副本（强一致性，多个副本写入完毕后回答客户端）、纠删码 CRC进行比特数据通信的完整性校验 数据落盘时记录日志应对突发情况 PG层使用PG日志（pglog）来应对副本之间的数据同步（保证多副本数据一致性）和恢复问题。pglog就在OSD上，一个OSD会管理多个pglog，同一个PG下的不同OSD上的pglog是一致的 不同对象的并发控制（多对象进入同一PG）：采用pglog加锁 同一对象的并发控制：网络层（TCP保证）、消息层（Ceph信息编号）、PG层（消息队列来的请求划分为多shared，消息来的时候就对pglog，保证有序）、对象读写锁（由PG层保证，不必单独提供）、ObjectStore层（FileStore里先通过单线程来控制持久化写到journal的顺序性，通过op的seq保证仿佛finish队列的顺序性，并且整个处理过程通过FIFO来保证出入队列的顺序性【？】）、副本层（PG层保证） Scrub机制：OSD状态异常（如磁盘坏道），需要一种机制主动去检查副本之间的数据是否一致（Scrub、Deep Scrub）【-】 Ceph 缓存Ceph缓存分为客户端缓存（RBD层在客户端的缓存）、Cache Tiering（在OSD端进行数据缓存），后者更下层。 Ceph缓存有两种模式，对应Cpeh块设备的两种实现方式，内核支持块设备用Ceph社区写的KRBD（内核模块）驱动，可以使用内核的缓存；用户态块设备则用librdb库实现。 用户态不能从内核缓冲中受益，所以Ceph实现了自己的用户态块设备缓存机制RBDCache，位于librbd库中，目前只能使用内存作为缓存。两种模式：写透（数据一致性问题），写回（安全问题） Linux内核中的缓存主要有Page Cache和Buffer Cache。前者为FS服务，后者则处于下层的块设备层，是块设备的缓存。RBDCache可以认为是块设备内部自带的缓存，也存在掉电等传统缓存有的问题，要用fsync等来完成数据回写。（linux内核提供fsync，librdb提供flush） KVM write barrier可以在写透与写回之间折中，即安全又高效。它可以根据每个事务来进行数据持久化。写透相当于每次写都会发起fsync，而KVM write barrier相当于每完成一个事务发起一次fsync RBDCache具体结构略【】 Ref.本文为《Linux开源存储全栈详解》一书的读书笔记","categories":[{"name":"存储","slug":"存储","permalink":"https://aisaka.cloud/categories/%E5%AD%98%E5%82%A8/"}],"tags":[]},{"title":"亲爱的旅人啊","slug":"日记/亲爱的旅人啊","date":"2021-07-09T11:23:05.000Z","updated":"2021-07-20T11:32:43.607Z","comments":true,"path":"日记/亲爱的旅人啊/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%BA%B2%E7%88%B1%E7%9A%84%E6%97%85%E4%BA%BA%E5%95%8A/","excerpt":"","text":"1 星空与银河一路看过了湖泊沙漠戈壁丘陵雪山与草原到了旅途中歇脚的小城市，突发奇想去看银河 因为很久以前就听说大西北的天空有多美，而我从小到大所生活的城市连北斗七星都看不到，正好今夜无月，晴空万里。于是凌晨1点拦了一辆出租车，跟司机说：“往城外开，去最黑暗的地方。”于是我经历了一个令人难以置信的夜晚当远离了城市的火光，走到了戈壁与沙漠附近，天空已如正午的海面一般，闪烁繁星，车子在星海中穿梭。密密麻麻的星星的映衬下，马路两道的树木已经成了漆黑的背景板终于到达了开阔的大平原，头顶的星空已经震撼到无以言表。第一次看到如此美丽的星海，第一次看到银河，极尽所能地想将天空中的所有星星尽收眼底司机将车熄火去小憩了，于是最后的一点亮光与声响也被吞没在这无垠的夜空中，只剩下寂静、浩瀚、与空灵。我静静地伫立着，静静地，想说的东西也被这璀璨的星河吞没了。第一次被震撼到眼眶湿润。只可惜手机拍照并无法很好的记录下来。 2 旅途的驿站、海上的列车在这座旅途中短暂停留的小城市的夜市中有个时光快递，一家开了10年的店，我在这里写了一封信，五年后店主会将信寄给我。这里有一整面墙的信，都是寄给未来，由岁月构成横纵坐标。在这面墙下写信的时候，我想，也有很多和我一样的旅人来到这里，短暂地停留之后，将正在发生的故事与希望寄往未来。无论是离别还是相遇，现在无论多久激烈的情感，在未来都会成为故事，而从过去漂流过去的思念，在未来将会无比珍贵。 旅途也已经接近尾声了，今天坐在车上，用车载音响放起了这首《亲爱的旅人啊》，是周深翻唱的中文填词千与千寻主题曲《いつも何度でも》。说起来夜市中公放的背景音乐也是这首歌的伴奏。千与千寻里的海上小火车也与旅途中遇到的蛮相似的。 在这段旅途中也遇到了不少旅人，未曾相识，没有联系方式，我们的联系仅仅是巧合，那就让现在的旅途更加美好吧。 3 “不要回头看，一直向前”“不要回头看，一直向前”从家出发之后，就开始了旅行，旅行的最后一站就是上海。这趟旅途，没有回程。我用指尖弹出盛夏，心之所动，且就随缘去吧亲爱的旅人啊，你要永远浪漫，永远保持理想，永远真诚，坚持到此生的光芒已黯淡 4 《亲爱的旅人啊》就此告别吧 水上的列车就快到站开往未来的路上 没有人会再回返说声再见吧 就算留恋也不要回头看在那大海的彼端 一定有空濛的彼岸 做最温柔的梦 盛满世间行色匆匆在渺茫的时空 在千百万人之中 听一听心声一路不断失去 一生将不断见证看过再多风景眼眸如初清澄 爱依旧让你动容 亲爱的旅人 没有一条路无风无浪会有孤独 会有悲伤 也会有无尽的希望亲爱的旅人 这一程会短暂却又漫长而一切终将 汇聚成最充盈的景象 Lalalalalalalalal……Lulululululu 就此告别吧 身后的灯火逐渐暗淡每个恋家的孩子 都要扬起远行的帆说声再见吧 美好的梦境不会消散你的爱枕在臂弯 心脏将毕生柔软 既然相遇是种 来自于时光的馈赠那么离别时 也一定要微笑着 回忆放心中生命无限渺小 却同样无限恢弘你为寻找或是告别耗尽一生 也足够让人心动 亲爱的旅人 你仍是记忆中的模样穿过人群 走过人间 再去往更远的远方你灵魂深处 总要有这样一个地方永远在海面漂荡在半空中飞扬永远轻盈永远滚烫不愿下沉不肯下降https://music.163.com/song?id=1371939273","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"这里就是这段旅途的终点了。","slug":"日记/这里就是这段旅途的终点了。","date":"2021-06-29T01:59:00.000Z","updated":"2021-07-20T11:38:37.809Z","comments":true,"path":"日记/这里就是这段旅途的终点了。/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E8%BF%99%E9%87%8C%E5%B0%B1%E6%98%AF%E8%BF%99%E6%AE%B5%E6%97%85%E9%80%94%E7%9A%84%E7%BB%88%E7%82%B9%E4%BA%86%E3%80%82/","excerpt":"","text":"我回来了完成这一章冒险了在座有没有人有兴趣听我说一路见过的潮起潮落 即使火车比机票还贵，回家也选择了坐火车，因为这趟旅途的起点就是从发往北京的火车开始的想再看一次沿途的风景，穿过湖泊与平原，想要一次漫长的道别好像来的时候和现在回家的时候一样，两手空空但是经历了那么多故事呢","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"我们会在更宽广的未来再次相遇","slug":"日记/我们会在更宽广的未来再次相遇","date":"2021-06-28T15:00:00.000Z","updated":"2021-07-20T11:40:51.957Z","comments":true,"path":"日记/我们会在更宽广的未来再次相遇/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%88%91%E4%BB%AC%E4%BC%9A%E5%9C%A8%E6%9B%B4%E5%AE%BD%E5%B9%BF%E7%9A%84%E6%9C%AA%E6%9D%A5%E5%86%8D%E6%AC%A1%E7%9B%B8%E9%81%87/","excerpt":"","text":"列出出发了","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"因为还有很多未曾见过的风景.","slug":"日记/因为还有很多未曾见过的风景，byebye","date":"2021-06-28T04:24:00.000Z","updated":"2021-07-21T00:00:55.907Z","comments":true,"path":"日记/因为还有很多未曾见过的风景，byebye/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%9B%A0%E4%B8%BA%E8%BF%98%E6%9C%89%E5%BE%88%E5%A4%9A%E6%9C%AA%E6%9B%BE%E8%A7%81%E8%BF%87%E7%9A%84%E9%A3%8E%E6%99%AF%EF%BC%8Cbyebye/","excerpt":"","text":"byebye. 最后十分钟一口气喝完了几年前买的尊尼获加，从寝室，到食堂，到校门，一路晕晕晃晃的。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"星空","slug":"日记/星空","date":"2021-06-18T13:03:52.000Z","updated":"2021-06-18T13:09:26.412Z","comments":true,"path":"日记/星空/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%98%9F%E7%A9%BA/","excerpt":"","text":"摸不到的颜色 是否叫彩虹 看不到的拥抱 是否叫做微风 一个人 想着一个人 是否就叫寂寞 命运偷走如果 只留下结果 时间偷走初衷 只留下了苦衷 你来过 然后你走后 只留下星空 那一年我们望着星空 有那么多的灿烂的梦 以为快乐会永久 像不变星空 陪着我 猎户 天狼 织女光年外沉默 回忆 青春 梦想何时偷偷陨落 我爱过 然后我沉默 人海里漂流 那一年我们望着星空 未来的未来从没想过 当故事失去美梦 美梦失去线索 而我们失去联络 这一片无言无语星空 为什么静静看我泪流 如果你在的时候 会不会伸手 拥抱我 细数繁星闪烁 细数此生奔波 原来所有 所得 所获 不如一夜的星空 空气中的温柔 回忆你的笑容 彷佛只要伸手 就能触摸 摸不到的颜色 是否叫彩虹 看不到的拥抱 是否叫做微风 一个人 习惯一个人 这一刻独自望着星空 从前的从前从没变过 寂寞可以是忍受 也可以是享受 享受仅有的拥有 那一年我们望着星空 有那么多的灿烂的梦 至少回忆会永久 像不变星空 陪着我 最后只剩下星空 像不变回忆 陪着我 很久以前很喜欢的歌。 生日快乐。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"promare","slug":"日记/promare","date":"2021-06-06T15:54:00.000Z","updated":"2021-07-20T12:13:05.862Z","comments":true,"path":"日记/promare/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/promare/","excerpt":"","text":"生病了，回老家修养一周。几个高中同学在群里商量去看promare，正好我也想看，于是我产生了一个好玩的想法XD我在他们那场也订了一张票，在开始前1分钟偷偷摸进影厅坐在他们旁边，我没有告诉他们我回来了，甚至还在群里虚晃一枪吐槽北京的天气。开播之后有时往群里传照片，想必他们很好奇为什么我看的进度和他们那么一致XDDDD然后电影结束之后才突然发现右边坐着我，然后我就看到了极其搞笑的一幕三脸懵逼XDDpromare真是燃出了天际，只是我生病一直咳嗽很难进入状态…..打算过段时间就把天元突破也补了。下午回家和弟弟一起打通了塞尔达最后一个神殿。四年了，打塞尔达是每年的定番。每年夏天就会和他坐在一起攻略神殿，然后妈就会一直在旁边吐槽催我弟去学习。明年夏天就该打加农了，嗯…然后晚上去了夜市。如果问我为什么喜欢南方胜过北方，那夜市一定是很重要的答案之一，漫步在灯光辉映的夜晚，走走停停吃吃喝喝，看到喜欢的就去抓取一把，摊贩的老板都很热情，弥散在空气中的香味与鼎沸的人声编织出一个个小小的幸福。这次回家也把《情书》的电影补完了，时隔多年在国内院线上映，然后全场就我一个人…包场了。我读过这部电影的原作小说，还好故事情节记不太清了没被自己剧透，只记得这是一个关于青春与回忆的暖暖的故事。看完之后我想，果然是日本人写的故事，真有日本的风格，暗含着物哀之美。捕获过去的情丝，追忆似水年华，那似有似无、淡淡的、捉摸不透的情愫，就是青春啊。探索回忆，穿越时间的界限，让故事变得圆满，很久的以后，再翻开这一页尘封的记忆，也会不自觉嘴角上扬吧。 只是平凡一天的一些日常咳死我了","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"如果没有光，自己便成为光 ——中科院黄国平博士论文致谢节选","slug":"阅读/中科院黄国平博士论文致谢","date":"2021-04-21T06:14:39.000Z","updated":"2021-04-21T06:21:53.406Z","comments":true,"path":"阅读/中科院黄国平博士论文致谢/","link":"","permalink":"https://aisaka.cloud/%E9%98%85%E8%AF%BB/%E4%B8%AD%E7%A7%91%E9%99%A2%E9%BB%84%E5%9B%BD%E5%B9%B3%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E8%87%B4%E8%B0%A2/","excerpt":"","text":"我走了很远的路，吃了很多的苦，才将这份博士学位论文送到你的面前。二十二载求学路，一路风雨泥泞，许多不容易。如梦一场，仿佛昨天家人才团聚过。 出生在一个小山坳里，母亲在我十二岁时离家。父亲在家的日子不多，即便在我病得不能自己去医院的时候，也仅是留下勉强够治病的钱后又走了。我十七 岁时，他因交通事故离世后，我哭得稀里糊涂，因为再得重病时没有谁来管我了。同年，和我住在一起的婆婆病故，真的无能为力。她照顾我十七年，下葬时却仅是一副薄薄的棺材。另一个家庭成员是老狗小花，为父亲和婆婆守过坟，后因我进城上高中而命不知何时何处所终。如兄长般的计算机启蒙老师■■没能看到我的大学录取通知书，对我照顾有加的师母也在不惑之前匆匆离开人世。每次回去看他们，这一座座坟茔都提示着生命的每一分钟都弥足珍贵。 人情冷暖，生离死别，固然让人痛苦与无奈，而贫穷则可能让人失去希望。家徒四壁，在煤油灯下写作业或者读书都是晚上最开心的力。如果下雨，保留节目就是用竹笋壳塞瓦缝防漏雨。高中之前的主要经济来源是夜里抓黄鳝、周末钓鱼、养小猪崽和出租水牛。那些年里，方圆十公里的水田和小河都被我用脚测量过无数次。被狗和蛇追，半夜落水，因蓄电瓶进水而摸黑逃回家中：学费没交， 黄鳍却被父亲偷卖了，然后买了肉和酒，都是难以避免的事。 人后的苦尚旦还能克服，人前的尊严却无比脆弱。上课的时候，因拖欠学费而经常被老师叫出教室约谈。雨天湿漉着上课，屁股后面说不定还是泥。夏天光着脚走在滚烫的路上。冬天穿着破旧衣服打着寒颤穿过那条长长的过道领作业本。这些都可能成为压垮骆驼的最后一根稻草。如果不是考试后常能从主席台领奖金，顺便能贴一墙奖状满足最后的虚荣心，我可能早已放弃。 身处命运的旋涡，耗尽心力去争取那些可能本就是稀松平常的东西，每次转折都显得那么的身不由己。幸运的是，命运到底还有一丝怜惜。进入高中后,学校免了全部学杂费，■■■一家帮助解决了生活费。进入大学后，计算机终于成了我一生的事业与希望，胃溃疡和胃出血也终与我作别。 我很庆幸保研时选择了自动化所，感谢研究生部的老师们将我从别的部门调剂到模式识别实验室，感谢导师宗成庆老肺选择了我，宗老师将我引入了科学研究的大门，博士这五年无疑是我过去最幸福的时光。惭愧的是，离宗老师的期望显然还有很远的距离，我也知道本可以做得更好。这一段经历已经成为我这一生值得回味的美好瞬间之一。我很喜欢人机交互式机器翻译这个题目，但也仅开 了个头。在未来，希望能有机会弥补这段遗憾。 从家出发坐大巴需要两个半小时才能到县城，一直盼着走出大山。从炬光乡小学、大寅镇中学、仪陇县中学、绵阳市南山中学，到重庆的西南大学，再到中科院自动化所，我也记不清有多少次因为现实的压力而觉得自己快扛不下去了。这一路，信念很简单。把书念下去，然后走出去，不枉活一世。世事难科，未来注定还会面对更为复杂的局面。但因为有了这些点点滴滴，我已经有勇气和耐心面对任何困难和挑战。理想不伟大，只愿年过半百，归来仍是少年，希望还有机会重新认识这个世界，不辜负这一生吃过的苦。最后如果还能做出点让别人生活更美好的事，那这辈子就赚了。 读着读着眼眶就湿润了。","categories":[{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/categories/%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"一个DP题的思路错误分析全过程","slug":"算法与数据结构/一个DP题的思路错误分析全过程","date":"2021-03-05T16:38:43.000Z","updated":"2021-03-05T17:14:58.000Z","comments":true,"path":"算法与数据结构/一个DP题的思路错误分析全过程/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E4%B8%80%E4%B8%AADP%E9%A2%98%E7%9A%84%E6%80%9D%E8%B7%AF%E9%94%99%E8%AF%AF%E5%88%86%E6%9E%90%E5%85%A8%E8%BF%87%E7%A8%8B/","excerpt":"","text":"这题可真是 《最大子矩阵》 给定一个正整数、负整数和 0 组成的 N × M 矩阵，编写代码找出元素总和最大的子矩阵。 返回一个数组 [r1, c1, r2, c2]，其中 r1, c1 分别代表子矩阵左上角的行号和列号，r2, c2 分别代表右下角的行号和列号。若有多个满足条件的子矩阵，返回任意一个均可。 示例： 输入：[ [-1,0], [0,-1]]输出：[0,1,0,1] 1 &lt;= matrix.length, matrix[0].length &lt;= 200 拿到题先开始分析，属于二维区间DP，这个题显然是LMS的升级版 $dp(i,j)$可能由$dp(i-1,j)$和$dp(i,j-1)$状态转移而来 并且存在状态转移中断的可能 所以我们定义$dp(i,j)$表示以$matrix(i,j)$元素为矩阵右下角（即该元素必选）的最大子矩阵 第一次，完全错了： 初步设想状态转移方式为 ①右扩$dp(i-1,j)\\to dp(i,j)$：如果右扩，则新增的并不是$matrix(i,j)$，而是$\\sum matrix(0…i,j)$，若$\\sum matrix(0…i,j)&gt;0$则转移，否则不转移； ②下扩$dp(i,j-1)\\to dp(i,j)$：如果下扩，则新增是$\\sum matrix(i,0…j)$，若$\\sum matrix(i,0…j)&gt;0$则转移，否则不转移。 显然发现这个转移方式有问题： 第二次，然而还是有错： 问题一：没有考虑状态中断。在状态转移中断之后，不是从0开始计算的，而是从上一次中断开始加和，所以需要第三维来记录上一个起点。并且根据题意要求输出坐标，所以也正好需要专门记录。 问题二：和LMS一样容易犯的老错误，状态$dp(i,j)$中$matrix(i,j)$是必选的！不是根据新增元素，以右扩为例，即不是根据$\\sum matrix(0…i,j)$大小来判断是否转移，而是应该判断$dp(i-1,j)&gt;0$才能转移，因为根据必须以$matrix(i,j)$为结尾的$dp(i,j)$定义，只要$dp(i-1,j)&gt;0$，那么加上新增元素无论大还是小都比中断状态转移更大。 所以综合下来，状态转移方程为： ①右扩$dp(i-1,j)\\to dp(i,j)$：如果右扩，若$dp(i-1,j)&gt;0$则转移： dp(i,j)=dp(i-1,j)+\\sum matrix(i_{dp(i-1,j)}...i,j) i_{dp(i,j)}=i_{dp(i-1,j)},j_{dp(i,j)}=j_{dp(i-1,j)}否则不转移： dp(i,j)=matrix(i,j) i_{dp(i,j)}=i,j_{dp(i,j)}=j②下扩$dp(i,j-1)\\to dp(i,j)$：如果下扩，若$dp(i,j-1)&gt;0$则转移： dp(i,j)=dp(i,j-1)+matrix(i,j_{dp(i,j-1)}...j) i_{dp(i,j)}=i_{dp(i,j-1)},j_{dp(i,j)}=j_{dp(i,j-1)}否则不转移： dp(i,j)=matrix(i,j) i_{dp(i,j)}=i,j_{dp(i,j)}=j代码： def getMaxMatrix(self, matrix: List[List[int]]) -> List[int]: #dp[i][j]：以nums[i][j]为最右下角的矩阵的最小值 n = len(matrix) #行 m = len(matrix[0]) #列 dp = [[(0,0,0)]*m for i in range(n)] #(nums,i,j) 分别代表该位值、上一个中断处 #start for i in range(n): for j in range(m): #右拓：dp(i,j)可能由dp(i,j-1)转移 right_rec = float('-inf') if j>0: #边界判断 row_sums = 0 #【关键点】中断之后，不是从0开始计算的，而是从上一次中断开始加和，所以需要第三维来记录上一个起点。同时根据题意，也需要专门记录。 for row_index in range(dp[i][j-1][1],i+1): row_sums += matrix[row_index][j] #若和增大，则可以转移，否则不转移（初始值） # if row_sums>=0: #【错误点】：和LIS问题一样，状态转移公式出错,dp[i][j]中matrix[i][j]是必选的！转不转移是由源状态是否>=0来判断！ if dp[i][j-1][0]>=0: right_rec = dp[i][j-1][0] + row_sums #下拓：dp(i,j)可能由dp(i-1,j)转移 down_rec = float('-inf') if i>0: col_sums = 0 for col_index in range(dp[i-1][j][2],j+1): col_sums += matrix[i][col_index] if dp[i-1][j][0]>=0: down_rec = dp[i-1][j][0] + col_sums #判断从哪个状态转移或未转移 if right_rec==float('-inf') and down_rec==float('-inf'): #错误点，inf少打了个负号...TMD找了半天BUG dp[i][j] = (matrix[i][j],i,j) #未发生转移，转移中断，设置为初始值，即matrix[i][j] else: #转移成功，这里要记录，本次矩阵起点与上一个转移状态起点一致 if right_rec>down_rec: dp[i][j] = (right_rec,dp[i][j-1][1],dp[i][j-1][2]) else: dp[i][j] = (down_rec,dp[i-1][j][1],dp[i-1][j][2]) #在dp矩阵中找值最大的状态 max_rec = float('-inf') startxy = (0,0) endxy = (0,0) for i in range(n): for j in range(m): if dp[i][j][0]>max_rec: max_rec = dp[i][j][0] startxy = (dp[i][j][1],dp[i][j][2]) endxy = (i,j) return [startxy[0],startxy[1],endxy[0],endxy[1]] 然而还是有问题… 举个例子： -1 -2 -9 6 8 -9 -3 -6 2 9 -7 -6 在这个输入中，主要关注左下角四个，其dp矩阵为 8 -1 10 10 这里显然错了！ 按照上面的算法，dp(2,1)只能来源于dp(2,0)或dp(1,1)。dp(1,1)&lt;0直接跳过，dp(2,0)所得矩阵的起点是(2,0)，也就是说是由这两个数组成的矩阵： 8 2 那么在右扩的时候，计算起点只能是这个4个数的方格如下，成为了10+(-9)+9=10： 8 -9 2 9 而正确答案是2+9=11： 2 9 上面的算法没给出这种可能性。所以思路是完全错误了，通过率为50%（悲）。 虽然有错，但是思路是很重要的。 正确答案正确思路是对矩阵进行降维，将二维问题拆解为一维LMS问题。 实际上是一个巧解….. 对于一个$n×m$的矩阵，有$1+2+\\cdots+n$种横向选择方案，我们堆每一种横向选择方案进行列求和，存储进一个$sum[]$数组中，也就是将所有行选法$n×m$降维成了$1×m$，变成了一个一维序列。 然后我们再对每个$sum[]$数组求LMS，求出所有$sum[]$数组最大的那个即可… 不过要注意，由于给出起始与终点位置，所以要记录起始位置，记录方法与上面一样。 eg: -1 -2 -9 6 8 -9 -3 -6 &#x3D;&gt;选第1行 sum[0]&#x3D;[-1,-2,-9,6] &#x3D;&gt;选第2行 sum[1]&#x3D;[8,-9,-3,-6] &#x3D;&gt;选第12行 sum[2]&#x3D;[7,-11,-12,0] 然后分别对sum[0],sum[1],sum[2]用DP求LIS，再选出最大那个即可。 其思想就是利用矩阵特性，即子矩阵中每一行等宽，枚举上下边加和成一维，将行列分开计算，实现降维为一维LMS问题： def getMaxMatrix(self, matrix: List[List[int]]) -> List[int]: n = len(matrix) m = len(matrix[0]) sum_matrix = [] row_info = [] #用于记录sum_matrix每一项对应的加法组合的行的起点和终点 #降维存入sum数组 #【错误点】通过双端指针枚举完所有组合法 for i in range(n): for j in range(i+1,n+1): #错误点：注意这里应该从i+1起始 new = [0]*m for k in range(i,j): for l in range(m): new[l] += matrix[k][l] sum_matrix.append(new) row_info.append((i,j-1)) #对sum中的每一个子串使用LMS求(最大值,起点,终点），记录在LMS_max中 LMS_max = [] for i in range(len(sum_matrix)): nums = sum_matrix[i] dp = [0]*m dp[0] = (nums[0],0,0) for j in range(1,m): if dp[j-1][0]>0: dp[j] = (dp[j-1][0]+nums[j],dp[j-1][1],j) else: dp[j] = (nums[j],j,j) list_res = (float('-inf'),0,0) for k in range(0,m): if dp[k][0]>list_res[0]: list_res = dp[k] LMS_max.append(list_res) #寻找最大那个 max_res = float('-inf') index = -1 for i in range(len(sum_matrix)): if LMS_max[i][0]>max_res: max_res = LMS_max[i][0] index = i return [row_info[index][0],LMS_max[index][1],row_info[index][1],LMS_max[index][2]] 答案是对的，但是部分答案OOT了，这不科学… 反正思路就是这个思路了，时间哪里应该还能优化，下次补充","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"时光盲盒","slug":"Music/时光盲盒","date":"2021-02-12T18:06:40.000Z","updated":"2021-02-12T18:21:47.000Z","comments":true,"path":"Music/时光盲盒/","link":"","permalink":"https://aisaka.cloud/Music/%E6%97%B6%E5%85%89%E7%9B%B2%E7%9B%92/","excerpt":"","text":"等车的人多像盲盒 拆开包装前都不知道结果时光在里面放了什么 别去揣测漫长轨道多像胶片 一格一格就拼成了好多天车轮串起不同情节 驶向起点 褪色的画面重叠 数着还没过完的日子入眠来时的梦已不新鲜 缺点感觉等待太令人疲倦 也不妨尝试着忙里偷个闲在脑海中将明天 先预演 一遍遍我回来了 完成这一章冒险了在座有没有人 有兴趣听我说 一路见过的潮起潮落走下列车 拆开名为我的盲盒有太多的苦与乐 超出我原本记得 拾起这平凡的时间 我渺小的挣扎没有人发现孤独和迷茫一样远 一样蜿蜒将记忆装进行囊 奔向那座等待我的避风港不再伪装 轮到是思念模糊了眼眶 曾经我也潇洒张狂 挥手趾气高扬却不料自己绊倒 在泥沼大声哭嚎然而还是怀着比热爱更热烈的感情向前跑 跌倒了也不会怎样 踹口气也无妨家就在不远的地方 累了就来停靠就算狼狈 也能微笑对自己说 辛苦了可以哭了 可以笑着说结束了丢下所有规则 忘记所有挫折敬自己一杯 因为值得 我还是我 除了长大 没变太多还好没有认输呢 还好还没有褪色 还在爱着辛苦了 “辛苦了”我回来了 可以拥抱着释然了感谢有你在这 陪我唱这首歌也敬你一杯 因为值得 会变好的 明天的事 明天再说跨越过一路坎坷 我们相聚在此刻。 bilibili链接","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[]},{"title":"2021春季追番表","slug":"Anime/2021春季追番表","date":"2021-01-18T10:46:06.000Z","updated":"2021-02-24T14:02:39.000Z","comments":true,"path":"Anime/2021春季追番表/","link":"","permalink":"https://aisaka.cloud/Anime/2021%E6%98%A5%E5%AD%A3%E8%BF%BD%E7%95%AA%E8%A1%A8/","excerpt":"","text":"啥也不说了，牛逼。 上个季度三部原创奶翻了两部（全员成神），怕了，这个季度只敢慎重奶一部原创动画了 由于这个季度基本都很精彩，所以没有等级划分了，列出全追 你永远可以相信续作 ——鲁迅 以下不分先后 半年番寒蝉鸣泣之时 业 咒术回战 续作摇曳露营$\\Delta$第二季 （钦点A霸） 悠哉日常大王nonstop 关于我转生变成史莱姆这档事 第二季 工作细胞！！ 工作细胞Black 五等分的花嫁$\\int\\int$（看情况追） 约定的梦幻岛 第二季【弃】 石纪元 第二季 进击的巨人 最终季 （钦点盘霸） Re0第二季下章 改编无职转生 堀与宫村 碧蓝航线 微速前进！ 弱角友崎同学（看情况追） 岸边露伴一动不动 原创皮蛋物语（钦点B霸） 无限滑板 天竺鼠车车","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"台式机迭代记录","slug":"硬件/台式机迭代记录","date":"2021-01-17T08:25:43.000Z","updated":"2021-03-26T16:42:12.371Z","comments":true,"path":"硬件/台式机迭代记录/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/%E5%8F%B0%E5%BC%8F%E6%9C%BA%E8%BF%AD%E4%BB%A3%E8%AE%B0%E5%BD%95/","excerpt":"主力机 2015 2016 2017 2018 2019 2020 2021 CPU e3 1231 v3 i7 8700k i9 9900k CPU 散热 12cm下压式风冷 280水冷 内存 8G DDR3 1600MHz 16G DDR4 2400MHz 64G DDR4 3600MHz 主板 B85N B360M Z390I 显卡 GTX960 GTX1070 GTX1080Ti RTX2080Ti RTX3090 显卡散热 - 240水冷 280水冷 无 固态硬盘 SATA 120G NVME 250G+SATA 480G NVME 3T+ SATA 2T 机械硬盘 1T 3T + 1T 电源 450w 650w 1250W 显示器 1080P 60Hz SRGB 21inch 4K 60Hz SRGB 27inch 4K 144Hz DCIP3 G-SYNC 27inch 机箱 JONSBO UMX1 PLUS 金河田 N12 酷冷至尊 Q300L NZXT MANTA Be Quiet 500DX 键盘 DUCKY 2108S 青轴 IKBC C87 红轴 NIZ ATOM68 静电容 鼠标 LOGIC G502 G903 G903 HERO G Pro Wireless","text":"主力机 2015 2016 2017 2018 2019 2020 2021 CPU e3 1231 v3 i7 8700k i9 9900k CPU 散热 12cm下压式风冷 280水冷 内存 8G DDR3 1600MHz 16G DDR4 2400MHz 64G DDR4 3600MHz 主板 B85N B360M Z390I 显卡 GTX960 GTX1070 GTX1080Ti RTX2080Ti RTX3090 显卡散热 - 240水冷 280水冷 无 固态硬盘 SATA 120G NVME 250G+SATA 480G NVME 3T+ SATA 2T 机械硬盘 1T 3T + 1T 电源 450w 650w 1250W 显示器 1080P 60Hz SRGB 21inch 4K 60Hz SRGB 27inch 4K 144Hz DCIP3 G-SYNC 27inch 机箱 JONSBO UMX1 PLUS 金河田 N12 酷冷至尊 Q300L NZXT MANTA Be Quiet 500DX 键盘 DUCKY 2108S 青轴 IKBC C87 红轴 NIZ ATOM68 静电容 鼠标 LOGIC G502 G903 G903 HERO G Pro Wireless 副机 2015 2016 2017 2018 2019 2020 2021 CPU i5 9400f CPU 散热 axp90 内存 16G DDR4 2400MHz 主板 B360I 显卡 R9 NANO 显卡散热 - 固态硬盘 SATA 480G NVME 1T + SATA 480G 机械硬盘 - 电源 400w 700w 显示器 1080P 60Hz SRGB 21 inch 4k 60Hz SRGB 24inch 机箱 Q300L K39","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[]},{"title":"Merry Christmas|龙与虎第八周目","slug":"日记/龙与虎第八周目","date":"2020-12-25T10:03:30.000Z","updated":"2021-01-18T07:21:39.000Z","comments":true,"path":"日记/龙与虎第八周目/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E9%BE%99%E4%B8%8E%E8%99%8E%E7%AC%AC%E5%85%AB%E5%91%A8%E7%9B%AE/","excerpt":"Merry Christmas","text":"Merry Christmas 世界上有任何人都没有见过的东西它很温柔 非常甜美大概 如果可以看见的话谁都会想要的吧正因为如此才会谁也没有见过它为了让人无法那么轻易地得到世界才把它藏了起来但是总有一天会有人找到应该得到的那个唯一的人一定能把它找出来。 爱情、亲情、友情、集体、成长，这部番包含了青春的全部主题，永远是我心中的校园top1。 第八遍温习，今年又发现了一些细节，以及又被感动了一次。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"记艰难的玩2077之路","slug":"日记/记艰难的玩2077之路","date":"2020-12-13T01:47:55.000Z","updated":"2021-01-18T05:46:19.000Z","comments":true,"path":"日记/记艰难的玩2077之路/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E8%AE%B0%E8%89%B0%E9%9A%BE%E7%9A%84%E7%8E%A92077%E4%B9%8B%E8%B7%AF/","excerpt":"早上遇到奇葩硬件BUG，晚上遇到奇葩软件BUG，我真是天选之子","text":"早上遇到奇葩硬件BUG，晚上遇到奇葩软件BUG，我真是天选之子 赶在2077发售前一天晚上，把对马岛之魂给白金了 然后第二天早上兴奋地打开电脑准备一第一时间打开赛博朋克2077 早上遇到硬件BUG：CPU差点挂了然后在我捏了接近20分钟脸之后，电脑突然就死机了.. 而且再也没法打开，无限重启。 我发现甚至没过开机自检，按照我的经验初步怀疑是内存出问题了，要么是内存松动了要么是内存挂了 然后我把两根内存拔下来/换着插试了一下，惊奇地发现并不是内存的问题，因为只有左通道无法使用 然后经过群友提醒我发现事情可能超出我的想象… 这种情况就更可能是因为瞬时电压过高导致内存控制器被烧毁，而内存控制器现在都是集成在CPU里的，那么意思是我的9900k…. 当时我的内心：？？？？？？？？？ 后来又想到有一种可能，那就是CPU的针脚接触不良 抱着仅有的一线希望，把CPU拆下来借室友的绝缘胶好好擦了一下，装回去发现竟然可以开机了！ 简直是把我吓坏了，最后结论是问题出自CPU针脚接触不良以致内存控制器失灵导致左内存通道故障。 可能这就是天选之子吧。 晚上遇到软件BUG：《BugPunk2077》然后下午我可算是能正式玩赛博朋克2077了 然后更神奇的事情发生了，我在这游戏里遇到了一个史诗级的bug… 我遇到有一章屏幕全是黑的，应该是游戏光源bug。但是我还以为是意识流表现手法（关键是在这里，屏幕全黑很符合这一章的剧情设定），于是我就真的这样打完了一整章（凌晨12点，寝室灯都熄了，我对着黑屏玩了1个小时） 黑屏如下： 然后早上起床，我正准备高兴地给同学分享昨天那章设计得有多么独特的时候，同学告诉我说，这是BUG 我：？？？？？？？？？？？ 这BUG可太赛博朋克了，BUG到我以为这是游戏设定，因为那一章的设定就是主角身体受到了损坏在反复挣扎，我以为他的义眼坏了。 大爷突然想到一个梗，鲁迅写的那句，“我家门前门前有两棵树，一棵是枣树，另一棵也是枣树” 这话鲁迅出自笔下，那就得是阅读理解，得分析用意 这话要是我写作文的时候写上去，直接能给我不及格…. 最后还是升级了3090赛博朋克2077这游戏的光追效果确实做得很不错，可以说正确的光追是非常重要的，有些东西应该加强光追效果，而有的东西应该舍去。 但是2080Ti在4k下把光追开到变态下还是比较吃力，室外场景只有25~30帧，室内场景30~40帧 所以最终还是决定买了3090，目前还没到货，期待一下效果吧！ 最后发一张我的游戏截图：","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"2020秋季追番表","slug":"Anime/2020秋季追番表","date":"2020-10-16T02:16:42.000Z","updated":"2021-01-18T07:32:21.000Z","comments":true,"path":"Anime/2020秋季追番表/","link":"","permalink":"https://aisaka.cloud/Anime/2020%E7%A7%8B%E5%AD%A3%E8%BF%BD%E7%95%AA%E8%A1%A8/","excerpt":"Record","text":"Record 京紫三年·秋这个季度的新番可真牛逼，感谢京紫，感谢那个伟大的时代，好起来了 【0】 突击莉莉 魔女之旅 成神之日【B霸候选】 全员恶玉【B霸候选】 请问您今天要来点兔子吗？BLOOM 咒术回战【B霸候选】 进击的巨人最终季【网盘霸权】 安达与岛村 寒蝉鸣泣之时 【1】 总之就是非常可爱 在魔王城说晚安 【泡面】 one room 【排雷中】 试着用土下座来拜托她们吧 前说！ 龙与魔女 忧国的莫里亚蒂 被神捡到的男人 1224更新奶了三个B霸，翻车了两个，还有一个（成神之日）喜提本季最烂，咒术回战也只是打戏好其它地方并不出彩 本季度最喜欢的是魔女之旅和巨人 突击莉莉和点兔没看下去","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"Docker原理&多阶段构建","slug":"网络与云/Docker原理多阶段构建COPY","date":"2020-08-10T16:12:32.000Z","updated":"2021-01-18T07:24:46.000Z","comments":true,"path":"网络与云/Docker原理多阶段构建COPY/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/Docker%E5%8E%9F%E7%90%86%E5%A4%9A%E9%98%B6%E6%AE%B5%E6%9E%84%E5%BB%BACOPY/","excerpt":"大致原理","text":"大致原理 Dockerfile 中的 COPY 与 ADD 命令的区别 COPY和ADD功能差不多，但COPY支持多阶段构建，ADD支持解压缩 注意这俩复制的时候都是默认复制目录下的所有文件 FROM…AS…：docker 多阶段构建可以解决编译和构建复杂的问题，减小镜像大小。 重点在于使用COPY指令的 -FROM参数，最终生成的还是一个镜像，但是通过COPY语句使用了上一个构建中的文件。 但除此之外，还有更重要的： COPY FROM不仅可以从前置构建阶段的镜像中拷贝文件，还可以从一个已经存在的镜像中远程拷贝。 这样就相当于FROM了多个base镜像（但并不是，是拷贝了该镜像里的文件） 栗子： COPY -from&#x3D;hub&#x2F;image_sample file_path_in_image_sample target_path_of_this_image 这样就把远程镜像的hub/image_sample的路径为file_path_in_image_sample的文件给拷贝到了本镜像的target_path_of_this_image路径 FROM golang:1.7.3 as builder WORKDIR &#x2F;go&#x2F;src&#x2F;github.com&#x2F;alexellis&#x2F;href-counter&#x2F; RUN go get -d -v golang.org&#x2F;x&#x2F;net&#x2F;html COPY app.go . RUN CGO_ENABLED&#x3D;0 GOOS&#x3D;linux go build -a -installsuffix cgo -o app . FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR &#x2F;root&#x2F; COPY --from&#x3D;builder &#x2F;go&#x2F;src&#x2F;github.com&#x2F;alexellis&#x2F;href-counter&#x2F;app . #注意这里COPY的from，就是从builder构建中继续执行 CMD [&quot;.&#x2F;app&quot;] docker原理：https://zhuanlan.zhihu.com/p/51836305 ①docker就是个应用程序，运行在用户空间，一个容器就是一个用户进程，通过调用系统接口实现功能，直接跑在内核上 对于linux宿主 ，docker直接使用宿主内核；对于mac/win，docker使用自带的linux内核 虚拟机完整虚拟了内核和用户空间；而 docker 仅仅虚拟了用户空间，不同容器使用了共用的内核，那么 docker 必然更轻量、更快 ②docker的资源隔离依靠namespace：https://zhuanlan.zhihu.com/p/67021108 在不同容器中看不到宿主、其它容器的进程、文件等，做到了隔离（用户级隔离），是通过linux内核的Namespace和Cgroups特性实现的 Namespace用于隔离不同容器的资源，Cgroups用于不同容器的资源使用限制 Namespace有六种：Mount、IPC、PID、Network、User，每个容器不同的资源都对应各自种类的namespace，只有namespace相同的（认定为同一容器）的才能访问该namespace下的资源。 （于是你甚至可以在容器启动的时候，指定这些参数，从而强制容器运行在特定namespace之中。例如，你可以指定 —pid host，从而让容器进程使用宿主机进程空间，此时容器可以看到host上所有的进程。见下） docker run中namespace相关参数 --ipc string IPC namespace to use --pid string PID namespace to use --userns string User namespace to use --uts string UTS namespace to use cgroups 的全称是control groups，是Linux内核提供的一种可以限制单个进程或者多个进程所使用资源的机制，可以对 cpu，内存等资源实现精细化的控制。 ③docker镜像是分层的：https://zhuanlan.zhihu.com/p/70424048 Docker镜像是分层构建的，Dockerfile 中每条指令都会新建一层。 （所以就会有加速docker镜像构建小优化：在使用 COPY 和 ADD 命令时，我们可以通过一些技巧来加速镜像的 build 过程。比如把那些最不容易发生变化的文件的拷贝操作放在较低的镜像层中，这样在重新 build 镜像时就会使用前面 build 产生的缓存） Dockerfile中构建镜像的每层都是只读层，当启动一个容器，Docker 会在最顶部添加读写层，你在容器内做的所有更改，如写日志、修改、删除文件等，都保存到了读写层内，一般称该层为容器层。也就是说，容器（container）和镜像（image）的最主要区别就是容器加上了顶层的读写层，使用Copy-On-Write 策略（基于联合挂载技术，这需要联合文件系统unionFS支持，如linux内核自带的overlay，AUFS等）。显然容器的任何修改都不会影响镜像，容器被删除，那该容器的读写层也就被删除了。 docker ps -s，可以看到最后有两列size和virtual size。其中 size就是容器读写层占用的磁盘空间，而 virtual size 就是读写层加上对应只读层所占用的磁盘空间 docker容器挺好玩的，以后有时间看看源码鼓捣一下！","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"洛神云","slug":"网络与云/洛神云","date":"2020-07-02T14:40:55.000Z","updated":"2021-01-18T07:27:02.000Z","comments":true,"path":"网络与云/洛神云/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E6%B4%9B%E7%A5%9E%E4%BA%91/","excerpt":"阿里云飞天洛神","text":"阿里云飞天洛神 飞天主要组件：洛神、盘古、伏羲、天基等等 洛神大二层网络到应用层网络的虚拟ecs，slb，rds，oss，avs等就是就是应用层的业务网元（网元产品）；物理交换机，nfv，物理机，vm等就是基础网元，是物理网络中的真实网元 业务网元对用户向下屏蔽物理网络和组成物理网络的基础网元，用户只感知到这些业务网元（基础设置服务，iaas），不需要关注物理网络细节。iaas做的就是如何向下屏蔽物理网络，向上对用户提供网元产品（并给用户API来使用这些网元产品，应用层通过使用这些网元产品相互连接即构成一个应用层虚拟网络，比如用户可以自己在vpc里用avs连接几个slb，slb后面挂几个ecs集群作为rs） 这些网元通过物理网络具体实现过程虚拟化的过程。具体地，底层是个大二层物理网络（而这个大二层物理网络实际上over在一个真实物理网络之上的）+SDN控制转发，对用户将下面这一切屏蔽掉，表现为不同的网元产品。 至于SDN，是我们具体实现如何向上提供API，向下屏蔽物理网络的一种网络设计方法，将控制与转发分离，来向下集中控制转发行为，向上提供API，打通虚拟网络和物理网络（但大二层实际也是个虚拟网络，但是接触物理机的）。 具体地，SDN的控制与转发具体操作： 控制组根据北向API监听，获取用户需求，再使用netconf南向API，进行配置下发 转发组参照Controller下发的配置，进行TCP/UDP通信，实现转发逻辑 而真实物理网络中，有直接的物理设备集群，也有NFV网元（再一层抽象！物理机器网元和NFV网元是基础网元，SLB ECS等网元是业务网元，基础网元和业务网元不是一个层面的东西！） 然后转发设备也就是物理设备（或NFV）才有装DPDK这些东西，是与硬件紧密结合的，加速转发 （飞天的SDN是自己定义的netcof，并没有用openflow协议进行流表下发） 真实物理网络到大二层网络的虚拟上层转发的物理主机/NFV之间的大二层通信网络实际上是个虚拟网络 实际上这下面还有一层，首先硬件由AIS（alibaba infrastructure service）负责，他们负责机房的物理搭建，线缆的连接； 然后使用VxLAN网关等物理设备，基于VxLAN隧道技术，将整个DC（Data Center）网络全部打通成一个大二层局域网（给上层提供一个overlay网络，比如上层转发设备想要建立北京的ECS-A到东京的ECS-B的通信，那么对于上层的转发层来说他们在一个大二层，可以直接内网IP寻址过去；但实际上DC网是隔离了广播域的，实际是使用VxLAN技术来联通的，可以理解为最底层的物理层网络向上提供了API，形成大二层） 这一层虚拟也是基于SDN架构的，也有控制与转发，转发设备就各个物理转发设备 具体地解释（为啥要有大二层这层虚拟）整个数据中心的所有主机，全都是在一个大局域网内的！（跨Region的DC（数据中心）之间通过比较复杂的广域网协议连接，一个Region底下有多个AZ） 但为了DC的复杂的管理结构，我们要使广播域隔离（将原来的大局域网分隔成多个具有横纵层级的广播域，以避免广播风暴）。（一个交换机隔离一个广播域）。广播域隔离之后，就无法跨广播域通信了，所以我们才要打隧道，使得主机可以跨广播域通信，形成一个虚拟的“大二层”。使用VxLAN网关可以支持隧道协议，这样我们既能享受广播隔离的好处（防广播风暴），也能做到跨广播域的灵活通信。（VxLAN网关实际上就是路由器，隧道协议本质就是MAC over IP，通过VxLAN路由器进行寻路过去的，看起来像是点到点隧道一样）【这里具体物理实现了解不多，需要更深入查阅】 想象一下，原来的复杂的数据网，在隧道技术下，变成了一个扁平式的大二层网络，这个大二层网络每一个节点就是一个VxLAN网关，挂载一个广播域！ 【那么，我就可以直接通过目的主机的内网IP地址，进行隧道传输，好像就在一个二层局域网内】 那么上层就可以直接在这个大二层上，用内网IP进行一切主机间通信 对于用户来说，屏蔽了物理主机，他们只看得见网元产品。但是对于网元产品研发来说，物理主机是可见的（但实际的真实网络不可见，我们看见的是大二层虚拟网络）。公有云数据网的内网IP对应一台唯一物理主机/NFV，我们也要负责管理。第一层虚拟化虚拟化的是通信承载网络，将跨广播域的通信网络虚拟成了一个大二层。 每台主机发出的包，在广播域出入口都有一个VxLAN网关，它进行VxLAN头的解析与封装进行传输，所有跨广播域的机器/NFV之间的交流就会通过VxLAN协议。同一个网关内的主机就不会走VxLAN协议。在跨广播域的时候（注意，一切都是在大数据中心局域网内！没有去公网！）路由器会把包带到目的网络的虚拟交换机，VxLAN网关通过拆UDP头解析VxLAN的IP，发现这个IP就是我自己，然后取出MAC地址，再在这个广播域内进行广播 显然整个数据中心网络公有云所有机器的内网IP（CIDR）是不能重叠的，不然就没法跨广播域通信了。 VxLAN，里面是内网MAC，外面是内网IP（CIDR） （其实教育网也是这样！（所以我在实验室部署NAS才不可能在寝室访问到，广播隔离了）） 但是VPC就不一样了，由于VPC内部不可访问，那么不同VPC的CIDR地址是可以重叠的！ 但是VPC与VPC互联的时候，CIDR地址就不能重叠了。所以出现了private link技术，特点就是CIDR地址重叠的VPC之间可以互相访问 继续阅读： http://blog.sina.cn/dpool/blog/s/blog_69c81c3e0102x96d.html https://blog.csdn.net/qq_42248536/article/details/88869263（环路问题） VPC一方面是为了灵活（地址可重复、也使得可用地址数量更多、且无缝迁移）、另一方面是拉通一个大二层网络不安全，所以诞生了VPC VPC的内部二层网络实际上也类似于VxLAN的随道技术，进行了二层包的封装 那为什么我一个公网SLB，要设计成（当然我知道实际上VPC本身就类似于隧道的封装，所以能做到理所应当）能够直接将VPC里的rs挂上去，不是完全逻辑隔离了吗——设计理念：SLB替代NAT作为公网入口，所以才这么设计！然后VPC实际上不是真独立的，虽然逻辑隔离，但是SLB/NAT这里是可以做到访问VPC的（应该底层实现更复杂） 总结注意一个问题，应用层的用户是无法接触到物理机的，而下面两层都会接触到物理机，最后一层都大二层的虚拟是将网络结构虚拟了。 三层虚拟： 真实网络-&gt;大二层网络-&gt;应用层网络（网元产品）；后者over在前者之上，每一层都是基于SDN实现 此即洛神，洛神即阿里云网络，两层虚拟都属于洛神网络平台；最底下的物理裸机、线缆、真实网络属于网络的基础设施，由AIS负责 阿里云网络主要由三个层面组成: 底层的物理层及其SDN控制器, Overlay网络层及其SDN控制器, 以及应用层。 其中每个层面都由更细节的模块组成。阿里云的物理层网络是世界上最大的SDN网络之一, 可以细分为DC 网络, 阿里城域网, 阿里骨干网等组件, 物理层的控制器负责管理物理层网络, 并向Overlay层提供 API, 屏蔽各种物理网络的细节, 在本文中不会对物理网络展开描述; Overlay 网络层则由网关(Gateway), 阿里虚拟交换机(AVS: Alibaba Virtual Switch), 负载均衡器(SLB: Server Load Balance)等本层数据面的网络组件, Overlay 网络层的控制平面以及 Overlay 网络层的管理平面组成。 Overlay 网络层控制器负责管理各个网络组件, 向应用层的产品和服务提供统一的API, 并调用物理层的控制器完成网络功能; 应用层则主要是阿里云网络的各大主要产品如CEN和资源管理调度系统(例如伏羲), 它们通过调用Overlay控制器的北向接口实现了阿里云网络的使用和调度. 摘自阿里巴巴云栖社区","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"docker","slug":"网络与云/docker","date":"2020-07-01T14:35:07.000Z","updated":"2021-01-18T07:24:36.000Z","comments":true,"path":"网络与云/docker/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/docker/","excerpt":"云技术中常用到docker，那就归类到这里8","text":"云技术中常用到docker，那就归类到这里8 docker的使用docker三大概念：镜像（Image）、容器（Container）和仓库（Repository） Registry是注册机构，可以管理多个仓库，参考：docker镜像的commit与push dockerfile是制作镜像的脚本，其描述了镜像如何制作和镜像的参数（重要），详细见：DockerFile与镜像(Image)仓库 镜像是冷的文件，镜像可以从仓库里拉取，也可以推送到仓库；可以由dockerfile创建，也可以由容器创建 启动镜像就会为其创建一个容器，容器有运行、暂停、停止三个状态 docker端口和宿主端口要对应，可以指定多个端口映射；目录也可以指定与宿主的映射 docker命令大全： 详细说明： P.S. docker镜像的命名一般是&lt;name:tag&gt;，不写tag则默认tag是latest # ====从远程仓库拉取镜像到本地==== docker pull &lt;name> # 如何设置默认仓库见https://www.cnblogs.com/silva/p/11505925.html # 可以创建自己的仓库服务，以阿里云为例，见 阿里云-容器镜像服务 说明 # 可以指定从哪个registry的哪个仓库拉取，比如registry是myregistry.local:1234，仓库是aisaka-test，想要拉取test-image： docker pull myregistry.local:1234/aisaka-test/test-image # 在仓库搜索镜像 docker search # ====推送容器镜像到远程镜像仓库==== docker push &lt;name> # 同pull一样也可以push到指定仓库 docker push myregistry.local:1234/aisaka-test/test-image # ====查看本地镜像==== docker images # 删除本地镜像 docker rmi &lt;name> # ====从容器生成镜像==== docker commit -a \"aisaka\" -m \"test\" nextcloud nextcloud:v1 # -a :提交的镜像作者； # -c :使用Dockerfile指令来创建镜像； # -m :提交时的说明文字； # -p :在commit时，将容器暂停。 # nextcloud:v1是我给生成镜像取的名字，:后面跟着的是TAG，用于标识版本 # ====用dockerfile生成镜像==== docker build # 见https://www.runoob.com/docker/docker-build-command.html # ====镜像创建容器==== docker create &lt;name> # 与run的区别在于，create创建的容器是stop状态，而run是running状态 # ====【运行容器镜像】==== docker run -d -p 3306:3306 -v /mnt/sde/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=WZS134125 --name mysql mysql # -d 后台守护进程方式运行（启动后进入后台） # -p 端口映射，宿主端口：容器端口【重要】 # -v 目录挂载，宿主目录：容器目录【重要】 # -e 设置变量 # --name 设置容器名称【别忘了】 # 最后一个 即为要运行的镜像名 # 【多端口，多目录映射】-p和-v参数都可以有多个，即可以指定多个端口和目录映射 # ====容器的暂停、终止==== # 容器终止 docker stop &lt;name> # 启动已终止运行的容器 docker start &lt;name> # 清理掉所有处于终止状态的容器 docker container prune # 暂停容器 docker pause &lt;name> # 继续已暂停的容器 docker unpause &lt;name> # 重启容器 docker restart &lt;name> # ====删除容器==== docker rm -f &lt;name> # 删除容器不是删除镜像 # -f可以删除未终止的容器；安全的操作是先终止再删除，-f可以省事 docker rm -v # -v 会同时删除该容器挂载的volume（且没有其它容器连接到该Volume，否则不会删除） # ====进入容器==== docker exec -it mysql /bin/bash #-it 分配一个虚拟终端，进入该容器命令行界面 # /bin/bash 放在镜像名后的是命令，这里我们希望使用/bin/bash。 # ====容器与宿主复制==== docker cp &lt;宿主文件地址> &lt;name>:&lt;容器文件地址> # ====查看容器状态==== docker ps # ====镜像打包相关==== # 将镜像打包成tar（打包就是压缩，格式为tar） docker save -o myImages.tar myImages #-o 指定打包后的名字 # 导入tar打包的镜像（导入到本地镜像仓库） docker load &lt; myImages.tar # 生成容器快照：容器直接打包成tar镜像（相当于commit+save） docker export &lt;name> > myDockerImage.tar # 导入容器快照：将打包的tar镜像直接生成容器（相当于load+run） docker import # 使用见：https://www.simapple.com/327.html # 给镜像打tag docker tag pull、push、run，commit，images，ps，rmi，rm，cp，build等都是很常用的命令 dockerfile是个文本文件，记录了一个镜像的制作过程。执行docker build即可制作镜像，详见dockerfile 而docker commit是将容器直接制作成镜像 dockerfile主要目的是将镜像制作细节展示出来，比commit直接给你个黑盒更易用，更容易看懂这个镜像到底是干嘛的 docker-compose用于容器的编排 多个docker之间要相互合作，比如nginx、mysql、nextcloud每个组件都在一个容器里，那我就需要docker-compose。将项目需要哪些镜像，每个镜像怎么配置，要挂载哪些volume等等信息都写在docker-compose.yml里来实现容器的协同工作 dockerfile记录了单个镜像的构建过程，而docker-compose.yml记录了一个项目（多个镜像）的构建过程 容器快照import和打包load的区别 容器快照将会丢弃所有的历史记录和元数据信息，而镜像存储文件将保存完整记录，体积也会更大。 是将宿主端口映射到容器端口，将宿主目录/volume挂载到容器目录（容器目录是挂载点，宿主目录/容器是被挂载卷），所以run的-v和-p参数都是宿主在前，容器在后 docker数据持久化bind mount在使用run语句进行目录挂载的时候，docker run的时候指定-v 参数 bind mount方式：-v 目录挂载，宿主目录：容器目录 bind mount方式简单明了，就是直接将宿主目录挂载到指定容器目录上 但问题在于这样就在不同的宿主机系统时不可移植，且必须指定全路径，不能在dockerfile里写 volumevolume方式（建议）：-v 目录挂载，volume名：容器目录 先在宿主新建一个volume，然后再将volume挂载到指定容器内的挂载点上。容器目录是不会变的，迁移的时候新建volume直接指定名字即可，所以也不需要改变。 volume是被docker管理的，docker下所有的volume都在host机器上的指定目录下/var/lib/docker/volumes 最常用的就是volume方式 # 新建一个volume docker volume create my-volume # 挂载 docker run -v my-volume:/var/lib/mysql mysql # （省略掉了其它参数） 如果不指定volume的话，也会挂载到该目录，不过名字是随机生成的一串id docker run -v /var/lib/mysql mysql # 未指定volume，自动生成了 使用dockerfile的话，直接写VOLUME项的挂载点即可 VOLUME &#x2F;var&#x2F;lib&#x2F;mysql 但是，通过 dockerfile的VOLUME 指令创建的挂载点，是自动生成的默认容器名字（和前面一样）！ docker的volume也有一套管理工具 docker volume create &lt;volume name> docker volume inspect &lt;volume name> #查看指定容器详细信息 docker volume ls docker volume rm docker volume prune #删掉本地所有未使用的容器 # 删除容器的时候同时删除挂载的volume（前提是没有其它容器连接到该Volume，否则不会删除） docker rm -v 关于volume的迁移：Docker数据卷Volume的备份，迁移，恢复 docker-compose也可以设置volume，且可以指定volume挂载目录！结合后面一节docker-compose看 建议首选在docker-compose中配置volume（最方便、明了）（等其它参数），而不是在dockerfile中 version: '2' # 表示该 Docker-Compose 文件使用的是 Version 2 file services: docker-demo: # 指定服务名称 build: . # 指定 Dockerfile 所在路径 ports: # 指定端口映射 - \"9000:8761\" volumes: - &lt;宿主目录volumes地址>:&lt;容器挂载目录> #使用具体路径直接挂载到本地 - &lt;volumes名>:&lt;容器挂载目录> #直接使用volumes名，但不能设置volumes目录，自动挂载在/var/lib/docker/volumes目录 生命周期容器中未被宿主目录挂载的目录和里面的数据，将被储存在容器里，随容器删除而删除 所以要想将数据和容器隔离，必须用前面的方式做数据持久化，只有被挂载的数据会被持久化 P.S.1 容器目录不可以为相对路径 P.S.2 显然，两种方法都可以做到容器之间共享数据（宿主目录or volume可挂载到多个容器的挂载点上） dockerfile参考：Dockerfile 详解，看这一篇就够了 常用命令：FROM（基础镜像）、MAINTAINER（作者信息）、RUN（执行命令）、EXPOSE（容器内打开的端口，运行镜像的时候还需要指定这些端口到宿主的映射）、CMD（默认命令）、ENTRYPOINT、ADD、COPY（将文件或目录从宿主复制到Dockerfile构建的镜像中）、VOLUME（向容器添加卷，可以提供共享存储等功能）、WORKDIR（容器内部设置工作目录）、ENV（设置环境变量，运行容器的时候可以指定env参数）、USER（什么用户运行镜像）、ONBUILD（镜像创建触发器，当一个镜像被用作其他镜像的基础镜像时，这个触发器会被执行） 通过ADD、COPY、RUN就可以将自己写的代码如jar包war包放进去跑，或者数据库表文件什么的放进去，总之有这些参数就可以生成自己想要的镜像了 Dockerfile的构建过程： docker会从Dockerfile文件头FROM指定的基础镜像运行一个容器 然后执行一条指令，对容器修改 接着执行类似docker commit的操作，创建新的镜像层 在基于刚创建的镜像运行一个新的容器 执行Dockerfile下一条指令，直到所有指令执行完毕 docker会删除中间层创建的容器，但不会删除中间层镜像，所以可以使用docker run运行一个中间层容器，从而查看每一步构建后的镜像状态，这样就可以进行调试。 P.S. docker CMD 和 ENTRYPOINT 区别 docker原理docker是一种容器技术。 容器运行在OS内核之上 Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 操作系统（OS）是管理计算机硬件、软件资源，并为计算机程序提供通用服务的系统软件。而管理硬件、软件资源，都是由内核实现的。docker镜像是不含内核的，容器与宿主机共享内核。docker镜像只包含一部分提供通用服务的用户态（userland），如各种lib、系统应用，还有一部分服务由内核提供。 操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。现在引入容器之后：我们开机的时候，linux内核会先启动，然后挂载root文件系统作为用户空间；而Docker镜像就相当于是一个root文件系统，每开一个就有了一个独立的用户空间。 容器是运行在操作系统内核之上的，容器对进程进行了封装隔离，属于不同容器之间是进程级隔离，不同容器之间OS内核是共用的。 VM和容器而VM是OS级别的隔离，不同的VM有自己的OS内核，只有硬件共用，软件完全隔离开。 不同的docker进程不能映射到同一个端口，而VM可以（端口指的是我们访问主机（OS内核）上的某一进程的标识号，而docker是进程级隔离，并没有达到OS级隔离，所以不同容器不能映射同一端口；而VM是OS级隔离的，所以可以映射到同一端口）因为docker的隔离程度没有VM高 容器相比VM非常轻量，快。 容器和镜像镜像是静态的，容器是动态的。 docker镜像是分层存储的，最开始要指定一个基础镜像，我们每做一次修改就会在原本的镜像存储层上多搭一层，记录这个更改；而新搭的这层是静态、且可以持久化存储的。docker镜像的每一层都可以被不同镜像共同使用，如果某几层镜像本地已经有了，再去pull的时候就不会再拉已经有的镜像层了 容器也是相同的存储架构，但是每次修改新搭的一层是动态的，而且并不是持久化存储的；当容器被删除，或者重启计算机（内存断电）之后，容器没了，相应的这些容器存储层也没了。所以我们在容器上进行了修改，想要保存下来这个修改的话必须commit成静态的镜像。（或者用volume，链接到宿主） docker-compose多个docker之间要相互合作，比如nginx、mysql、nextcloud每个组件都在一个容器里，那我就需要docker-compose。将项目需要哪些镜像，每个镜像怎么配置，要挂载哪些volume等等信息都写在docker-compose.yml里来实现容器的协同工作 阅读参考（这个写得很详细了，具体配置和指令见此文）：Docker：Docker Compose 详解 在docker-compose中会指定多个dockerfile，且会指定该dockerfile生成的镜像的端口容器端口：宿主端口的映射（注意勿忘了必须在dockerfile里配置要暴露的端口） # 在 docker-compose.yml 所在路径下执行该命令 Compose 就会自动构建镜像并使用镜像启动容器 docker-compose up -d docker-compose ps docker-compose logs docker-compose build docker-compose start docker-compose stop docker-compose rm docker-compose up docker-compose kill docker-compose run docker-compose scale 模板（参数可选）： version: '2' # 表示该 Docker-Compose 文件使用的是 Version 2 file services: server-docker-name1: # 指定服务名称 build: . # 指定 Dockerfile 所在路径，如果没写下面三个子项就可以只写这里 context: ./dir dockerfile: Dockerfile #对象 args: image: #指定镜像 ports: # 指定端口映射 &lt;宿主>:&lt;容器> volumes: #设置volumes dns: dns_search: environment: #环境变量 env_file: #环境变量文件 expose: #暴露端口，只将端口暴露给连接的服务，而不暴露给主机 network_mode: #设置网络模式 links: #将指定容器连接到当前连接，可以设置别名，避免ip方式导致的容器重启动态改变的无法连接情况 volumes: #卷挂载目录 logs: #日志输出信息 server-docker-name2: # xxxxxx 和前面一样 SOA和微服务SOASOA=Service Oriented Architecture，面向服务的架构 SOA是一种设计方法，其包含多个服务，而服务之间通过相互依赖配合最终会提供一系列功能。一个服务通常以独立的形式存在于操作系统进程中。服务之间通过网络调用，而非采用进程内调用的方式进行通信。 显然SOA通过REST RPC等手段进行的“调用”，比依赖注入还更解耦，进一步降低了服务耦合 如何通俗易懂地解释什么是SOA？ - 光太狼的回答 - 知乎 https://www.zhihu.com/question/42061683/answer/251131634 ESB（企业服务总线）是SOA里的概念，简单来说 ESB 就是一根管道，用来连接各个服务节点。为了集成不同系统，不同协议的服务，ESB 做了消息的转化解释和路由工作，让不同的服务互联互通 微服务随后SOA演变出一种微服务架构。微服务要求“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。 容器技术大大帮助了微服务，因为容器就是可以独立开发、设计、运行，不依赖其它东西的小单元 而在微服务中替代SOA中ESB的就是API网关了，向外暴露出API接口 微服务是SOA的子集，一种实现方式 Java EE部署架构，通过展现层打包WARs，业务层划分到JARs最后部署为EAR一个大包， 而微服务则打开了这个黑盒子，把应用拆分成为一个一个的单个服务，应用Docker技术，不依赖任何服务器和数据模型，是一个全栈应用，可以通过自动化方式独立部署，每个服务运行在自己的进程中，通过轻量的通讯机制联系，经常是基于HTTP资源API，这些服务基于业务能力构建，能实现集中化管理参考：https://zhuanlan.zhihu.com/p/88095798 敏捷开发&amp;Scrum&amp;CICD&amp;DevOps敏捷开发&amp;ScrumScrum是一种敏捷的开发过程框架：敏捷，即强调加快交付速度，变革的持续性。 持续——随时可运行。 CI&amp;CDCI（持续集成，Continuous Integration）：在源代码变更后自动检测、拉取、构建和（在大多数情况下）进行单元测试的过程。四大特点：频繁发布，自动化流程，可重复，快速迭代。 自动化流程：关键是用自动化流程来处理软件生产中的方方面面。这包括构建、测试、分析、版本控制，以及在某些情况下的部署。 频繁发布：如果我们把某个历史版本的代码作为输入，我们应该得到对应相同的可交付产出。 单元测试：由开发人员编写的小型的专项测试，以确保新代码独立工作。“独立”这里意味着不依赖或调用其它不可直接访问的代码，也不依赖外部数据源或其它模块。 由于这与持续集成工作流有关，因此开发人员在本地工作环境中编写或更新代码，并通单元测试来确保新开发的功能或方法正确。通常，这些测试采用断言形式，即函数或方法的给定输入集产生给定的输出集。它们通常进行测试以确保正确标记和处理出错条件。有很多单元测试框架都很有用，例如用于 Java 开发的 JUnit。 CD（持续交付，Continuous Delivery）：通常是指整个流程链（管道），它自动监测源代码变更并通过构建、测试、打包和相关操作运行它们以生成可部署的版本，基本上没有任何人为干预。 持续交付管道：将源代码转换为可发布产品的多个不同的 任务(task)和 作业(job)通常串联成一个软件“管道”，一个自动流程成功完成后会启动管道中的下一个流程。 监测程序通常是像 Jenkins、CodePipeline（阿里云）这样的应用程序，它还协调管道中运行的所有（或大多数）进程，监视变更是其功能之一。监测程序可以以几种不同方式监测变更。这些包括轮询（监测程序反复询问代码管理系统）、定期、推送 详细参考：什么是持续集成（CI）/持续部署（CD）？ 想象一个多条流水线的工厂来理解，所有流水线连接在一个机器人上，不同流水线对应机器人身上不同的组件，各个组件持续集成，持续交付。 DevOps运维开发(DevOps) 是关于如何使开发和运维团队更容易合作开发和发布软件的一系列想法和推荐的实践。 持续交付管道是几个 DevOps 理念的实现。 三者关系敏捷专注于在加速交付的同时突出变化的过程。 CI/CD 专注于软件生命周期内强调自动化的工具。 DevOps 专注于强调响应能力的文化角色。 参考：敏捷，持续集成/持续交付, DevOps 三者的区别 图来源：DevOps到底是什么意思？ 可以看得出，容器技术使得开发环境各个组件和部署环境都可以更好地隔离了，减小了相互之间的影响，大大助力了敏捷开发、CICD、DevOps开发模式。","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"虚拟化与云计算","slug":"网络与云/虚拟化","date":"2020-06-28T13:38:25.000Z","updated":"2021-01-18T07:30:30.000Z","comments":true,"path":"网络与云/虚拟化/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E8%99%9A%E6%8B%9F%E5%8C%96/","excerpt":"硬件虚拟化，网络虚拟化，网络功能虚拟化等技术","text":"硬件虚拟化，网络虚拟化，网络功能虚拟化等技术 七层协议 名称 作用 协议 所属设备 应用层 用户接口应用成 TELNET，HTTP，FTP，NFS，SMTP 网关 表示层 定义数据格式，压缩，加密等 无协议 网关 会话层 会话的建立，控制结束 无协议 网关 传输层 选择差错恢复协议还是无差错恢复协议，提供端到端接口 TCP，UDP，SPX 网关 网络层 端到端的接口定义，选址 IP，BGP，ICMP，RIP，OSPF，IGMP 路由器 链路层 定义如何传输 ARP，RAPP，MTU，PPP，SLIP 交换机，网卡，网桥 物理层 通过物理介质传输而二进制流 ISO2110，IEEE802，IEEE802.2 集线器，中继器 链接：https://www.jianshu.com/p/20fb5068f2ea 一次传输是一个封装和解封过程，是L5加UDP头成L4，加IP头成L3，加MAC头成L2，再加物理层头成L1。也就是说①发出方：(加头封装）L5-&gt;L4-&gt;L3-&gt;L3-&gt;L1②接受方：（拆头解析）L1-&gt;L2-&gt;L3-&gt;L4-&gt;L5。 （设备工作在几层就封装和解析到几层） Hypervisor物理硬件虚拟化的管理程序 Hypervisor（超级监督者）完成物理资源虚拟化（也叫VMM虚拟机监视器，是一类软件的统称）；分为两种，直接安装在物理机或安装在操作系统之上。如VMware、KVM、Xen、Virtual Box等，而OpenStack是管理VM的，是一个云管理平台。 举例KVM：https://www.cnblogs.com/polly-ling/articles/7154334.html，kvm的管理工具是Libvirt 容器属于轻量级虚拟化，Docker就是个创建容器的工具，K8S（Kubernetes）可以对容器进行编排（启动容器，自动化部署、扩展和管理容器应用，回收容器） 物理硬件虚拟化使得在一台物理的服务器上可以跑多台虚拟机，虚拟机共享物理机的 CPU、内存、IO 硬件资源，但逻辑上虚拟机之间是相互隔离的。 Hypervisor是NFV（见后）的基础，NFV的NFVI组件主要是Hypervisor NV：网络虚拟化为了达到VM在不同服务器迁移后，IP和MAC都保持不变的目的 ，所以我们就需要网络虚拟化技术 ，为了实现虚拟化就要实现大二层 NV是二层的虚拟化 云服务商给租户的网络是虚拟网络，尽管使用相同的底层物理网络的基础设施，每个租户得到的虚拟网络(包括控制平面和数据平面)却是相互独立的，完全隔离的，通过云服务商提供的控制平面，租户可任意的配置管理自己的虚拟网络。ECS或VPC等就是网络虚拟化基础上提供的服务，ECS并不是指定某一台机器上的一个VM（否则就是VPS了。ECS它只是提供了一个对外的公网IP，你以为它是一台你在操控的计算机，但其内部实际上是一个虚拟网络，这个公网IP指向的是这个网络整体），VPC也并不是真正存在的一个具体与实际网络设备对应的私有物理网络，它们都是建立在虚拟网络上的逻辑网络，给用户提供的IP可能就只是一个VIP，用户在VPC里设置的IP也都是overlay虚拟网络的逻辑IP，真正的underlay网络对用户不可见。 大二层大二层：跨三层路由的二层网络 如何理解大二层网络？（视频） - 牛博恩的回答 - 知乎 https://www.zhihu.com/question/312012730/answer/598018973 大二层技术需要解决的核心问题：二层环路问题（因为为了保证可靠性，有冗余设备+冗余链路，所以导致了环路；传统二层网络通过STP协议解决环路问题） 有三大方案实现大二层：①略 ②略（基于虚拟交换机技术，做一个虚拟的交换机合并链路） ③Overlay，基于IP隧道的方式，建立“大二层隧道” 园区网络扁平化除了取消汇聚层之外还有哪些？ - summer课堂的回答 - 知乎 https://www.zhihu.com/question/67268856/answer/251271775 eg： （以下为Overlay的VxLAN技术实现大二层方式） 假设有两台服务器： 服务器A 192.168.1.10 服务器B 192.168.2.10 两服务器通过L3路由器打通，也就是两机器互通。 此时在两机器上部署VMware NSX，通过隧道技术用VTEP打Vxlan标签， 实现两物理机上虚拟机仿佛在二层通信一样。 附： IP隧道技术：是路由器把一种网络层协议封装到另一个协议中以跨过网络传送到另一个路由器的处理过程 IP协议是IOS唯一选择的传输协议，在隧道技术中IP协议作为封装协议，将被封装的协议报文（可以是任何协议）封装在IP包中，然后由IP协议传输，达到目的地后解封。对于承载者IP协议来说，装的是什么不重要，IP协议就像在源和目的地两头打通了一个隧道一样，让被封装报文直接传送过去。 如VPN和VxLAN就是基于隧道实现的 Overlay由IT厂商提出，基于隧道技术，将一个大二层网络叠加在传统网络之上 具体实现有比如Vmware提出的VxLAN技术（见后），NVGRE等 于是整个网络就变成了一个巨大的“二层交换机” Overlay网络和Underlay网络是相互独立的，且都有控制面和数据面，Overlay网络使用Underlay网络点对点传递报文，而报文如何传递到Overlay网络的目的节点完全取决于Underlay网络的控制平面和数据平面，报文在Overlay网络入和出节点的处理（如丢弃，转发）则完全由Overlay网络的封装协议来决定。 阿里云网络主要由三个层面组成: 底层的物理层及其SDN控制器, Overlay网络层及其SDN控制器, 以及应用层. 其中每个层面都由更细节的模块组成. 阿里云的物理层网络是世界上最大的SDN网络之一, 可以细分为DC 网络, 阿里城域网, 阿里骨干网等组件, 物理层的控制器负责管理物理层网络, 并向Overlay层提供 API, 屏蔽各种物理网络的细节（为Overlay网络层提供了虚拟网络组件，于是在Overlay就可以用这些虚拟网络组件搭建网络了） Overlay 网络层则由网关(Gateway), 阿里虚拟交换机(AVS: Alibaba Virtual Switch), 负载均衡器(SLB: Server Load Balance)等本层数据面的网络组件, Overlay 网络层的控制平面以及 Overlay 网络层的管理平面组成. Overlay 网络层控制器负责管理各个网络组件, 向应用层的产品和服务提供统一的API, 并调用物理层的控制器完成网络功能; 应用层则主要是阿里云网络的各大主要产品如CEN和资源管理调度系统(例如伏羲), 它们通过调用Overlay控制器的北向接口实现了阿里云网络的使用和调度. 摘自阿里云云栖社区 VLAN虚拟局域网，原目的是缩小MAC帧的广播域，实现广播域内的分组隔离 vlan就是交换机内定义的广播域，在一个局域网内，再使用多个交换机来划分广播域，交换机分配vlan号，MAC帧带有VLAN号以供交换机识别，只在vlan号匹配的虚拟局域网内广播 工作层级：L2 VxLAN详见参考：VLAN ，VXLAN和overlay 一种overlay网络的实现技术：L2 over L3，是VMWare的技术 工作层级：L2 over L3 叠加在三层网络上，内部虚拟网络MAC帧封装VxLAN头，然后依次封装在承载的物理网络的UDP头和IP头（L3） 在物理网路中一次传输是一个封装和解封过程，是L5加UDP头成L4，加IP头成L3，加MAC头成L2，再加物理层头成L1。也就是说①发出方：(加头封装）L5-&gt;L4-&gt;L3-&gt;L3-&gt;L1②接受方：（拆头解析）L1-&gt;L2-&gt;L3-&gt;L4-&gt;L5。然而在VxLAN中就存在overlay网络和underlay网络，于是就有两个封装和解析过程！ 具体地，将overlay虚拟网络的MAC帧添加VXLAN首部后（虚拟网络的L2-&gt;L1过程），直接封装在物理网络中的UDP报文（物理网络的L5-&gt;L4过程）中，然后以传统网路络的通信方式传送该UDP报文，到达目的主机后，去掉物理网络报文的头部信息以及VXLAN首部，将报文交付给目的终端。整个通信过程中，目的终端不会感知到物理网络的存在。 封装UDP报文使用IP协议进行路由选择，形成隧道，IP协议是最底层的（在UDP的L4之下），所以说是覆盖了物理L3网络 VTEP：VXLAN Tunnel End Point，即VXLAN隧道端点，是通过VXLAN使终端所在的路由器之间形成一条在虚拟链路中的通道两端的终端 VTEP的转发表：VNI、MAC、VTEP三列。VNI表示的是租户，MAC便是终端的地址（虚拟网络地址），VTEP表示终端所在的VXLAN（物理网络地址） 如果终端是物理机，那么充当VTEP一般是交换机、路由器等硬件，但是如果是物理机上的虚拟终端一般是由所在物理机的的hypervisor进程承担VTEP的功能。终端就是VXLAN的网关，有虚拟地址与物理地址转换的功能，通过拆包解析VXLAN头实现。 VxLAN具体细节：http://www.h3c.com/cn/d_201811/1131076_30005_0.htm NFV：网络功能虚拟化NFV基本概念 NFV（Network Functions Virtualization）：就是网络功能虚拟化的缩写（不是NV），利用虚拟化技术，将设备中的功能提取出来，【通过虚拟化的技术在上层提供虚拟功能模块】（提供一个VM），不再拘限于硬件架构。提供的功能比如路由、CPE、移动核心、IMS、CDN、饰品、安全性、策略等等。也就是说NFV希望能够使用通用的x86体系结构的机器替代底层的各种异构的专用设备，然后通过虚拟化技术，在虚拟层提供不同的功能，允许功能进行组合和分离。 ①NFV与NV的区别： NFV是L4~L7的虚拟化，而NV是L2的虚拟化！NFV虚拟化的是一台机器的网络功能——点，且NV虚拟化的是网络本身——面（主流实现：overlay）！ ②NFV与SDN的区别： SDN是一种集中控制的网络架构，侧重于将设备层面的控制模块分离出来，简化底层设备，进行集中控制，底层设备仅仅只负责数据的转发。目的在于降低网络管理的复杂度、协议部署的成本和灵活、以及网络创新。基于SDN的网络架构可以更容易地实现网络虚拟化，可以改善NFV网络性能。 SDN与网络虚拟化 SDN和NV是关注整个网络，而NFV是关注一个点 【连点成线】NV是网络的虚拟化（仅用于数据中心），需要大二层，大二层可以由overlay实现，overlay可以由VxLAN实现，VxLAN是基于隧道技术的 NFV是网络功能的虚拟化，将网络设备变成VM SDN是一种控制转发分离的网络架构设计 于是一个完整的数据中心网络虚拟化端到端方案：【①物理架构 ②NV虚拟网络 ③NFV网络功能虚拟化+SDN来控制网络】 在这其中，用SDN设计网络 【通过将网络设备的功能虚拟化（NFV，将网络设备变成VM），再将网络虚拟化（NV，实现虚拟二层局域网），就可以非常方便地使用SDN架构（因为很多老设备不支持可编程，不支持openflow协议，当NFV化后就可以了！）】 理解三个网络热点名词：SDN，NFV与NV VxLAN与SDN？VXLAN究竟有多大的魅力？ - 阿布的回答 - 知乎 https://www.zhihu.com/question/24004028/answer/112632872 我们在做SDN，也在做NFV，我们在用SDN的思想实现NFV。从SDN的思想来说，我们有自研的Controller（控制器）和XGW（转发设备）。从NFV来说，我们的Controller（控制器）和XGW（转发设备）都是基于x86服务器和自己研发的软件实现的，在这基础上，实现了VPC、路由器、交换机、NAT网关等等网络功能。因此，VPC可以认为是NFV的一个网络功能或网络产品。 摘自阿里巴巴云栖社区 DPDK(无关)高性能网络数据处理框架，由Intel主导 参考：https://zhuanlan.zhihu.com/p/43735684 传统的IO需要经过内核，在数据量增大的情况背景下，内核会导致IO瓶颈。所以产生了解决方案：旁路网卡IO，绕过内核直接在用户态收发包来解决传统IO的内核瓶颈问题。DPDK就是一种旁路IO技术。 以下为数据流动方式区别 传统方式：网卡 -&gt; 驱动 -&gt; 协议栈 -&gt; Socket接口 -&gt; 业务 DPDK方式，基于UIO（Userspace I/O）旁路数据：网卡 -&gt; DPDK轮询模式-&gt; DPDK基础库 -&gt; 业务 DPDK基于UIO（Userspace I/O，是Linux提供的运行在用户空间的I/O技术），UIO可以通过read（主动方式）感知中断，通过mmap实现和网卡的通讯。 DPDK的UIO驱动屏蔽了硬件发出中断，然后在用户态采用主动轮询的方式，这种模式被称为PMD（Poll Mode Driver） DPDK可以作为SDN数据平面的实现框架（为了追求极致的转发效率） 附：VM网络连接几种方式NAT：（略）只运行VM联外网，反过来不行 Bridged Adapter 桥接模式：VM直接分配一个独立的IP，直接和外部相连，可以理解为一个VM就是一个真实计算机 Internal 内部网络模式：只允许VM连VM Host-only Adapter 主机模式：Host-Only模式其实就是NAT模式去除了虚拟NAT设备，然后使用VMware Network Adapter VMnet1虚拟网卡连接VMnet1虚拟交换机来与虚拟机通信的，Host-Only模式将虚拟机与外网隔开，使得虚拟机成为一个独立的系统，只与主机相互通讯。 可见，将VM和主机隔绝成两个系统，然后虚拟网卡（主机方）与虚拟交换机（VM方）作为沟通桥梁，主机方的主机网卡又可和虚拟网卡共享，从而可以实现各种功能 https://www.linuxidc.com/Linux/2016-09/135521p3.htm PSmininet是SDN的仿真工具，可以创建虚拟网络，包含真实的工作组件，但运行在一台机器上 运行py mininet/mininet.py打开可视化窗口创建拓扑，也可以cli/python脚本方式 虚拟化，就是实现云计算的基础","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"SDN：软件定义网络","slug":"网络与云/SDN","date":"2020-06-28T13:33:37.000Z","updated":"2020-06-28T14:00:53.000Z","comments":true,"path":"网络与云/SDN/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/SDN/","excerpt":"Software Defined Network","text":"Software Defined Network SDN：软件定义网络SDN，即Software Defined Network，核心思想是将控制平面（Control Plane）和数据平面（Data Plane）分离；将传统交换机、路由器的分布式算法（如OSPF等）用控制器（Controller）的集中式算法实现，加强全局视角的控制能力，提高效率。 网络结构的扁平化的核心思想是功能上手，那么SDN就是做得最彻底的功能上收 基础设备不需要专有设备，不依赖任何网络，只要有控制和转发功能即可 园区网络扁平化除了取消汇聚层之外还有哪些？ - summer课堂的回答 - 知乎 https://www.zhihu.com/question/67268856/answer/251271775 WhatSoftware Defined Network（软件定义网络） 导论文章：图解SDN：软件定义网络导论篇 （包括网络架构发展和常用网络拓扑） 在网络中有三大模块：管理平面负责配置和管理指令，然后给控制平面生成相应的控制表（ARP表，FIB表，MPLS标签表，ACL访问控制表等等），然后再交由转发平面根据控制表进行处理与转发。但在传统网络中是分布式控制的，且这三大模块是耦合的，这导致①管理部署难：网络厂商杂、设备类型多、设备数量多、命令不一致；②性能瓶颈：独立计算、接力棒交互、分布式架构；而SDN就是为了；③流量控制棘手：带宽静态分配（无法编程），流量可视化难；④无法按需，不可编程。而SDN就是为了解决以上问题诞生的思想。 SDN是一种网络设计理念，核心思想是 ①能够弹性响应上层应用变化的网络可编程=&gt;随心应变、随应用而动 ②引入一个集中统一的控制与管理层=&gt;控制与管理、动态响应 ③解耦网络设备的管理平面、控制平面、数据平面（将管理平面、控制平面从基础设施中抽取出来） 这样一来，底层网络设备通过解耦实现了简单化；网络的管理通过集中控制器实现了全局化；网络的运维通过SDN南向接口与协议实现了自动化；网络的应用通过SDN北向接口与协议实现了更加弹性的人性化 结构ONF定义的SDN的基本架构——应用层、控制层、转发层： 应用层：提供应用和服务（用户业务系统） 控制层：提供统一的管理和控制（下发流表到转发层，指导包转发行为）===网络的大脑 转发层（基础设施层）：只提供基础的数据转发功能 使用南向接口协议（OpenFlow）实现控制层面对转发平面的控制，使用北向API（REST API）实现业务应用与SDN控制器的交互。南向接口协议OpenFlow已经标准化，所有底层硬件设备厂商都满足该协议，这样就便于编程不依赖于底层设备；北向API使用REST API是主流 ONF定义ONF定义的SDN体系架构（四大平面，两大接口）：控制平面、应用平面、数据平面（转发层/基础设施层）、管理平面，以及北向接口、南向接口。 南向接口协议主要采用OpenFlow，北向API主要采用REST API OpenFlow是P4语言建模的PISA协议无关交换机架构架构的起源，这个PISA架构也称为OpenFlow2.0 openflow1.0和后面的版本不兼容，同时都在支持 openflow协议需要芯片支持，所以需要openflow交换机；openflow交换机分为物理的和虚拟的（软件的，比如OVS，同时OVS提供OVSDB协议实现控制器对虚拟交换机vS的可编程访问和配置管理） OF-Config协议是openflow协议的伴侣协议，用于openflow交换机的管理和配置 数据平面数据平面：解析数据包头、转发数据包到某些端口（网络IO可基于DPDK框架） 数据面也叫转发面，在SDN白盒设计中，相当于一台通用的网络设备，只有数据转发和处理功能，而所有SDN白盒的控制层面（如ARP表、FIB表）功能全部集中到控制面去了 所有转发表都被抽象为流表，转发过程抽象为匹配-动作过程 流表（1.0版本）： 动作就是将数据包转发给不同的端口，不同的端口对应不同的进程，处理不同的功能，比如有的端口是按照传统方式转发，有的是按照表转发，有的是转发给交换机等等（具体看协议对不同端口的定义）。总得来说，流表记载了不同数据包的转发行为。 数据包处理流程： Openflow协议openflow协议有三种消息类型： Controller-to-Switch消息（控制器发起） Asynchronous消息（交换机发起） Symmetric消息（可由任一方发起） Openflow消息体由openflow Head和openflow message组成 然后再发送packet_out（属于Controller-to-Switch），packet_in（属于Asynchronous）消息，通过packet_out中的LLDP包进行网络拓扑探测，通过flow_mod信息下发流表操作（增删改等） 然后一次客户端的请求通信流程demo如下： OF-Config协议用于OF交换机的配置，是Openflow的伴侣协议，也属于南向协议 由openflow配置点统一对OF交换机进行配置 有控制器连接设置（控制器IP端口传输协议）、多控制器参数配置、OF逻辑交换机资源配置、连接中断配置、加密设置（证书配置）、队列配置（速率）、端口设置（包括如基于VxLAN的逻辑端口）、能力发现配置 还要支持配置隧道等运维需求 OF-Config数据模型由XML语言定义 NetConf协议这个协议不是SDN必须的，但是一个很常用的网络设备的管理和配置协议，常用于自动化运维 也属于南向协议，基于C/S模型，使用RPC通信模式，采用XML编码的&lt;rpc&gt;和&lt;rpc-reply&gt;元素提供独立于传输层协议的请求和回应消息框架。 配置数据有running、candidate、startup三个数据库，&lt;running/&gt;库用于保存当前已经生效的配置；&lt;candidate/&gt;用于保存可以提交为生效的数据；以及&lt;startup/&gt;用于保存启动时的配置数据。 也是写XML，通过配置RPC操作 详细参考见：网络运维自动化入门二：NETCONF 控制平面：SDN控制器 内置应用层的overlay网络指的是如果本网络是另一个overlay网络的underlay网络，那么物理网络和虚拟网络都是有各自的SDN三平面的，下层网络的控制器提供给上层overlay调用 南向网络控制以下功能都是使用openflow协议实现，SDN控制器和SDN交换机通过前面所述的OF三种消息类型进行交互 链路发现：获得SDN全网信息，实现网络地址学习、VLAN、路由转发；SDN交换机直连链路（指控制器与SDN交换机直连）的发现由LLDP协议实现，对于非直连链路通过广播的方式实现 拓扑管理：监控和采集SDN交换机的信息，反馈工作状态和链路连接状态 策略制定 表项下发：主动下发/被动下发 P.S 使用OF协议作为南向接口协议的SDN交换机也叫OF交换机 北向业务支撑目前尚未统一标准（因为受实际业务影响很大），REST API是比较主流的一种 开源SDN控制器有如Mul、Trema、NOX、POX、Ryu、Beacon、Floodlight、ONOS、OpenDayLight（ODL）等","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"REST API","slug":"网络与云/RESTAPI","date":"2020-06-27T13:45:26.000Z","updated":"2020-06-28T14:00:57.000Z","comments":true,"path":"网络与云/RESTAPI/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/RESTAPI/","excerpt":"REST API","text":"REST API REST APIREST=Representational State Transfer（表述化状态转移） REST是一组架构约束条件和原则，满足REST设计原则的设计规范或架构风格叫RESTful，遵循RESTful设计的API叫REST API。REST是为了规范HTTP请求而提出的（如URL规范） REST是面向资源的设计，一个资源对应唯一的一个URI（通过URI来暴露资源），在web中资源标识符的实例就是URI（包含URL和URN两种形式） eg：DELETE /student/10 REST的约束条件： 客户-服务器模型：实现解耦（客户端、服务器各干各的） 无状态：要求来自客户端的每一个请求必须包含服务器处理该请求所需要的所有信息 缓存：要求一个请求的响应中的数据标记为是否可缓存 统一接口：客户和服务器之间通信的方法是统一化的，如标准的HTTP动作GET、POST、PUT、DELETE等 分层系统：允许服务器和客户端之间的中间层（如反向代理、网关），对于客户端来说都是透明的 （按需代码） REST API的设计规范：【HTTP动词+URI】 ①HTTP动词用于标识操作，常用的有HEAD，GET，POST，PATCH，PUT，DELETE ②URI用于标识资源，资源的原型有文档、集合、仓库、控制器 集合是资源的一个容器（目录），可以向里面添加资源（文档）；控制器可以执行一个方法，支持参数输入，结果返回 URI命名规范： 文档类型：名词单数 集合、仓库类型：名词复数 控制器类型：包含动词的词语 字段可以是变量，在实际使用中可以按需替换，变量写在&#123;&#125;中 URI格式规范： 分隔符/一般用于对资源层级的划分，/不应该出现在URL的末尾 尽量使用连字符-代替下换线_的使用 统一使用小写字母 不要包含文件（或脚本）的扩展名 CRUD操作不能体现在URI中 URI的query字段作为查询的参数补充，以标示一个唯一的资源，可以作为过滤条件使用 需要设置HTTP的响应状态码： 2xx：操作成功；3xx：重定向；4xx：客户端错误；5xx：服务端错误 常用的：200,201,400，401,404,500 元数据设计：HTTP头部设置元数据字段格式，如Content-Type、Content-Length等字段 举例（SDN中ryu控制器提供的ACL模块的北向REST API）： //这个就是一个REST API，C端根据这个API进行传输请求 //后面的这个URL就是S上的资源地址，POST就是操作 //POST动作、DELETE动作还需要在JSON中写入需要传输的数据，见下面的请求demo REST API : POST http://&lt;controller_ip>:8080/wm/acl/rules/json //crul命令是一个http请求工具（-X：请求协议，-d：POST内容） crul -X POST -d '&#123;\"src-ip\":\"10.0.0.1/32\",\"dst-ip\":\"10.0.0.2/32\",\"action\":\"deny\"&#125;' http://&lt;controller_ip>:8080/wm/acl/rules/json P.S. REST API是SDN北向接口的主要实现标准 URI是统一资源标识符，URL是统一资源定位符，URL是URI的子集 元数据：表述数据的数据上（如媒体类型、最后修改时间、源链接等） 无状态：每一个步骤不依赖于前一个步骤（直接定位到服务器的资源，不依赖于客户端-服务器的会话状态）","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"HTTPS(ver2)","slug":"网络与云/HTTPS-ver2","date":"2020-06-25T14:32:57.000Z","updated":"2020-07-15T14:37:39.000Z","comments":true,"path":"网络与云/HTTPS-ver2/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/HTTPS-ver2/","excerpt":"老版总结的不够清晰具体","text":"老版总结的不够清晰具体 非对称加密非对称加密算法的公钥就是通过私钥生成的，所以得到私钥那就能推出公钥 公钥和私钥是成对的，它们互相加解密。 常见非对称加密算法有如RSA、ECC等 RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为公钥。 SSH，HTTPS都是基于公私钥体制的 于是非对称加密创造的公私钥体制的两大用途： （公钥向所有人开放，私钥仅自己持有） ①【数据加密】：公钥加密，私钥解密。（加密信息发送方持有公钥，接收方持有私钥解密） ②【数字签名】（防伪造）：私钥加密（称作“数字签名”），公钥解密（称作“验证”）。（发送方持有私钥加密，接收方持有公钥解密） 数字签名的作用如其表面意思，就是发送者签名（私钥加密一下数据），这样任何其它人就不能伪造发送者的信息了（发送者提供的公钥只能解密发送者签名即加密的信息） 公钥CSR，私钥KEY 数字证书于是就出现了数字证书，证书就是秘钥的载体 数据加密中，发送方用公钥进行加密的证书叫加密证书，国际标准的SSL证书就是加密证书 CA证书CA：Certification Authority，证书权威机构 CA证书是去申请！CA生成一对公私钥，然后给我私钥！（证书） 引入第三方来统一管理公钥，以防止不可信的公钥（防伪造证书的坏蛋，或者这个公司有鬼OvO），我们只相信权威机构下发的SSL证书（含公钥）才是真正的 所以作为加密信息接收方，我们需要向权威机构申请证书，就是在让CA申请一对公私钥，然后CA将私钥给我（只有我本地有公钥进行解密，保证信息安全性），将SSL证书（含公钥）提供给公众，让公众到获取CA认证的证书来和我通信 但为了防止CA下发证书途中被篡改，权威机构会用自己的私钥对加密证书进行数字签名，签名后存放于签名表项中也给出签名算法（签名即CA私钥加密），然后客户端收到的SSL证书是一个已经被签名（私钥加密）了的，必须要用CA公钥进行解密（CA公钥和CA一样，一起默认存在于操作系统中），由于CA公钥只能解私钥加密的信息，所以可以确保SSL证书本身不被篡改，否则无法解密取出加密证书 我们自己就可以通过openssl来创建SSL证书（将公钥、证书颁发者等信息写入证书），但这个证书由于是我们自己颁发的，所以不被别人信任；所以我要让CA来创建一堆公私钥，私钥给我，公钥保存在CA上，以后其它人想要访问我的网站，就会获取到我服务器上的SSL证书后，去CA验证，有CA背书， 那就可以信任我的网站了 SSL证书解析过程：①先用CA的公钥来解密数字签名，如果能解密表示信息未被篡改；②然后从证书中取出服务提供商的公钥 【注意记住：SSL证书携带公钥，对于加密通信，公钥/证书持有者是信息的发送方；】 HTTPS=HTTP over SSLHTTPS=HTTP over SSL，它使用默认端口443，而不是像HTTP那样使用端口80来和TCP/IP进行通信。HTTPS协议使用SSL在发送方把原始数据进行加密，然后在接受方进行解密，加密和解密需要发送方和接受方通过交换公钥来实现。 SSL协议就是一个数据加密传输的完整协议，其描述了一个过程，使用了非对称加密算法 主要过程：（爱丽丝是客户端，鲍勃是服务端；注意区分对称和非对称） ​ =============【双方交流阶段】：双方传递SSL准备信息================= 第一步：爱丽丝给出支持SSL协议版本号，一个【客户端随机数】(Client random，请注意这是第一个随机数)，客户端支持的加密方法等（对称加密方法）信息； 第二步：鲍勃收到信息后，确认双方使用的加密方法（对称加密方法），并返回数字证书，一个服务器生成的【服务端随机数】(Server random，注意这是第二个随机数)等信息； ======【非对称加密阶段】：传输随机数3号，以准备生成下一阶段的对称秘钥====== 第三步：爱丽丝确认数字证书的有效性，然后生成一个新的【随机数3号】(Premaster secret)，然后使用数字证书中的公钥，加密这个随机数，发给鲍勃。 第四步：鲍勃使用自己的私钥，解密爱丽丝发来的【随机数（预主密钥）】(即Premaster secret)； ========【对称加密阶段】：生成对称秘钥，开始对称加密的数据传输======== 第五步：爱丽丝和鲍勃通过约定的加密方法(通常是AES算法)，使用前面三个随机数，生成对话密钥（对称秘钥），用来加密接下来的通信内容；【对称加密通信阶段，生成对话秘钥】 SSL过程参考：https://zhuanlan.zhihu.com/p/32513816 一些术语： ①预主秘钥(pre_master secret)：即第三个随机数，它是生成主密钥的关键 ②主密钥（master secret）：由预主秘钥、客户端随机数、服务端随机数、常量字符串，计算获得 ③（国密中存在）工作密钥（见下面国密部分） 其中随机数是通过伪随机数函数PRF生成的 TLSHTTPS、SSL、TLS区别：https://blog.csdn.net/enweitech/article/details/81781405 SSL是基于HTTP之下TCP之上的一个协议层，是基于HTTP标准并对TCP传输数据时进行加密，所以HPPTS是HTTP+SSL/TCP的简称。 TLS是SSL的标准化后的产物，TLS1.0和SSL3.0几乎没有区别（有很多安全性改进），但历史原因我们还是称作SSL","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"负载均衡","slug":"网络与云/负载均衡","date":"2020-06-23T14:12:59.000Z","updated":"2020-06-28T14:00:41.000Z","comments":true,"path":"网络与云/负载均衡/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"SLB入坑学习笔记","text":"SLB入坑学习笔记 引入 Nginx Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。 Nginx 主要提供反向代理、负载均衡、动静分离(静态资源服务，即静态web server)等服务。 反向代理部分，以以前的例子来说，比如国内访问香港快，香港访问github快，但国内访问github慢，那我用一个香港服务器做nginx反代github，就能加速国内访问github了 反向代理需要设置在配置文件的HTTP模块中 Nginx作为负载均衡使用的话就是一种常用的SLB软件。具体见后面“SLB：Nginx”一节 参考阅读：Nginx 正向代理和反向代理 正向代理：Proxy代理客户端去访问服务器 反向代理：客户端访问Proxy，该Proxy代理了服务端 反代是负载均衡的一种实现手段（的一个步骤） 使用负载均衡的网络架构举例架构笔记：负载均衡SLB，互联网架构大剖析 反向代理层的负载均衡，是通过“DNS轮询”实现的 站点层的负载均衡，是通过“nginx”实现的 服务层的负载均衡，是通过“服务连接池”实现的 数据层的负载均衡，要考虑“数据的均衡”与“请求的均衡”两个点，常见的方式有“按照范围水平切分”与“hash水平切分” 四层和七层负载均衡由前面的例子可以看到，负载均衡实际上是可以实现在网络结构的每一个层次的，其核心目的就是平衡负载，前面所说的层次是指在网络请求架构上的层次，而这里的“四层”，“七层”SLB指的是SLB实现在在OSI七层模型的第几个层次。这两者是不冲突的，勿混淆。 那么根据OSI七层网络模型，1物理层、2数据链路层、3网络层、4传输层、5会话层、6表示层、7应用层。 四层SLB工作在OSI第四层，也就是传输层；七层SLB工作在最高层，也就是应用层。 区别如图： 四层负载均衡：使用IP加端口的方式进行路由转发，也就是说客户端并没有和proxy建立TCP连接，而是客户端直接和后端服务器建立TCP连接（客户端先向负载均衡发送SYN请求建立第一次连接，然后再通过SLB算法，让客户端去与目标后端服务器进行三次握手连接）； 七层负载均衡：一般是基于请求URL地址的方式进行代理转发，七层服务均衡在应用层选择服务器，只能先与负载均衡设备进行TCP连接，然后负载均衡设备再与后端服务器建立另外一条TCP连接通道。 四层和七层负载均衡实现方式整体原理（重要）：四层负载均衡和七层负载均衡区别在哪里？ 常用负载均衡软件：四层和七层负载均衡的特点及常用负载均衡Nginx、Haproxy、LVS对比 （四层: F5、LVS等，七层: nginx、apache等） 显然七层SLB更损失性能；四层SLB可能会遭受SYN Flood攻击（一种DDoS攻击），可能将垃圾流量转发给后台服务器，而七层显然可以在SLB服务器上设置过滤 （SYN Flood：利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽，更细节原理参考：详解SYN Flood攻击原理与防范 待阅读） 负载均衡四层负载均衡可通过LVS（Linux Virtual Server）+ keepalived的方式实现，七层负载均衡通过Tengine（淘宝网发起的Web服务器项目，在Nginx的基础上，针对有大访问量的网站需求进行了优化）实现。 来自公网的请求通过等价多路径路由（ECMP）到达LVS集群，LVS集群内的每台LVS通过组播报文将会话同步到该集群内的其它LVS机器上，从而实现LVS集群内各台机器间的会话同步。同时，LVS集群会对Tengine集群进行健康检查，将异常机器从Tengine集群移除，保证七层负载均衡的可用性。 产品架构：阿里云负载均衡产品架构 集群综述集群根据功能分为两大类：高可用集群（HA）和负载均衡集群（SLB） 高可用集群主要是防止服务器宕机导致服务不可用，主要功能是服务器状态检测和故障隔离（热备） 负载均衡集群则是平衡负载功能，请求分发给后端服务器处理 HA：VIP、VRRP虚拟IP，方便切换实际主机而保持IP不变，目的是高可用性HA，虚拟IP(VIP) 持有VIP的是集群中的一台主机，只是对于外界来说，整个集群好像一台IP为VIP的主机 其需要使用VRRP协议 VRRP (Virtual Router Redundancy Protocol-虚拟路由冗余协议)：双机热备份-VRRP VRRP可以通过把多台设备虚拟化成一台设备，然后通过配置虚拟IP地址(VIP)作为网关就能实现对网关的备份（这虚拟IP地址是代表整个VRRP组内的所有设备），当其中一台设备出现故障之后，VRRP组内其他设备会通过某些机制来接替故障设备的工作。 VIP地址与VRRP组中的某台VRRP设备实际IP地址相同，则此设备为IP地址拥有者（如在keepalived中我们最开始会手动设置一个master，后面再通过各种检查和选举机制决定新master）只有IP地址拥有者（master）才真正拥有这个VIP，显示在网卡信息中，其它backup是没有的 master会通过组播的形式向各个backup发送VRRP协议的数据包，当backup收不到master发来的VRRP数据包时，就会认为master宕机了。此时就需要根据各个backup的优先级来决定谁成为新的mater。 HA：keepalivedkeepalived是一个实现服务器HA的软件 keepalived通过VRRP实现HA：基于VIP的keepalived高可用集群架构 Keepalived主要有三个模块，分别是core、check和vrrp。 ①core模块：为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析 ②check模块：负责健康检查 ③vrrp模块：是来实现VRRP协议的。 keepalived可以集成LVS配置，这样就不必单独配置LVS（见后面“keepalived+LVS集群”部分） SLB：LVSLVS：Linux Virtual Server LVS 是一个实现负载均衡集群的开源软件 LVS工作模式分为NAT模式、TUN模式、以及DR模式（见下面链接） NAT模式就是运用NAT的原理，直接改IP头，这样的话数据往返都要经过ds。 DR模式：为了实现每台rs在向外发送响应报文的时候，可以把VIP作为源地址，因此我们设置ds和rs集群的所有主机都是同样的VIP，这样数据返回的时候就可以直接返回给请求端了。但需要在rs上禁用ARP解析，让所有的rs上的VIP地址不响应VIP的arp广播请求（否则vip一样，所有rs同时响应，谁响应快调度谁，不符合slb目的，这样一来只有ds会响应MAC地址请求，那么请求报文就一定发给ds了，再由ds根据调度算法指定目的rs的MAC地址，传给它，rs拿到清请求包后，将请求数据结果返回SIP（sourceIP）即可。 DR模式是最常用的，因为一般返回的数据比较庞大，返回流量不经过SLB可以大大减小负荷 LVS的十大调度算法：LVS十种调度算法介绍 使用LVS架设的服务器集群有三个部分组成： 负载均衡层(Load Balancer)：包含负载调度器（Director），简写“ds” 服务器集群层(Server Array)：包含后端的服务器，真实服务器（Real Server）集群，是客户端真实访问的服务器，简写“rs” 数据共享存储层(Shared Storage)：提供给后端服务器进行数据访问 LVS已经是Linux标准内核的一部分，只需要再安装一个lvs的管理工具：ipvsadm即可（ IPVS为LVS的核心模块） Lvs之NAT、DR、TUN三种模式的应用配置案例以及底层原理（整理版本：LVS安装使用详解） SLB：NginxNginx配置详解 Nginx如何配置反向代理 Nginx如何配置负载均衡【很清晰，推荐】 Nginx功能有反向代理、七层负载均衡，也可以作为静态web服务器，邮件服务器。默认使用端口80。其它功能见“引入”一节。 Nginx的这些功能都是工作在第七层的，都是通过HTTP/HTTPS实现的，所以我们在写反代、负载均衡等的配置的时候自然要写在HTTP模块里。在HTTP子模块中主要有server和upstream子模块，server中需要配置location路由信息模块。 反向代理：在配置反向代理的时候，我们在http模块中定义server子模块，这个子模块配置虚拟主机，该服务器接受到端口80的所有流量（所有到达本Nginx服务器的HTTP请求）都发往该虚拟主机，也就完成了反代。 负载均衡：如果有定义upstream子模块，server虚拟主机子模块将所有流量转发上游upstream子模块中的服务器，在upstream中可以设置多台rs后端服务器，可以选用负载均衡策略，也就实现了负载均衡功能。默认轮询调度upstream中的backend rs。（注意，upstream名称和server配置中的proxy_pass需要匹配才能转发到upstream。） Nginx的负载均衡功能支持3种负载均衡策略，2种常用的第三方策略 以下为Nginx通用配置结构 main # 全局配置 events &#123; # nginx工作模式配置 &#125; http &#123; # http设置 .... server &#123; # 服务器主机配置（虚拟主机） .... location &#123; # 路由配置 .... &#125; location path &#123; .... &#125; location otherpath &#123; .... &#125; &#125; server &#123; .... location &#123; .... &#125; &#125; upstream name &#123; # 负载均衡配置 .... &#125; &#125; 注意：所有rs都要禁用arp解析（写个jio本），原因和lvs集群须禁用rs的arp解析一样 SLB：Tengine淘宝网发起的Nginx的升级版，就是针对淘宝网的需求优化了一下 keepalived+LVS集群：实现高可用负载均衡【整体网络架构：keepalived管理LVS集群，LVS管理后端服务器集群】 （LVS集群中由keepalived指定的就是本次工作的ds） 为什么要两者结合？因为LVS做负载均衡，来达到分发请求的目的，但是不能很好的避免单点故障，假如LVS服务器挂点了，那么所有的服务也会跟着瘫痪 。keepalived+LVS，就能很好的解决这一问题 keepAlived用于保证SLB集群（LVS）的高可用性，是指的SLB本身的高可用。对于在keepalived中配置lvs模块，起目的是补充lvs的配置，keepalived属于lvs的扩展项目 实践例子： ①keepalived基础使用 ②keepAlived+lvs→效率最高的负载均衡【重要：KeepAlived集成LVS】 ③keepalived + nginx 实现高可用集群方案（这里Nginx只是安装好后直接启动，没有任何配置，其实和①差不多） keepalived可以集成LVS配置，在①的配置文件中，若多写个virtual_server项，即可在keepalived中配置本机的VIP等信息的时候同时将本机配置为LVS服务器，virtual_server中的real_server项配置即为本机LVS负责调度的真实的后端服务器集群，keepalived的负载均衡框架实际上就是使用的LVS，keepalived直接使用了IPVS，即LVS的核心组件，实现了负载均衡功能。 这样一来，keepalived就接管了虚拟ip完成了虚拟ip的高可用（主从热备功能），同时keepalived也监测了两台Real Server（负载均衡功能） 也可以不在KeepAlived中配置LVS，单独手动配置LVS，见前面“LVS-Lvs之NAT、DR、TUN三种模式的应用配置案例以及底层原理”一部分，但这样显然更麻烦；对于集群不是LVS集群，如是普通主机集群or Nginx集群，就只能各个服务自己配置自己的了，keepalived只负责主从热备。 [KeepAlived+LVS大概步骤总结]： 先给每台LVS配置同一个VIP（增加一个本地路由lo0，设置其IP为想要的VIP，注意VIP必须和实际IP在同一个网段）linux配置虚拟IP—VIP 安装ipvsadm 集群中每台主机都安装keepalived，写keepalived配置：配置VIP和真实服务IP，配置LVS（配置virtual_server和对应的real_server） 如果是LVS工作在DR模式，需要在每台rs上抑制arp响应 那么网络结构就是：请求端——keepalived+lvs集群（ds）+后端服务器集群（rs） keepalived+LVS集群+Nginx集群：实现四层、七层高可用负载均衡LVS+KeepAlived+Nginx高可用实现方案【这篇写得很详细，推荐】 网络结构：请求端——keepalived+lvs集群（ds）——Nginx集群（ds/rs）——后端服务器集群（rs） Ningx集群对于lvs集群来说是rs，对于后端服务器集群来说是ds（配置也就按这样ds-rs关系配置） LVS作为四层和七层SLB的入口。对于四层，由LVS集群转发给rs；对于七层，LVS集群将请求转发给Tengine集群，再由Tengine集群转发给rs；由于lvs的消耗很低，所以这种结构是合理的，即能满足四层SLB的速度，又能满足七层SLB的多功能。 在使用VIP下，如果lvs集群、nginx集群、rs集群对外的vip都是一样的，所以为了让请求到达云的时候，只让lvs的ds响应，我们要抑制nginx集群和rs集群的arp响应：LVS负载均衡中arp_ignore和arp_annonuce参数配置的含义（对于keepalived+lvs集群本身，keepalived会根据VRRP协议，只让master（也就是VIP目前指向的真实MAC地址机器）作出响应，所以无需再手动抑制lvs集群的arp响应） 高性能负载均衡设计与实现 - 阿里云云栖号的文章 - 知乎 https://zhuanlan.zhihu.com/p/29949340 高可用架构可能出现的问题脑裂：主备集群中两个节点互相认为对方已挂掉，都成为了master，然后开始争抢共享资源，结果会导致系统混乱，数据损坏。 在keepalived+LVS集群+Nginx集群网络结构中，只有keepalived+LVS集群这一层可能出现脑裂（keepalived导致），即keepalived的master主机使用vrrp对keepalived+lvs集群进行心跳检查（vrrp报文）的时候出现故障，以为对方挂了，在vrrp协议中，backup如果收不到来自master的心跳包，就认为master down了，自动转为master，那集群就出现两个master了，它们都持有VIP，那么他俩都能接收到SIP（source IP）发出的请求，开始争抢资源，系统混乱，也就是脑裂。 可能原因：VRRP中的心跳检查出故障了 待更新更多可能问题… Key Server如果相应的负载均衡实例服务端口使用的是七层HTTPS协议，与上述HTTP处理过程类似（keepalived+LVS集群+Tengine集群），差别是在按策略将服务请求最终分发到后端ECS服务器（rs）前，先调用Key Server进行证书验证及数据包加解密等前置操作。 这一步是由Tengine集群向Key Server发送请求进行验证，而不是后端服务器rs","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"为年度雷王的诞生献上礼炮","slug":"Game/最后生还者2","date":"2020-06-21T15:29:13.000Z","updated":"2020-06-23T00:49:02.000Z","comments":true,"path":"Game/最后生还者2/","link":"","permalink":"https://aisaka.cloud/Game/%E6%9C%80%E5%90%8E%E7%94%9F%E8%BF%98%E8%80%852/","excerpt":"垃圾游戏不吐不快 《The Last Of Us 2》评分：-10/10","text":"垃圾游戏不吐不快 《The Last Of Us 2》评分：-10/10 乔尔一代各种小心翼翼，一路屠遍了窝点，二代上来直接给陌生人报名字，然后直接无条件信任走进别人窝点去，实在是太tm“真实”了，编剧玩过前作么？后面的剧情我就不吐槽了，说了涉及剧透。 去年一直在爆出顽皮狗工作室有各种员工离职泄愤剧透的，原来都TM是真的啊，敢问贵工作室的制作人是来做游戏的还是来宣扬你那套白左政治宣传的？SJB。 这么重量级的IP，这么备受期待的游戏，就这么乱搞？ 各路媒体分打得可高了，mc96呢 看看以“硬核”著称的机核的评测 看到这段话我还以为是哪位贴吧大神在跟人对线呢。 翻译一下：“我收了钱，我不能不吹啊，但实在找不到地方吹，所以不解释，不然你来打我啊” b站看到的两个段子，看来觉得像《铁血的孤儿》的人不止我一个 这游戏就是铁血孤儿的精神续作 乔尔奥尔加团长说1、乔尔是美末主角，奥尔加是铁血奥尔芬斯主角2、乔尔一代杀穿了东海岸，是末日王。奥尔加创立了铁华团，是火星王3、美末1是双主角设计，主角是高个子乔尔和矮个子爱莉。奥尔芬斯也是双主角设计，主角是高个子奥尔加和矮个子三日月4、美末剧情在2代崩坏，奥尔芬斯剧情也在2代崩坏5、乔尔2代智商忽低，被反派当场打死。奥尔加2代智商也低，被暗杀兵当场打死。6、顽皮狗编剧想要写死乔尔来突出末日的阴暗，却在最后爱莉忽然原谅了反派，是屑。奥尔芬斯编剧强行团灭铁华团，是屑7、乔尔毫无预兆的被打死。奥尔加也毫无预兆的被打死。8、乔尔很惨，死了女儿又被打死，奥尔加也很惨，被打死后被人迫害乔尔奥尔加说，成立QED 总觉得很安静呢街上也没有火萤的人，和本部完全不同是啊，大概是把战力全调到西雅图去了不过那些已经不重要了你心情很好嘛那是当然的!大家都能得救，蒂娜也在努力我也是加把劲骑士(指加把劲哈草)是啊，我们一直以来积累的东西，没有全部木大(迫真)今后也是，只要我们不停下脚步，道路就会不断延续……棕色高级马，恐怖肌肉女下马(你们怎么看起来一副知道我们的样子)汤米击晕倒地乔尔夫时间乔尔，在干什么啊，乔尔!什么嘛，我报名字还是蛮准的嘛乔尔……艾莉，你怎么发出那种声音，ride on(指骑上马)因为，因为!我是，末世老油条，乔战神哒咗几杆子高尔夫球杆不要紧的怎么会，你尽然为了我这种人(并不)保护艾莉是我的使命(这是真的)可是!够了，你们走!大家……在等着你们而且，泰丝，我终于懂了我们根本不需要什么好剧情只要不断前进就行(指zzzq剧情加清一色媒体浪潮裹挟)只要不停止，道路就会不断延续(生财之道)是啊，我明白了因为我是不会停下来的只要你们不停下来那前面一定就有我(传授经验ing)所以啊……不要停下来啊。 不要停下来啊（指暴死） 这种满身zzzq，不好好搞游戏内容，到处夹杂私货的垃圾游戏（及其设计团队），祝赶快滚出游戏圈。顽皮狗已死","categories":[{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"}],"tags":[]},{"title":"人生的分叉口","slug":"日记/人生的分叉口","date":"2020-06-08T14:50:25.000Z","updated":"2020-06-11T12:07:27.000Z","comments":true,"path":"日记/人生的分叉口/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%BA%BA%E7%94%9F%E7%9A%84%E5%88%86%E5%8F%89%E5%8F%A3/","excerpt":"毕业倒计时：一年","text":"毕业倒计时：一年 马上就要离开家了，今年的生日也没能（差点）在家里过。先放一首歌…（网易云不支持外链播放器了，只能超链接了） 成都 同时拿到了某顶级技术公司最核心部门的研发Offer和某顶级游戏公司的游戏设计师Offer 两者都是爱好，一直以来都是双线操作（反复横跳），这次终于跌跌撞撞走到了十字路口，面临选择了。 技术还是非技术？游戏还是非游戏？无论选哪个，另一个永远都只能是副业了。 初二的时候第一次接触到编程，那时候是用PASCAL打NOI；然后高三毕业的时候第一次接触到核心游戏，第一个是买PSV的时候一起买的弹丸论破2（真要算所有游戏的话，那大概得追溯到小学了）。一直以来我都是既热爱技术也热爱游戏，既想成为一个技术宅，也想成为一名游戏制作人。 头疼，当两个梦想只能二选一的时候，我该走哪条路呢。如果我一天有48小时就好了。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"今日芒种","slug":"Music/今日芒种","date":"2020-06-05T09:47:52.000Z","updated":"2020-06-05T09:50:55.000Z","comments":true,"path":"Music/今日芒种/","link":"","permalink":"https://aisaka.cloud/Music/%E4%BB%8A%E6%97%A5%E8%8A%92%E7%A7%8D/","excerpt":"音乐链接","text":"音乐链接 一想到你我就 wu~~~~","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[]},{"title":"夏","slug":"日记/夏","date":"2020-06-01T00:12:20.000Z","updated":"2020-12-24T14:50:19.963Z","comments":true,"path":"日记/夏/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%A4%8F/","excerpt":"","text":"六月的盛夏承载着无数的想象 此时此刻，即是序章","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"GIT","slug":"工具/GIT","date":"2020-05-31T04:15:47.000Z","updated":"2020-06-06T02:55:52.000Z","comments":true,"path":"工具/GIT/","link":"","permalink":"https://aisaka.cloud/%E5%B7%A5%E5%85%B7/GIT/","excerpt":"系统性地整理一次GIT","text":"系统性地整理一次GIT Git结构SVN是集中式版本控制系统，版本库是集中放在中央服务器的，必须联网 Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库。只需把各自的修改推送给对方，就可以互相看到对方的修改了。 GIT架构： remote：远程仓库；repository：本地仓库；index：暂存区 当你在一个工程文件的目录下git init的时候，就会在该工程目录下创建.git文件夹，这个.git文件夹里包含暂存区、本地仓库，然后就可以在该工程目录下使用add、push、pull等指令对该工程目录进行git操作。（可以写个gitignore来指定哪些不git） 所以每个需要git（分布式版本控制）的项目都可以在其工程目录下新建git仓库 Git 身份认证本地仓库连接远程仓库进行PUSH等操作之前，需要认证身份，有两种方式：SSH协议和HTTPS协议。 SSH协议认机器（通过ssh key公私秘钥认证），HTTPS协议认账号（通过账号密码登陆远程仓库来认证）。 SSH KEY方式 使用ssh方式添加远程仓库： # 第一次新建项目后指定本地代码关联的远程仓库地址 git remote add origin git@github.com/aisakaki/aisakaki.github.io.git 所有的git仓库都默认使用global的ssh key，存放于home目录下的.ssh文件夹 ssh key配置一对秘钥（本地私钥，远程仓库如github放私钥），这样就本地和远程就能验证身份，通过身份认证就可以进行push pull等各种远程操作 生成ssh key（默认生成ssh-key到home/.ssh目录下）： #用ssh-keygen来生成公私钥，后面指点非对称加密算法和署名 ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" #可以在后面添加参数如-f C:\\Users\\htt20\\.ssh\\test\\new-rsa来指定生成秘钥储存在哪个文件 #不指定就默认用户目录下的.ssh文件夹下，如果自命名又不指定路径就储存在用户根目录下 #若未用-f指定enter后，可以自己命名储存秘钥文件的名字 Generating public/private rsa key pair. #&lt;-到这里稍等一下，别急着回车 Enter file in which to save the key (C:\\Users\\htt20/.ssh/id_rsa): newName-rsa #&lt;-这就指定新公私钥储存的名字 会生成公钥id-rsa.pub和私钥id-rsa，然后将公钥存放在github远程仓库配置中即可。 【多ssh key怎么配置】：即“同一台主机多个git账户”，就需要 ①生成多个ssh key ，②然后配置 ~/.ssh/config 或~/.gitconfig来管理③使用局部邮箱用户名配置 依然是用上面ssh key生成方法，不过注意新生成ssh key不能重名（要么-f指定新生成在哪，要么自己改名） 修改~/.ssh/config或~/.gitconfig文件 #~.gitconfig文件内容、 #-----------------------------------------------------------------------# #git account1 Host github.com HostName github.com IdentityFile ~/.ssh/home_rsa #git account2 Host github.com HostName github.com IdentityFile ~/.ssh/lab_rsa 私钥位置记录在config中，公钥都记录在远程仓库配置中。写了配置，多ssh key就可以生效了。 具体不同的git使用哪个ssh，是在添加远程仓库语句：git remote add origin git@github.com/aisakaki/aisakaki.github.io.git中绑定的。 如果配置过global邮箱和用户名，就必须先取消 # 取消全局邮箱和账户名配置 git config --global --unset user.name git config --global --unset user.email # 在每个项目目录，新建仓库的时候，单独使用局部配置，不指定global参数 git init git config user.name \"aisaka_home\" git config user.email aisaka_home@gmail.com ssh key和depoly key的区别：ssh keys拥有最高权限，可以管理所有仓库（项目）；depoly key是这个仓库的专有key，只能操作这个项目 一样在本地创建公私钥，然后ssh key的话是将公钥添加在github账号设置里，而depoly key是添加在项目仓库的设置里 HTTPS方式使用https方式添加远程仓库： #和ssh方式区别在于后面url不同 git remote add origin https://github.com/aisakaki/aisakaki.github.io.git 连接远程仓库的时候，输入账号和密码登陆远程仓库（就是github的账号密码），省去了本地配置的麻烦，只要有URL和相应的权限便能进行相应的操作。但每次连接都要输入账号密码。 可以参考git http/https方式储存密码来记住账户密码 windows有GUI的git，如果使用HTTP方式会记住并自动输入github的账号密码进行认证 HTTPS方式只能public GIT配置&amp;操作流程步骤（SSH方式）HTTPS方式就不需要配置SSH KEY，并且制定远程仓库的url的协议标识修改一下 配置ssh key ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" 单ssh key情况，多情况需要建立多个并写config 新建远程仓库并配置ssh公钥 github网页上进行 设置全局邮箱和用户名（如果需要） git config --global user.name \"Your Name\" git config --global user.email \"email@example.com\" 新建本地仓库 ======从这里开始的操作就是在项目文件夹目录下进行操作了====== #进入目标项目的文件夹 git init 设置局部邮箱和用户名（如果需要，多ssh key情况） git config user.name \"Your Name\" git config user.email \"email@example.com\" clone项目到本地（如果需要。注意这里要先init，再clone） git clone https://github.com/aisakaki/aisakaki.github.io.git 添加远程仓库 # 添加远程仓库 git remote add origin git@github.com/aisakaki/aisakaki.github.io.git 【origin】：origin是一个名字，它是在你clone一个托管在Github上代码库时，git为你默认创建的指向这个远程代码库的标签。你也可以改名叫其它名字，比如aisakagit，都OK的，下面你用这个仓库的时候就用aisakagit你取的别名 【这个origin就是远程仓库git@github.com/aisakaki/aisakaki.github.io.git的别名】 开始各种GIT操作 P.S. 邮箱和用户名 为什么git需要配置邮箱和用户名呢？因为远程仓库里需要记录提交记录是由谁来完成的，只是个署名，这里的邮箱和用户名并没有身份验证作用！。 git config --global user.name \"Your Name\" git config --global user.email \"email@example.com\" # （多ssh key情况不能带上global参数） origin&amp;master远程仓库名字 “origin” 与分支名字 “master” 一样，在 Git 中并没有任何特别的含义，原因仅仅是它的广泛使用。 origin 是当你运行 git clone 时默认的【远程仓库】名字。 如果你运行 git clone -o booyah，那么你默认的远程分支名字将会是 booyah/master。 master 是当你运行 git init 时默认的【起始分支】名字 所以master就是local branch（本地仓库默认分支），origin/master是remote branch（远程仓库默认分支） 默认分支即主分支 #eg，这里就用了默认仓库别名origin和默认主分支名master git remote add origin 远程仓库url #origin你改成其它的名字也是OK的，下面push的origin跟着改 git push -u origin master P.S.后面&lt;远程仓库别名（默认origin）&gt;写得太累赘了，可以直接看作origin，因为一般都是取origin的 分支分支是什么？分支就相当于是一个原来完整代码的一个副本，完全由你自己独占，修改当前分支不会影响另一个分支，就像一个平行宇宙一样（但git的分支实现方式并不是直接复制一份，而是版本组成一颗多叉树，见下）。 默认分支是主分支master，主分支是init git 的时候就默认创建的。 分支有什么用？当你修改完后，可以选择将此分支再合并到原分支（这样一来就方便管理和修改，也避免了如果在原分支上修改，修改了一半push之后别人没法使用，因为代码没写完） GIT分支实现原理：git分支的理解 实际上，git的操作会构成一个版本链（每commit提交一次，就生成一个版本，会记录修改），分支实现的实质是指向版本链上的指针，默认分支master即是指向版本链上的master指针（见上文理解）那么在进行git操作的时候，版本链新增一个版本，然后当前分支下的分支指针后移，如果多个分支都被修改，那就会出现分叉了 【不同分支的版本链组成了一个多叉树，分支指针指向当前分支的最新版本】。分叉口即为分支修改出现不同的地方，如果仅仅是修改了一个分支，那是不会分叉出去的，原未被修改的分支还是指向原来新分支之前那个版本链位置，这时候的分支合并即为快速合并：直接将master指针指向当前分支指针位置。如果两个分支都修改了，那么git就会尝试将各自的修改合并起来（合并两个版本），如果出现冲突，那就需要手动解决冲突。 HEAD指针指向当前版本 GIT操作详解重点记忆加粗命令 本地基本操作 暂存（add） git add file git add . 提交（commit） git commit # 注释换行，单引号开始结束 git commit -m ' > line1 > line2 > line3 ' 可以多次向暂存区add，commit则是一次将暂存区所有内容提交到仓库 查看操作记录 # 查看所有已提交的版本信息 git log # commit后跟的就是commit-id # 还有其它相关信息比如日期、提交注释等 # 可以查看所有分支的所有操作记录（包括已经被删除的 commit 记录和 reset 的操作，结合下面reset指令可以撤销回退） git reflog 回退到某个版本 可以回退到老版本（查log），也可以回退到新版本（查reflog） git reset --hard &lt;commit-id> 查看文件状态（是否跟踪） 跟踪指的是commit提交的时候会提交这些add的文件，实际上就是查看暂存区哪些文件被add了。和本地分支跟踪远程分支的跟踪不是一个意思 git status # 被跟踪：tracked # 未被跟踪：untracked # 忽略：ignored，即.gitignore下的 撤销add git reset HEAD 撤销上一次add的所有文件 git reset HEAD file 撤销file 放弃修改 放弃未暂存（add），未提交（commit）的修改 # 放弃单个文件的修改 git checkout filename # 放弃当前目录下的修改 git checkout . 分支操作 创建分支 git branch newBranch 切换分支 # 切换本地分支 git checkout newBranch 查看分支 # 本地 git branch # 本地分支及追踪的远程分支 # 所谓本地追踪的远程分支，就是push -u指定的本地分支对应远程分支的关系，或者创建并切换远程分支指定的 git branch -vv # 远程 git branch -r # 本地+远程 git branch -a 带星号的是当前所处分支 合并分支 git merge newBranch git merge合并当前分支到master分支上 如果master分支未修改，那么执行的是快速合并，见上分支一节 如果两个分支都修改了，那么git将试图合并两个版本 如果合并两个版本的时候发生冲突，就需要手动处理冲突 删除分支 git branch -d newBranch 创建并切换分支（12合并写法） # 本地 git checkout -b newBranch # 远程：将远程分支拉到本地的一个新分支 git checkout -b newBranch 仓库别名（一般origin）/远程分支名 # 经过这个命令之后，会形成本地分支-远程分支的追踪关系 重命名分支 git branch -m oldName newName 查看本地分支与远程分支差异 git diff --stat &lt;localBranch> &lt;远程仓库别名(默认origin)>/&lt;remoteBranch> 远程操作 推送（push） # 将本地分支推送到远程 【-u表示默认，下一次推送就会默认使用后面的参数】 git push -u &lt;远程仓库别名(默认origin)> &lt;本地分支名>:&lt;远程分支名> # 经过这个命令之后，会形成本地分支-远程分支的追踪关系 eg: git push -u origin master:master #这里本地和远程分支都是默认的master #【第一次push使用-u之后就建立了跟踪关系，以后再推送就只需要如下简写，就会默认采用之前的设置】 git push 拉取并合并（pull） pull=fetch+merge git pull &lt;远程仓库别名（默认origin）> &lt;远程分支名> 拉取（fetch）（不合并） git fetch &lt;远程仓库别名（默认origin）&gt; &lt;远程分支名&gt; 重新设定远程仓库（仓库级别）： # 当代码库远程迁移后，重新设定本地代码关联的远程地址 git remote set-url origin git@github.com/aisakaki/aisakaki.github.io.git 添加远程地址（仓库级别） git remote add &lt;远程仓库别名（默认origin）> &lt;url（https方式 or ssh方式）> 删除本地指定的远程地址（仓库级别） git remote remove &lt;远程仓库别名（默认origin）> 查看远程仓库信息 # 列出远程分支 git remote # 列出远程分支详细信息，在每一个名字后面列出其远程url git remote -v # 更详细了。。 git remote -vv GITHUB设置分支PUSH权限 ① 管理员身份登录GitHub，找到项目②Settings—&gt;Branches—&gt;Protected branches—-&gt;Choose a branch… ，选择需要保护的分支，然后点击edit按钮，③Branch protection for 所选的分支名 —&gt; 勾选Restrict who can push to this branch People and teams with push access若不选择任何人，则任何人都没有push代码到该分支的权限。 测试链接（git方式） 测试本地的私钥能否与我账户中的公钥认证 ssh -T git@github.com 常见GIT指令的选项参数-d --delete：删除 -D --delete --force的快捷键 -f --force：强制 -m --move：移动或重命名 -M --move --force的快捷键 -r --remote：远程 -a --all：所有 操作习惯一般我们Git提交都不会直接提交主分支master，先提交到dev分支，没问题，再会合并到master分支。 可以写.gitignore来让git忽略某些文件 常见分支设定： Production分支（主线分支用于发版，不会直接改） Develop分支（开发分支） Feature分支（新功能分支） Release分支（偏向测试） Hotfix分支（紧急bug发布） 底层原理【待更新】暂存区实际上是索引，所以才说是跟踪 P.S. 有些打了&lt;&gt;有些忘打了不要在意细节","categories":[{"name":"工具","slug":"工具","permalink":"https://aisaka.cloud/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"Transformer&BERT","slug":"人工智能/Transformer-BERT","date":"2020-05-29T14:51:54.000Z","updated":"2020-05-29T15:06:05.000Z","comments":true,"path":"人工智能/Transformer-BERT/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Transformer-BERT/","excerpt":"以前的，整理到网站上x3 基于Attention实现，前置文：Attention","text":"以前的，整理到网站上x3 基于Attention实现，前置文：Attention Transformer论文：Attention is all you need Transformer的基础是Self-Attention，集齐了上面一节Self-Attention中的所有东西之后，可以召唤Transformer出场了 Transformer是真正双向的，而不像Bi-LSTM那种“假双向” 结构 add是把上一个multi-head attention的[输入]与[输出]加起来，采用了ResNet一样的思想，可以防止像Transformer这种深度结构出现梯度弥散问题 norm指的是layer normlization与batch normalization不同，layer normalization一般搭配RNN/Transformer BN是一个batch里的不同向量的同一维度做标准化 LN是一个batch里的同一向量的所有维度做标准化 Feed forward层【-】 Masked Multi-head Attention：在Decoder中，我们输入masked就是输出层在计算第$j$个词与其他词的attention时，只考虑$j$前面的词，因为$j$后面的词我们不知道是什么，所以我们要把后面的位置给mask掉 注意Decoder的Multi-head Attention的输入，$K,V$来源于Encoder中最顶层Transformer中的$K,V$ 此时这个$K,V$已经编码了input中的信息，以$key-value$形式，而$query$来自于decoder的上一个输入（从起始符开始），就相当于是一个”查找最可能的输出“的过程。 这种attention叫encoder-decoder attention 注意Transformer是怎么训练的【-】 例子 每个Encoder的输入首先会通过一个self-attention层，通过self-attention层帮助Endcoder在编码单词的过程中查看输入序列中的其他单词。 图中灰色部分重复很多次 不突出细节的结构图： Transformer [预测]过程动图： Transformer-XLAPIpytorch中包含对Transformer的支持，nn.Transformer模块，也可以单独使用nn.TransformerEncoder和nn.TransformerEncoderLayer，nn.TransformerDecoder和nn.TransformerDecoderLayer torch.nn.Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation='relu', custom_encoder=None, custom_decoder=None) #默认参数 具体代码实现看源码 BERTBERT 的创新点在于使用了 Transformer 用于语言模型，Transformer是真正双向的，而不像Bi-LSTM那种“假双向” 论文中介绍了一种新技术叫做 Masked LM（MLM），在这个技术出现之前是无法进行双向语言模型训练的 预训练中Word2vec,ELMO,GPT与BERT对比堆叠Transformer（有Multihead Attention），像CNN一样层层提取特征，逐层（Encoder）提取高级语义 而word2vec只有一层隐藏层 左为BERT 可以看出：BERT解决了ELMo无法双向问题，替换了ELMo中的LSTM为更优越的Transformer GPT是单向Transformer 预训练上面的网络结构是Google预训练的 Pre-training Task 1#: Masked LM 大部分替换成MASK，少部分替换成其它词，少部分不替换 看能否预测出原词 Pre-training Task 2#: Next Sentence Prediction 因为涉及到QA和NLI之类的任务，增加了第二个预训练任务，目的是让模型理解两个句子之间的联系。训练的输入是句子A和B，B有一半的几率是A的下一句，输入这两个句子，模型预测B是不是A的下一句。预训练的时候可以达到97-98%的准确度。 Fine-Tune略 比较 优缺点word2vec： nlp中最早的预训练模型，缺点是无法解决一词多义问题.ELMO：优点： 根据上下文动态调整word embedding,因为可以解决一词多义问题；缺点：1、使用LSTM特征抽取方式而不是transformer，2、使用向量拼接方式融合上下文特征融合能力较弱。GPT：.优点：使用transformer提取特征缺点：使用单项的语言模型，即单向transformer.BERT： 优点：使用双向语言模型，即使用双向transformer；使用预测目标词和下一句这中多任务学习方式进行训练。 无论RNN LSTM word2vec Transformer BERT，都是在训练词向量，不过RNN LSTM是非预训练的 训练好词向量，嵌入之后，根据具体的任务进行处理 中文改进BERT略","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"损失函数，MLE，MAP，ERM的关系","slug":"人工智能/损失函数，MLE，MAP，ERM的关系","date":"2020-05-29T14:47:31.000Z","updated":"2020-05-29T15:06:24.000Z","comments":true,"path":"人工智能/损失函数，MLE，MAP，ERM的关系/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8CMLE%EF%BC%8CMAP%EF%BC%8CERM%E7%9A%84%E5%85%B3%E7%B3%BB/","excerpt":"以前的，整理到网站上x2","text":"以前的，整理到网站上x2 关系关系：根据ERM的思想需要一个损失函数，而MLE的相反数可以作为损失函数 $L(\\theta)$是极大似然估计MLE，$J(\\theta)$是基于经验风险最小化ERM的损失函数Loss Function 交叉熵损失函数推导下面给出交叉熵损失函数的推导（二分类为例，以MLE方法推导） 对于二分类问题，可以作出如下式子，使该式子最大化的参数$\\theta$即为MLE方法： l(\\theta)=\\prod_{i=1}^N[\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i} MLE：\\arg\\max_\\theta l(\\theta)【【其中，$\\pi(x_i)$即为预测结果（模型输出；输入$x_i$，经过模型之后输出$ \\pi(x_i)$，在损失函数中为一个关于输入$x_i$的函数），$y_i$即为对应的真实标签】】 对于交叉熵损失函数来说，如果最后一层softmax生成概率，那么这个输出需处理为经过阈值后的确定标签 于是我们要让乘法的概率，即最大似然估计（下面这个式子）最大化（以下以像LR的二分类为例） MLE_{P(y|x)}=\\prod_{i=1}^N[\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i}【其中，$\\pi(x_i)$即为预测标签（模型输出），$y_i$即为对应的真实标签】 【这个式子将多分类的多项之积的MLE写成一个式子，当$y_i=1$时，只有$[\\pi(x_i)]^{y_i}$会生效，$[1-\\pi(x_i)]^{1-y_i}$由于指数部分为0使得该子项等于1；反之$y_i=0$时，只有后半部分会生效。】 【于是当比如真实标签$y_i=1$时，左边部分生效，那么$\\pi(x_i)$的输出越小，即输出概率越偏离真实值，MLE整体就越小，而我们就是要在整体样本之上极大化MLE，也就是尽量让输出概率整体接近真实值，此即MLE的意义】 取对数变成： L(\\theta)=\\sum_{i=1}^N[y_i\\log \\pi(x_i)+(1-y_i)\\log(1-\\pi(x_i))]MLR的相反数其等价于ERM方法的损失函数（$m$为mini-batch size）： J(\\theta)=-\\frac{1}{m}L(\\theta)于是定义好了损失函数，根据ERM思想我们想要最小化损失函数，即求使得损失函数极小值下的参数$\\theta$。但往往直接求0导得极值无法做到，因为参数众多无法求解，于是常用牛顿拟牛顿法，梯度下降法解决 以梯度下降法为例，对损失函数用参数$\\theta$求偏导：$\\nabla_\\theta L(\\theta)$，然后在各个$\\theta_i$的方向上梯度下降，这里写总式：$\\theta\\to \\theta+\\nabla_\\theta L(\\theta)$ 其中$\\nabla_\\theta L(\\theta)$这样求: 这里的$h(x_i)$即上面的$\\pi(x_i)$。即输入$x_i$，经过模型之后输出 P.S. 交叉熵还可以从信息论角度推导，通过信息熵相对熵推导出交叉熵 交叉熵标准表达式 H(p,q)=-\\sum p(x)\\log q(x)其中$p(x)$是真实标签，$q(x)$是模型预测 注意一个理解，这里容易混淆，多分类，比如一个手写数字识别，是个十分类任务，0~9共十个类别。 对于识别数字1，神经网络的输出结果越接近[0,1,0,0,0,0,0,0,0,0] 若模型输出为[0.2,0.8,0.34,0.2,0.6,0.7,0.7,0.7,0.6,0.2] （显然这个没有经过softmax层） 那么反应在交叉熵损失函数上，则为：$H(·)=-(0×\\log0.2+1×\\log0.8+0×\\log0.34+0×\\cdots)$ 只有在正确分类上才生效，其它的都不生效 正确的理解这个形式 多层神经网络（MLP）用SGD求损失函数最小化深度神经网络使用交叉熵损失函数也是同理：可以想象对于神经网络来说，其用梯度下降法求导是非常复杂的，因为多层神经网络模型输出的预测函数$h(x_i)$非常复杂，其有非常多的中间变量（隐藏层结点），于是在使用梯度下降法，对$J(\\theta)$求导的时候，其中的子项$\\frac{\\partial h(x_i)}{\\partial x_i}$是个非常庞大的过程，需要根据链式法则逐渐传导回输入层$x_i$，于是就发明了反向传播（BP）算法来便于计算，见以前的文章对BP的理解。 无论是交叉熵还是MSE还是其它损失函数，使用SGD都要涉及对MLP模型的预测输出$\\hat y=h(x_i)$求对输入$x_i$的偏导 Q：交叉熵适合分类问题，MSE适合回归问题回归问题指输入可以是连续的（实数）或无上下界 分类问题使用交叉熵： ①均方误差损失函数一般是非凸函数（non-convex），其在使用梯度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数（二阶导大于等于0）。不过在LR中，交叉熵是凸函数，所以LR中必用交叉熵。而在多层神经网络（MLP）中，交叉熵是非凸函数了。②使用MSE的另一个缺点就是其偏导值在输出概率值接近0或者接近1的时候非常小，这可能会造成模型刚开始训练时，偏导值几乎消失。 当然了，分类问题也是可以使用MSE的，不过因为以上原因效果不好 回归问题使用MSE： 交叉熵的损失函数【只和分类正确】的预测结果有关系（根据前面的推导式子，显然对于分类错误的项，不会生效，直接变为常数项（乘1）），而MSE的损失函数不仅和分类正确的预测结果有关，【还和错误的分类有关系】，所以回归问题不能用交叉熵！ 见上面“交叉熵标准表达式”的例子 MAP贝叶斯学派，最大后验估计 略","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"Attention","slug":"人工智能/Attention","date":"2020-05-29T14:23:08.000Z","updated":"2020-05-29T15:06:15.000Z","comments":true,"path":"人工智能/Attention/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Attention/","excerpt":"以前的，整理到网站上","text":"以前的，整理到网站上 Attention机制 如上图，将Source中的构成元素（输入序列）想象成是由一系列的$$数据对构成，此时给定Target中的某个元素$Query$，①通过计算$Query$和每个$Key$的相似性（相关性），得到每个$Key$对应$Value$的权重系数，②然后将得到的各个权重系数与对应的各个$Value$相乘进行加权求和，即得到了最终的$Attention$数值。所以本质上Attention机制是对Source中元素的$Value$值进行加权求和，即可以将其本质思想改写为如下公式： Attention(Query,Source)=\\sum_{i=1}^{||Source||}Similaity(Query,Key_i)*Value_i$Similaity(Query,Key_i)$也叫Attention Score。在词嵌入空间，两个向量的相似度可以由内积求得，也就是说$query·key$再经过softmax归一化后即为attention权重。 理解思想：以上步骤可以理解为从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息。聚焦的过程体现在权重系数的计算上（$softmax(query·key)$），权重越大越聚焦于其对应的$value$值上，即权重代表了信息的重要性，而$value$是其对应的信息。 也可以理解为是一种软寻址过程（这种寻址会从各个地址根据一定权重取出数据）：$key$是数据地址，$value$是对应地址储存的数据内容，$query$是待查地址，任务目标是查询$key=query$地址所储存的数据。于是先用$query$与每个$key$求相似度，得到每个地址的重要性，然后再对每个地址的$value$进行加权求和，得到最终的$value$值 P.S.1在基于Attention的Seq2Seq任务中，$Key=Value$，即输入的都是句子中每个单词对应的语义编码，具体实践反应在$Key$和$Value$是共享同一个线性层（参数矩阵） P.S.2 Attention Score即$query与key$的相似度，其计算方式有多种，最常用的点积：即$q·k$，还有其它方式，略 P.S.3 求得各输入的$key$与$value$的相似度（Attention Score）之后还要经过一层softmax，做归一化，转化为概率才是注意力权重 应用Attention于Seq2Seq结构无attention的Seq2Seq模型： \\mathbb y_1=f(C) \\mathbb y_2=f(C,\\mathbb y_1) \\mathbb y_3=f(C,\\mathbb y_1,\\mathbb y_2)→→→有attention的Seq2Seq模型（$Source≠Target$，non-intra attention）←←←： \\mathbb y_1=f(C_1) \\mathbb y_2=f(C_2,\\mathbb y_1) \\mathbb y_3=f(C_3,\\mathbb y_1,\\mathbb y_2)在有attention的seq2seq模型中，$C$变成了不同的$C_1,C_2,C_3$就是说：不同输出时刻（输出序列的不同单词）的注意力（对Encoder所编码的语义分配的概率信息）不同。换句话说在生成每个单词$\\mathbb y_i$的时候，原先都是相同固定的中间语义表示$C$会被替换成根据当前生成单词而不断变化的$C_i$。理解Attention模型的关键就是这里。 如何理解Attention？一般在NLP里会把Attention模型看作是[输出Target句子中某个单词]和[输入Source句子每个单词]的对齐（对应概率关系）模型 对于采用RNN的Decoder来说，$query$是Decoder RNN目前时刻的hidden state $h_t$，$Key$和$ Value$是Encoder RNN各个时刻的hidden state $H_1,H_2,H_3,H_4$。 （这个例子使用soft-attention+2RNN seq2seq结构） （接上段话）于是就有：在时刻$i$，如果要生成$y_i$单词，我们是可以知道Target在生成$Y_i$之前的时刻$i-1$时，隐层节点$i-1$时刻的输出值$H_{i-1}$的，而我们的目的是要计算生成$Y_i$时输入句子中的单词$x_1,x_2,x_3$对$Y_i$来说的注意力分配概率分布，那么可以用Target输出句子$i-1$时刻的隐层节点状态$H_{i-1}$去一一和输入句子Source中每个单词对应的RNN隐层节点状态$h_j$进行对比，即通过函数$F(h_j,H_i-1)$来获得目标单词$y_i$和每个输入单词对应的对齐可能性，这个$F$函数在不同论文里可能会采取不同的方法。 Non-Intra Attention①源与目标不同，$Source≠Target$ ②$query$来源于输出Decoder部分，$key$来源于输入Encoder部分。如上面例子里用的soft-attention+2RNN seq2seq结构，非self-attention都是decoder里输出的每个Target：$y$作为$query$，encoder的语义编码（隐藏层输出）作为$key$，然后这两做内积求attention 下面三种attention都以Encoder为RNN举例 Soft attention 该图中橘黄色方块就是Decoder部分的当前输出$s_t$，$\\alpha_i$就是注意力权重，$query=s_t$，$Key=h_1,h_2,\\cdots,h_N$，最基本的attention机制，原理很容易理解 上面举的soft-attention+2RNN seq2seq结构例子用的就是用的soft attention 这个“软”指的是每个输入的向量（单词）都会分配一个注意力权重 实践例子：官网DEMO 这个例子用GRU Decoder + soft-attention做seq2seq机器翻译 Hard attention 权重很硬，只在输入句子中找到特定单词，其注意力权重才为1，其它单词的注意力权重都是0 这个“硬”指的就是只有某特定向量权重为1，其它权重全为0，只注意那一个向量；用在图像领域 local attention （半软半硬attention） 只考虑部分窗口内的encoder隐藏输出，其余部分为0，在窗口内和soft attention（global attention）一样 半软：窗口内的是soft attention 半硬：对于指定窗口外的所有输入全部设置注意力权重为0 相比soft(global) attention可以减少计算量 Intra Attention：Self-Attentionintra attention与上面几种attention都不同，是一种特殊的attention： ①【源与目标相同，$Source=Target$】，也就是说一个Self-Attention结构本身就是一个Source输入与Target输出相同的Seq2Seq，如下图 也就是说【self-attention的$query$和$key$都来源于输入句子】，是一种原文自己内部的注意力机制 ②其$Q,K,V$不通过RNN等神经网络产生，而是训练三个嵌入层参数矩阵 这种结构可以完全替代Seq2Seq中Encoder和Decoder中的RNN，变成后面的Seq2Seq with self-attention结构 也是Transformer结构的基础 与RNN和CNN相比 Seq2Seq模型中运用RNN或CNN的问题： RNN难以平行化；CNN虽可以平行化，但是dependent范围比较短，必须通过叠多层来扩大视野域 RNN有长距离依赖问题，当前时间必然受最相邻时间步输入的影响，而以前时间步需要经过若干时间步步骤的信息累积，距离越远，有效捕捉得到的历史信息越少，甚至可能出现梯度消失； 于是提出Self-Attention来完全代替RNN： 一切RNN能做的，都可以用self-attention替代 （也同理，使用预训练word2vec之后，Transformer模型之前也可以nn.embedding嵌入层生成词向量，一起训练嵌入层参数以特化词向量） self-attention的好处： 并行、可以很好捕捉长距离依赖问题（用注意力解决）,它也 摒弃了 CNN 的局部假设，想要寻找长距离的关联依赖。 为什么Self-Attention可以替代RNN 无论是RNN还是CNN还是DNN，还是self-attention，本质都是特征提取器 RNN在每个时刻存在一个隐藏状态，其中包含了当前和以前时刻输入的信息==&gt;其实就是特征提取，同CNN； Self-Attention是直接同时输出所有”隐藏状态”，其中包含通过每一个输出从整句话中获取到的注意力信息=&gt;也是特征提取 于是它们就都可以对隐藏层的输出输入进一个前馈神经网络，执行任务，或用提取得到的特征干其它事情 结构$q,k,v$的含义以及为什么要这么运算：见上面的“Attention的本质“ 由每个输入获取$q、k、v$三个向量 输入$x_i$是已经embedding的词向量 $a_i=Wx_i$每一个输入$x_i$乘以三个不同的权值矩阵$W^q,W^k,W^v$（即线性变换），得到每个输入对应的$q_i、k_i、v_i$。query，key，value(information)。 此操作即对输入进行三个不同的embedding：$x_i$经过三个不同的线性层变成$q,k,v$，其实就相当于再经过了三个不同的词嵌入（embedding，权值矩阵$W^q,W^k,W^v$即不同的词嵌入矩阵）。结合上面的attention本质可以理解为什么要这样。 这个权值矩阵的形状即为： 词表长度 x 目标向量q/k/v维度，得到一维向量$q,k,v$ 然后拿每一个$q$去与每一个输入对应的$k$做点积，得到每一个输入对应一个的$\\alpha$ 这个$\\alpha$就是attention权重，其实质上就是q和k的相似度（点积求相似度） 这里先用第一个$q_1$ $q·k$之后除以$\\sqrt d$，为了防止太大 然后将self attention得到的$\\alpha$经过softmax得到$\\hat \\alpha$ 然后再将softmax输出的$\\hat \\alpha$乘各自的$v$向量，并全部求和，得到第一个$q_1$的self-attention输出$b_1$，也就是第一个输入的self-attention输出结果 下图softmax层没画出来 同理，以上1234都是求第一个输入对应的$q_1$的self-attention输出结果$b_1$，求第二个输入对应的输出就用$q_2$重复上述流程 如下列举第二个$q_2$，softmax层没画出来 可以看到，产生的每个输出，都用到了整个句子所有输入的信息。每个位置所乘的$W^q、W^k、W^v$就是模型要学习的东西。不同单词乘以这个权值参数生成不同的$q,k,v$，体现了”输入序列中不同单词的关注度不一样，具有注意力” $q,k,v$的意义：$q$代表着这一整句话的embedding，$k=v$代表着每个单词的embedding 此时输出的每一个位置的$b$就已经包含了从整句话（输入）中提取得到的注意力信息（特征信息）了 如果再多经过几层，那么提取得到的语义信息将会更抽象 矩阵表达：注意矩阵乘法的左行右列 将上面图中每个位置对应的$q,k,v$组合起来成为矩阵以并行计算： 于是根据上面的流程继续推： 只看$q_1$的1,2步过程（softmax之前，生成$q_1$与每一个位置上的$k_i$的每一个位置上的内积向量$\\alpha_i$），可以如此组合 若看所有输入位置的$q$： 如此便生成了$\\alpha$构成的Attention矩阵$A$，再经过softmax生成$\\hat A$。 再看第4步乘$b$求和，矩阵表达 $O$即最终输出的序列 $Q、K、V$的维度都是$h_{hidden}×l_{src}$ 总结 实际的矩阵乘法表示 全是矩阵乘法，可以方便用GPU加速 $q,k,v$这个过程的意义的补充 主要部分都在Attention机制一节里，这里更具体化一下 通过$q$和$k$进行点积，并通过softmax得到每个词的一个attention权重（归一化，转化为概率），在句子内部做了一个attention，所以称作Self Attention。Self Attention可以刻画句子内部各成分之间的联系，比如说“看”跟“书”之间就建立了联系。这样，每个词的向量表示（$\\hat \\alpha$）就包含了句子里其他词的关联信息。 Multi-head Self-attention多个self-attention，对于一句话（一个输入序列）生成多个$Q、K、V$ 得到多个$O$ 这时候将多个$O$整合（可以求平均(多个head的期望），etc） Multi-head Self-attention的意义：每个head（即一个完整的attention）的关注点不一样（即每个attention生成的$Q、K、V$不一样），于是多个attention组合起来就可以从“多个角度”去匹配输入句子中不同的模式 注意区别，单个attention与multi-head attention： 一个attention能够学习到输入序列的一种模式：即每个时刻的输出对输入（整句话）的“注意点”都不同，输入序列到每个输出时刻识别出一种模式，最终多个输出构成一个序列 多个attention就能够学习到输入序列的多种模式：每个输出时刻识别出多种模式，最终多个时刻的多个输出构成多个序列 Positional Encoding在self-attention中没有编码输入单词的相对位置信息如句子$i_1,i_2,i_3,i_4$中，$i_1$与$i_2$相邻，$i_1$与$i_4$相隔很远，这种信息就没有编码进去。 具体实现有两种方式，一种是Facebook版本：《Convolutional Sequence to Sequence Learning》，另一种Google版本：Postional Encoding，两种效果没有差别。 将输入[经过一个嵌入层]再[加上]一个位置向量$e^i$再乘以权值矩阵 这个位置向量是每个位置独有一个的，不是从数据中学习到的 位置向量$e^i$生成：由编码位置信息的one-hot向量$p_i$乘上词嵌入矩阵$W^P$得到的。这个$W^P$是人为设定的，就是原论文中sin，cos公式所表达的矩阵： 当然这个$W^p$也可以直接随机初始化让模型来学习 为什么要用这个公式的一种理解是：如何理解Transformer论文中的positional encoding，和三角函数有什么关系？ - 徐啸的回答 - 知乎 （mark） 【O】Seq2seq with Self-Attention将Seq2Seq模型中Encoder和Decoder全用self-attention代替 注意力允许解码器网络针对解码器自身输出的每一步“聚焦”编码器输出的不同部分。 实践Pytorch.nn中已经实现Multi-head Attention torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None) attention的实现实际上就是从原理上来实现，本质就是在线性层（参数就是个矩阵）基础上多了一些（一堆）变换，训练attention就是训练该线性变换层的参数矩阵 而self-attention由于有三个参数矩阵，输入经过了三个不同的线性层，要训练的就是这三个线性层的参数矩阵 具体实现见源代码 Attention机制+Encoder Decoder结构不仅在NLP（在NLP已成标配），在很多领域都有大量应用，如图像描述等","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"JAVA容器","slug":"程序语言/JAVA容器","date":"2020-05-29T14:12:54.000Z","updated":"2020-05-29T15:06:55.000Z","comments":true,"path":"程序语言/JAVA容器/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA%E5%AE%B9%E5%99%A8/","excerpt":"容器相关源码阅读笔记 ，未完待续","text":"容器相关源码阅读笔记 ，未完待续 线程安全在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染，无法运行，死循环等意外情况 上面举例了hashmap为什么线程不安全（两个原因） 而其它容器，比如arraylist也是线程不安全的：https://www.cnblogs.com/maoyali/p/8805975.html是因为**无法保证add等操作的原子性，导致数组越界等问题。**（比如add要先判断容器空间是否足够，和hashmap的b原因一样） Hashmaphashmap详解 源码解析【】：https://www.jianshu.com/p/4aa3bb16f36c https://my.oschina.net/muziH/blog/1596801 ①hashmap通过hashcode()找到目标在数组中的存储位置（桶），再根据equals()方法从该位置上的链表中取出目标【用hashcode算出目标在散列表哪个位置，通过equals在该位置的链表（红黑树）上一一进行比较，hashcode相同也就是hash冲突，所以要串在后面的链表/红黑树上】插入的时候，就是插入在散列表对应位置的链表/红黑树里（链表的话，串在最后一位后面） ②默认的equals方法比较自定义的对象比较的是地址，hashcode也是默认将对象的地址拿去hash，所以要将自定义对象加入hashmap的时候是要用hashcode和equals来判断对象是否相等的，这个时候就要想清楚了要不要重写hashcode和equals（不重写，那hashmap判定两个对象是否相等就是地址相等才叫相等） P.S.使用==，eqauls比较两个自定义对象默认比较地址（==不可重写，eqauls可重写） ③注意：hashcode()和equals()都是Object对象的方法（hashmap只是使用了要hash的Object的这两个方法）。且，重写了eqalus()就必须重写hashcode()（因为是先判断hashcode()，再判断eqauls()） 重写示例： class Key &#123; private Integer id; public Integer getId() &#123; return id; &#125; public Key(Integer id) &#123; this.id = id; &#125; @Override //这里我让hashCode方法返回该对象内部的变量id的hashCode，也就是说，你hashmap在hash我这个对象的时候，实际上是hash的变量id！而不是默认的这个对象的地址 public int hashCode() &#123; return id.hashCode(); &#125; @Override //这里就是比较本对象与传入对象是否相等的具体方法了（hashcode可能导致冲突，不够，还得equals定义具体的比较方法） public boolean equals(Object obj) &#123; if (obj == null || !(obj instanceof Key)) &#123; return false; &#125; else &#123; return this.getId().equals(((Key) obj).getId()); &#125; &#125; &#125; ④hashmap的rehash 当散列表（list）被填的越满，冲突概率越高，当超过一个负载因子后，就会resize。resize开销很大，扩大一倍，需要重新计算hash。 hashmap可以使用HashMap(int initialCapacity, float loadFactor)来指定初始容量和负载因子，根据自己的需求设置 hashmap默认初始容量为16，默认负载因子为0.75 hashmap长度必须为2的幂（为了hash均匀，hashcode/长度映射到hash表里，这个长度-1最好是全1，（0开始）也就是1000就ok，也就是2的幂次） ⑤线程不安全 a. 但rehash会遇到问题——线程不安全：多个线程同时对hashmap进行rehash扩容的时候，存储在链表中的元素的次序会反过来（transfer函数转移的时候是逆序转移的，比如1-&gt;2-&gt;3 rehash到新链表就成了3-&gt;2-&gt;1）。【所以如果条件竞争发生了，rehash就会产生环形链表，那么就死循环】了 https://www.cnblogs.com/laojiao/p/9622058.html b.另一方面，如果多个线程同时put数据到同一个位置，会导致某线程put的数据被立即覆盖（线程1判断该位置没有后打算put了，但被线程2给插入了，也就是【无法保证put等操作的原子性】，数据不一致） 【因为如此，才引入了ConcurrentHashMap，其是线程安全的】（ConcurrentHashMap替代hashtable，hashtable也是线程安全的，但它是全表加锁，而前者锁细化，所以效果好） ⑥hashmap在链表长度超过8的时候会转为红黑树 随机哈希代码下，桶中的节点频率遵循泊松分布，超过8的概率很小（基于概率统计得出） https://blog.csdn.net/fst438060684/article/details/89716554 ArrayListhashset 加速比较的办法同hash join 比如要在list a中找list b共有的元素 可以将list b全部求hash到一个set中 然后遍历list a，求hash(a)判断a是否在set中 hashmap计数的思想！特别是对于重复元素，hashmap非常有效 StringBuider、StringBuffer区别（无关）StringBuffer是线程安全的，所以使用效率比stringbuilder低一些StringBuilder是单线程的，不提供同步","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"操作系统与计算机网络补充","slug":"计算机理论/操作系统与计算机网络补充","date":"2020-05-29T14:02:12.000Z","updated":"2020-09-10T10:26:45.000Z","comments":true,"path":"计算机理论/操作系统与计算机网络补充/","link":"","permalink":"https://aisaka.cloud/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%A1%A5%E5%85%85/","excerpt":"很久以前总结过一次，这里着重突出一些内容","text":"很久以前总结过一次，这里着重突出一些内容 操作系统 死锁恢复 死锁四要素：互斥、占有和等待、不可抢占、环路等待 死锁恢复办法： 撤消进程，剥夺资源 线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁 死锁发生的时候设置随机的优先级；如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。 也可以死锁避免（银行家算法），避免系统进入危险状态 进程间通信 ①管道 ②消息队列 ③共享储存 ④信号量 ⑤套接字 ⑥信号 JAVA线程间通信 ①volatile ②Object的wait()和notify() ③JUC的CountDownLatch ④JUC的各种锁 ⑤管道 ⑥信号量 内存泄漏和内存溢出的区别 内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现 out of memory； 内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。 局部变量 局部变量的生命周期是在一个大括号内，即一个所处块结束。 所以循环内、方法内定义的变量都是局部变量。他们都虚拟机栈中（一层循环/一次方法调用使用一个栈帧，即栈的一格）。 （循环不会导致栈溢出，因为每一层循环入栈之后，该层循环结束就销毁） 局部区域可以引用到全局变量，外部区域无法引用局部变量（内部括号可以识别外部括号的变量，所以不能在局部区域定义一个和外部变量一样的变量。但是外部环境不认识局部变量，局部环境内定义的局部变量的生命周期随局部环境（栈）的释放而释放。） 【循环或方法内创建的对象，也是储存在堆中，而引用才是储存在栈中，java里没有局部对象，凡是new创建的对象，都是在堆中】 栈溢出：StackOverflow 栈过深（递归深度太大） 局部变量过多 （数组、List、map数据过大：这些结构里存放对象的引用，引用过多，实际上和2条一样，也是局部变量过多导致栈溢出） 进程和线程有什么区别 根本区别：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位 在开销方面：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 所处环境：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行） 内存分配方面：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。 包含关系：没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 协程 协程（Coroutines）是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程 协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。协程仅仅是一个特殊的函数，协程与进程和线程不是一个维度的。一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。协程与进程一样，切换是存在上下文切换问题的。协程的切换者是用户（编程者或应用程序） 计算机网络 IPV4是32位（4B），IPV6是128位（16B） socket 套接字可以看成是两个网络应用程序进行通信时，各自通信连接中的一个端点。通信时，其中的一个网络应用程序将要传输的一段信息写入它所在主机的Socket中，该Socket通过网络接口卡的传输介质将这段信息发送给另一台主机的Socket中，使这段信息能传送到其他程序中。因此，两个应用程序之间的数据传输要通过套接字来完成 socket有三种类型： SOCK_STREAM：即TCP，工作在传输层，进程之间通信（IP＋端口），需要先建立连接，保证数据的完整性和有序性，有分包机制，有流量控制机制SOCK_DGRAM：即UDP，工作在传输层，进程之间通信（IP＋端口），无连接，不保zd证数据完整性，不保证有序性，有分包机制，无流量控制机制SOCK_RAW：即IP，工作在网络层，主机之间通信（IP），无连接，不保证数据完整性和有序性，无分包机制，无流量控制 socket调用流程： bind()绑定本地地址，connect()建立连接，listen()等待连接，accept()接受连接请求，send(),recv(),dendto(),recvfrom(),close() 分为阻塞模式和非阻塞模式，非阻塞要使用select() 更多相关：https://www.jianshu.com/p/066d99da7cbd 多路复用机制：https://www.jianshu.com/p/397449cadc9a TCP和UDP的区别，什么时候使用谁，哪些用了TCP哪些用了UDP？ TCP是面向连接的，UDP是无连接的 1、基于连接与无连接； 2、对系统资源的要求（TCP较多，UDP少）； 3、TCP保证【数据正确性】，UDP可能丢包； 4、UDP更保证即时性 5、TCP保证数据【顺序】，UDP不保证。 6、TCP只能1对1，UDP不限制 7、由于历史的原因，互联网上物理链路的最小MTU = 576，基于UDP传输的DNS为了限制报文不超过576，所以将DNS报文限制在512字节。这样一旦DNS查询应答超过512字节，基于UDP的DNS就只有截短为512字节，那么用户得到的DNS应答就是不完整的。为了克服这种困难，最简单的方式就是使用TCP，来重新查询。但使用UDP同样可以传输远远大于576字节的数据，只要应用程序可以标识数据ID。 UDP使用尽最大努力交付，即不保证可靠交付 https://blog.csdn.net/huanglei305/article/details/99712771 DNS使用TCP or UDP 使用UDP传输是由于效率高，传输小于等于512字节报文。 使用TCP传输是由于可以传输大于512字节报文。 使用签名是保证数据来源的可靠性。 使用TCP传输，同样是可以传输证书链、签名。 使用UDP同样可以传输远远大于576字节的数据，只要应用程序可以标识数据ID。 游戏中使用TCP or UDP 都有 对于实时性要求较高的部分，使用UDP（比如FPS、MOBA，需要低延迟） 其余的可以使用TCP 三次握手，四次挥手，详细状态、过程、参数 1、ACK 是TCP报头的控制位之一，对数据进行确认。确认由目的端发出， 用它来告诉发送端这个序列号之前的数据段都收到了。 比如确认号为X，则表示前X-1个数据段都收到了，只有当ACK=1时,确认号才有效，当ACK=0时，确认号无效，这时会要求重传数据，保证数据的完整性。 2、SYN 同步序列号，TCP建立连接时将这个位置1。 3、FIN 发送端完成发送任务位，当TCP完成数据传输需要断开时,，提出断开连接的一方将这位置1。 状态变化：客户端 SYN-SENT-&gt;ESTABLISHED 服务端：LISTEN-&gt;SYN-RCVD-&gt;ESTABLISHED 状态变化：客户端ESTABLISHED-&gt;FIN-WAIT-1-&gt;FIN-WAIT2-&gt;TIME WAIT-&gt;CLOSED 服务端：ESTABLISHED-&gt;CLOSE-WAIT-&gt;LAST-ACK-&gt;CLOSED 服务端的CLOSE-WAIT状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文 客户端的TIME_WAIT状态是为了确保最后一个确认报文能够到达（如果服务端没收到，会再次重发连接释放报文请求），让本连接持续时间内所产生的所有报文都从网络中消失 TCP头包含哪些信息？三握四挥参数怎么变化？ 几大参数：源端口、目的端口、标记字节流序号[序号seq，确认号ack]，数据偏移量（数据部分offset），状态标志位[同步SYN，确认ACK，终止FIN]，窗口值（不提），校验和（不提） 连接请求报文：SYN=1，ACK=0 连接确认/确认报文：SYN=1，ACK=1 客户端连接释放报文：FIN=1 服务端连接释放报文：FIN=1，ACK=1 注意，发送和接收是两个字节流，所以seq和ack标号也是不同的起点，x，y A-&gt;B seq=x，那B-&gt;A seq=y，ack=x+1，A-&gt;B seq=x+1,ack=y+1 注意：TCP头部有端口信息没IP信息！IP信息是在IP包头中 TCP四大算法 TCP可靠传输（超时重传） TCP滑动窗口（缓存，发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。提高【吞吐量】，【进行流量控制】（下面）；这样就可以发很多包，而不用等确认了） TCP流量控制（接收方的TCP报文中，设置发送方窗口的大小！从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。） TCP拥塞控制（通过各种算法来设定报文段一轮的发送数量。慢开始、拥塞避免；快重传、快恢复） 流量控制和拥塞控制都是控制速率，但不同在于流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。【路由器中包含arp表和路由表，arp表是记录ip地址和mac对应关系，相邻路由器可以看做广播域，路由器也是通过arp知道相连路由器的mac地址】 主机在进行ip地址请求的时候，①先找网关路由器的MAC地址：先通过arp协议找到本地网关路由器（如果有交换机，则该帧到达交换机后由交换机进行广播该arp请求帧），然后网关路由器广播回复arp请求，②然后开始IP请求过程（此时MAC目的地址为网关路由器，IP目的地址为目的IP），网关路由器查路由表判断该ip地址是否属于本网络，如果是本网络，则不会走外网，直接内网ARP协议，MAC直达；如果是外网，就走下一跳（内部网关协议：RIP OSPF或外部网关协议：BGP）。 ARP协议：每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。（本地路由表） 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 【交换器、路由器的区别：交换机工作在链路层，只工作在一个广播域；路由器工作在传输层，连接异构网络，隔离广播域】 路由器工作原理 路由表根据这个数据包的的目的IP，然后查出下一跳的IP地址，然后根答据ARP解析得到下一跳，然后再将链路层封装好，发送出去。 路由器的工作原理 1)HostA在网络层将来自上层的报文封装成IP数据包，其中源IP地址为自己，目标IP地址是HostB，HostA会用本机配置的24位子网掩码与目标地址进行“与”运算，得出目标地址与本机不是同一网段，因此发送HostB的数据包需要经过网关路由A的转发。 2)HostA通过ARP请求获取网关路由A的E0口的MAC地址，并在链路层将路由器E0接口的MAC地址封装成目标MAC地址，源MAC地址是自己。 3)路由器A从E0可接收到数据帧，把数据链路层的封装去掉，并检查路由表中是否有目标IP地址网段(即192.168.2.2的网段)相匹配的的项，根据路由表中记录到192.168.2.0网段的数据请发送给下一跳地址10.1.1.2，因此数据在路由器A的E1口重新封装，此时，源MAC地址是路由器A的E1接口的MAC地址，封装的目标MAC地址则是路由器2的E1接口的MAC地址。 4)路由B从E1口接收到数据帧，同样会把数据链路层的封装去掉，对目标IP地址进行检测，并与路由表进行匹配，此时发现目标地址的网段正好是自己E0口的直连网段，路由器B通过ARP广播，获知HostB的MAC地址，此时数据包在路由器B的E0接口再次封装，源MAC地址是路由器B的E0接口的MAC地址，目标MAC地址是HostB的MAC地址。封装完成后直接从路由器的E0接口发送给HostB。 5)此时HostB才会收到来自HostA发送的数据。 总结：路由表负责记录一个网络到另一个网络的路径，因此路由器是根据路由表工作的。 为什么要划分子网？ 划分子网就是人为地将一个公网IP分成多个子网段，方便管理。就算不划分也可以，不过这个公网IP下的所有计算机都能互相连接而不受限制，那么就不好管理机密数据了。 三个表 路由表是IP地址可达范围的一张表，相当于是网络里的地图，负责三层的数据转发；ARP表示IP地址和MAC地址的逻辑关系表；MAC地址表是MAC地址和交换机接口的逻辑关系表，负责二层的数据转发 MAC不会走出广播域 路由器在要跨网段的时候起作用 一些应用层协议是基于什么底层协议实现的？【继续补充】 DNS（TCP/UDP） FTP（TCP） DHCP（UDP） Ping（网络层ICMP，ICMP封装在IP数据报中），Traceroute（UDP） web请求页面：DHCP-ARP-DNS-HTTP(基于TCP) 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT 内部专用网络要想将内部地址转换为外部地址就需要网络地址转换NAT 虚拟专用网络VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。 VPN会对内部数据进行加密，只有目标路由器才能解密 数据传输单元 应用层——消息 传输层——数据段(segment) 网络层——分组、数据包，包（packet） 链路层——帧（frame） 物理层——P-PDU（bit） HTTP的post和get请求 GET 用于获取资源，而 POST 用于传输实体主体。 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。 安全的 HTTP 方法不会改变服务器状态，也就是说它【只是可读】的。GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 HEAD 获取报文首部 PUT 上传文件 …….（） DNS 权威解析记录，DNS过程 由本地服务器代理，先查根，然后迭代/递归的方式去查顶级，权威 https://jingyan.baidu.com/article/ad310e80e8f6c91848f49e4c.html 一个服务器所负责管辖(或有权限)的范围叫做区(zone) 权限域名服务器：负责一个“区”的域名服务器。 很多情况下，根域名服务器并不直接把待查询的域名直接解析出IP地址，而是告诉本地域名服务器下一步应当找哪一个顶级域名服务器进行查询。 DNS记录类型 A记录：A记录就是服务器的IP，域名绑定A记录就是告诉DNS，当输入域名的时候给你引导向设置在DNS的A记录所对应的服务器。 CNAME记录：别名。这种记录允许您将多个域名映射到同一台计算机。 MX记录：是邮件交换记录，它指向一个邮件服务器，用于电子邮件系统发邮件时根据 收信人的地址后缀来定位邮件服务器 NS记录：Name Server 是一种域名服务器记录，用来明确当前你的域名是由哪个DNS服务器来进行解析的。","categories":[{"name":"计算机理论","slug":"计算机理论","permalink":"https://aisaka.cloud/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"查找算法&图的应用","slug":"算法与数据结构/树-图","date":"2020-05-17T11:09:28.000Z","updated":"2020-05-29T15:14:14.000Z","comments":true,"path":"算法与数据结构/树-图/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91-%E5%9B%BE/","excerpt":"回顾查找算法、图算法","text":"回顾查找算法、图算法 查找算法二叉查找树（BST）对于任何节点 若其左子树存在，则其左子树中每个节点的值都不大于该节点值； 左子节点小 若其右子树存在，则其右子树中每个节点的值都不小于该节点值。 右子节点大 二叉排序树中序遍历可输出从小到大的排序数列 https://www.jianshu.com/p/ff4b93b088eb 操作：查找、插入、删除 查询节点过程：比较元素值是否相等，相等则返回，不相等则判断大小情况，迭代查询左、右子树，直到找到相等的元素，或子节点为空，返回节点不存在。最好O(nlogn)（AVL），最差O(n) 插入节点的过程：比较元素值是否相等，相等则返回，表示已存在，不相等则判断大小情况，迭代查询左、右子树，直到找到相等的元素，或子节点为空，则将节点插入该空节点位置。易错：插入必能插到一个新的空位置上去！（如果没重复） 删除节点过程：1.查找出左子树中的最大值节点 $Node_{max}$2.替换待删除节点 $Node$ 的值为$Node_{max}$的值3.删除 $Node_{max}$节点因为 $Node_{max}$ 作为左子树的最大值节点，所以节点的度一定是 0 或 1，所以删除节点的情况就转移为以上两种情况。 平衡二叉树（AVL）二叉查找树+每一个结点的左子树和右子树的高度差最多为1 （可以规避BST的最坏情况） https://www.jianshu.com/p/3a6650269d39 插入：先按照BST的插入方法插入，然后再进行旋转操作 旋转操作-4种情况： 在根结点的左孩子的左子树上插入，对根结点进行右旋转。 在根结点的右孩子的右子树上插入，对根结点进行左旋转。 在根结点的左孩子的右子树上插入，先对根结点的左孩子进行左旋转，再对根结点进行右旋转。 在根结点的右孩子的左子树上插入，先对根结点的右孩子进行右旋转，再对根结点进行左旋转。 插入之后还要调整每个结点的平衡因子 B树即多路平衡查找树，一个结点有多个分叉。 B树相比AVL树高度更低，查询耗时更少 B+树B+树相比于B树：叶子节点有序且串成一串 InnoDB底层数据结构 红黑树红黑树也是二叉树，基于AVL改进，它对平衡的要求没那么严格，使得增删结点旋转次数降低减少开销(红黑树最多需要3次旋转就能回复红黑树平衡），但是不平衡导致高度增加，使得查询次数相比AVL增加。 红黑树是一种对时间和性能的折中，实际使用中，如果搜索次数远大于插入和删除次数，那么选AVL；如果差不多，则旋转RB 红黑树的性质：①每个结点要么黑，要么白②根节点黑③每个叶子节点（null）为黑④每个红色结点的两个子节点一定都黑⑤任意一结点到每个叶子结点的路径都包含数量相同的黑色结点 哈夫曼树哈夫曼树使得带权路径长度最小（一个结点=深度×结点权重） 那么就要将权值最小的结点放最底层（因为底层深度大，所以应该尽量将权值小的放到长路径上） 于是就在所有结点中找到最小的作为叶子节点，然后合并作为中间结点，开始层层向上 哈夫曼树结构固定 哈夫曼编码即是先求出各个字母出现的频率，频率即为结点权值，尽量放深层 Hash算法 hash函数 ①直接定址法：$H(key)=a×key+b$ ②除留余数法：$H(key)=key\\%p$ ③数字分析法 ④平方取中法 ⑤折叠法 冲突处理方法 ①开放定址法：$H_i=(H(key)+d_i)\\%m$，$d_i$为增量序列，$m$为散列表表长 增量序列的取法：线性探测法$d_i=0,1,2,\\cdots,m$、平方探测法$d_i=0^2,1^2,-1^2,2^2,\\cdots,k^2,-k^2$、再散列法（双散列法）$d_i=Hash_2(key)$、伪随机序列法$d_i=random(m)$ ②拉链法 java中hashmap的处理方法，后来冲突链改为红黑树了（当冲突链比较长的时候） KMP【】略 图的应用最小生成树最小生成树：树中所有边权值和最小 Prim算法：以点为中心从顶点开始扩展生成树，生成树不断壮大，加入跟多的节点 设$N=(V,E)$是连通网 初始空集合$G$，点集合$V$，先将任一结点加入集合$G$ 然后选择与集合$G$中相连的点中最短的那一条，连线，将该结点加入集合$G$（一次循环加入一个点） 不断重复上述 时间复杂度$O(|V|^2)$，不依赖于边，所以适合稠密图 伪代码： void Prim(G,T) &#123; T&#x3D;∅; U&#x3D;&#123;w&#125;; while((V-U)!&#x3D;∅) &#123; 设(u,v)是使u∈U与v∈(V-U)，且权值最小的边 &#x2F;&#x2F;这里要用一个内存循环去找 T&#x3D;T∪&#123;(u,v)&#125;; U&#x3D;U∪&#123;v&#125;; &#125; &#125; Kruskal算法：以边为中心按权值的递增次序选择合适的边来构造最小生成树 设$N=(V,E)$是连通网 每一轮循环不断选取当前未被选取的，边集中权值最小的边（不需要像Prime一样必须是已加入集合的结点的邻边），最终没有连通分量为1时候，表明已经生成一棵树 时间复杂度：$O(|E|\\log|E|)$（用堆来存放边集，否则$O(|E|^2)$，适合边稀疏的图 伪代码： void Kruskal(V,T) &#123; T=V; numS=n; //连通分量数 while(numS>1) &#123; 从E中取出权值最小的边(v,u) //一个内存循环 if(v和u属于T中不同的连通分量) //注意这里判断【】 &#123; T=T∪&#123;(v,u)&#125;; numS--; &#125; &#125; &#125; 最短路径基本思想：如果要让任意两点（例如从顶点a点到顶点b）之间的路程变短，只能引入第三个点（顶点k），并通过这个顶点k中转即a-&gt;k-&gt;b，才【可能】缩短原来从顶点a点到顶点b的路程 Dijkstra算法【1】思想：广度优先搜索+贪心算法，每轮找最优解，局部最优最后达到全局最优 【数学原理：一条最短路径上的任意结点到原点的距离都是最短的】。（证明略） 核心步骤：广度优先遍历，每轮找到距离最小的那条路，计算出来比原来不走这条路小则更新；每一层遍历选择出距离最小的走法那个结点，再次进行下一层广度优先遍历。 实现需要：①邻接矩阵 ②$S$数组（储存已访问节点）③$dist$数组（储存起点到目标节点的当前最短路径；可以直接将邻接矩阵第一行作为dist数组）④$path$数组（path[i]表示源点到结点$i$的最短路径的前驱结点，可用此追溯路径） 时间复杂度：$O(|V|^2)$ 如果是找某点到特定终点的最短路径，那就只能先计算所有点到该终点的最短路径，再找最短的，需要$O(|V|^3)$ Dijkstra 算法不能处理带有负权边的图，有负边就不能保证局部最优可以使得全局最优了。 伪代码与理解： 1~4：初始化，起点加入已访问数组，当前结点为源结点，记录第一跳的最短路径dict值（这里源结点的dict初始化可以放在下面的循环里）（当前结点指当前访问的结点） 5：当还有结点未被访问，继续循环 ——6：从最短路径$dist$中找到当前结点到其它结点最短路径对应的结点$j$（且未被访问） ——7：结点$j$加入已访问数组，当前结点变为结点$j$（我们判断要不要经过这个点，这就是最开始那个原理） ——8~10：将经过当前结点$j$到各结点的距离更短的距离值更新进dict，更长的不更新；同时更新path也是同理，如果途径当前结点距离更短了，则前驱结点变为当前结点，否则不更新 （然后注意，循环到下一层的6中，是在所有最短路径dist里找最短，有可能未更新的是最短的，所以下一轮依然会从未更新的结点继续选择，上一个当前结点访问后没有加入路径！ 注意一个误区：从源点到某个结点的最短距离并不一定需要包含所有结点！最短路径问题并不是要求把所有结点串起来成一条路径求最短！ 代码实现【】：https://blog.csdn.net/u011638883/article/details/17200869 Floyd算法【2】基于开头的基本思想：如果要让任意两点（例如从顶点a点到顶点b）之间的路程变短，只能引入第三个点（顶点k），并通过这个顶点k中转即a-&gt;k-&gt;b，才可能缩短原来从顶点a点到顶点b的路程 那我们直接一个个去试不就好了？ 三个for for(k=1;k&lt;=n;k++) //k设定为途径结点 for(i=1;i&lt;=n;i++) for(j=1;j&lt;=n;j++) if(e[i][j]>e[i][k]+e[k][j] ) e[i][j]=e[i][k]+e[k][j]; 理解：https://www.cnblogs.com/wangyuliang/p/9216365.html 不允许负权值(带有“负权回路”的图没有最短路) 拓扑排序 定义： 由一个有向无环图（DAG）的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序： ①每个顶点出现且只出现一次 ②若顶点A排在顶点B前面，则在图中不存在从顶点B到顶点A的路径 拓扑排序算法： ①从DAG图中选择一个没有前驱结点的顶点输出 ②从图中删除该顶点和所有以它为起点的有向边 ③重复①②直到当前的DAG图为空（输出成功）或不存在无前驱的结点（无拓扑排序，必存在环）为止 代码实现：（使用栈实现） ①将所有入度为0的顶点入栈 ②若栈非空，顶点出栈，将所有该顶点指向的顶点入度-1，并将入度减为0的顶点压入栈中 ③如此循环直到结束，检查是否输出所有顶点，是则ok，不是则无拓扑排序 拓扑排序的应用：关键路径在带权有向图中，顶点表示事件，边表示活动，边的权值表示完成事件的开销=&gt;AOE网（用边表示活动的网络） ①只有某顶点所代表的事件发生后，从该顶点出发的各有向边才能开始活动 ②只有在进某一顶点的各有向边所代表的活动都已结束时，该顶点所代表的事件才能发生 完成整个工程的最短时间就是关键路径的长度 AOE网中仅一个入度为0的顶点：开始顶点（源点） 仅一个出度为0的顶点：结束顶点（汇点） 此类题的解决办法：拓扑排序 【】","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"HTTPS","slug":"网络与云/HTTPS","date":"2020-05-16T16:26:12.000Z","updated":"2020-06-28T14:01:00.000Z","comments":true,"path":"网络与云/HTTPS/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/HTTPS/","excerpt":"CA、公私钥体制、证书、HTTPS","text":"CA、公私钥体制、证书、HTTPS 认证权威（Certificate Authority）专门负责管理和签发证书的第三方机构 一般浏览器、电脑、手机里都会有一批受信机构的根证书 公私钥加密公私钥加密体制属于非对称加密，即加密和解密算法不是同一个秘钥，分为公钥私钥（公可解私、私可解公、自己不能解自己） 公私钥对由RSA算法生成 加密：加密算法+公钥，对内容进行加密，得到密文。 解密：解密算法+私钥，对密文进行解密，得到明文。 生成一对公钥和私钥，公钥和加密算法对所有人公开，私钥保密 只有私钥持有者才能解密。 公钥私钥还可以做数字签名，私钥加密后的内容就是数字签名。其目的是确保发送数据未被修改。发送方用私钥来加密数据，接收方用公开的公钥来解密，如果解得看就说明一定是我发的，因为只有我才有私钥 但是会遇到问题，如果有人偷换了你原本交流对象的公钥成它的公钥，然后私自发送他私钥的数字签名给你，那你拿到后用被偷换的公钥就能解开，就还以为是原来那个人给你发的数据，但这时候实际上已经被冒充了 所以才需要权威机构CA来生成作为证书中心，为公钥做认证，保管那些受认证的公钥，人们只新人权威机构保证了的公钥，阿猫阿狗的未被权威机构认证的公钥不被别人信任 数字证书与下面CA证书结构一样，只是泛指，不一定由CA签发，非CA签发的证书就叫不受信任的证书 http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.html CA证书CA证书即由CA机构签发的证书，包含以下信息： 证书的发布机构 证书的有效期 公钥 证书所有者（Subject）：即发布给谁 签名所使用的算法：数字证书的数字签名所使用的加密算法 指纹以及指纹算法：用于保证证书完整性，指纹算法是一个hash算法，即发送和接收的时候用同样的hash算法看是不是一样的 SSL证书：由受信任的CA机构颁发的，遵守SSL协议的数字证书 SSL证书需要申请，为你的网站申请了SSL证书之后，【CA机构就等于为你的公钥进行了信用担保，这个公钥一定是正确的，不会被别人偷换仿冒】，就可以和访问网页的客户端使用HTTPS方式进行通信。 证书信任链CA机构签发根证书A，证书A信任证书B，证书B信任证书C..这条链都可以被信任，叫证书信任链。如果根证书不可信，那么这条链将变得全部不可信。 HTTPS：HTTP over SSLHTTP使用端口80基于TCP/IP协议进行通信，是明文传输，不安全，容易被窃听、伪装、篡改 HTTPS协议（443端口）使用SSL在发送方把原始数据进行加密，然后在接受方进行解密，加密和解密需要发送方和接受方通过交换共知的密钥来实现。SSL在传输层对网络连接进行加密 以下即为基于SSL协议的HTTP通信方式 客户端向一个需要https访问的网站发起请求 服务器向客户端发送用自己的私钥加密后的网页+数字证书（包含公钥） ①【公钥是否受信验证-防伪装】：客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看数字证书内的公钥是否受信任（是否在信任链上）。如果没有权威机构对证书（公钥）进行担保，那么这个公钥就有被仿冒伪装的风险，你拿到的公钥可能不是他的公钥。（提示未受信任的证书） ②【证书未被篡改验证-防篡改】：用公钥对服务器证书的指纹和指纹算法进行解密；然后用指纹算法对服务器证书的摘要进行计算得到指纹，将计算出的指纹和从服务器证书中解密出的指纹对比看是否一样，如果一样则通过认证（否则，说明证书被篡改） ———-SSL证书认证完成，③【开始对称加密通信-防窃听】———- 校验成功之后，客户端会生成一个随机串然后使用服务器证书的公钥进行加密之后发送给服务器 服务器通过使用自己的私钥解密得到这个随机值，服务器从此开始使用这个随机值进行对称加密开始和客户端进行通信。 客户端拿到值用对称加密方式 使用随机值进行解密 ①②③即为HTTPS的目的，这些都HTTP做不到的","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"MySQL零散知识","slug":"数据库与中间件/MySQL","date":"2020-05-16T02:29:36.000Z","updated":"2021-04-08T13:49:46.805Z","comments":true,"path":"数据库与中间件/MySQL/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/MySQL/","excerpt":"MySQL日志、范式、SQL语句优化、JOIN优化、EXPLAIN","text":"MySQL日志、范式、SQL语句优化、JOIN优化、EXPLAIN MySQL是单进程多线程的 MySQL 采用插件式的存储引擎。存储引擎是针对于表的而不是针对库的（一个库中不同表可以使用不同的存储引擎），服务器通过 API 与存储引擎进行通信，用来屏蔽不同存储引擎之间的差异。 my.ini文件为数据库配置文件 MySQL体系结构 网络连接层 查看连接状态：show processlist; 服务层 连接池、管理服务和工具组件、SQL接口、查询解析器、查询优化器、缓存 SQL语句先查询缓存（一个查找表），没有的话就经过查询解析器、查询优化器 查看缓存情况：show status like &#39;Qcache%&#39; 储存引擎层 插件式储存引擎，默认为InnoDB 调用储存引擎的原子API执行SQL语句，然后返回结果（如需缓存就缓存） 系统文件层 文件系统，数据，日志（redo、undo），索引，错误日志，查询记录，慢查询等 MySQL日志文件Error log（错误日志）：err结尾文件 show variables like '%log_err%'; Slow query log（慢查询日志）：可以设置参数来开启慢查询日志以及慢查询阈值等。默认不开启。主机名-slow.log文件。最好使用mysqldumpslow 来查看 show variables like '%query%'; General query log（通用查询日志）：记录mysql所有操作日志。主机名.log SHOW VARIABLES LIKE '%general%'; binary log（二进制日志）：即bin log，用于数据恢复和主从复制。记录修改数据的语句。主机名-bin.编号 show variables like '%log_bin%'; 在数据目录下，一个database就是一个文件夹，每张表对应一组文件，IBD 文件（独享表，每个表放在一个独自的文件）和 IBDATA 文件（共享表，所有表放在一个文件）存放 InnoDB 的数据文件（包括索引） （共享表碎片化验证，独享表可能占用空间大） ibdata1文件:undo段 pid文件：存放进程id（unix/linux有） socket文件：（unix/linux有） 数据库三范式1NF：字段不可再分（每一列只有单一值，不可再分） 2NF：只有对主键的完全依赖，每一行被主键唯一标识（靠主键能区分出每一行） 3NF：不存在传递依赖（非主键字段只依赖于主键） 三范式只是一个指导，完全按照这样做也会带来问题，比如太多表，以及表关联，外键，带来性能损耗，很多额外开销。所以我们应该平衡范式和冗余 可以通过3范式，1-&gt;2-&gt;3来进行划分 MySQL优化可以从几个角度进行 索引（见MySQL索引） 缓存（见MySQL并发相关原理） SQL语句（见下） 分表（水平、垂直） 范式（属于建库的时候） SQL语句优化禁用储存过程（将它分离到业务层）、储存文件不要太大、平衡范式和冗余、禁止使用外键、建议分离冷热数据 尽量定义为not null并提供默认值、禁用TEXT、根据业务选择char/varcahr 索引不宜过多、禁止在更新十分频繁的属性建立索引、禁止在区分度不高的属性上建立索引、建立联合索引遵循最左原则 禁止以下语句，否则会导致遍历全表：select *、属性隐式转换、where条件属性上使用函数表达式、负向查询、模糊查询、null判断 禁止大表用join（会产生临时表）、尽量用union all代替union（后者有去重功能）、使用limit、尽量使用inner join（默认join，因为inner join会选择较小的表作为驱动表，大表作为被驱动表）、尽量用小表去驱动大表（减少连接次数） 当mysql优化器选错索引的时候，我们可以用FORCE INDEX来强制使用某索引（SQL索引-慢查询-3） 应用程序需要捕获SQL异常并处理 P.S. null还有一些坑：负向查询无法获取null值行，通配符不能匹配到null，group by时null是一个单独分组，count函数会忽略null行，最大的坑还是where x is null会引发全表扫描 （整理自：https://www.yuque.com/yinjianwei/vyrvkf/mpu8gk） JOIN优化select * from user tb1 left join level tb2 on tb1.id=tb2.user_id 【JOIN本质就是在两个list中，找出一样的行】 首先，禁止大表用join（会产生临时表占很大空间）、尽量使用inner join（默认join，因为inner join会选择较小的表作为驱动表，大表作为被驱动表）、尽量用小表去驱动大表（减少连接次数） ①暴力比较方案（Simple Nested-Loop Join）：通过两层循环一一比较驱动表和非驱动表显然开销非常大，要扫描MxN（两表行数乘积次），于是MySQL在此之上进行了优化 ②基于索引优化（Index Nested-Loop）：当被驱动表上有索引时，可以使用索引来减少比较次数：外表（被驱动表）中的每条记录通过内表（驱动表）的索引进行查找访问，由于索引查找开销小，所以速度快。索引如果采用的是主键索引，那么就很快，但如果索引是辅助索引，那就要回表查询（两次IO），那这样就又拖累了join速度 ③基于缓冲优化（Block Nested-Loop）：在暴力比较上进行修改，一次性缓存多条外表数据，把参与查询的列缓存到join buffer 里，,然后拿join buffer里的数据【批量与内层表的数据进行匹配】，这样一个buffer只需要扫内表一次，从而减少了外层循环的次数 所谓批量匹配就是buffer在内表的循环上，每往下一栋一个是一次循环，每次循环进行了连续多次比较，即buffer行和内表对位行的比较，由于每个循环子问题都是拿buffer_size条外表和内表数据进行比较，大大减少了磁盘IO。所以外层循环次数大大减小了，比较次数虽不变但顺序比较变快了 假设外表有1000行，buffer大小为10，那么外循环就只有10轮 所以buffer当然越大越好 MySQL查询优化器算法的选择：如果外表有索引，那就用Index Nested-Loop，否则用Block Nested-Loop（需要开启优化器配置管理的optimizer_switch的设置block_nested_loop为on默认为开启，否则使用暴力，设置join_buffer_size指定buffer大小） 参考：学习Mysql的join算法：Index Nested-Loop Join和Block Nested-Loop Join 未使用的hash方法（也很有效）：Hash join散列连接是CBO 做大数据集连接时的常用方式，优化器使用两个表中较小的表（通常是小一点的那个表或数据源）利用连接键（JOIN KEY）在内存中建立散列表，将列数据存储到hash列表中，然后扫描较大的表，同样对JOIN KEY进行HASH后探测散列表，找出与散列表匹配的行。需要注意的是：如果HASH表太大，无法一次构造在内存中，则分成若干个partition，写入磁盘的temporary segment，则会多一个写的代价，会降低效率。 MySQL查询优化器自动进行几种优化方式，比如 ①语句等价变换，将两个语句合成一个 ②覆盖索引 ③将多级子查询优化成一级查询 ④limit提前终止查询 ⑤对in查询进行排序，然后二分查找。比如in(2,1,3)优化成(1,2,3)，然后第一找了1，发现第二次2&gt;1，那就只找1右边，这样找 等等。 查询优化器基于数据抽样进行试验，成本最低原则，找到最优执行计划 EXPLAIN语句通过EXPLAIN语句可以查看SQL语句的执行计划，并未实际执行 （explain参数见以前的文章） 常关注的有使用了什么索引，扫描了多少行，是否使用索引优化查询算法，是否全表扫描，是否覆盖索引，过滤百分比，可能用到的索引等 数据库设计常用结构水平分片+垂直分组（读写分离） 保证读库的高可用：主从备份，但需要考虑主从一致性问题（同步延时） 保证写库的高可用：双主同步（两个互相同步），但要考虑双主的键冲突问题 然后就一堆分布式问题了。 其它 select * from table_name limit 1; 从表中随机取出一条数据 VARVHAR最大长度是16384，储存app meta够用。CHAR的长度是255。 全双工：双发可以同时发送和接收，半双工：一方发送的时候另一方只能接收，单工：单向通信 InnoDB的优点：支持热备份、ACID事务、支持行级锁、聚类索引方式储存、MVCC非阻塞解决脏读、不可重复读","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"MySQL并发相关原理","slug":"数据库与中间件/MVCC","date":"2020-05-12T13:41:07.000Z","updated":"2021-04-08T12:31:33.808Z","comments":true,"path":"数据库与中间件/MVCC/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/MVCC/","excerpt":"隔离级别、封锁协议、MVCC、快照读、当前读、缓存、redo日志、undo日志、锁","text":"隔离级别、封锁协议、MVCC、快照读、当前读、缓存、redo日志、undo日志、锁 事务四大特性 ACIDAtomicity（原子性）：事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。通过Undo Log实现 Consistency（一致性）：数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。 Isolation（隔离性）：一个事务所做的修改在最终提交以前，对其它事务是不可见的。 Durability（持久性）：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。通过Redo Log实现 在满足AID的情况下，就会满足C。四者非并行关系 隔离级别、封锁协议四个隔离级别：RU、RC、RR、SERIALIZABLE 对应四个级别封锁协议。不同级别封锁协议目的就是达到对应隔离级别 两段封锁协议是指可加锁阶段和锁释放阶段分为两个阶段进行，这样保证可串行化调度。可串行化调度指通过并发控制，使得并发执行的结果=串行执行的结果 MySQL的InnoDB储存引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁 MySQL默认隔离级别：RR 注意RU读未提交：指的是线程A修改后还没有提交！万一线程A没修改完，还在继续修改，或者线程A回滚了，那这个时候线程B读取的就是脏数据，此即脏读。这个时候脏是指的读取了线程A没有完成修改的数据，只修改了一半 四个隔离级别的实现假设两个事务，写事务和读事务 RU（读未提交）：写事务未提交，读事务读取了写的脏数据 RC（读已提交）：在读事务未提交的过程中，写事务完成了多次提交，导致读事务同一个事务内看到的数据前后不一致，不可重复读。通过MVCC的当前读实现，需要在语句中手动加读锁/写锁，读锁：... lock in share mode；写锁：... for update。 RR（可重复读）：在读事务未提交的过程中，可以重复读取已提交的写事务的数据。通过MVCC的快照读实现，且是InnoDB默认隔离级别，无需多余操作 S（串行化）：所有事务严格按照串行化进行 同时通过MVCC RC隔离级别+Nexy-Key-Lock 解决幻读：... between 10 and 20 for update 四个级别的封锁协议，即对应四个隔离级别，封锁协议是隔离级别的逻辑实现 MVCC原理、快照读MySQL的InnoDB通过MVCC（多版本并发控制）实现RC和RR隔离级别（封锁协议） 在MVCC中，事务的写操作会为数据行新增一个版本快照，储存有事务ID，也是快照的版本号（事务ID递增）。 一行数据维护一个快照列表，每当开始一个写事务，它就copy一份行数据，生成一个快照（Undo日志），然后自己写自己的。将所有写版本快照（事务信息）串起来，后来的在队尾，版本号最大，最早的在队头，版本号最小。有两个指针，max指针是最新开始的事务（还未提交）的事务号（版本号最大），min指针指向当前最新提交的事务的事务号（版本号最小）。也就是说，快照列表中间，全都是活跃事务（已开始，未提交）。 活跃事务提交失败，则回滚。 于是我们可以根据select查询的数据快照的ID和快照队列的ID进行对比， 快照储存在Undo日志中。这个快照列表叫ReadView。 于是我们要读的时候： ①对于RC：读取最新提交事务（版本号最大）的快照版本（复用快照列表） ②对于RR：读取最老提交事务（版本号最小）的快照版本（每次查询都会重新生成快照列表）也就是我只要开始读了，那一串写快照链都雨我无瓜了。 在读写锁（即共享锁S和互斥锁X）中，我们已经实现了读-读兼容 MVCC的意义在于①实现读-写兼容。也就是实现了不阻塞查询，即允许了读时写。②同时由于没有加锁，也使得效率提高。 快照读、当前读SQL默认快照读：就是默认的MVCC方法（不含锁）（即我们平时默认SQL语句比如select * from tb1） 当前读：不使用MVCC方案，而是采用读写锁（需要SQL显示加锁：select * from tb1 where ? lock in share mode，select * from tb1 where ? for update） 快照读是非一致性读，当前度是一致性读 当前读用在一致性要求高的地方，比如多个并发数据库请求，当读被写阻塞的时候，我就得等写完（释放写锁），再进行读（加读锁）。当一致性要求不高的时候，使用MVCC，那即使前面有事务在写，那我也可以读，只不过读的是个旧的快照罢了！ Undo log也用于事务回滚 MVCC+Next-Key Locks（临键锁=Gap Lock间隙锁+Record Lock记录锁（行锁））解决幻读 MySQL实现高并发的基本原理： 最开始是使用普通锁，各种操作互斥， 然后通过引入读写锁，使得读-读兼容， 再然后通过MVCC，使得读-写也能兼容，快照读就是InnoDB能做到高并发的核心原因 缓存（无关） 写缓冲：数据修改后会先写入缓存，然后从缓存定期将数据刷回磁盘，将随机写，通过缓存后变为顺序写，使得写速度非常快。 更多：写缓冲(change buffer)，这次彻底懂了！！！ 业务是写多读少，或者不是写后立刻读取时适用，默认占缓冲池25% 读缓冲：缓存同时也有作用加速查询的作用，如果缓存有的数据就不必去磁盘IO查了 更多：缓冲池(buffer pool)，这次彻底懂了！！！：预读（局部性原理），非传统LRU（解决预读失败；分为新生代、老年代；为防止大量数据读入的缓冲池污染，页被访问，且在老生代停留时间超过配置阈值的，才进入新生代） 读缓冲区就是一个查找表（lookup table）；数据缓存就是内存中的一块存储区域，其存储了用户的SQL文本以及相关的查询结果。 通常情况下，用户下次查询时，如果所使用的SQL文本是相同的，并且自从上次查询后，相关的表记录没有被更新（插入数据）过，此时数据库就直接采用缓存中的内容。 缓冲池通常以页(page)为单位缓存数据 优化： ①因此尽量不要进行大的SQL语句而是分开成小的重复的SQL语句有利于查询效率 ②进行表分区。将频繁更新的表字段和基本不变动的表字段分开。对于写任务频繁的程序，关闭查询缓存可能会改进性能。 ③成批的进行写入操作而不是逐个执行，以避免数据更新后被清出缓存 ④根据实际场景和表的特性选择读写缓冲区分配 undo日志、redo日志（无关）undo日志记录了数据库未提交的事务的操作，当数据回滚、崩溃的时候可以使用就版本数据，撤销未提交事务对数据库产生的影响（如前MVCC原理所述）：undo 日志用于保障，未提交事务不会对数据库的 ACID 特性产生影响。 redo日志redo日志记录了修改数据库的物理操作（不是数据缓存，是物理操作缓存）当数据库崩溃，redo日志里的内容会重做，使得数据能刷会磁盘。：redo日志保障了已提交事务的ACID特性 锁共享锁S：也叫读锁 排它锁X：也叫写锁 行锁：InnoDB的行锁给索引项加锁，所以只有通过索引条件检索数据才会对行加行锁，否则加表锁（非索引查询方式需要全索引/全表扫描，所以上表锁。这也是不加索引查询很慢的原因之一）同时，非主键索引被加行锁时，其对应的主键索引也会一起被加行锁。行锁属于读写锁。 临键锁：临键锁Next-Key Locks=Gap Lock间隙锁+Record Lock记录锁，这个记录锁就是行锁 意向锁：意向锁是一种表锁，行锁在加锁前要先加意向锁。与其说它是锁不如说它是标志位。意向锁只与表锁冲突，即当事务2想要申请表锁的时候，如果此时表有意向锁，那就申请失败。意向锁的目的在于解决事务想申请表锁的时候，需要先一行行判断表中是否有行锁，耗费时间的问题。如果加行锁之前必加意向锁，那么只要存在意向锁就代表表中有行锁，那就不能给另一个事务申请表锁。 事务与日志（以下摘自网络） 参考：https://www.jianshu.com/p/4bcfffb27ed5 MySQL中是如何实现事务提交和回滚的？ 为了保证数据的持久性，数据库在执行SQL操作数据之前会先记录redo log和undo log，这俩叫事务日志 redo log是重做日志，通常是物理日志，记录的是物理数据页的修改（比如某字段的值是多少balabala，而不是操作记录），它可以用来恢复提交后的物理数据页。它缓存了运行时的部分修改，然后提交的时候，将这些修改刷到磁盘里 对数据页的修改是先redo log记录到os kernel的buffer中，再使用fsync命令刷到磁盘里（落盘，和redis的aof方案一样）。（redo log也一样，redo/undo log都是写先写到日志缓冲区，再通过缓冲区写到磁盘日志文件中进行持久化保存） redo log的buffer是一个环形的缓冲记录空间，只会记录运行时的修改 有了redo log，当数据库发生宕机重启后，可通过redo log将【未落盘】的数据恢复，即保证【已经提交的事务记录】不会丢失。 undo log是回滚日志，用来回滚行记录到某个版本，undo log一般是逻辑日志，根据行的数据变化进行记录 undo日志还有一个用途就是用来控制数据的多版本（MVCC） redo log是用来恢复数据的，用于保障已提交事务的持久性 undo log是用来回滚事务的，用于保障未提交事务的原子性 redo log里记录了提交前的操作 【不提交 不回滚，那么事务就不会结束（表现为事务中对物理数据页的修改仍然只记录在redo log中，等待下一步安排，要么回滚，撤销redo log中的这些未提交操作；要么提交，redo log将操作刷回磁盘）】 bin log是sql server级别的，为了保binlog和redolog的一致性，commit后，redo log刷盘后还要写bin log。binlog负责主从同步，数据恢复。 如下为写commit的时候redo log和bin log发生了什么 会话发起COMMIT动作 存储引擎层开启[Prepare]状态：在对应的Redo日志记录上打上Prepare标记 写入binlog并执行fsync(刷盘) 在redo日志记录上打上COMMIT标记表示记录提交完成 bin log和redo log的区别： 1.redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 2.redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；bin log 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 3.redo log 是循环写的，空间固定会用完，只会记录一定时间内的数据修改；binlog 是追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 所以说，要恢复数据，还得看bin log 提交过程中，主要做了4件事情， 1、清理undo段信息 2、释放锁资源（事务结束），mysql通过锁互斥机制保证不同事务不同时操作一条记录，事务执行后才会真正释放所有锁资源，并唤醒等待其锁资源的其他事务； 3、刷redo日志，前面我们说到，mysql实现事务一致性和持久性的机制。通过redo日志落盘操作，保证了即使修改的数据页没有即使更新到磁盘，只要日志是完成了，就能保证数据库的完整性和一致性； 4、清理保存点列表，每个语句实际都会有一个savepoint(保存点)，保存点作用是为了可以回滚到事务的任何一个语句执行前的状态，由于事务都已经提交了，所以保存点列表可以被清理了。","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"5月5日，夏至","slug":"日记/夏至","date":"2020-05-05T12:40:12.000Z","updated":"2020-05-06T03:36:10.000Z","comments":true,"path":"日记/夏至/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%A4%8F%E8%87%B3/","excerpt":"一候鹿角解；二候蝉始鸣；三候半夏生 还记得寒假之前一天一杯瑞幸咖啡在实验室看书写代码，然后就到了喜气洋洋的新年，再之后，在家里这么一呆就度过了春天，蛰伏已久的炽热从地底升腾，夏天到了。","text":"一候鹿角解；二候蝉始鸣；三候半夏生 还记得寒假之前一天一杯瑞幸咖啡在实验室看书写代码，然后就到了喜气洋洋的新年，再之后，在家里这么一呆就度过了春天，蛰伏已久的炽热从地底升腾，夏天到了。 然后今晚，在写这篇的时候，突然停电…父母也不在家 还好IPAD电是满的，就摸黑把素晴的剧场版看了（音量拉满，沉浸式体验XD） 素晴还是那股熟悉的味道，沙雕中又有一点正经，每个角色依然那么可爱（惠惠天下第一）。感觉又回到了几年前的夏天 结尾曲依然那么好听，名字叫マイ・ホーム・タウン（My Home Town） 希望她们冒险能继续下去（什么时候有第三季啊kora） 这次寒假（？还能算寒假吗）难得能在家呆这么久（也许是最后一次能呆这么久），但是很可惜的是得一直学习… 没能欣赏玉渊潭的春樱，但能抚摸巴蜀温柔的夏风，也算是还彳亍口巴。 最近还会很忙，希望忙过这段时间，我有机会能够惬意享受最美的盛夏。 P.S.1原本打算春节写的年终总结一直没写，算了，鸽了（shit） P.S.2没有想到自己竟然入了格斗坑，格斗游戏真好玩 P.S.3我还是更喜欢家的气候，在北京这个时候我估计已经活不下去了","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"JAVA并发原理笔记","slug":"程序语言/JAVA并发原理笔记","date":"2020-05-04T03:41:10.000Z","updated":"2020-05-04T04:00:13.000Z","comments":true,"path":"程序语言/JAVA并发原理笔记/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0/","excerpt":"《JAVA并发编程的艺术》笔记，主要记录我以前理解不够的地方，并不是重点笔记","text":"《JAVA并发编程的艺术》笔记，主要记录我以前理解不够的地方，并不是重点笔记 JAVA并发机制底层原理减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 如何在资源限制的情况下，让程序执行得更快呢?方法就是，根据不同的资源限制调整 程序的并发度 如果一个字段被声明成volatile，Java线程内存 模型确保所有线程看到这个变量的值是一致的。 Lock前缀的指令在多核处理器下会引发了两件事情1)将当前处理器缓存行的数据写回到系统内存。2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了保证各个处理器的缓存是一致的，就会实现缓存一 致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当 处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状 态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存 里。 ———— 从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对 象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有 详细说明。但是，方法的同步同样可以使用这两个指令来实现。（这里说的是重量级synchonized使用monitor对象，monitor锁底层是的操作系统mutex互斥信号量；非重量级不会用这个monitor）monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结 束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有 一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 synchronized用的锁是存在Java对象头里的一个markword字段（锁实质）Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位（4种锁状态：无，偏，轻，重） 当一个线程访问同步块并 获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否 存储着指向当前线程的偏向锁。偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时（其它锁cas失败后修改Mark word撤销偏向锁）， 持有偏向锁的线程才会释放锁 轻量级锁适用无实质竞争或少量竞争的并发（每个线程cas基本都成功），不需要加锁，这样就没有线程切换问题也没有内核态用户态切换问题，开销少当cas大量失败，就会膨胀成重量级（太多cas自旋非常吃cpu） ————cpu实现原子操作：总线锁（锁总线，完全禁止其它cpu访问ram）/缓存锁（锁缓存）————同步是指程序中用于控制不同线程间操作发生相对顺序的机制 JAVA内存模型：JMMJava线程之间的通信由Java内存模型(本文简称为JMM)控制，JMM决定一个线程对共享 变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽 象关系:线程之间的共享变量存储在主内存(Main Memory)中，每个线程都有一个私有的本地 内存(Local Memory)threadlocal？，本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的 一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优 化。线程A与线程B之间要通信的话，必须要经历下面2个步骤。1)线程A把本地内存A中更新过的共享变量刷新到主内存中去。 2)线程B到主内存中去读取线程A之前已更新过的共享变量。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供 内存可见性保证。在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型：编译器优化级，cpu指令流水级，内存系统级；这些重排序可能会导致多线程程序 出现内存可见性问题 ；JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证（如写后读，du后写，写后写都不可重排）为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁 止特定类型的处理器重排序。在JMM中，如果一 个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关 系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。一个happens-before规则对应于一个或多个编译器和处理器重排序规则。JMM提供了happens-before保证：如果程序是正确同步（即需要程序员自己正确设置同步锁）的，程序的执行将具有顺序一致性(Sequentially Consistent)——即程 序的执行结果与该程序在顺序一致性内存模型中的执行结果相同（顺序一致性：a～一个线程中的所有操作必须按照程序的顺序来执行。且b～(不管程序是否同步)所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内 存模型中，每个操作都必须原子执行且立刻对所有线程可见。）（只是和它结果相同，如果真本体顺序一致模型了，那就是完全禁止重排序，少了很多编译器和指令优化）（可见对应不确定，意思是另一个线程的执行结果对这个线程是确定的）如果A happens-before B，那么Java内存模型将向程序员保证——1.A操作的结果将对B可见， 2.且A的执行顺序排在B之前（重排序并不一定要求a先于b执行！只要结果与a先于b执行且a的结果对b可见这个haappens-before关系一致即可！）JMM只根据happens-before规则禁止了会改变程序运行结果的重排序，不改变的不禁止JMM其实是在遵 循一个基本原则:只要不改变程序的执行结果(指的是单线程程序和正确同步的多线程程序) 编译器和处理器怎么优化都行。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为Java程序员呈现 了一个一致的内存模型。对于未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障:线程执行时读取 到的值，要么是之前某个线程写入的值，要么是默认值(0、null、false)。 ————volatile写的内存语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。volatile读的内存语义：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。为了实现volatile内存语义，JMM 会通过在指令中插入内存屏障来禁止特定类型的重排序（见下）（不同的vloatile执行环境，禁止重排序事项也不同，它并不是禁止所有重排序，而只是禁止部分重排序） 也就是说： 1线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了(其对共享变量所做修改的)消息。2线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的(在写这个volatile变量之前对共享变量所做修改的)消息。3线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过 主内存向线程B发送消息。 ————释放锁内存语义：当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。获取锁内存语义：当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 锁释放与volatile写有相同的内存语义;锁获取与volatile读有相同的内存语义。 也就是说：1线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了(线程A 对共享变量所做修改的)消息。2线程B获取一个锁，实质上是线程B接收了之前某个线程发出的(在释放这个锁之前对共 享变量所做修改的)消息。3线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发 送消息。 并发编程基础ReentrantLock是aqs框架的具体实现，其中用到了volatile和cas 更新变量都是靠cas，cas更新是原子操作————中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行 了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt() 方法对其进行中断操作。———— 等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B 调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而 执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的 关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。使用wait()、notify()和notifyAll()时需要先对调用对象加锁。notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。wait时候就已经释放锁了！然后就等通知了，等到通知之后，再重新获取到锁继续执行！流程：WaitThread首先获取了对象的锁，然后调用对象的wait()方法，从而放弃了锁 并进入了对象的等待队列WaitQueue中，进入等待状态。由于WaitThread释放了对象的锁，NotifyThread随后获取了对象的锁，并调用对象的notify()方法，将WaitThread从WaitQueue移到 SynchronizedQueue中，此时WaitThread的状态变为阻塞状态。NotifyThread释放了锁之后， WaitThread再次获取到锁并从wait()方法返回继续执行。 等待/通知机制依托于同步机制，其目的就是确保等待线程从wait()方法返回时能够感知到通知线程对变量做出的修改。————可以使用管道来进行线程数据传输PipedOutputStream、PipedInputStream、PipedReader和PipedWriterPipedWriter out = new PipedWriter();PipedReader in = new PipedReader();out.connect(in);// 将输出流和输入流进行连接，否则在使用时会抛出IOException out.connect(in); 如何传入对象：static class Print implements Runnable { private PipedReader in; public Print(PipedReader in) {this.in = in; }}———— 一个线程A执行了thread.join()语句，其含义是:当前线程A等待thread线程终止之后才 从thread.join()返回 —————可以看到，线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端 线程，客户端线程将任务放入工作队列后便返回，而工作者线程则不断地从工作队列上取出 工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上，当有客户端提交了 一个任务之后会通知任意一个工作者线程，随着大量的任务被提交，更多的工作者线程会被 唤醒。————— 锁synchronized是基于jvm底层实现的数据同步（不属于AQS），lock是基于Java编写 Lock锁（接口，implement之）是面向使用者的，它定义了使用者与锁交 互的接口(比如可以允许两个线程并行访问)，隐藏了实现细节;AQS队列同步器（类，extends之）面向的是锁的实现者， 它简化了锁的实现方式。AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。基于AQS实现的同步器包括:ReentrantLock、Semaphore、ReentrantReadWriteLock、 CountDownLatch和FutureTask。使用aqs通常声明了一个内部私有的继承于AQS的子类。 锁和同步器很好地隔离了使用者和实现者所需关注的领域。实现Lock的类：ReentrantLock() 可重入锁ReadWriteLock 读写锁ReentrantReadWriteLock 可重入读写锁StampedLock 读写锁中读不仅不阻塞读，同时也不应该阻塞写这些既实现了Lock接口，在其内部的同步器也继承了AQS，使用了AQS自带的同步器来实现Lock接口，这样一来我们自定义一个Lock同步组件就方便很多，AQS给我们省了很多事情 AQS 同步器内部对同步状态的管理：1独占式同步状态获取与释放：acquireQueued方法。同步器维 护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋;移出队列 (或停止自旋)的条件是前驱节点为头节点且成功获取了同步状态（这时候还没轮到次节点运行，等释放）。在释放同步状态时，同步 器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。（此为公平锁的前提下）2共享式同步状态获取与释放：acquireShared方法。 共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态（比如多读）3独占式超时获取同步状态：基于1，很好理解在AQS中，同步状态表示锁被一个线程重复获取的次数 什么是可中断获取锁：在Java 5之前，当一 个线程获取不到锁而被阻塞在synchronized之外时，对该线程进行中断操作，此时该线程的中 断标志位会被修改，但线程依旧会阻塞在synchronized上，等待着获取锁。在Java 5中，同步器 提供了acquireInterruptibly(int arg)方法，这个方法在等待获取同步状态时，如果当前线程被中 断，会立刻返回，并抛出InterruptedException。 非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁公平锁需要维护一个队列，加入了同步队列中当前节点是否有前驱节点的判断，如果该 方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释 放锁之后才能继续获取锁。 公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换，且需要维护一个队列。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。（因为非公平锁中，刚释放锁的线程再次获取同步状态的几率会非常大，所以线程切换少。） ————- 如果当前线程在获取读锁时，写锁已被其他线程 获取，则进入等待状态。写锁能降级成读锁（锁降级是指把持住(当前拥有的)写锁，再获取到 读锁，随后释放(先前拥有的)写锁的过程，中间有段过程会使得读锁等待，一但释放立即获取）读锁不能升级（为了可见性）写锁是一个支持重进入的排它锁static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();static Lock r = rwl.readLock();static Lock w = rwl.writeLock(); —————任意一个Java对象，都拥有一组监视器方法(定义在java.lang.Object上)，主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以 实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等 待/通知模式获取一个Condition必须通过Lock的newCondition()方法ConditionObject是同步器AbstractQueuedSynchronizer的内部类一个锁上面可以生产多个Condition。一个锁对应一个aqs同步器（底层由aqs实现），一个aqs同步器有一个同步队列和多个condition，每个condition包含一个等待队列。调用await方法时，相当于aqs同步队列的首节点移到该condition的等待队列中，signal则相反（signal被唤醒加入同步队列，不是立即执行）等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是 在Condition对象上等待的线程 对比：lock-aqs拥有一个同步队列和多个等待队列sychnized-监视器模型是一个同步队列和一个等待队列—————— 并发容器和框架ConcurrentLinkedQueue 可以非阻塞且安全先是定位尾指针的位置，然后使用CAS算法能将入队节点设置成尾节点的next节点，如不成功则重定位尾节点并重试。 ——————阻塞队列使用等待/通知模式实现来通知消费者/生产者队列可用的。通知模式，就是比如当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。比如ArrayBlockingQueue使用了Condition来实现，使用await，signal方法 —————— Fork就是把一个大任务切分 为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结 果。join和fork都是thread的方法先分割任务，再合并任务eg：CountTask leftTask = new CountTask(start, middle);CountTask rightTask = new CountTask(middle + 1, end);// 执行子任务leftTask.fork();rightTask.fork();// 等待子任务执行完，并得到其结果int leftResult=leftTask.join();int rightResult=rightTask.join();// 合并子任务sum = leftResult + rightResult; ————-—— 工作窃取(work-stealing)算法是指某个线程从其他队列里窃取任务来执行去其他线程的队列 里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被 窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿 任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 —————— 原子操作类和并发工具类AtomicBoolean，AtomicInteger，AtomicLong都是通过cas实现下同AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray:AtomicReference原子更新引用AstomicIntegerFieldUpdater 原子地更新某个类里的某个字段——————Exchanger(交换者)是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交 换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过 exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也 执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产 出来的数据传递给对方。 线程池线程池的意义：第一:降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。第二:提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。第三:提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源， 还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用 线程池，必须对其实现原理了如指掌。 —————— 队列排的都是竞争核心线程，非核心线程是队列满的时候创建执行（这样反而会导致队满后后来的线程先执行了，所以比如fix线程池，core和max线程数相同，即没有非核心线程）核心线程（默认情况）下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)，非核心线程闲置会被销毁（cache线程池的核心数就设置为0，max无界，这样就做到了都是非核心线程，闲置一段时间会被自动销毁，不来任务不创建）（但CachedThreadPool的maximumPool是无界的也意味着，如果主线程提交任务的速度高于 maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下， CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。） ThreadPoolExecutor执行execute方法，如图1234四个判断下分别执行的事情 如果无法将任务加入BlockingQueue(队列已满)，则创建新的线程来处理任务，这里需要全局锁，很耗性能，所以才这么设计 FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。—————— 向线程池提交任务：execute()方法用于提交不需要返回值的任务，submit()方法用于提交需要返回值的任务 性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的 线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配 置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务 和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量 将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。依赖数据库连接池的任务属于io密集型，因为线程提交SQL后需要等待数据库返回结果，等待的时间越 长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高 的任务先执行。—————— FixedThreadPool和SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的 工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列（SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一 个线程的对应移除操作）ScheduledThreadPoolExecutor 使用DelayQueue作为任务队列 —————— Excutor框架Excutor框架是ThreadPoolExcutor的祖师爷应用程序通过Executor框架控制上层的调度;而下层的调度由操作系统 内核控制，下层的调度不受应用程序的控制。 ThreadPoolExecutor执行execute方法，如图1234四个判断下分别执行的事情 如果无法将任务加入BlockingQueue(队列已满)，则创建新的线程来处理任务，这里需要全局锁，很耗性能，所以才这么设计 FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。—————— 向线程池提交任务：execute()方法用于提交不需要返回值的任务，submit()方法用于提交需要返回值的任务 性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的 线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配 置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务 和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量 将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。依赖数据库连接池的任务属于io密集型，因为线程提交SQL后需要等待数据库返回结果，等待的时间越 长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高 的任务先执行。—————— FixedThreadPool和SingleThreadExecutor使用无界队列LinkedBlockingQueue作为线程池的 工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列（SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一 个线程的对应移除操作）ScheduledThreadPoolExecutor 使用DelayQueue作为任务队列 ——————Excutor框架是ThreadPoolExcutor的祖师爷应用程序通过Executor框架控制上层的调度;而下层的调度由操作系统 内核控制，下层的调度不受应用程序的控制。 后续AQS框架的细节以后需要更多了解（源码）","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"关于CPU线程调度与并发、JAVA重量级锁的一些理解","slug":"程序语言/关于线程调度与并发、重量级锁的一些理解","date":"2020-05-02T17:43:47.000Z","updated":"2020-05-04T04:13:50.000Z","comments":true,"path":"程序语言/关于线程调度与并发、重量级锁的一些理解/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E5%85%B3%E4%BA%8E%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E4%B8%8E%E5%B9%B6%E5%8F%91%E3%80%81%E9%87%8D%E9%87%8F%E7%BA%A7%E9%94%81%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/","excerpt":"一个程序对应一个进程，一个进程下有很多线程","text":"一个程序对应一个进程，一个进程下有很多线程 现代操作系统多采用时间片轮转的线程调度算法来管理线程并发任务，对于单颗CPU来说，它为每一个线程分配时间片，每个线程运行一个时间片长度就切换到另一个线程，像流水线一样。时间片切换的时候会发生线程的上下文切换，然而在CPU流水中的线程上下文切换并不怎么耗时间，因为切换都处在内核态中。 时间片轮转算法让所有进程好像在“同时”执行，这就是并发；同一时刻执行才行并行（多核就能同一时刻执行） 回到java中，java程序中的每一个线程是与刚刚CPU线程调度的线程是一个东西，时间片轮转调度就调度的它。 时间片轮转调度实际上就是一个所有线程都公平竞争，排队各自轮流执行一小段时间。但是我们在java并发编程的时候，会遇到很多实际问题，比如线程间存在依赖关系等等，不能让它们公平竞争，这时候我们想到加锁来管理多线程并发，这是建立在CPU线程调度管理之上的人为干预。 锁有几种，偏向锁、轻量级锁实际上并没有对由操作系统管理的CPU线程调度造成改变，它们依然是时间片调度公平执行，只是实现了锁的效果 而重量级锁是获取了对象关联的monitor对象（每一个JAVA对象都会与一个监视器monitor关联，没有获取到monitor对象即竞争锁失败，阻塞），而monitor实际上是操作系统的高级原语，充当着维护 mutex（操作系统提供的互斥量）以及定义 wait/signal API 来管理线程的阻塞和唤醒的角色。这时候进行线程切换，就是通过系统来进行的，需要从用户态切换到核心态，然后再进行上下文切换。（概括：重量级锁的线程切换需要从用户态切换到核心态）而从用户态切换到核心态才是重量级锁耗时的元凶！ 当程序中有系统调用语句，程序执行到系统调用时，首先使用类似int 80H的软中断指令，保存现场，去的系统调用号，在内核态执行，然后恢复现场，每个进程都会有两个栈，一个内核态栈和一个用户态栈。当执行int中断执行时就会由用户态，栈转向内核栈。系统调用时需要进行栈的切换。而且内核代码对用户不信任，需要进行额外的检查。系统调用的返回过程有很多额外工作，比如检查是否需要调度等。 为什么用户态和内核态的切换耗费时间？ （实际上使用mutex进行切换就是操作系统线程调度级别的线程切换了，它可能是强行将CPU时间片交给获得锁的线程，而无法获得锁的互斥线程就无法获得CPU时间片）","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"筛子翻转路径","slug":"算法与数据结构/筛子翻转路径","date":"2020-04-27T13:02:57.000Z","updated":"2020-04-27T13:15:28.000Z","comments":true,"path":"算法与数据结构/筛子翻转路径/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AD%9B%E5%AD%90%E7%BF%BB%E8%BD%AC%E8%B7%AF%E5%BE%84/","excerpt":"一个地图，#表示可走的格子，.代表不可走的格子，S代表起点，E代表终点，没有岔路且S到E必可达 S上摆放了一个筛子：前面为3，后面为4，上面为1，底面为6，左面为5，右面为2 筛子只能通过翻转从S走到E，每翻转一次，筛子就会给路径上的格子染上与底面同样的颜色（用数字表示） 请输出骰子到终点后的地图 输入第一行为组数，第二行为地图尺寸","text":"一个地图，#表示可走的格子，.代表不可走的格子，S代表起点，E代表终点，没有岔路且S到E必可达 S上摆放了一个筛子：前面为3，后面为4，上面为1，底面为6，左面为5，右面为2 筛子只能通过翻转从S走到E，每翻转一次，筛子就会给路径上的格子染上与底面同样的颜色（用数字表示） 请输出骰子到终点后的地图 输入第一行为组数，第二行为地图尺寸 输入示例： 1 5 S###. ...#. E#.## .#..# .#### 示例答案： 6215. ...4. 12.26 .3..3 .5621 解答主要就是明确筛子的状态空间 只有一条路径，无岔路，我这里看成有岔路了，然后写dfs去找正确路径耽误了时间。。 import java.util.Scanner; class S &#123; int qian,hou,shang,xia,zuo,you; int temp_shang,temp_xia,temp_zuo,temp_you; S(int qian,int hou, int shang ,int xia,int zuo,int you) &#123; this.qian = qian; this.hou = hou; this.shang = shang; this.xia = xia; this.zuo = zuo; this.you = you; &#125; void youFan() &#123; temp_zuo = zuo; temp_you = you; you = shang; zuo = xia; shang = temp_zuo; xia = temp_you; &#125; void xiaFan() &#123; temp_shang = shang; temp_xia = xia; xia = qian; shang = hou; qian = temp_shang; hou = temp_xia; &#125; void zuoFan() &#123; temp_zuo = zuo; temp_you = you; zuo = shang; you = xia; xia = temp_zuo; shang = temp_you; &#125; void shangFan() &#123; temp_shang = shang; temp_xia = xia; shang = qian; xia = hou; hou = temp_shang; qian = temp_xia; &#125; int color() &#123; return xia; &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int T = sc.nextInt(); for(int group=0;group&lt;T;group++) &#123; int n = sc.nextInt(); int[][] array = new int[n][n]; int startX = 0,startY=0; int endX =0 ,endY=0; for(int x=0;x&lt;n;x++) &#123; String line = sc.next(); for (int y = 0; y &lt; n; y++) &#123; if (line.charAt(y) == 'S') &#123; array[x][y] = 6; startX = x; startY = y; &#125; if (line.charAt(y) == 'E') &#123; array[x][y] = 0; endX = x; endY = y; &#125; if (line.charAt(y) == '#') array[x][y] = 0; if (line.charAt(y) == '.') array[x][y] = -9; &#125; &#125; //新建筛子 S shaizi = new S(3,4,1,6,5,2); int i=startX,j=startY; while(!(i==endX&amp;&amp;j==endY)) &#123; //上 if (i+1&lt;n) if(array[i+1][j]==0) &#123; shaizi.shangFan(); array[i+1][j]=shaizi.color(); i++; continue; &#125; //下 if (i-1>=0) if(array[i-1][j]==0) &#123; shaizi.xiaFan(); array[i-1][j]=shaizi.color(); i--; continue; &#125; //右 if (j+1&lt;n) if(array[i][j+1]==0) &#123; shaizi.youFan(); array[i][j+1]=shaizi.color(); j++; continue; &#125; //左 if (j-1>=0) if(array[i][j-1]==0) &#123; shaizi.zuoFan(); array[i][j-1]=shaizi.color(); j--; continue; &#125; &#125; array[i][j]=shaizi.color(); //输出array for(int i1 = 0; i1 &lt; n; i1++) &#123; for (int j1 = 0; j1 &lt; n; j1++) &#123; if (array[i1][j1]==-9) System.out.print(\".\"); else&#123; System.out.print(array[i1][j1]); &#125; &#125; System.out.println(); &#125; &#125; &#125; &#125;","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"搜索算法：BFS/DFS问题","slug":"算法与数据结构/搜索算法：BFS-DFS问题","date":"2020-04-25T11:06:37.000Z","updated":"2021-04-13T02:43:01.686Z","comments":true,"path":"算法与数据结构/搜索算法：BFS-DFS问题/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%EF%BC%9ABFS-DFS%E9%97%AE%E9%A2%98/","excerpt":"DFS BFS搜索算法经常带有一个visited矩阵 DFS算法入口一般传入第一轮位置参数，就像树遍历传入root根节点一样，然后每一轮DFS（每一层递归）就调用DFS（参数位置+1）（即下一个位置，具体不一定要这样） 其涵盖拥有前面递归所说的一切经验：理解子问题，思考齐全①递归出口（所有终止条件）、②递归入栈（如何继续递归）与③执行体（做什么操作）（①和②可以合并在一起，不符合条件不继续递归，自然出栈） 经常需要使用全局变量来记录递归中的参数 对于DFS，要有子问题思维：以前、以后的问题是不可见的，现在只需要考虑当前该节点的小问题，当前结点拥有哪些变量 也要有全局思维：理清子问题与以前、以后问题的关系 回溯返回值可以跨越递归层级进行各种信息（当然得当前结点看得见的）传递 对于BFS问题，有两个关键：出队的时候执行执行体，入队的时候判断是否入队（这两者可以在一起，即入队就是上层出队结点的执行体） 队列为空则遍历结束 DFS的关键：①入口与出口 ②【单线程执行】（进栈出栈顺序），回溯（同层多入口。同层多入口间要回溯以免同层其它递归路径的影响）","text":"DFS BFS搜索算法经常带有一个visited矩阵 DFS算法入口一般传入第一轮位置参数，就像树遍历传入root根节点一样，然后每一轮DFS（每一层递归）就调用DFS（参数位置+1）（即下一个位置，具体不一定要这样） 其涵盖拥有前面递归所说的一切经验：理解子问题，思考齐全①递归出口（所有终止条件）、②递归入栈（如何继续递归）与③执行体（做什么操作）（①和②可以合并在一起，不符合条件不继续递归，自然出栈） 经常需要使用全局变量来记录递归中的参数 对于DFS，要有子问题思维：以前、以后的问题是不可见的，现在只需要考虑当前该节点的小问题，当前结点拥有哪些变量 也要有全局思维：理清子问题与以前、以后问题的关系 回溯返回值可以跨越递归层级进行各种信息（当然得当前结点看得见的）传递 对于BFS问题，有两个关键：出队的时候执行执行体，入队的时候判断是否入队（这两者可以在一起，即入队就是上层出队结点的执行体） 队列为空则遍历结束 DFS的关键：①入口与出口 ②【单线程执行】（进栈出栈顺序），回溯（同层多入口。同层多入口间要回溯以免同层其它递归路径的影响） 结点搜索问题：机器人的运动范围核心问题： 遍历到符合要求的结点就全局计数，路径走不通就返回 注意是搜索符合要求的结点 (DFS)思路：维持一个全局计数矩阵，DFS中走到死路直接该条递归路径出口 (BFS)思路：在BFS中走到死路不入队 问题： 地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1] 。一个机器人从坐标 [0, 0] 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格 [35, 37] ，因为3+5+3+7=18。但它不能进入方格 [35, 38]，因为3+5+3+8=19。请问该机器人能够到达多少个格子？ 注意：①是要能够走到的格子 ②求的是位和 解答： DFS解法 class Solution &#123; //标记矩阵 boolean[][] visited; int count = 0; public int movingCount(int m, int n, int k) &#123; visited = new boolean[m][n]; //init visited array for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++) visited[i][j] = false; //开始dfs dfs(0,0,m,n,k); return count; &#125; public void dfs(int x,int y,int m,int n,int k) &#123; //出口条件 //注意边界条件，题目中写的是0~m-1,0~n-1走，不能走到n！ if(x>m-1 || y>n-1 || (x/10+x%10+y/10+y%10)>k || visited[x][y]==true) return ; //执行体 count++; visited[x][y] = true; //递归入栈 dfs(x,y+1,m,n,k); dfs(x+1,y,m,n,k); &#125; &#125; BFS解法 class Solution &#123; boolean[][] visited; int count = 0; public int movingCount(int m, int n, int k) &#123; visited = new boolean[m][n]; //init visited array for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++) visited[i][j] = false; //开始bfs;注意这里将坐标以一个数组的形式记录入队 Queue&lt;Integer[]> qe = new LinkedList(); qe.add(new Integer[]&#123;0,0&#125;); while(!qe.isEmpty()) &#123; //出栈，执行体 Integer[] pos = qe.remove(); //【这里判断本层结点是否执行执行体：计数count+1】 if ((pos[0]/10+pos[0]%10+pos[1]/10+pos[1]%10)&lt;=k &amp;&amp; visited[pos[0]][pos[1]]==false) &#123; count++; visited[pos[0]][pos[1]] = true; //【本层结点能执行说明路没被堵，这才判断相邻下一层结点是否入队；所以要放进外层if执行体里】 if (pos[0]&lt;m &amp;&amp; pos[1]+1&lt;n) qe.add(new Integer[]&#123;pos[0],pos[1]+1&#125;); if (pos[0]+1&lt;m &amp;&amp; pos[1]&lt;n) qe.add(new Integer[]&#123;pos[0]+1,pos[1]&#125;); &#125; &#125; return count; &#125; &#125; 实测DFS比BFS快13倍 字符串的排列输入一个字符串，打印出该字符串中字符的所有排列。 你可以以任意顺序返回这个字符串数组，但里面不能有重复元素。 示例： 输入：s &#x3D; &quot;abc&quot; 输出：[&quot;abc&quot;,&quot;acb&quot;,&quot;bac&quot;,&quot;bca&quot;,&quot;cab&quot;,&quot;cba&quot;]解答： import java.util.*; class Solution &#123; List&lt;String> res = new LinkedList&lt;>(); //用来缓存得到的搜索路径 char[] c; String[] permutation(String s) &#123; //转化为字符数组 c = s.toCharArray(); dfs(0); return res.toArray(new String[0]); //注意，传入的这个参数表明array元素的类型，必须是一个对象 &#125; //每次递归的路径该怎么记录：因为【用的是交换来固定元素以确定路径】当一堆交换，那么字符串本身就是结果！ void dfs(int x) &#123; //dfs到最后一位了，这时候已经通过交换确定了一个搜索路径了。所以即为c本身！（一个序列） if (x==c.length-1) &#123; res.add(String.valueOf(c)); return ; &#125; HashSet&lt;Character> set = new HashSet&lt;>(); for(int i = x; i &lt; c.length; i++) &#123; //使用hashset判断要交换的i位是不是重复元素（字符串中可能含有重复元素），避免【同层】重复搜索 if (set.contains(c[i])) continue; set.add(c[i]); //将x与i位交换 swap(x,i); dfs(x+1); //注意要换回来，因为这是同一轮（同一个位置）下，为了下一次固定数选其他位置交换要先还原 swap(x,i); &#125; &#125; void swap(int a,int b) &#123; char temp = c[a]; c[a] = c[b]; c[b] = temp; &#125; public static void main(String[] args) &#123; Solution sol = new Solution(); String[] solution = sol.permutation(args[0]); Arrays.sort(solution); System.out.print(\"[\"+solution[0]); for (int i=1;i&lt;solution.length;i++) System.out.print(\",\"+solution[i]); System.out.print(\"]\"); &#125; &#125; 路径搜索问题：寻找某个路径核心问题： 遍历符合要求的路径才计数，路径走不通就返回 即整条递归路径（栈）符合要求才计数 思路：通过回溯返回值来标记符合要求的路径，当只要递归路径中所有结点全满足要求才返回满足要求 即通过返回值来标记该节点后面的所有节点组成的问题（递归子问题）是否满足要求 问题：请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一格开始，每一步可以在矩阵中向左、右、上、下移动一格。如果一条路径经过了矩阵的某一格，那么该路径不能再次进入该格子。例如，在下面的3×4的矩阵中包含一条字符串“bfce”的路径（路径中的字母用加粗标出）。 [[“a”,”b“,”c”,”e”],[“s”,”f“,”c“,”s”],[“a”,”d”,”e“,”e”]] 但矩阵中不包含字符串“abfb”的路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入这个格子。 示例 1： 输入：board &#x3D; [[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;E&quot;],[&quot;S&quot;,&quot;F&quot;,&quot;C&quot;,&quot;S&quot;],[&quot;A&quot;,&quot;D&quot;,&quot;E&quot;,&quot;E&quot;]], word &#x3D; &quot;ABCCED&quot; 输出：true 示例 2： 输入：board &#x3D; [[&quot;a&quot;,&quot;b&quot;],[&quot;c&quot;,&quot;d&quot;]], word &#x3D; &quot;abcd&quot; 输出：false 提示： 1 &lt;= board.length &lt;= 2001 &lt;= board[i].length &lt;= 200 解答： 递归参数：坐标位置x,y，当前目标字符在字符串word中的索引 终止条件：①行列位置越界 或②当前矩阵元素与目标字符不同 或③当前矩阵已经访问过 P.S.注意由于可以从任何一个位置开始dfs，那么就有多个dfs过程，所以不能直接使用全局visited矩阵，但是如果使用局部visited矩阵，那每一次递归栈里都有一个visited矩阵，储存开销/时间开销巨大！ 所以如果我们要使用全局的形式就需要每一次return就还原visited当前值矩阵！（看代码中“注意visited矩阵的处理”那段，进栈标记，以防子问题走到已经访问过的格子，出栈复原） public class Offer12 &#123; static boolean[][] visited; public static boolean exist(char[][] board,String word) &#123; visited = new boolean[board.length][board.length]; //每一个格子都可以是起点，对于每一个格子起点的dfs都有一个visited矩阵 for(int i=0;i&lt;board.length;i++) for(int j=0;j&lt;board.length;j++) //以i,j为起点开始dfs if(dfs(board,word,i,j,0)) return true; return false; &#125; public static boolean dfs(char[][] board,String word,int x,int y,int nowPointer) &#123; //退出条件：①单元格撞墙或②单元格的内容与字符串索引位不匹配或③访问过 if(x&lt;0 || y&lt;0 || x>=board.length || y>=board.length || board[x][y]!=word.charAt(nowPointer) || visited[x][y]==true) return false; //退出条件：遍历到字符串最后一个 if(nowPointer==word.length()-1) return true; //回溯返回值：当前结点所有子问题如果有一条路可行（返回true）那就是true //递归入口：即探访子问题——可以向上下左右四个方向走 //注意visited矩阵的处理，进栈流程中要标记为true，出栈流程中要复原回去 visited[x][y] = true; boolean res = dfs(board,word,x+1,y,nowPointer+1) || dfs(board,word,x-1,y,nowPointer+1) || dfs(board,word,x,y+1,nowPointer+1) || dfs(board,word,x,y-1,nowPointer+1); //出栈复原 visited[x][y] = false; return res; &#125; public static void main(String[] args) &#123; char[][] board = new char[][]&#123;&#123;'A','B','C','E'&#125;,&#123;'S','F','C','S'&#125;,&#123;'A','D','E','E'&#125;&#125;; String word = \"ABCCED\"; System.out.println(exist(board,word)); &#125; &#125; --- true 路径记录问题：迷宫问题在DFS的同时还需要记录DFS的搜索路径：使用一个list或stack保存路径！ 具体地，出栈的时候，如果满足要求，就将该节点保存下来（入list或stack） 如果要保存多个路径：每次传递的时候就逐层累计记录下来已经走下的路径，走到终点判断该路可以就记录该累计变量or打印 变种：打印符合某条件的路径（一样的思路） 回溯返回值问题：树的深度思路： 回溯返回值除了可以用于寻找满足条件的递归路径，还可以做很多事情，只要抓住一点，回溯返回值可以传递递归不同层级当前结点看得到的各种信息 树的深度其实就是求最长递归路径 解答： 注意观察路径记录问题和回溯返回值问题路径记录问题，越往下递归路径越多，所以我们得前序遍历，递归到一个节点就执行执行体（记录该路径点） 回溯返回值问题，我们是要比较左右子树符合条件的路径，最终我们只要一条路径，所以得后序遍历，递归返回的时候才执行执行体（比较左右子树最深那个，返回深度值） 注意区别递归顺序和执行顺序","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"各大排序算法实现","slug":"算法与数据结构/各大排序算法实现","date":"2020-04-25T09:23:06.000Z","updated":"2020-05-17T10:31:52.000Z","comments":true,"path":"算法与数据结构/各大排序算法实现/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%90%84%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/","excerpt":"冒泡、插入、选择、归并、快速、堆、基数、计数","text":"冒泡、插入、选择、归并、快速、堆、基数、计数 冒泡排序//冒泡排序：每轮遍历相邻冒出最大者，冒到最[右边]，每轮冒出一个确定数 static void bubbleSort(int[] array) &#123; //只进行length-1轮 for (int i=0;i&lt;array.length-1;i++) //每一轮中，[0,length-i]为待排序区 //最后一个元素不参与比较，否则越界 for (int j=0;j&lt;array.length-i-1;j++) //只交换向量位置 if (array[j]>array[j+1]) &#123; int temp = array[j]; array[j] = array[j+1]; array[j+1] = temp; &#125; &#125; 插入排序//插入排序：每轮选一个数，在已排区（在[左边]）查找合适位置插入 static void insertSort(int[] array) &#123; //array[i]为待插入数 for (int i=1;i&lt;array.length;i++) //遍历被插区（已排区） for (int j=0;j&lt;i;j++) //左插：将i插第一个大于j的数左边，[插入点~已排区边界]进行数组位移（易错） if (array[j] > array[i]) &#123; //注意这里怎么移动，移动的边界 int temp = array[i]; for (int k=i;k>j;k--) array[k] = array[k-1]; array[j] = temp; break; &#125; //如果没有，插最右边，也就是待插数原地不动，不用执行其它操作 &#125; 选择排序//选择排序：每轮遍历交换选出最大者，从左边开始大轮遍历，与大轮计数位交换，每轮交换出一个确定数 static void chooseSort(int[] array) &#123; for (int i=0;i&lt;array.length-1;i++) for (int j=i+1;j&lt;array.length;j++) if (array[i]>array[j]) &#123; int temp = array[i]; array[i] = array[j]; array[j] = temp; &#125; &#125; 归并排序//归并排序：见过程，特别注意实现细节以及对递归的理解 static class mergeSort &#123; //在递归设计中，要有终止（继续）递归条件，且要有执行体（解决子问题的具体操作）；在归并中，执行体为Merge，但最小子问题是不用Merge的 //也就是说执行体也有条件（即Left&lt;Right），叶子结点不用执行Merge操作，与递归条件是一样的（叶子结点不用再继续递归） //那么我们就将执行体写如递归判断条件中去！ //合并步骤 static void merge(int[] array,int left,int mid, int right) &#123; int[] array_merge = new int[array.length]; //注意这里的初值易错，这里是截取出了一段left~right之间的数进行merge int i=left,j=mid+1,array_index=left; //比较合并 while(i&lt;=mid&amp;&amp;j&lt;=right) if (array[i]&lt;array[j]) array_merge[array_index++] = array[i++]; else array_merge[array_index++] = array[j++]; //末尾未参与比较直接确定大小的数据 while(i&lt;=mid) array_merge[array_index++] = array[i++]; while(j&lt;=right) array_merge[array_index++] = array[j++]; //复制回原数组 for (int m=left; m&lt;=right; m++) array[m] = array_merge[m]; &#125; //递归子问题 static void sonMerge(int[] array,int left,int right) //注意命名方便 &#123; //判断是否可以继续递归（切分子问题）：【本子问题可以继续切分条件：left&lt;right】 if (left&lt;right) &#123; //计算中间点位置 int mid = (left+right)/2; //【注意由于是从0开始标号，那么计算mid的时候是有不同之处的；注意中间点是用＋算】 //递归入口1 sonMerge(array,left,mid); //递归入口2 sonMerge(array,mid+1,right); //注意第二段是从mid+1起始 //递归出口1，进行merge操作，【merge的是两段，所以递归树叶子结点不merge，放到left&lt;right非叶子结点里】 merge(array,left,mid,right); &#125; //递归出口2 （最小子问题从递归出口2出口，不执行操作） //对于最后切分成的子问题，由于不满足left&lt;right了，那么其执行体就直接跳过上面的if到这里来-递归出口2，也就是不执行任何操作 //然后递归栈就推出了最小子问题（不merge），然后回到上一个子问题，即在if里的递归出口处！ //更多递归细节见再探递归 &#125; static void mergeSort(int[] array) &#123; sonMerge(array,0,array.length-1); &#125; &#125; 快速排序//快速排序 static class fastSort &#123; //快排子问题执行体[partition]-解荷兰国旗问题：在序列中选择一个元素（这里默认最左边元素），将小于它的放在左边，大于它的放在右边，最后再赋值给边界元素 //函数返回值为本子问题选择元素确定的最终位置（以便切割） //关键点：先右后左（先右边界移动，再左边界移动） static int hollandFlag(int[] array,int left,int right) &#123; int temp = array[left]; while(left&lt;right) &#123; //注意边界的处理，直接赋值而没有交换，巧妙设计流程使得信息没有损失 //赋值的顺序一定是满足【先将右边界不满足数放到左边界上】，【再将左边界不满足数放到右边界上】，【第一次发生的必然是先将右边界不满足数放到左边】 //而左边界第一个数是基准数已被记录，可以被直接覆盖，然后边界相遇的时候的那个点必定已经赋值给左/右了，那么基准数直接覆盖相遇点即可 while (left &lt; right &amp;&amp; array[right] >= temp) //注意等于情况，不然遇到第一个等于的就无限循环了 right--; array[left] = array[right]; //将不满足要求的右边界数（right指针目前指向）放左边界数（第一个为temp，默认交换） while (left &lt; right &amp;&amp; array[left] &lt;= temp) left++; array[right] = array[left]; //将不满足要求的左边界数放右边界上 &#125; array[left] = temp; //最后将基准值放到相遇处 return left; &#125; //快排递归子问题；注意与归并排序子问题的区别 //①快排子问题的切分：left~上轮确定位置，上轮确定位置~right //②快排子问题是前向顺序，即先执行荷兰国旗子问题，再进行切分 static void sonFastSort(int[] array,int left,int right) &#123; if (left&lt;right) &#123; //只有非叶子节点（最小子问题）才会执行荷兰国旗问题 int temp_index = hollandFlag(array,left,right); //递归入口： sonFastSort(array,left,temp_index); sonFastSort(array,temp_index+1,right); &#125; &#125; //快速排序 static void fastSort(int[] array) &#123; sonFastSort(array,0,array.length-1); &#125; &#125; 堆排序//堆排序 static class heapSort &#123; /*堆的储存结构是一个数组，从0开始（一般是一个完全二叉树，且只有完全二叉树堆才能用数组储存） * 父节点 i 的左子节点在数组中的位置 (2*i+1); * 父节点 i 的右子节点在位置 (2*i+2); * 子节点 i 的父节点在位置 (i-1)/2; * 结点在数组中的位置也是其完全二叉树的结点标号 * 关键逻辑：①建堆（从最右子树父节点开始调整到根节点） * ②堆排序（交换根节点与已排序区指针位置，调整根节点） * 关键过程：调整（若本节点孩子不符合规则，则调整完该结点继续调整孩子结点，即遍历调整该结点，直到不需要调整或到叶子结点） */ //堆排序主函数 //先建立堆，然后在数组末尾维持一个已排序区，将根节点取出、调整、扩大已排序区 public static int[] heapSort(int[] array) &#123; //先建堆 buildMaxHeap(array, array.length - 1); //将堆根(最大值）与堆最末尾元素交换（已排序区在数组末尾，指针左移） //这里先在循环外进行一次swap，排序的最后是以swap结尾的 swap(array, 0, array.length - 1); for (int i = 1; i &lt; array.length - 1; i++) &#123; //进行堆（数组范围0~array.length-1-i)调整，这里都是parent=0开始调整，因为删除的都是根节点 adjustMaxHeap(array, 0, array.length-1-i); //将堆根(最大值）与堆最末尾元素交换（已排序区在数组末尾，指针左移） swap(array, 0, array.length - 1 - i); &#125; return array; &#125; public static void buildMaxHeap(int[] data, int lastIndex) &#123; //(lastIndex-1)/2即为最右下子树父节点；因为插入第i个节点，那就要从第i个节点开始调整到根节点 for (int i=(lastIndex-1)/2; i>=0; i--) adjustMaxHeap(data, i, lastIndex); &#125; //以parent为根节点，对堆data（范围为parent~lastindex）进行调整 public static void adjustMaxHeap(int[] data, int parent, int lastIndex) &#123; /*从parent开始进行遍历调整该子结点*/ //【当已经没有孩子结点的时候，停止遍历】 while (2*parent+1 &lt;= lastIndex) &#123; /*这一段用于找到最大孩子index，判断左右孩子存在性和谁更大*/ //先假定最大孩子是左孩子 int maxChildIndex = 2*parent + 1; // 如果当前左孩子不是末尾元素 if (maxChildIndex &lt; lastIndex) &#123; // 如果左孩子小于右孩子,取右孩子下标，即 if (data[maxChildIndex] &lt; data[maxChildIndex + 1]) maxChildIndex++; &#125; /**比较当前父节点和最大孩子节点**/ if (data[parent] &lt; data[maxChildIndex]) &#123; //不符合堆设定，交换parent和最大孩子 swap(data, parent, maxChildIndex); //【继续向下调整，以maxChildIndex为根节点调整】（继续执行下一层while循环） parent = maxChildIndex; &#125; else //【当该结点符合规则，停止遍历】 break; &#125; &#125; public static void swap(int[] data, int i, int j) &#123; int temp = data[i]; data[i] = data[j]; data[j] = temp; &#125; &#125; 基数排序public static int[] radixSort(int[] array) &#123; //找到最大那个元素 int max = 0; for (int i = 0; i &lt; array.length; i++) &#123; max = array[i] > max ? array[i] : max; &#125; //记录最大那个元素的位数time int time = 0; while (max > 0) &#123; time++; max /= 10; &#125; //一个元素类型为List的List！，List里的每个子list就是桶，有基数个桶（比如10进制排序，那就有10个桶） List&lt;ArrayList&lt;Integer>> queue = new ArrayList&lt;>(); //初始化【基数个桶】 for (int i = 0; i &lt; 10; i++) queue.add(new ArrayList&lt;>()); //循环time次，每一次排序一个位置！ for (int i = 0; i &lt; time; i++) &#123; // 按位d【对原数组】进行【一趟排序】 for (int j = 0; j &lt; array.length; j++) &#123; //使用Math.pow(10, i + 1)来方便遍历10,100,1000,10000各个位 //先用根据外层循环的i得到【内存循环的数组元素】在【当前排序的位】的值 int d = array[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); //获取第d个桶 ArrayList&lt;Integer> list = queue.get(d); //将这个数加入第d个桶中 list.add(array[j]); //将修改后的桶赋值回大list queue.set(d, list); &#125; // 【把queue进行过一趟排序的数据拷贝回原数组】 //count设计为数组下标计数 int count = 0; //遍历每个桶（基数为10,所以10个桶） for (int k = 0; k &lt; 10; k++) //将桶内的数据复制回数组 while (queue.get(k).size() > 0) &#123; array[count] = queue.get(k).get(0); queue.get(k).remove(0); count++; &#125; &#125; return array; &#125; 计数排序public static int[] countingSort(int[] array) &#123; //先找到最大元素 int max = 0; for (int i = 0; i &lt; array.length; i++) max = array[i] > max ? array[i] : max; //开辟最大元素这么大的数组 int[] count = new int[max + 1]; for (int i = 0; i &lt; array.length; i++) count[array[i]]++; //开始计数，每个元素对应到数组下标，数组内容即为该下标的计数次数 int sum = 0; for (int i = 0; i &lt; count.length; i++) &#123; if (count[i] > 0) for (int j = 0; j &lt; count[i]; j++) array[sum + j] = i; sum += count[i]; &#125; return array; &#125;","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"JVM&JVM类加载器","slug":"程序语言/JVM类加载器","date":"2020-04-17T10:02:51.000Z","updated":"2020-05-29T14:17:44.000Z","comments":true,"path":"程序语言/JVM类加载器/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/","excerpt":"类加载器","text":"类加载器 类加载 类加载器 （这里参考ZYG同学的博客——类加载） ①类加载器之间的关系如上图示 [BootstrapClassLoader]-启动类加载器：(Cpp)加载JAVA核心类库，位于java.*在Java_Home/lib目录下 [ExtClassLoader] -扩展类加载器：(java)加载扩展库，如classpath中的jre ，javax.*或者java.ext.dir 指定位置中的类，开发者可以直接使用标准扩展类加载器。 [AppClassLoader]-系统类加载器（应用程序类加载器）：(java)加载程序所在的目录，如user.dir所在的位置的.class。也就是说我们写的代码的类是被这个加载器加载的。（系统类加载器和启动类加载器名称区分清） [CustomClassLoader]-自定义类加载器：java编写,用户自定义的类加载器,可加载指定路径的class文件 自定义类加载器的使用情景：热插拔。比如同名jsp文件要替换掉，那么重新生成一个累加载器，再加载一下这个类，把原来的关了，重新生成页面，不用停机 一些实现和API：ClassLoader是类加载器类，通过ClassLoader.getSystemClassLoader()方法返回应用程序的系统类加载器。然后其提供一系列方法getParent()获取类加载器的父类加载器、loadClass(String name)、findClass(String name)、findLoadedClass(String name)、defineClass(String name,byte[] b,int off,int len)（可以将.class文件转化为Class对象)、resolveClass(Class&lt;?&gt; c)（链接指定的java类） 见解析ClassLoader、getSystemClassLoader与Launcher 双亲委派机制 当某个类加载器需要加载某个.class文件时，它首先把这个任务[从当前类加载器]委托[给他的上级类加载器]，[递归]这个操作，如果上级的类加载器没有加载，自己才会去加载这个类，加载了就直接返回。这是一种代理模式。 意义 ①保证一个类只被加载一次，省内存 ②安全（保证不被篡改） 为了系统类的安全，类似“ java.lang.Object”这种核心类，JVM需要保证他们生成的对象都会被认定为同一种类型。即“通过代理模式，对于 Java 核心库的类的加载工作由引导类加载器来统一完成，保证了 Java 应用所使用的都是同一个版本的 Java 核心库的类，是互相兼容的”。 具体来说：比如我们想写一个java.lang.Object类，我们写的类属于程序的类，当前由系统类（应用程序类）加载器加载，它是启动类加载器和扩展类加载器的儿子，那么根据双亲委托机制，就会先由父类的类加载器来加载java.lang.Object，那么这样我们自己写的类就无法被加载（比如我们自己定义包名和类名叫java.lang.Object)，那么我们的系统类加载器加载这个类之前先会找更上层的类加载器，更上层的类加载器在java核心类库找到了java.lang.Object，那么久不会再调用系统类加载器加载我们自己写的了）；不过我们可以自己定义一个类加载器来达到这个目的，为了避免双亲委托机制，这个类加载器也必须是特殊的。由于系统自带的三个类加载器都加载特定目录下的类，如果我们自己的类加载器加载一个特殊的目录，那么系统的加载器就无法加载，也就是最终还是由我们自己的加载器加载。 类加载器&amp;java双亲委派机制及作用、为何采用双亲委派机制 注意 注意要明白是从当前类加载器开始往上递归（这也导致实现SPI机制的类库无法通过原始方式加载，原始方式的当前类加载器是启动类加载器，找不到SPI类库） 上下文类加载器 可以破坏双亲委派机制，上级可指派下级类加载器来加载类 上面的SPI机制中就用到了 类加载阶段包括加载、连接（验证、准备、解析）、初始化、使用和卸载，它们开始的顺序一定，但是完成的顺序并不一定，因为在一个阶段内会调用其他阶段。 整个初始化流程见JAVA-Ch.14类型信息-初始化流程 JVM如何认定两个对象同属于一个类型，必须同时满足下面两个条件： 基于双亲委派机制，可以看出 都是用同名的类完成实例化的。 两个实例各自对应的同名的类的加载器必须是同一个。比如两个相同名字的类，一个是用系统加载器加载的，一个扩展类加载器加载的，两个类生成的对象将被JVM认定为不同类型的对象。 TiPS 常量池 在Java方法区会维护一个常量池，对于使用简单赋值直接创建的一些可以共享的字符串、基本类型，会先在常量池中查找是否存在相同的内容，如果有就直接返回，不创建新对象。（JAVA字符串不可修改，修改其实就是建立一个新的String对象）而如果是显式创建对象就不会是这样的，new就是new个新的了 //显式创建（非字符串和基本类型，只能显式创建） System.out.println(new test() == new test()); //输出false，不是同一个对象 //显式创建 String a = new String(\"abc\"); String b = new String(\"abc\"); System.out.println(a==b); //输出false，不是同一个对象，未共享对象，其它基本类型的包装类也是同理 //非显式创建 String a = \"abc\"; String b = \"abc\"; System.out.println(a==b); //输出true，是同一个对象，共享对象，其它基本类型同理 static变量也是常量，储存于常量池 类加载器的加载路径和import引入声明是两个东西，import是一个使用声明，是给编译器用的，静态；类加载器的加载路径是运行时，类加载器只认识加载路径下的类，动态。类加载器认识，但不一定会import：比如lang是启动类加载器认识，且默认import（只有lang默认import），util是扩展类加载器认识，但不默认import。 JAVA的很多东西都是告诉建议不这么做，但你可以这么做，比如final修饰符，意思是告诉别人你不要改我，但是可以用反射破坏；双亲委派机制就是告诉你别替代我，但我可以用上下文类加载器破坏；异常机制提醒你要处理异常，但你可以直接抛出不处理 基本数据类型存放在哪里？ ①在方法/循环中申明的基本类型放在栈中 ②在对象中申明的基本类型放在堆中 ③被final修饰的基本数据类型和String类型变量在编译时会被确定下来，存放在常量池中。 java哪些情况会内存泄漏程序员可能创建了一个对象，以后一直不再使用这个对象，这个对象却一直被强引用，即这个对象无用但是却无法被垃圾回收器回收的，这就是java中的内存泄露 ①长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收。 比如有一个循环，循环内部不断生成对象，但这个对象是在循环外面定义的，外部持有内部的对象的引用。在一般的循环中建立的变量都是局部变量（局部方法栈中），然而由于外部对象的引用，即使循环结束后，局部对象迟迟无法被gc回收，导致不被使用的对象不断增加导致内存泄漏。 可以在循环内部用完将对象设置为null即可。 ②集合中的内存泄漏，比如 HashMap、ArrayList 等（加入集合等于一个强引用） 我们将引用add入集合，然后令该引用=null，但实际上由于集合对象还对该对象有一个强引用，那么该对象实际上并没有被释放 见：纳尼，Java 存在内存泄泄泄泄泄泄漏吗？ - 纯洁的微笑的文章 - 知乎 https://zhuanlan.zhihu.com/p/66689341 可以使用JVisualVM等工具来监视jvm运行信息来判断内存泄漏","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"类型信息","slug":"程序语言/类型信息","date":"2020-04-17T09:54:27.000Z","updated":"2020-05-17T00:54:44.000Z","comments":true,"path":"程序语言/类型信息/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E7%B1%BB%E5%9E%8B%E4%BF%A1%E6%81%AF/","excerpt":"JAVA类型信息","text":"JAVA类型信息 本节涉及很多JVM知识，结合JVM内容理解，这里只有一部分 类动态加载机制JAVA是动态加载类的，这是JAVA与其它静态加载语言如CPP的主要区别之一 整个初始化流程①加载类并创建实例的流程：类加载-实例化。注意加载类不一定要创建实例。 ②类加载阶段包括加载、连接（验证、准备、解析）、初始化、使用和卸载，它们开始的顺序一定，但是完成的顺序并不一定，因为在一个阶段内会调用其他阶段。 加载就是加载Class对象，见3 类加载的准备步骤中给静态成员变量开辟了内存，也就相当于全部为0或null，在初始化步骤中才执行初始化赋值（final成员除外，final成员在准备阶段即进行初始化赋值） 举例：public static int a=1，变量在准备阶段过后的初始值是0而不是1，如果是引用成员变量就会为null，其他基本类型对应的是其基本默认值。只有在初始化阶段过后，才会变成1。 （类加载也可以叫类初始化过程，注意类初始化不是子过程的字段初始化） 类加载流程更多内容见JAVA虚拟机 ③实例化阶段包括新建对象-非静态成员初始化-调用构造器 这里的非静态成员变量也和类加载同理，先分配内存（准备），再调用构造器，赋予初值（初始化） 不过要先新建一个对象（开辟内存），对位于类加载中加载Class Class对象①每个类在编译的时候都会生成一个Class对象，固化储存在类名.class文件中，由JVM中的类加载器子系统加载进内存中的方法区里。Class对象也是对象，可以由个Class类型的引用指向它 ②Class对象包含了类的元数据（包括类名，变量名，方法），加载后储存在方法区中。与类绑定的成员和方法（静态成员、静态方法）都在Class对象中。（也就是说，这时候类信息、静态成员和静态方法已经被初始化了，此时对象还没生成，此时构造器还没调用） ③在程序第一次引用（见下）会触发加载该类的Class对象。（构造器是一个类的静态方法）。 ④引用：分为主动引用和被动引用（这里参考ZYG同学的博客） a.主动引用 五种情况会触发初始化阶段，这五类情况是主动引用 new、getstatic、putstatic和invokestatic命令 后三个是对于静态字段的读写与静态方法的调用 反射调用某个类 加载某个类，如果父类没有被加载，那么也进行加载 执行主类（包含main函数） 使用MethodHanler（类似于反射的一个针对于方法的东西，链接https://my.oschina.net/floor/blog/1535062） b.被动引用 子类调用父类的静态字段，只会初始化父类 初始化该类的数组 调用静态（static）常量（final）已经优化到常量池里面 ⑤一旦Class对象被加载进内存方法区，它就可以被用来在堆上创建这个类的所有对象（类加载器先会检查是否已加载Class对象，已加载类就可以直接用）【对象实例是由该类的Class对象实例来创建的】 ⑥所有Class对象都属于Class类 初始化流程于是现在就可以更底层理解Ch.5中的初始化顺序了 初始化顺序：静态块=静态成员&gt;非静态块=非静态成员&gt;构造器调用 生成对象过程：非静态部分初始化、构造器调用 以new命令为例，new引用类会触发初始化，其目的是新建该类对象，如果该类没有在内存方法区中（即Class对象未加载），那么就会在方法区上先加载Class对象，走类加载过程；然后再走实例化过程 加载类不一定会生成对象（比如调用类的静态成员/方法）这样就不会初始化非静态成员/方法、调用构造器了 双亲委派机制类加载的双亲委派机制 当某个类加载器需要加载某个.class文件时，它首先把这个任务[从当前类加载器]委托[给他的上级类加载器]，[递归]这个操作，如果上级的类加载器没有加载，自己才会去加载这个类，加载了就直接返回。这是一种代理模式。 意义 ①保证一个类只被加载一次，省内存 ②安全（保证不被篡改） 为了系统类的安全，类似“ java.lang.Object”这种核心类，JVM需要保证他们生成的对象都会被认定为同一种类型。即“通过代理模式，对于 Java 核心库的类的加载工作由引导类加载器来统一完成，保证了 Java 应用所使用的都是同一个版本的 Java 核心库的类，是互相兼容的”。 具体来说：比如我们想写一个java.lang.Object类，我们写的类属于程序的类，当前由系统类（应用程序类）加载器加载，它是启动类加载器和扩展类加载器的儿子，那么根据双亲委托机制，就会先由父类的类加载器来加载java.lang.Object，那么这样我们自己写的类就无法被加载（比如我们自己定义包名和类名叫java.lang.Object)，那么我们的系统类加载器加载这个类之前先会找更上层的类加载器，更上层的类加载器在java核心类库找到了java.lang.Object，那么久不会再调用系统类加载器加载我们自己写的了）；不过我们可以自己定义一个类加载器来达到这个目的，为了避免双亲委托机制，这个类加载器也必须是特殊的。由于系统自带的三个类加载器都加载特定目录下的类，如果我们自己的类加载器加载一个特殊的目录，那么系统的加载器就无法加载，也就是最终还是由我们自己的加载器加载。 类加载器&amp;java双亲委派机制及作用、为何采用双亲委派机制 Class常用API①首先获取class对象（Class类引用）： Ⅰ.Class.forName(className)：使用加载当前类的类加载器来装载制定的类，可以获取className类的Class对象的引用（如果获取的时候还未加载Class对象，那就执行类加载流程；必须检查异常，如果找不到，抛出ClassNotFoundException；这里的className要包含包名） Ⅱ.Object.getName(objectName)可以获取objectName实例的类的Class引用 注意this指代的是这个类的实例，而不是这个类！所以要获取this的类信息得用getClass() Ⅲ.className.class ，类字面常量，获取className类的Class对象的引用，在编译时检查，安全，所以可以不检查异常，且使用方便，高效、推荐使用这个替代forName；且不但适用于普通的类，也适用于接口、数组、基本数据类型。（基本数据类型及其封装类都可以使用class，基本数据类型封装类还有个TYPE字段指向该类未封装的基本数据类型Class对象）；但是使用.class创建对象引用的时候，不会自动初始化该Class对象（类加载流程：加载-链接-初始化），仅在对静态方法/非常数静态域(非static final)第一次引用时才初始化。 于是可以这样写Class abcclass = abc.class ②然后就可以通过class对象搞事情可以做到很多类信息相关的事情： 获取到Class引用之后（设名字为class）可以使用class.getSimpleName()来获取不含包名的类名、class.getCanonicalName()获取含包名的类名，class.getInterfaces()获取该class对象中包含的所有接口，class.getSuperclass()查询基类 class.isInterface()可以通过Class对象来判断该类是否为接口，同理还有isXXX()等一堆方法，获取类信息，总之，很牛逼 class.getDeclaredConstructor().newInstance()可以创建实例并返回引用。getDeclaredConstructor()获得class的构造器对象并调用其newInstance()方法创建对象创建实例，适用于有参构造器和无参构造器；该方法需要检查异常NoSuchMethodException（class.newInstance()仅适用无参构造器且已被JAVA9不推荐）；注意，即使使用泛型，返回的引用类型也为确切类型。 ③类型判断 object instanceof className：判断实例是否是某类，返回布尔值；注意是className类名，而不是Class对象 class.isInstance(object)：判断实例是否是class对象的类的实例（是否由class类创建） 父类.class.isAssignableFrom(子类.class)：判断子类是否继承父类 泛化Class的引用（Class与泛型）B是A的子类，但B.class并不是A.class的子类，所以Class&lt;?&gt; A是强制检查是A的Class实例，B不行；只有写Class&lt;? extends A&gt; intClass = B.class，才会同时检查其子类Class 见Ch.15-通配符 反射机制 反射机制可以提供运行时的类信息。如果不能在主程序运行的时候知晓某类的类型和类信息，我们就可以通过反射机制来让我们在运行的时候获取类信息，使用该类。 反射机制应用场景： ①使用实现SPI的库（如JDBC），SPI(Service Provider Interface)由JAVA核心库提供接口，由不同厂商具体实现。那么我们就可以通过反射动态加载不同厂商的SPI实现 ②动态代理：根据对象在内存中加载的Class类创建运行时类对象，从而调用代理类方法和属性。我也不知道我的接口，真正实现是谁传过来后我用类名加载，屏蔽掉实现的细节，让使用者更加方便好用，提高程序的灵活性 静态代理通俗点将就是自己手写一个代理类，而动态代理则不用我们手写，而是依赖于java反射机制 ③越权：可以用反射改变类方法或变量的权限，比如私有的改成共有的 反射机制实现：反射由Class类与java.lang.reflect类库提供支持，该类库包含Field类、Method类、Constructor类。这些类型的对象是由JVM在运行时创建的，用以表示位置类里对应的成员。 反射常用API：Java高级特性——反射（记住常用的，这篇总结的非常好！） 注意使用：①getMethod(),getConstructor()都只能获取公有的，getDeclaredMethod和getDeclaredConstructor能获取任意权限的，带s的方法即为获取全部，返回列表 反射机制四大类：Class、Field、Method、Constructor，都有实例化对象 ②从Class获取到的Field、Method都是类信息，想要调用该成员、方法，首先得构建对象实例，然后方法调用invoke(Object,Object...args)还得传入对应的参数,Object...args表示是边长参数列表，args只要是Object类即可（即一切） ③获取Class中的Method、Constructor的方法中，获取单个的需要明确指定方法的参数表，比如getMethod(String name, Class...&lt;?&gt; parameterTypes)，其中Class...&lt;?&gt; parameterTypes表示参数类型的Class类。距离：假设参数是两个字符串，那就应该写`getMethod(String name, String.class,String.class) java的反射到底是有什么用处？怎么用？ - Java3y的回答 - 知乎 动态代理代理模式是用代理类来代理实现类进行操作，在代理类中生成目标类的对象，但又增强了其它方法。代理其实就是个每一层代理加强一点的套娃。其目的是想要将额外的操作从“实际”对象中分离到不同的地方 但是静态代理的缺陷是，每有一个目标类 ，我们就要写一个代理类，这样不好 在静态代理中，我们需要写一个代理类（大套娃），而在动态代理中，我们想不写代理类，而是生成一个代理Class对象，然后用它创建代理实例，再由代理 实例调用目标对象。（也就是说Class对象就是代理，基于反射机制，也就成了个动态套娃） 动态代理的调用处理程序必须事先java.lang.reflect.InvocationHandler接口，及使用java.lang.reflect.Proxy类中的newProxyInstance方法动态的创建代理类。 首先用Proxy.getProxyClass()用实际接口class去构造代理class，然后在代理class中建立代理对象。代理Class的构造器创建对象时，需要传入InvocationHandler（一般用匿名内部类）。每次调用代理对象的method方法，最终都会调用InvocationHandler的invoke()方法（将代理代理对象方法导向invoke），在invoke里新建目标类实例（目标类以参数形式传入），然后使用method.invoke来调用该实例的method方法 这里参考：Java 动态代理作用是什么？ - bravo1988的回答 - 知乎 （这篇写得非常清晰） 参考：Java 动态代理作用是什么？ - ZeaTalk的回答 - 知乎 https://www.zhihu.com/question/20794107/answer/23330381 package test; //接口 public interface Subject &#123; public void doSomething(); &#125; package test; //真实类 public class RealSubject implements Subject &#123; public void doSomething() &#123; System.out.println( \"call doSomething()\" ); &#125; &#125; package test; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class ProxyHandler implements InvocationHandler &#123; //真实对象 private Object tar; //绑定委托对象，并返回代理类 public Object bind(Object tar) &#123; this.tar = tar; //绑定该类实现的所有接口，取得代理类 ，这里就是前面所说的，用真实接口class来构造代理class，再用代理class的构造器生成代理对象 return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; //调用代理对象实际上就会调用该方法 public Object invoke(Object proxy , Method method , Object[] args)throws Throwable &#123; Object result = null; //这里就可以进行所谓的AOP编程了 //在调用具体函数方法前，执行功能处理 //【这里就是，让真实对象tar，调用method方法，参数为args】，在这前后就可以进行增强 //这里就可以看出动态代理的优越处了：实例对象、方法全是动态的 result = method.invoke(tar,args); //在调用具体函数方法后，执行功能处理 return result; &#125; &#125; public class TestProxy &#123; public static void main(String args[]) &#123; ProxyHandler proxy = new ProxyHandler(); //绑定该类实现的所有接口 Subject sub = (Subject) proxy.bind(new RealSubject()); sub.doSomething(); &#125; &#125; 如上：在实际使用中直接Proxy.newProxyInstance()，然后就返回代理实例，简化使用 Spring AOP基于动态代理的 反射可以做到解耦：编译期不依赖、运行时依赖 bean：可重用组件 反射加载配置+（单例）bean工厂 解耦类依赖 IOC=====再发展一下，框架做工厂的事情，那就是Spring框架 P.S.JAVA是个大玩具，很有意思，反射机制下，JAVA没有秘密（所以真秘密要用NDK）","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"泛型","slug":"程序语言/泛型","date":"2020-04-17T09:54:17.000Z","updated":"2020-04-25T09:09:50.000Z","comments":true,"path":"程序语言/泛型/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E6%B3%9B%E5%9E%8B/","excerpt":"JAVA泛型","text":"JAVA泛型 泛型的意义范型——类型参数化 目的是安全 多态提供灵活性，范型提供安全性（泛型提供了安全的向下转型） 泛型语法可以让编译器强制执行额外的类型检查，如ArrayList&lt;Integer&gt; list;，会强制检查内部元素是否为Integer类型 在为了泛化而使用多态特性的情景中，因为在使用泛型类时指明了数据类型，赋给其他类型的值会抛出异常，于是向下转型的时候没有潜在的风险。否则使用Object作为默认参数类型，不进行类型检查，取出再向下转型很危险；我们通过把类型也作为参数，解决了这个问题 泛型语法其实就是把类型当成一个参数进行传递，不过写法比较特别 与普通类的定义相比，泛型的代码在类名后面多出了&lt;T1, T2&gt;，T1, T2是自定义的标识符，也是参数，用来传递数据的类型，而不是数据的值，我们称之为类型参数。在泛型中，不但数据的值可以通过参数传递，数据的类型也可以通过参数传递。T1, T2只是数据类型的占位符，运行时会被替换为真正的数据类型。 传值参数（我们通常所说的参数）由小括号包围，如(int x, double y)，类型参数（泛型参数）由尖括号包围，多个参数由逗号分隔，如&lt;T&gt;或&lt;T, E&gt;。也可以定义范型方法、泛型接口，总之只要是（引用）类型，都可以作为参数了，使用也是按原来那样使用 举例： //使用泛型的类 ClassName&lt;T1,T2> //这里&lt;T1,T2>就是泛型参数表了，这是一种专门传递类型参数的特殊写法 &#123; T1 x; //这里就使用了T1,T2类型参数 T2 y; &#125; //主函数使用 objectName&lt;T1,T2> balabala.... //&lt;T1,T2>就是实际使用的时候，传递进去的参数 类型参数需要在类名后面给出。一旦给出了类型参数，就可以在类中使用了。类型参数必须是一个合法的标识符，习惯上使用单个大写字母，通常情况下，K 表示键，V 表示值，E 表示异常或错误，T 表示一般意义上的数据类型。 注意：方法参数列表中的的参数类型是局部参数，形式参数！这点和普通参数一样 泛型边界限制：（关于边界的意义见下面第4条） ①通过 extends关键字可以限制泛型的类型上边界：&lt;T extends Number&gt; 表示 T 只接受 Number 及其子类，传入其他类型的数据会报错。这里的限定使用关键字 extends，后面可以是类也可以是接口。但这里的extends已经不是继承的含义了，应该理解为 T 是继承自 Number 类的类型，或者 T 是实现了 XX 接口的类型，它申明了边界。 可以一个class边界+多个interface边界：&lt;T extends Artist &amp; CanPlay &amp; CanSing&gt; ②特殊用法：使用通配符（通配符?，如Class&lt;?&gt; intClass = int.class ） 通过&lt;? extends T&gt;限制泛型的类型下边界，通过&lt;? super T&gt;限制泛型的类型下边界，单边界 为什么要用通配符： 如下常用用法：可以扩大泛型表示范围。如果左边写Plate&lt;Fruit&gt;就会出错，因为Apple虽然是Fruit的子类，但Plate&lt;Apple&gt;不是Plate&lt;Fruit&gt;的子类（前面Class与泛型就是这个原因用通配符！见Ch.14-8）于是我们用通配符，导致往里存的可以是任意Fruit或其子类的实例 通配符&lt;?&gt;和类型参数&lt;T&gt;的区别就在于，对编译器来说所有的T都代表同一种类型，而&lt;?&gt;不是。所以扩大范围会导致副作用：&lt;? extends T&gt;只能取，不能存（?代表可以是不同类型，但容器规定不能向容器中存不同类型的对象），而&lt;? super T&gt;只能存，不能取，要取只能取出Object类（泛型范围扩大到Object，取出来也必须设为Object类型才装得下） 所以要遵循PECS（Producer Extends Consumer Super）原则：频繁往外读取内容的，适合用上界Extends，经常往里插入的，适合用下界Super 更多参考：为什么要使用通配符边界表示，区别与作用 ③特殊用法：无界通配符 &lt;?&gt; 不知道里面是什么，所以不允许向List&lt;?&gt;存数据，也不可取数据，更多作为类型参数检查 捕获转换技术：如果向一个使用&lt;?&gt;的方法传递原生类型，那么对于编辑器来说，可能会推断出实际的类型参数，使得这个方法可以调用另一个使用确切类型的的方法（略） JAVA泛型与多态JAVA泛型都是按无类型信息的Object存的（类型信息被擦除），它的实现基础是多态，多态的实现是依靠动态绑定 JAVA泛型深层理解——擦除、边界C++的泛型通俗点说是通过在编译时的实例化将泛型类（以类为例）实例化为多个实例（保留了类型信息，是实体）。而Java则是在编译的时候进行泛型的错误检查，然后进行类型擦除，去掉泛型，保留原始类型，共享同一块代码。也就是说：JAVA没有C++那种真正的泛型 JAVA泛型是使用擦除实现的，在JAVA编译期结束后，泛型信息都被擦除了。实际上：你唯一知道的就是你在使用一个对象。泛型类型信息只有在静态类型检查期间（编译期的一个步骤）才会出现，它帮助编译器执行类型检查，在此之后，程序中的所有泛型类型信息都被擦除，替换为它们的非泛型上界（边界见下） 于是在编译期结束，java文件编译为class文件后，JVM看到的只有实际对象，而由泛型附加的类型信息对JVM来说已经被擦除，是不可见的。 举例：List&lt;Integer&gt;和List&lt;String&gt;在运行时事实上是相同的类型：List，Class&lt;Integer&gt;和Class&lt;Father&gt;事实上也是相同的类型Class，而普通的类型变量在未指定边界的情况下将被擦除为Object（未指定上界，那么任何object extends Object，其上界就是Object） 在C++中，由于泛型被真正的实现了，所以程序在编译期就能判断该泛型具体是什么类型，如果你调用了该泛型没有的方法或属性，那么程序在编译期就会报错，如果有就不会。然而，JAVA泛型做不到：由于泛型类型被擦除，JAVA编译器无法判断该泛型具体是什么类型，一律无法编译通过。于是在JAVA中，我们必须协助泛型类，人为给出泛型的边界，以告诉编译器只能接受遵循这个边界的类型。（如果不遵守，就会编译报错，这其实就达到了C++一样的目的，不过泛型边界是编码者人为设置的）本段话具体例子见下面的“举例” 于是我们可以得出：一个泛型参数&lt;T&gt;不能直接拿去用，得先规定边界，比如&lt;Integer&gt;、&lt;? extends Father&gt;都是边界，前者限定Integer，后者限定Father及其子类（上界） 举例： class Father &#123; static String f() &#123; return \"i am father\"; &#125; &#125; //可行 class FXtest&lt;T1 extends Father> //规定上边界Father；或者class FXtest&lt;Father>也行 &#123; FXtest() &#123; System.out.println(T1.f()); &#125; &#125; //不可行 class FXtest&lt;T1> //没有规定边界，一律报错；然而这在C++里是可行的。 &#123; FXtest() &#123; System.out.println(T1.f()); &#125; &#125; JAVA泛型只是提供了一种类型信息，它的底层仍然只是个Object（或其它上界），你只是看起来好像拥有有关参数的类型信息而已，所以涉及具体操作的时候，你要认识清楚，它实际上是什么类（Object或其它上界），只不过我们额外告诉编译器它应该的类型信息，提供一种安全向下转型的保证。（不过像容器类，你get()将对象取出容器的时候就顺带给你转型了（毕竟泛型已经提供安全了），而不是让你取出来的还是个Object或其它上界然后自己转型） 所以“擦除”擦的是：真实类型（上界）以下的类型信息。真实对象类型是默认情况的最高上界（无人为规定上界的话）。 一些细节问题①任何基本类型都不能作为类型参数（声明泛型类型引用的时候必须写非基本类型，但向里存的时候容器类会自动装箱，但底层依然不是基本类型） ②一个类不能实现同一个泛型接口的两种变体，由于擦除的原因，这两个变体会成为相同的接口 ③使用带有泛型类型参数的转型或instanceof不会有任何效果 ④不能重载：由于擦除的原因，重载方法将产生相同的类型签名 自限定类型【略】自限定类型强制泛型当做其自己的边界参数来使用 class SelfBounded&lt;T extends SelfBounded&lt;T&gt;&gt; &#123; &#125; 后记擦除减少了泛型的泛化型。在JAVA基于擦除的泛型实现中，泛型类型被当作第二类类型处理（如前文所说），即不能在某些重要的上下文环境中使用的类型。JAVA使用擦除实现泛型的主要原因是JAVA是后来才加入泛型的，为了兼容性。JAVA泛型不是真正的泛型，像是在原先不安全的多态使用上加了一层限制，也就是刚开始说的：“泛型提供了安全的向下转型” 泛型的所有动作都发生在边界处 容器类就用到了指定类型的泛型，比如List&lt;Integer&gt;，它没有用到泛型基于多态的泛化作用，只顺带用到了泛型的类型检查作用。指定类型实际上就是界内容量为1。 当JAVA最初被创建时,它的设计者们当然了解C++的模板，他们甚至考虑将其囊括到JAVA语言中，但是出于这样或那样的原因，他们决定将模板排除在外（其迹象就是他们过于匆忙） 所以说，JAVA泛型搞成这个样子，就是因为，工期不够。。。。然后后来也没法改了","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"递归设计再探","slug":"算法与数据结构/递归再探","date":"2020-04-02T02:38:33.000Z","updated":"2020-10-17T15:33:12.879Z","comments":true,"path":"算法与数据结构/递归再探/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%80%92%E5%BD%92%E5%86%8D%E6%8E%A2/","excerpt":"再探","text":"再探 递归树：描述递归的问题结构递归树可以用如下图表示，这个树描述了递归的问题结构（二分递归） 对于先左后右，出栈执行（倒序执行）的递归（后序续历），如下设计： void func() &#123; if (left可递归) func(left) if (right可递归) func(right) 执行体（访问） &#125; 执行过程：[入]0、1、3、7、15 [出]15 [入]16 [出]16 [出]7 [入]8 [出]3 [入]4 [入]9 [出]9 [入]10 [出]10 [出]4 [出]1 [入]2、5、11 [出]11 [入]12 [出]12 [出]5 [入]6、13 [出]13 [入]14 [出]14、6、2、0 所以对于通过前中序序列来还原二叉树的问题，即可通过前序序列找到子问题个根节点，再通过中序序列找到左右节点的顺序（因为前序遍历是访问到子问题的根节点的时候就输出，中序遍历的输出顺序是左中右） 核心：在递归问题中，不变的就是要理清大问题和小问题，拥有“局部”的眼光，只看当前问题，不看以前的问题，将子问题封装成一个整体。一个递归是一个进入跟结点后的子问题（递归函数体），只解决了以这个结点为根节点的子问题，左右结点都是下一层递归的问题！左右结点就是左右子问题，和本层节点一样，自会去执行各自的子问题（比如输出data域，如果其下还有子问题，必然会有相应的输出，但不需要在目前这个问题管），所以不用管，看成一个整体即可。于是对于中序遍历，一个子问题就是：左递归完成，然后输出本节点data域，再进入右节点子问题——对于每一个子问题，都是先输出左边（不管，继续递归的子问题）再输出中间（本层）再输出右边（不管，继续递归的子问题）（对于最小子问题，就需要结束递归了，即最终出口） 结合代码去想，这个函数即为进入一个根节点所对应的一个子问题的执行过程。 几个要点与理解①每一个子问题都满足该函数内部的内容 ②必须有子问题递归条件 对于子问题，判断是否继续递归（即上面中的if语句），否则就停止该子问题的递归，出栈该子问题（注意，出栈的是该子问题，不再继续递归该子问题） ②执行体：解决子问题所进行的操作；在二叉树的深度遍历中，称作“访问结点” 执行执行体：解决该子问题 ③a.子问题出栈的时候即解决该子问题（倒序执行） 在二叉树深度遍历中相当于后序遍历 void func() &#123; if (left可递归) func(left) if (right可递归) func(right) 执行体（访问） &#125; b.若要让子问题入栈的时候即解决该子问题（正序执行），则如下设计： 在二叉树深度遍历中相当于前序遍历 void func() &#123; 执行体（访问） if (left可递归) func(left) if (right可递归) func(right) &#125; ④递归树中父节点与子节点的关系 递归的不同层次（父问题与子问题） ⑤只有当子问题全部出栈（执行执行体，即解决问题），父问题才会出栈（执行执行体，即解决问题） 以上面递归树例子为例，对于7的子问题，[入]7，代表开始解决7问题了，这时候递归7问题，发现7还有子问题，于是 [出]15 [入]16 [出]16，这时候7的子问题全部出栈（全部解决完），这时候再 [出]7（解决父问题：7） 基于思想灵活变通基于以上的要点思想，进行灵活的递归设计 但是有几个核心要明确：①子问题继续递归条件②执行体 （或者说：①递归最终出口（递归树叶子结点）②下一层递归入口③当层递归出口执行体；执行体可以在下一层递归入口之前（相当于前序），也可以没有单独的递归最终出口，直接在下一层递归入口处判断即可） 脑子要清晰，我现在处于哪一层的子问题，现在的环境变量，各个变量现在是什么（因为多个子问题，很容易搞错），要结合递归树、子问题、栈、执行过程仔细思考 举例：归并排序的递归结构在归并中，执行体为Merge，但最小子问题（即划分为只有一个数的时候）是不用Merge的也就是说执行体也有条件（即Left&lt;Right），叶子结点不用执行Merge操作，与递归条件是一样的（叶子结点不用再继续递归）那么我们就将执行体写如递归判断条件中去！ void sonMergeSort &#123; if (left&lt;right) &#123; int mid = (left+right)/2; //递归入口1 sonMergeSort(array,left,mid); //递归入口2 sonMergeSort(array,mid+1,right); //执行体 Merge(array) &#125; &#125; 假设现在序列中某处子问题序列是(2,1)，那么回归到递归树上，将子问题与问题内容一一对应 [7]=(2,1)，[15]=(2)，[16]=(1) 那么递归栈将会[入]7 [出]15 [入]16 [出]16 [出]7 出栈即执行执行体，而对于[15]和[16]问题，我们判断不符合Left&lt;Right，那么就不会执行Merge，不做任何事就出栈 于是就到了[出]7，在子问题[7]中，环境变量中有left，mid，right，当然满足left&lt;right，于是我们就要对left~mid和mid~right执行merge操作 易误解 我自己的一个误区：递归并不是并发进行的，而是逐层进出栈，整个递归调用的顺序是线性的一条链。所以完全可以用一个全局变量来记录当前递归信息 二分查找是不需要递归来做的，外面一个循环，内部进行分治查找 二叉树的叶子结点有个虚的null结点，这样思考会更好一些 并不是出栈即执行，结合代码思考","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"C-回顾一些细节问题","slug":"程序语言/C-回顾一些细节问题","date":"2020-03-18T09:41:06.000Z","updated":"2020-03-23T09:47:00.000Z","comments":true,"path":"程序语言/C-回顾一些细节问题/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/C-%E5%9B%9E%E9%A1%BE%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98/","excerpt":"挺久没写C了，回顾一些易错的细节","text":"挺久没写C了，回顾一些易错的细节 输入输出输入和输出都要写格式控制表 输入的时候需要在变量前加一个&amp;，因为实际上scanf是将输入流中的数据输入到给定变量地址对应的储存单元上 但注意字符串并不需要加&amp;，因为字符串变量名实际上就是一个指向字符串所在地址的指针（数组变量名也是） scanf读取任何数据都以空格、换行为分隔符 /*INPUT*/ //输入格式控制 //int、float、double、char scanf(\"%d\",&amp;a); scanf(\"%c\",&amp;a); //string不需要&amp; scanf(\"%s\",s); /*OUTPUT*/ //输出格式控制 printf(\"%d\",a); printf(\"%s\",s); 读字符串问题http://c.biancheng.net/view/1833.html 注意：字符串不能这样，以下两者都是错的 char *str; scanf(\"%s\",str); //或 gets(str); 在C中，无论字符串或数组都必须要初始化，也就是要给定初值，或者只申明长度（初值默认为NULL） scanf默认以空格作为分隔符 gets默认以回车作为分隔符 数组定义c数组声明的时候必须指定长度：int a[5] 若声明的时候有初值，那就自动计算长度：int a[]=&#123;1,2,3,4,5&#125; 通过指针直接操作数组数组名是常量指针，指针是变量指针 数组在空间连续，数组名即指向数组储存单元首地址的指针，然后算地址偏移量即可找到数组某元素所在储存单元，我一般都习惯用指针来直接控制数组 不过注意数组在定义的时候就已经开辟了一串相邻的空间，指针增加元素要自己额外开辟内存 返回数组的函数C 语言不允许返回一个完整的数组作为函数的参数。 但是可以通过指定不带索引的数组名来返回一个指向数组的指针。 //举例 #include&lt;stdio.h> int* input() &#123; int a[5] = &#123;1,2,3,4,5&#125;; return a; &#125; int main() &#123; int *a = input(); printf(\"%d\",*a); &#125; 形参实参要改变实参需传递指针（地址）给函数 像在java中就不需要考虑这个问题，因为java中没指针，一切变量名皆引用（基本数据类型除外） 多维数组int [2][3];//只申明长度，默认初始化，值为NULL int [][]=&#123;&#123;1,2&#125;,&#123;2,3&#125;&#125;//不申明长度，直接自定义初始化 字符串其定义方式很像字符数组： char greeting[] = \"Hello\"; //也可以这样定义（我常用） char *string = \"abc\"; 但字符串末尾是&#39;\\0&#39;，标志字符串的结束位，而字符数组不需要，因为字符串变量名/数组变量名实际上就是一个指向字符串所在地址的指针，所以程序必须通过&#39;\\0&#39;来判断读取字符串是否结束。 所以sizeof(s)-1才是字符串s的长度，而sizeof(array)即是数组长度 比如对于上面定义的字符串 //字符串 char *string = \"abc\"; printf(\"%d\",sizeof(string)); --- 4 //'a','b','c','\\0' //字符数组 char string[] = &#123;'a','b','c'&#125;; printf(\"%d\",sizeof(string)); --- 3 //'a','b','c' 以下三个函数需导入#include &lt;string.h&gt; 字符串长度：strlen函数 将指定长度的字符串复制到字符数组中：strncpy函数 置字节字符串s的前n个字节为零：bzero函数，memset函数 文件读写：EOF问题略 C中的NULL在C语言中,NULL和0的值都是一样的,但是为了目的和用途及容易识别的原因,NULL用于指针和对象,0用于数值而Java中的null就是个关键字，是任何引用类型的默认值 常见问题warning: incompatible implicit declaration of built-in function ‘malloc’ 头文件缺：#include&lt;stdlib.h&gt;","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"C","slug":"程序语言/C","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/C/"}],"tags":[]},{"title":"JAVA链表基本操作","slug":"算法与数据结构/JAVA链表基本操作","date":"2020-03-14T14:22:25.000Z","updated":"2020-04-25T11:14:19.000Z","comments":true,"path":"算法与数据结构/JAVA链表基本操作/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/JAVA%E9%93%BE%E8%A1%A8%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"和C版对应","text":"和C版对应 /*链表常用操作*/ class LinkNode &#123; /* * 链表常用操作类 * 无头结点链表 */ //结点定义 static class Node &#123; Node(int data) &#123; this.data = data; &#125; int data; Node next = null; &#125; //从输入流建链表 static Node createLinkList() &#123; Scanner scanner = new Scanner(System.in); int data = scanner.nextInt(); Node head = new Node(data); Node p = head; //直到输入的值不为整数则结束读入 while (scanner.hasNextInt()) &#123; data = scanner.nextInt(); Node node = new Node(data); p.next = node; p = node; &#125; scanner.close(); return head; &#125; //快速新建下一个头结点 static void fastCreateNode(Node head,int data) &#123; Node p = new Node(data); head.next = p; &#125; //建立默认链表：5 2 1 3 4 static Node fastCreateDefaultList() &#123; Node linkList = new Node(5); LinkNode.fastCreateNode(linkList,2); LinkNode.fastCreateNode(linkList.next,1); LinkNode.fastCreateNode(linkList.next.next,3); LinkNode.fastCreateNode(linkList.next.next.next,4); return linkList; &#125; //打印链表 static void printLinkList(Node head) &#123; Node p = head; while(p.next!=null) &#123; System.out.print(p.data+\" \"); p = p.next; &#125; System.out.println(p.data); &#125; //反转打印链表 static void reversePrintLinkList(Node head) &#123; if (head.next!=null) reversePrintLinkList(head.next); System.out.print(head.data+\" \"); &#125; //在指定位置添加结点 static void addNode(Node head,int position,int data) &#123; Node p = head; //特殊情况，添加结点为首节点，position=0 if (position==0) &#123; Node headexgNode = new Node(head.data); headexgNode.next = head.next; head.next = headexgNode; head.data = data; return; &#125; for(int i=0; i&lt;position-1; i++) p = p.next; //p和p.next中间插一个新结点 Node newNode = new Node(data); newNode.next = p.next; p.next = newNode; &#125; //删除结点 static void deleteNode(Node head,int position) &#123; Node p = head; //特殊情况，删除头结点 if (position==0) &#123; head.data = head.next.data; head.next= head.next.next; return; &#125; for (int i=0; i&lt;position-1; i++) p = p.next; //删除p.next结点 p.next = p.next.next; &#125; //反转链表 static Node reverseLinkList(Node head) &#123; Node p=head,q=head.next; while(q.next!=null) &#123; Node temp = q.next; q.next = p; p = q; q = temp; &#125; //处理头结点head head.next = null; //注意这里,这句容易漏，漏了的话最后的头结点就是个单节点了 q.next = p; return q; &#125; &#125;","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"链表基本操作","slug":"算法与数据结构/链表基本操作","date":"2020-03-14T12:22:06.000Z","updated":"2020-03-14T12:24:52.000Z","comments":true,"path":"算法与数据结构/链表基本操作/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"建输增删查改反","text":"建输增删查改反 #include &lt;stdio.h> // null head node struct node &#123; int content; struct node *next; &#125;; struct node *createLinklist() &#123; struct node *head = malloc(sizeof(struct node)); struct node *p = head; int input=-1; while(input!=0) &#123; scanf(\"%d\",&amp;input); struct node *new = malloc(sizeof(struct node)); new->content = input; new->next = NULL; p->next = new; p = p->next; &#125; p->next=NULL; return head; &#125; void printLinkList(struct node *head) &#123; struct node *p = head->next; while(p->next!=NULL) &#123; printf(\"%d \",p->content); p = p->next; &#125; printf(\"\\n\"); &#125; void reversePrintLinkList(struct node *head) &#123; // 递归出入口 if (head->next!=NULL) reversePrintLinkList(head->next); //递归执行体 printf(\"%d \",head->content); &#125; void deleteNode(struct node *head,int label) &#123; struct node *p = head; int i; for(i=0; i&lt;label-1;i++) &#123; p = p->next; &#125; p->next = p->next->next; &#125; void addNode(struct node *head,int label,int content) &#123; struct node *p = head; int i; for (i=0; i&lt;label;i++) &#123; p = p->next; &#125; struct node *new = malloc(sizeof(struct node)); new->content = content; new->next = p->next; p->next = new; &#125; int findNode(struct node *head,int content) &#123; struct node *p = head->next; int count = 1; do &#123; if (p->content == content) return count; else &#123; count+=1; p = p->next; &#125; &#125;while(p->next!=NULL); return -1; &#125; int main() &#123; struct node *LinkList = createLinklist(); printLinkList(LinkList); // printf(\"which one to delete?\\n\"); // int label; // scanf(\"%d\",&amp;label); // deleteNode(LinkList,label); // printLinkList(LinkList); // printf(\"where to add behind and what?\\n\"); // int label,content; // scanf(\"%d %d\",&amp;label,&amp;content); // addNode(LinkList,label,content); // printLinkList(LinkList); // printf(\"what content to find?\\n\"); // int content; // scanf(\"%d\",&amp;content); // printf(\"found it in position %d\",findNode(LinkList,content)); printf(\"start reversing...\\n\"); reversePrintLinkList(LinkList->next); printf(\"\\n\"); return 0; &#125;","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"JUC组件实践总结","slug":"程序语言/JUC组件实践总结","date":"2020-03-12T14:45:05.000Z","updated":"2020-09-03T01:46:30.000Z","comments":true,"path":"程序语言/JUC组件实践总结/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JUC%E7%BB%84%E4%BB%B6%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/","excerpt":"JUC组件总结","text":"JUC组件总结 volatilevolatile变量应该作为类变量，不能放在方法里，否则局部变量保存在栈中，就没意义了 线程中断机制当阻塞方法收到中断请求的时候就会抛出InterruptedException异常（所以对于阻塞方法，必须捕获处理中断异常） 阻塞方法有wait、sleep、join、以及很多阻塞读写等等、 中断不是暂停，也不是停止，中断是改变了该线程的一个请求中断标志位。 中断标志位只是一个标志，如果不处理的话程序会继续执行下去（阻塞会抛出中断异常，非阻塞不会抛出）： ①对于阻塞方法，该中断标志位为true则直接抛出InterruptedException（然后可以在catch中捕获异常并处理，甚至可以再使用interrupted函数修改标志位让线程继续执行）； ②对于非阻塞方法，该中断标志位为true不会抛出InterruptedException，可以通过在线程程序中根据中断标志位的值来做出很多操作 线程中断相关函数： ①isInterrupted：实例方法，检查请求中断标志位是true还是false ②interrupted：静态方法，首先检查请求中断标志位是true还是false（并返回该检查值），然后将中断标志位重置为false（未请求中断的状态）。可用于线程被中断后，经过处理（或不打算处理）还要让线程继续运行的情况（注意该函数是先检查然后返回该值，再改变标志位，也就是说返回的不是改变后的中断标志位值） ③interrupt：中断线程 可以理解为isInterrupted是检查标志位，interrupted是检查并恢复中断标志位，interrupt就是中断 Synchronizer锁代码块在代码块中锁住某对象（在代码块中获得该对象的对象锁） synchronized(Object) //锁住圆括号里的对象 &#123; //锁住该对象的作用范围 &#125; 如果要锁的目标是本实例，则锁this引用指代的对象 synchronized(this) &#123; //todo &#125; 如果要锁的目标是该类的所有对象，则锁该类的Class对象 synchronized(Object.class) &#123; //todo &#125; 锁方法锁的作用范围是该方法，线程执行该方法必须获得同步锁 public synchronized void method() &#123; // todo &#125; 如果锁的是静态方法，则锁定的就是这个类的所有对象的该静态方法 public synchronized static void method() &#123; // todo &#125; 接口方法不适用，synchronized方法不可被继承，synchronized方法被重写默认不同步 ReentrantLockReentrantLock实现了Lock接口： //可用的Lock接口方法 void lock(); //阻塞获取锁 void lockInterruptibly(); //阻塞获取锁，获取到之前可被中断，中断后会抛出中断异常 boolean tryLock(); //非阻塞获取锁 boolean tryLock(long time, TimeUnit unit); void unlock(); //释放锁 Condition newCondition(); //返回当前线程的Condition，可用获得多个Condition ReentrantLock自己添加的方法，主要是管理作用： ReentrantLock(boolean fair); //构造器方法，传入true为公平锁，false为非公平锁 int getQueueLength(); //等待锁的线程数量 boolean hasQueuedThreads() //是否有线程等待锁 boolean hasQueuedThread(Thread thread) //是否有指定线程等待锁 int getHoldCount() //当前线程是否获取到了锁，返回1表示获取到了 boolean isLocked() //是否有线程持有该锁 boolean isFair() //是不是公平锁 一个ReentrantLock锁可以创建多个Condition，每个Condition都维护一个等待队列 await() / signal()是属于ReentrantLock机制的Condition组件的方法，而不是Object的 ReetrentLock需要处理异常 使用Lock时一定要在finally语句里面释放锁，否则发生异常时可能会导致锁无法被释放，导致程序奔溃 synchronized是获取目标对象关联的monitor对象的锁（获取锁的过程即修改monitor中的markword字段），而reetrentlock本身就是锁对象（不过可以通过Condition来维护多个等待队列）。线程争用的实际上是锁。 对象监视器：对象监视器实际上就是与每个对象关联的Monitor对象，也叫做管程锁。实际上监视器也是一个数据结构，里面维护着一系列等待队列、同步队列等。wait方法、notify方法、notifyAll方法，在使用的时候，必须要有自己的同步监视器（锁对象）。换句话：wait方法、notify方法、notifyAll方法，必须注册在某个同步监视器上（锁上）。 Condition即reetrentlock的监视器，它和monitor，也即Object的对象监视器是一样的作用 Condition： Condition是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition。 Condition类能实现synchronized和wait、notify搭配的功能，另外比后者更灵活，Condition可以实现多路通知功能，也就是在一个Lock对象里可以创建多个Condition（即对象监视器）实例，线程对象可以注册在指定的Condition中，从而可以有选择的进行线程通知，在调度线程上更加灵活（这样就可以只通知部分等待线程唤醒，开始抢锁）。而synchronized就相当于整个Lock对象中只有一个单一的Condition对象，所有的线程都注册在这个对象上。线程开始notifyAll时，需要通知所有的WAITING线程，没有选择权，会有相当大的效率问题。 1、Condition是个接口，基本的方法就是await()和signal()方法。 2、Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition() 3、调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用。 4、Conditon中的await()对应Object的wait()，Condition中的signal()对应Object的notify()，Condition中的signalAll()对应Object的notifyAll()。 参考：https://blog.csdn.net/weixin_43767015/article/details/104933955 reentrantlock和synchronized主要区别reentrantlock：多次加解锁、可中断、可公平、可非阻塞、多个condition-多同步队列-精确控制 reentrantlock底层：AQS同步器、CAS方式获取同步器状态 实践例子见生产者消费者问题 信号量多个线程竞争获取许可信号，并发控制交由信号量本身实现，我们只需要调用其提供的API即可 release()释放信号量，信号量计数+1；acquire()获取信号量，信号量计数-1 例子见生产者消费者问题，信号量方法 阻塞队列阻塞队列就相当于给你提供了一个带有同步功能的list，那就不需要自己辛苦去做线程同步了，直接使用阻塞队列提供的put() get() take()等方法即可 见生产者消费者问题，阻塞队列BlockingQueue方法 Object线程相关方法wait、notify等都是Object类的方法： Object.wait() Object.notify() Object.notifyAll() 每个Object都有一个等待队列，队列上是等待线程（若无多线程同步访问，则该等待队列是空的） wait()必须配合notify()使用，wait()等待由notify()唤醒（wait带参数可以设定最大等待时长） wait()等待会让当前线程立即放弃锁（即使它在同步块中），加入等待队列，直到notify()唤醒才会重新获取锁 notify()会让当前线程放弃锁，并通知Object的等待队列第一个等待线程可以获取锁了 notifyAll()会让当前线程放弃锁，并通知Object的等待队列上的所有等待线程可以获取锁了 （sleep()不放弃锁，且sleep()是Thread类的方法） 调用该对象的wait()，notify()和notifyAll()的线程在调用这些方法前必须”拥有”对象的锁。当前的线程不是此对象锁的所有者，却调用该对象的notify()，notifyAll()，wait()方法时抛出IllegalMonitorStateException异常。 ThreadLocal为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。主要就是不同线程有不同数据副本的情形下使用，如用来解决数据库连接、Session管理等；而如果该数据需要不同线程同步访问一份，那就不能用ThreadLocal 每个线程包含一个自己的ThreadLocal.ThreadLocalMap实例对象（成员变量引用名为threadLocals，private的），其中包含&lt;threadlocal-value&gt;键值对，我们通过ThreadLocal管理ThreadLocalMap。每创建一个ThreadLocal实例就是在当前线程中断ThreadLocalMap中创建了一个键，通过set函数设置其value 如下例子： ThreadLocal th1 = new ThreadLocal(); th1.set(new Object()); ThreadLocal th2 = new ThreadLocal(); th2.set(1); System.out.println(th1.get().getClass().toString()); //class java.lang.Object System.out.println(th2.get()); //1 P.S. ThreadLocal可能引发内存泄漏问题（原因同weakhashmap）：ThreadLocalMap的key是弱引用（ThreadLocalMap-&gt;Entry），而Value是强引用(Entry-&gt;Value)。这就导致ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，这样value就会一直存在，导致内存泄漏。 https://blog.csdn.net/Rex_WUST/article/details/98959422 线程池ExecutorService pool = Executors.newXXXThreadPool(); pool.submit(Callable&lt;T> callable); pool.execute(Runnable runnable); 四要素：核心线程，阻塞队列，非核心线程，最大线程数。各种线程池由以上不同的设置实现 P.S.new Exception.printStackTrace打印日志（最好用log4j） sleep、wait等函数的单位都是ms 在Runnable、Callable、FutureTask中可以可以使用Thread.currentThread来获取运行时当前任务所在线程的引用 （Thread.currentThread可以用在任何地方）","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"季节","slug":"日记/季节","date":"2020-03-10T11:25:38.000Z","updated":"2020-03-10T11:29:24.000Z","comments":true,"path":"日记/季节/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%AD%A3%E8%8A%82/","excerpt":"-","text":"- 在流动的季节里，忽然间感受到时间的长度 3月的风承载着想象，只要到了春天樱花就会持续绽放","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"我的硬件设备","slug":"硬件/我的硬件设备","date":"2020-02-23T15:21:26.000Z","updated":"2021-03-26T16:44:08.104Z","comments":true,"path":"硬件/我的硬件设备/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/%E6%88%91%E7%9A%84%E7%A1%AC%E4%BB%B6%E8%AE%BE%E5%A4%87/","excerpt":"这里记录我所使用的硬件，持续更新","text":"这里记录我所使用的硬件，持续更新 PCWorkstation(主机)CPU：Intel core i9 9900k + NZXT 海妖X62 280一体水冷主板：华擎 Z390 Phantom Gaming itx/ac显卡：Nvidia RTX 3090内存： Asgard 64G DDR4 4166MHzNVMe M2固态硬盘：SAMSUNG PM981 1T + HIKVISION C2000 Pro 2TSATA3固态硬盘： WD蓝盘 2T机械硬盘：东芝 P300 3T + 希捷酷鱼 1T显示器：ACER XV273K 27寸 4K 144Hz G-SYNC 10bit HDR外设：HHKB Professional2 + 罗技 G502 Wireless电源：长城巨龙 金牌1250w机箱：Be Quiet 500DX风扇：NZXT AER RGB2 x2 + NZXT HUE2控制中心 + Be Quiet wing3 PWM 14风扇 x5 Portable Desktop PC(副机)CPU：Intel core i5 9400f主板：MSI B360i Gaming Pro ac显卡：AMD R9 NANO内存：海盗船 32G DDR4 3200MHzSATA3固态硬盘： 英睿达 BX300 480G (mlc) + WD SN750 1T显示器：ViewSonic VX2478 4k 24寸 10bit外设： Akko + 雷蛇蝰蛇 + Apple magic touchpad2电源：极智猫 小1u 700w散热：AXP 90i 纯铜机箱：K39(22cm(H) x 18cm(L) x 10cm(W)=3.9L)系统：MAC OSX/WINDOWS 10 LaptopMicrosoft Surface Pro（Gen6 i5 8G 128G） Apple Macbook Pro (2014 i5 4G 128G) ConsolePlaystation 4 Pro Playstation Vita Nintendo Switch 3DS Xbox Elite Controller TabletIPAD PRO （Full Screen 12.9Inch 1T Cellular Version ） Mobile PhoneIPHONE Xr （128G） IPHONE 12 mini （128G） Sound PlayerSony 1000MX2 Apple Airpods Bose SoundLink Mini","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[]},{"title":"排序","slug":"算法与数据结构/排序","date":"2020-02-09T01:31:57.000Z","updated":"2021-04-17T14:11:23.678Z","comments":true,"path":"算法与数据结构/排序/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F/","excerpt":"序列长度为$N$，默认目标：从小到大排序","text":"序列长度为$N$，默认目标：从小到大排序 稳定性：排序前后与过程中，相等两个元素的相对顺序不会改变（需注意：有时候实现方式不同，稳定性也不同） 排序成本模型：在研究排序算法的时候，我们需要计算比较和交换的数量。对于不交换元素的算法，我们会计算访问数组的次数；空间复杂度如果是在原储存空间上即为$O(1)$，额外数组需要计算空间，每一次递归会开辟一个递归栈也需要占用空间。 基本排序算法冒泡排序经典 [步骤]：①外层循环：从第1个数到第$N-1$个数 ②内层循环：从第1个数到第$N-i-1$个数（$i$为外层循环计数，$N-i$即为待排序序列）开始依次两两比较（$j$与$j+1$比，$j$为内存循环计数），若遇到前者大于后者，则两两交换顺序 [核心]：内层循环设置一一交换相邻两个顺序不对的元素位置，像水泡一样一点点不断向上冒出来，每一轮外层大循环可以冒出一个最大的元素，加入已排序序列。 [特性分析]：①稳定（相同相邻元素不交换，交换只发生在相邻元素） [复杂度]：①时间：两层循环，最坏情况是完全反序，每两个相邻的都交换一次，比较$(N-1)+\\cdots+1+2=\\frac{N(N-1)}{2}$次，交换最$\\frac{N(N-1)}{2}$次；最好的情况是已经有序，只需进行一轮冒泡就发现已经有序（设置一个本轮未发生交换的flag），此时比较了$N-1$次。平均时间复杂度为$O(N^2)$ ②空间：原地in-place，$O(1)$ 选择排序[步骤]：①每一个大循环找到待排序序列中最小的元素 ②将其与待排序序列第一位交换，当前待排序序列第一位及左边元素即为该轮新的已排序序列 [核心]：不断地选择待排序序列中的最小者，放置到已排序序列末尾 [特性分析]：①复杂度与初始顺序无关（上一遍的扫描不能为下一步提供任何信息）②数据移动少（交换）③不稳定（将最小者固定放到已排序序列末尾，打乱了相等元素的顺序；④每个时刻生成的已排序序列是最终序列的子序列， 举例，某一轮排序：| 5(1) 5(2) 3-&gt;3 | 5(2) 5(1)) [复杂度]：①时间：两层循环，$\\frac{N(N-1)}{2}≈\\frac{N^2}{2}$次比较，$N$次交换，增长级为$O(N^2)$ ②空间：in-place（同一个序列内部排序，并划分为已排序部分和未排序部分，无需外部储存），空间复杂度为$O(1)$ [改进]：将内层循环中的交换改为将较大元素都向右移动 插入排序[步骤]：①每一个大循环顺序从待排序序列里取一个元素②将其插入进已排序序列里的正确位置（在已排序序列中找到第一个前者小于该数后者大于该数的位置，插入，后面的已排序序列依次右移一位） [核心]：顺序循环待排序序列中的每一个元素，将按正确顺序插入进已排序序列中 [特性分析]：①复杂度与初始顺序有关（基本有序序列比完全无序序列快很多，所以基本/部分有序序列使用效果非常好）②稳定（可设定未排序序列中的相等元素始终被插入已排序序列中相等元素的后面） ③每个时刻生成的已排序序列不是最终序列的子序列④不适合大规模数据，因为每一次的插入都伴随大规模的数组移动（数组） [复杂度]：①时间：两层循环，最坏情况（完全逆序）需要$\\frac{N^2}{2}$次比较和交换；最好情况（完全有序）需要$N-1$次比较和$0$次交换；平均需要$\\frac{N^2}{4}$次比较和交换；增长级见后图（为比较次数去掉常数参数项） ②空间：in-place（同一个序列内部排序，并划分为已排序部分和未排序部分，无需外部储存），空间复杂度为$O(1)$ 希尔排序基于插入排序 [步骤]：①外层大循环，每一轮选取一个GAP大小（设定每一轮$GAP\\to GAP/h$）②序列中所有间隔$GAP$距离的元素为一个GAP分组，对每个分组进行插入排序 ③直到GAP缩小到1，此时最后一轮相当于对整个序列进行插入排序 [核心]：改进了插入排序的缺点：越无序，数组越长，时间越长。通过巧妙分组，局部排序，每一次插入排序的数组仅限于一个GAP内，数量少；每经过一轮，序列逐渐局部有序，虽GAP逐渐缩小导致每个分组内元素逐渐变多，但是插入排序对基本有序序列排序具有很大优势，巧妙利用了插入排序的优势。 [特性分析]：①复杂度与初始顺序有关、每个时刻生成的已排序序列不是最终序列的子序列（毕竟基于插排） ②不稳定（gap子插排的存在）③希尔排序比插入排序和选择排序要快得多，且数组越大，优势越大 [复杂度]：略 基于分治思想的排序算法归并排序一种分治算法 [步骤]： 分（归）：两种归并的方法，区别在于归并顺序不同 可以用一个二叉树来表示所有的比较子问题，其中每个结点代表访问一个子问题（实际上所有递归比较问题都可以这么等效，包括下面的快速排序） ①自顶向下（递归） 开始递归，将问题划分为左边序列和右边序列两个子问题，先考虑左边子问题，出栈的时候开始执行并操作 递归的顺序：先左，依次入递归栈，直到抵达最小子问题，进入并流程，最底层递归出栈，再右，如此往复层层进栈出栈，每出一次栈解决一个子问题。 类似于二叉树的深度遍历 ②自底向上（多次遍历整个序列） 先将问题（整个序列）全部划分为最小子问题（长度为2或3的序列），然后进行两两归并，然后四四归并，然后八八归并，直到全部归并完毕。 类似于二叉树从底部开始的层次遍历 治（并）：如何处理一个子问题（即如何“并”：将两个有序序列合并为一个有序序列） 开辟一个temp数组，依次比较左边序列和右边序列的第一个元素，若左边的小就先将左边第一位元素插入temp中，若右边的小就先将右边第一位元素插入temp中，插入后该序列左移排除空位，继续比较。若某一边元素全部已插入，那么另一边子序列的剩余元素全部直接插入temp末尾。 [核心]：归并排序是分治思想的典型应用。将一个大问题分割成小问题分别解决，然后用所有小问题的答案来解决整个大问题。 「分」而「治」之——「归」而「并」之——归并： ①分：归：将序列排序问题套娃划分成短序列排序的子问题 ②治：并：将子问题采用并入中间数组的方式进行排序 分而治之，为什么分了之后“治”子问题的时候采用并入的方式排序会高效？因为这里利用了并的时候两边子序列是有序的特性，这样每并入一个元素的时候只需要比较左边序列第一个和右边序列第一个谁大谁小即可，且当某一边最大元素小于另一边的时候，剩下的元素直接copy，所以对两边都有序的子序列求并的运算复杂度很低 对于并过程中的短序列，也可以使用插入排序解决（可能比直接并更快） [特性分析]：①当数组长度为2的幂时，自顶向下和自底向上的归并顺序所用的比较次数和数组访问次数正好相同，只是顺序不同。②稳定（相等元素不会被交换先后位置） [复杂度]：分析归并算法的时间复杂度，实际上就是分析递归算法复杂度。 ①时间：比较模型为二叉树，那么可以直接计算出：$x$为递归次数（子问题个数），$2^x=N,\\therefore x=\\log N$，每个子问题即为进行一次合并，需要用时$1到N$之间，那么归并排序的时间复杂度增长极即为：$子问题个数×合并时间=O(N\\log N)$ ②空间：out-place，除原数组外需要一个“并”数组储存空间，用于并的时候做临时“并”用，再拷贝回原数组。其长度为$N$；又因为递归栈的深度为$\\log N$，所以空间复杂度为$O(N)+O(\\log N)=O(N)$ （归并排序可多线程） 快速排序一种分治算法，与归并排序互补，也是基于递归，存在递归调用二叉树。 [步骤]： 分： ①开始前先随机打乱序列 ②开始递归，随机选择一个元素作为切分元素（默认选序列第一个元素） ③每次递归选择一个切分点将序列划分为两个子序列，将随机选定的切分元素交换到切分点位置上，左边序列所有元素都小于切分点，右边序列所有元素都大于切分点 ④按照先左后右，与深度遍历二叉树一样的顺序继续递归左右子序列，不断获得切分点，得到最终序列 治：每个子问题③中如何选择切分点（荷兰国旗问题） 从子序列最左设定指针$i$，指向的元素为$a[i]$；子序列最右设定指针$j$，指向的元素为$a[j]$，随机选定的切分元素为$v$。 先$i$不断右移，直到找到一个$a[i]&gt;v$；然后$j$不断左移，直到找到一个$a[j]&lt;v$；将$a[i]和a[j]$交换，继续重复先后移动指针$i,j$。如果在$i或j$移动过程中相遇了，即$i==j$，则将切分元素和相遇处元素$a[j]$交换，作为切分点。（具体实现可以不这样，有更好的基于直接赋值的实现方式） 直到两个指针相遇，该点即为切分点，再将切分元素和切分点上的元素交换。 [核心]：基于分治算法。 分：每次递归计算一个切分点，将序列排序问题套娃切分成短序列排序的子问题 治：如何计算这个切分点：确保切分点后的子序列所有数大于切分点前所有数 [特性分析]：①每一次切分过程总是能排定一个元素，处于最终位置，不会再改变 ②序列越随机，效果越好，最好的情况是每次切分点正好是将子序列对半平分；最坏的情况是序列是已经排好的序列，一次切分只确定了第一个数，下一次切分的子序列只比上一个子序列少1（即上一个问题确定的切分点），子问题很大。所以我们首先将数组随机打散，避免了最坏情况③不稳定（比如 2 2 1 4 7 8，走一遍流程就看出来）④对于小数组，快速排序比插入排序慢（看增长级图） [复杂度]： ①时间：$x$为递归次数（子问题个数），问题模型为二叉树，最好情况下是每次切分点正好将子序列对半平分，即体现为完全二叉树，则子问题个数大约为：$2^x=N,\\therefore x=\\log N$；最坏的情况是序列是已经排好的序列，每个子问题只确定了一个数的正确位置，则子问题个数为$N$；治中交换的成本增长级为$N$。 递归时间复杂度=递归次数（子问题个数）×子问题处理时间。所以时间复杂度为：最坏$O(N^2)$，最好$O(N\\log N)$，平均$O(N\\log N)$ ②空间：数组储存空间是原地的：in-place，复杂度为$O(1)$；递归栈需要空间，所以快排的空间消耗只由递归栈的深度决定，最好情况深度为$\\log N$，平均$O(\\log N)$，最坏$O(N)$，分析方法同时间 [与归并排序的区别]：在归并排序中，先递归，再处理子序列（merge）；而在快速排序中，先处理子序列（荷兰国旗问题），再递归。不过两种算法的“处理子序列”含义是不一样的，在归并排序中是将子序列完全排序，而在快速排序中，是确保切分点后的子序列所有数大于切分点前所有数，并不要求完全排序 [改进]： ①在排序小数组子问题中切换到插入排序，结束该分支下的递归 ②三取样切分：找序列的中位数点一分为二，再找子序列中为数点一分为二，再找一次一分为二，共做三次中位数划分，分别对划分出的子序列做快速排序，最后再做插入排序 ③三向切分：针对存在大量重复元素的序列，其时间复杂度降低到线性级别$O(N)$【略】 堆排序[核心]： 堆的数组存储方式中，完全是按照完全二叉树的序号顺序存储的，对于父节点序号parent，左子节点序号为2*parent+1，右子节点序号为2*parent+2，序号最大的父节点序号为(lastindex-1)/2 几个核心动作： ①一次调整(adjust)：一次调整是一个循环过程。从parent节点子树往下进行调整（直到尾节点），如果不满足条件则子节点与父节点交换(swap)，并继续调整子节点，直到满足条件则停止继续往下调整，跳出循环。注意：从序号最大的parent开始，对每个节点进行调整！！！遍历范围: parent~((length-1)-1)/2 ②建堆(build)：从序号最大的父节点开始向上进行多次调整(adjust) ③堆排序(heap sort)：建堆(build)，然后每次取堆顶与堆尾进行交换(swap)，然后对堆顶进行一次调整(adjust) [数据结构]：优先队列两大基本操作：①删除最大元素②插入元素。 二叉树 简称 堆。大根堆：二叉树上的每个子树的父节点大于两个子节点；小根堆：二叉树上的每个子树的父节点小于两个子节点。（注意理解“子树”的含义，所有的递归套娃子树都要满足这个条件） 完全二叉树可以用数组实现，即二叉堆：一组能够用堆有序的完全二叉树排序的元素，并在数组中按层级储存（不使用数组中的第一个位置） 堆排序即是将无序堆通过上浮转化为大根堆，或通过下沉转化为小根堆，的堆有序化过程，是一种基于堆的优先序列实现。 [步骤]： 用[二叉堆数组]实现，且使用遍历算法（无需递归） 关键步骤 ①建堆（从最右子树父节点开始调整，一直调整到根节点）②堆排序（不断交换根节点与已排序区指针位置，调整根节点（array[0]）） 堆排序过程中维持一个不断扩大的已排序区，堆区域则一直在缩小（0,lastindex) 关键过程： 调整（若本节点孩子不符合规则，则调整完该结点继续调整孩子结点，即遍历调整该结点，直到不需要调整或到叶子结点） [核心]：每取出一个最大/最小的数，堆就进行一次有序化 [特性分析]：①适合在大量数据中，找序列中前几个最大/小的元素 ②不稳定 [复杂度]：①时间：树的深度最深为$\\log N$，每上浮/下沉一个数需要耗时的数量级则为$O(\\log N)$，一共有$N$个数，则全部排序需要耗时数量级为$O(N\\log N)$ ②空间：不需要递归，不需要额外空间，in-place，只在堆数组上进行，则时间复杂度为$O(1)$ 基于区间划分思想的排序算法计数排序将数字铺到一个数组里 空间浪费 非比较的 桶排序划分多个范围相同的区间，每个自区间自排序，最后合并（merge）。 桶排序(Bucket Sort)假设输入数据服从均匀分布，然后将输入数据均匀地分配到有限数量的桶中，然后对每个桶再分别排序（可以使用任何排序算法），对每个桶再使用插入排序算法（merge），合并方法同归并的merge。最后将每个桶中的数据有序的组合起来。假设输入是由一个随机过程生成，该过程将元素均匀的分布在一个区间[a,b]上，在[a,b]之间放置一定数量的桶，由于桶排序和计数排序一样均对输入的数据进行了某些假设限制，因此比一般的基于比较的排序算法复杂度低。 基数排序按照基数分桶，比如是十进制排序，则每一位是0~9，那么就分为10个桶 每一轮循环排序一个位，排序的时候储存在桶中，然后再复制回原数组 这样对每一位经过若干轮之后，最后的原数组即为最终排序数组 复杂度显然是基数（外层循环）×元素个数（内层循环） 注意是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。 https://www.runoob.com/w3cnote/radix-sort.html 总结 关于归并排序与快速排序空间复杂度问题： 归并排序每次递归需要用到一个辅助表，长度与待排序的表相等，虽然递归次数是O(log2n)，但每次递归都会释放掉所占的辅助空间，所以下次递归的栈空间和辅助空间与这部分释放的空间就不相关了，因而空间复杂度还是O（n）。而快速排序每次递归都会返回一个中间值的位置，必须使用栈。所以空间复杂度就是栈用的空间。 可以画出增长级图来根据数据量选择合适的算法，但也要考虑其它特殊因素，比如插入排序对基本有序数列非常快等等特性","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"补番表","slug":"Anime/补番表","date":"2020-01-31T07:51:41.000Z","updated":"2020-06-27T15:32:45.000Z","comments":true,"path":"Anime/补番表/","link":"","permalink":"https://aisaka.cloud/Anime/%E8%A1%A5%E7%95%AA%E8%A1%A8/","excerpt":"bgm记录会把在追的新番和在补的旧番放在一起，很是不方便，所以单独将补番表记录在此；持续更新","text":"bgm记录会把在追的新番和在补的旧番放在一起，很是不方便，所以单独将补番表记录在此；持续更新 TV ☐ 空之境界 ☑ 永生之酒 ☐ 去南极 ☐ 碧蓝幻想第一季 ☐ 碧蓝幻想第二季 ☐ space dandy ☑ 星际牛仔 ☐ 混沌武士 ☐ 超人幻想 ☐ 告白实行委员会 ☐ 喵内 ☑ 一拳超人 9/10 战斗戏业界标杆，各方面都极其优秀，过瘾 ☑ FLCL #0，9/10 “不挥棒的话，什么都不会发生哦” “没有什么了不得的大事，只有理所当然的事情在发生。像往常一样渡过大桥，即使是在这么短暂的光阴之中季节也在变换。” “NEVER KNOWS BEST” 只有动画里才会有如此天马行空的想象和表现。虽然不尽相同，但这就是青春啊。 ☐ FLCL Alternative ☐ 摇曳露营 ☐ 攻壳机动队 ☐ 珂朵莉 ☑ 妄想代理人 “我失去归宿的现实才是我真正的归宿” ☐ 钢之炼金术师 ☐ 冰海战记 ☐ 月色真美 ☐ 罪恶王冠 ☐ Promare ☐ 女友修罗场 ☐ 机动战士高达UC ☐ 穿越时空的少女 ☐ 灵能百分百 ☐ 百合熊 ☐ 回转企鹅罐 ☐ 齐木楠雄第二季 ☐ 鬼灭之刃 ☐ 3月的狮子 ☐ WIXOSS ☐ 续·终物语 ☐ 龙与虎（八周目，6月） Anime Movie ☑ 未麻的部屋 无情造梦机器今敏老师，给我看傻了 ☐ 若能与你共乘海浪之上 ☐ 东京教父 长篇 ☐ 银魂 ☐ ☑","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"新年","slug":"随笔/新年","date":"2020-01-24T17:20:12.000Z","updated":"2020-02-18T15:27:10.000Z","comments":true,"path":"随笔/新年/","link":"","permalink":"https://aisaka.cloud/%E9%9A%8F%E7%AC%94/%E6%96%B0%E5%B9%B4/","excerpt":"to be continued主题曲：春意红包 先请自行脑补XD","text":"to be continued主题曲：春意红包 先请自行脑补XD 明明去年有那么多那么多的事情，但回顾稿却无从下笔 已经记不清这是第几天没法出门了，不过还好在假期的开头就和朋友们见了个遍下学期就要到另一个阶段了啊。刚看完星际牛仔（2.3），老实说不是很对胃口，但是也感受到了贯穿全片的浪漫主义情怀浪漫主义和理想主义的区别是什么呢？大概前者偏向主观的行为，而后者是对理想世界的刻画吧。今年要完成的事情还有很多，加油 P.S.待这篇到第二页之后再补完","categories":[{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[]},{"title":"我永远喜欢岩永琴子","slug":"Anime/我永远喜欢岩永琴子","date":"2020-01-23T13:27:48.000Z","updated":"2020-01-25T13:31:33.000Z","comments":true,"path":"Anime/我永远喜欢岩永琴子/","link":"","permalink":"https://aisaka.cloud/Anime/%E6%88%91%E6%B0%B8%E8%BF%9C%E5%96%9C%E6%AC%A2%E5%B2%A9%E6%B0%B8%E7%90%B4%E5%AD%90/","excerpt":"","text":"","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"老婆","slug":"老婆","permalink":"https://aisaka.cloud/tags/%E8%80%81%E5%A9%86/"}]},{"title":"某科学的一月新番","slug":"Anime/某科学的一月新番","date":"2020-01-15T14:23:47.000Z","updated":"2020-03-30T16:35:55.000Z","comments":true,"path":"Anime/某科学的一月新番/","link":"","permalink":"https://aisaka.cloud/Anime/%E6%9F%90%E7%A7%91%E5%AD%A6%E7%9A%84%E4%B8%80%E6%9C%88%E6%96%B0%E7%95%AA/","excerpt":"1.18更新 京紫外传 1.31删除 地缚少年花子君，22/7 3.31 评分 异度侵入 9/10，加入剧情向人类圣经","text":"1.18更新 京紫外传 1.31删除 地缚少年花子君，22/7 3.31 评分 异度侵入 9/10，加入剧情向人类圣经 京紫三年·冬今年新番整体质量上乘，第一集全部扫了一遍，喜欢的还蛮多的 #0 紫罗兰永恒花园 剧场版：永远与自动书记人偶 我宣布，我成为了真正的京吹了 用极致的音乐，完美的作画，讲究的分镜与脚本，立体的人物描绘和设定，将一个简单的故事刻画地十分精致，完成度极高，细节丰富，情感渲染非常棒。 这次是我发自内心的吹爆，选入#0 ，并且归入“人类圣经” #1 有生之年 某科学的超电磁炮T 啥也不说了。。老泪纵横，等了多久了啊！！ 还记得以前在教室里用讲台上的电脑追超炮S的情景www 感谢JC爸爸给我们魔禁厨留了最后一块处女地（没被无情的粉碎机粉碎） 这质量，这线条，这光，这水，这炮姐，这初春！啊，是熟悉的味道 #2 非常感兴趣 别对映像研出手！ 汤浅政明四个字就是追下去的理由 异度侵入 ID:INVADED 这个动画的设定可以直接拿来出游戏了，太妙了，设定很棒，剧情目前来看也很精彩，1月最期待剧情作品。让我想起打越钢太郎才出不久的AI 梦境探案，不过这个设定要更新奇更有意思 索玛丽与森林之神 很治愈很温暖，但我感觉结局要致郁…希望别是毒奶 虚构推理 设定有意思；女主，爱了 齐木楠雄的灾难 再始动篇 艾博，拉面一库贼 #3 很有意思 恋爱小行星 猛男番 房间露营Delta（泡面） 猛男番x2 精力有限，还有不少番要补，这个季度就不挖太多坑了，然而即使如此收敛还是追了这么多orz 后记 感谢京紫，感谢这个伟大的时代 不得不提星掠者这个番，实属把我逗乐了，比手机侠还NB的番真不多见了……. 呼~寒假开始了~","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"新番","slug":"新番","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E7%95%AA/"}]},{"title":"三年前的今天，京紫降世","slug":"Anime/三年前的今天，京紫降世","date":"2020-01-10T11:33:53.000Z","updated":"2020-01-10T11:38:46.000Z","comments":true,"path":"Anime/三年前的今天，京紫降世/","link":"","permalink":"https://aisaka.cloud/Anime/%E4%B8%89%E5%B9%B4%E5%89%8D%E7%9A%84%E4%BB%8A%E5%A4%A9%EF%BC%8C%E4%BA%AC%E7%B4%AB%E9%99%8D%E4%B8%96/","excerpt":"又到一年一度狂欢盛典","text":"又到一年一度狂欢盛典 三年前的今天，京紫降世，开启了新… 算了这次不瞎黑吹了… 发自内心祝京紫剧场版大卖","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"doc2vec","slug":"人工智能/doc2vec","date":"2020-01-10T05:59:18.000Z","updated":"2020-01-10T10:40:33.000Z","comments":true,"path":"人工智能/doc2vec/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/doc2vec/","excerpt":"原论文：http://proceedings.mlr.press/v32/le14.pdf – Le &amp; Mikolov, ICML 2014 evedroid算法用到了doc2vec来表征api的特征空间向量，看了一下doc2vec其实就是word2vec的DLC版。 doc2vec是将一篇文档转化为一个向量，word2vec是将一个单词转化为一个向量，doc2vec是基于word2vec的，论文作者将word2vec方法扩展到了句、段，甚至文档，将其嵌入到向量空间。本文句子实际就可代替文档。 doc2vec支持不定长输入","text":"原论文：http://proceedings.mlr.press/v32/le14.pdf – Le &amp; Mikolov, ICML 2014 evedroid算法用到了doc2vec来表征api的特征空间向量，看了一下doc2vec其实就是word2vec的DLC版。 doc2vec是将一篇文档转化为一个向量，word2vec是将一个单词转化为一个向量，doc2vec是基于word2vec的，论文作者将word2vec方法扩展到了句、段，甚至文档，将其嵌入到向量空间。本文句子实际就可代替文档。 doc2vec支持不定长输入 最基础的一种想法是直接将整句话词向量求和做平均，但这样的问题在于忽略了句子的结构和前后顺序，丧失了很多信息。 PV-DMdoc2vec中的PV-DM（Distributed Memory Model of paragraph vectors）对应word2vec中的CBoW PV-DM在CBoW的基础上，输入不仅是一句话滑动窗口内的所有词，还有一个在一句话中共享的句子向量(Paragraph vector) 训练模型：在滑动窗口内的输入词中取其中一个为预测词；构造了一个新的向量，即句子向量(Paragraph vector)；然后把句子向量和滑动窗口内所有one-hot词输入进模型：①句子向量用矩阵$D$表示，其作为训练参数，每一列代表一个句子，最开始要初始化；②one-hot词向量乘以输入词权值向量矩阵$W$，③然后线性求和得到隐藏的中间向量，④再乘以输出权值矩阵通过softmax激活，来预测预测词，与输入的预测词求损失，⑤通过反向传播梯度下降，训练结束后得到训练完成的$D,W$。 输入的句子向量保留了整个句子信息，相当于记忆。同一句话经过滑动窗口滑动，会有多次训练，每次训练中输入都包含上一次该句子滑动窗口使用的句子向量。 这个句子向量相当于这句话的“主题”。随着窗口的滑动，一句话训练多次，不断训练得到句子向量也会越来越准确，越能代表该句话 训练完模型之后，如何预测句子向量：实际上依然是要将初始化句子向量矩阵和词的one-hot向量输入模型，滑动窗口选词，句子向量矩阵共享，进行多次反向传播梯度下降，不断迭代调整句子向量权值矩阵，只不过输出权值矩阵$W’$和词向量都已经固定不变了，变的只有句子向量权值矩阵，而最终得到的结果这个句子向量矩阵。 PV-DBOWdoc2vec中的PV-DBOW（Distributed Bag of Words of paragraph vector）对应word2vec中的skip-gram 就，反过来呗 Doc2Vec的想法和RNN的想法很像 Toolsgensim库中有doc2vec","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"2020初雪，是结束也是起点","slug":"日记/旧的结束，也是新的开始","date":"2020-01-07T00:15:06.000Z","updated":"2020-01-07T01:23:41.000Z","comments":true,"path":"日记/旧的结束，也是新的开始/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%97%A7%E7%9A%84%E7%BB%93%E6%9D%9F%EF%BC%8C%E4%B9%9F%E6%98%AF%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B/","excerpt":"今天（指1月5号），终于到了最后呈现结果的日子。 我们组的独立游戏获得了第一名！ 本来最后还以为一点希望都没有了，上台展示和给评委试玩后被评委喷了个狗血淋头，世界观人设太薄弱balabala，丝毫不提我们的玩法，下台后我们都已经想好等以后当上P9如何处置这些评委了（草） 但在最后颁奖的时候，一转攻势（？），听到评委口中念出我们的名字的那一刻，本组组员们当场喜极相拥（？）过于震惊 此处一万字心理描写","text":"今天（指1月5号），终于到了最后呈现结果的日子。 我们组的独立游戏获得了第一名！ 本来最后还以为一点希望都没有了，上台展示和给评委试玩后被评委喷了个狗血淋头，世界观人设太薄弱balabala，丝毫不提我们的玩法，下台后我们都已经想好等以后当上P9如何处置这些评委了（草） 但在最后颁奖的时候，一转攻势（？），听到评委口中念出我们的名字的那一刻，本组组员们当场喜极相拥（？）过于震惊 此处一万字心理描写 我们是冠军！！！ 这就是欲扬先抑吗！？哈哈哈哈 这是我人生第一次参与游戏制作（如果不算初中自己瞎鼓捣的那个勇者斗恶龙XD），认识了来自各个学校的小伙伴，见识了很多大大大大大佬。 获得了这么多朋友，真的很开心。 能够一起做游戏，真的很开心。 想起《头号玩家》里的那句话：谢谢你玩我的游戏。 游戏不仅能带给玩家快乐，也能带给制作者快乐。给人带来快乐就是游戏存在的意义吧。 最后老师说了一些话，我记得最深的一句是： 在游戏行业，支撑你走下去的，一定是热情。 晚上快9点了，腾讯结业典礼也结束了，出门即看到2020年京城的第一场大雪，漫天飞雪如鹅毛。 虽然不是每个人都会继续加入光子，但是未来也渐渐更清晰了。 经过这一学期，深感做游戏的不易，尤其要感谢辛苦的美术大佬和程序大佬。 PS1. 拿着巨大奖金支票的美术大大XD，并将支票一路拿到地铁站抬回寝室 PS2. 第五组赛高！！","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"下山","slug":"Music/下山","date":"2020-01-02T00:27:04.000Z","updated":"2020-01-02T00:45:57.000Z","comments":true,"path":"Music/下山/","link":"","permalink":"https://aisaka.cloud/Music/%E4%B8%8B%E5%B1%B1/","excerpt":"","text":"最近越来越喜欢这种风格的歌了是怎么回事 醋醋六道版（Bilibili） 六道原来是成都人我才知道 我最喜欢的完整版是这个版本（QQ音乐） 男声原版（网易云音乐）的也很棒","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[]},{"title":"2020","slug":"日记/2020","date":"2019-12-31T17:04:12.000Z","updated":"2020-01-08T06:45:07.000Z","comments":true,"path":"日记/2020/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/2020/","excerpt":"","text":"经历了剧烈成长的一年之后 你好，2020","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"圣夜祭","slug":"Anime/龙与虎·圣夜祭","date":"2019-12-24T15:29:57.000Z","updated":"2020-01-01T16:07:46.000Z","comments":true,"path":"Anime/龙与虎·圣夜祭/","link":"","permalink":"https://aisaka.cloud/Anime/%E9%BE%99%E4%B8%8E%E8%99%8E%C2%B7%E5%9C%A3%E5%A4%9C%E7%A5%AD/","excerpt":"ホーリーナイト さあ クリスマス いっぱいの笑顔 来吧 Christmas 将满满的笑容 君に届けんだ パーティー・ナイト 传达给你的 Party Night さあ クリスマス いっぱいの願い 来吧 Christmas 用满满的愿望 君に誓うんだ ホーリー・ホーリー・ナイト 向你发誓 Holy Holy Night 今年のクリスマス ちょっと特別さ今年的Christmas 稍微有点特别 ホワイト・クリスマスじゃ なくたって 虽然这并不是 White Christmas 星屑のイルミネーション ほら ふりつもるよ 但群星就如明亮灯彩 看 堆积起来了哦 キラキラ 輝いて みんなが幸せで 亮晶晶地 闪耀著 大家都很幸福 チカチカ 瞬いて みんなが夢をみて 一闪闪地 眨著眼 大家都已入眠","text":"ホーリーナイト さあ クリスマス いっぱいの笑顔 来吧 Christmas 将满满的笑容 君に届けんだ パーティー・ナイト 传达给你的 Party Night さあ クリスマス いっぱいの願い 来吧 Christmas 用满满的愿望 君に誓うんだ ホーリー・ホーリー・ナイト 向你发誓 Holy Holy Night 今年のクリスマス ちょっと特別さ今年的Christmas 稍微有点特别 ホワイト・クリスマスじゃ なくたって 虽然这并不是 White Christmas 星屑のイルミネーション ほら ふりつもるよ 但群星就如明亮灯彩 看 堆积起来了哦 キラキラ 輝いて みんなが幸せで 亮晶晶地 闪耀著 大家都很幸福 チカチカ 瞬いて みんなが夢をみて 一闪闪地 眨著眼 大家都已入眠 さあ クリスマス いっぱいの笑顔来吧 Christmas 将满满的笑容 君に届けんだ パーティー・ナイト 传达给你的 Party Night さあ クリスマス いっぱいの願い 来吧 Christmas 用满满的愿望 君に誓うんだ ホーリー・ホーリー・ナイト 向你发誓 Holy Holy Night 今年のクリスマス きっと特別さ 今年的Christmas 一定非常特别 ロンリー・クリスマスじゃ つまらない 若是Lonely Christmas的话 就太无趣了 笑顔はイルミネーション ほら 飾ってあげる 笑容就如明亮灯彩 看 装饰起来了 ユラユラ 揺らめいて みんなで手をつなぎ 摇来摇去 摇摆著 大家一起手拉著手 ピカピカ きらめいて みんなで星みあげ 闪闪亮亮 发著光 大家一起仰望星空 さあ クリスマス いっぱいの笑顔 来吧 Christmas 将满满的笑容 君に届けんだ パーティー・ナイト 传达给你的 Party Night さあ クリスマス いっぱいの願い 来吧 Christmas 用满满的愿望 君に誓うんだ ホーリー・ホーリー・ナイト 向你发誓 Holy Holy Night 音乐链接 第十九集·圣夜祭·圣诞夜会全剧的一次情感高潮，这首歌是这集剧中bgm之一和ED 无论看多少次依然会泪目 图to be continued","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"龙与虎·文化祭·幸福的掌中萌虎","slug":"Anime/龙与虎3","date":"2019-12-23T15:10:06.000Z","updated":"2019-12-24T13:43:58.000Z","comments":true,"path":"Anime/龙与虎3/","link":"","permalink":"https://aisaka.cloud/Anime/%E9%BE%99%E4%B8%8E%E8%99%8E3/","excerpt":"龙与虎七周目记录，图多","text":"龙与虎七周目记录，图多 第十二，三集·大桥高校文化祭（中，下篇）大河选择相信了爸爸，但爸爸又一次利用和欺骗了她 亚美变得不一样了，露出了她坚强且善良的本性。 男主知道了自己对大河爸爸的期望原来都是一厢情愿，知道了自己的错 在大河最孤独的时候，男主和实乃梨一起走了出来，为了她拼尽全力奔跑，为了陪在她身边，一生要有这样的朋友，大概是上辈子拯救了银河系吧。 在全篇动画的中篇，所有人的情感都发生着微妙的变化，大河面对北村这次没有脸红了，龙儿面对实乃梨也已经不像以前那样了，实乃梨却渐渐意识到了自己的情感。 第十四集·しあわせの手乗りタイガー·幸福的掌中老虎 摸到就会变得幸福的掌中萌虎传说，可是大河自己呢？所有人都能获得幸福，除了主角们。 北村与会长的故事即将到达高潮。 另一方面，亚美真正的内心也只有男主看穿了，只有在高须面前，亚美不再是个“成熟的大人”。 大河也已经完全从父亲事件中走出来了。 幸福是什么呢？ 第十五集·星は远く·星星，好远像星星一般追逐着 第十六集·踏み出す一歩·迈出的那一步北村会长线高潮 （上帝视角·亚美又是看穿了一切。。） 北村大概是全校最猛的汉子 这集结束后，佑作和大河的故事彻底收尾了。 最后亚美和实乃梨的对话埋了一个大伏笔，她已经看穿了实乃梨的“负罪感”的心情，并铺垫了男主和实乃梨线。","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"给自己的圣诞礼物~","slug":"硬件/给自己的圣诞礼物","date":"2019-12-22T13:42:33.000Z","updated":"2021-01-18T05:46:45.000Z","comments":true,"path":"硬件/给自己的圣诞礼物/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9C%A3%E8%AF%9E%E7%A4%BC%E7%89%A9/","excerpt":"这两天把以前用的DELL U2718QM显示器换成了新买的ACER XV273K，当作给自己的圣诞礼物~","text":"这两天把以前用的DELL U2718QM显示器换成了新买的ACER XV273K，当作给自己的圣诞礼物~ 参数： 4K分辨率，144Hz刷新率，支持G-SYNC，10bit色深，电影领域专业色域标准DCIP3 95%，HDR，延迟&lt;1ms，色差Delta E&lt;1，IPS屏幕 10bit色深，超低色差，以及DCIP3标准下，色彩完全超越了以前用的U2718QM；144Hz下显示效果丝般顺滑，有了G-SYNC也终于可以扔掉万恶的垂直同步了… P.S.1 G-SYNC是我的主要目的，深受垂直同步不开撕画面（我的心情也撕裂），开了帧暴降（我的心情也暴降）困扰的我：(〝▼皿▼) P.S.2 同学推荐我的这个型号，也参考了知乎大佬：“最强”4K144显示器，还只要7000-宏碁xv273k评测，这参数这价格，性价比真的强无敌… 双DP下，4K144Hz+10bit+G-SYNC开启成功~ 甚至还有LED灯，把XBOX手柄放在这里特别帅气，很Gamer！ 显示器也送了左上右的遮光罩，里面还有吸光棉（因为专业用户对色彩要求极高，不能有光线打扰，所以不少会送这个），但我觉得我桌上环境已经蛮暗了，遮光罩还是吃灰去吧…. 啊爽死了！","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[]},{"title":"网站冬日主题改动","slug":"程序语言/next冬日风格改动","date":"2019-12-20T10:02:34.000Z","updated":"2019-12-20T10:11:55.000Z","comments":true,"path":"程序语言/next冬日风格改动/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/next%E5%86%AC%E6%97%A5%E9%A3%8E%E6%A0%BC%E6%94%B9%E5%8A%A8/","excerpt":"明天就是冬至了，想起来网站的风格几个月没变了，就稍微改了一下记录下来，不然下次忘了自己改了啥了= = 主要是以雪色#b1bbf0为主题，直接从背景图取的色，我还挺喜欢这个颜色的 标题和副标题的字号都调了一下 全文字体改为谷歌的思源字体了","text":"明天就是冬至了，想起来网站的风格几个月没变了，就稍微改了一下记录下来，不然下次忘了自己改了啥了= = 主要是以雪色#b1bbf0为主题，直接从背景图取的色，我还挺喜欢这个颜色的 标题和副标题的字号都调了一下 全文字体改为谷歌的思源字体了 设置手机与PC端不同的背景样式，我直接在主样式下加了 @media screen and (min-aspect-ratio: 1/1)&#123; &#125; @media screen and (max-aspect-ratio: 1/1)&#123; &#125; 主题透明度的样式新添在主样式下 .main-inner 根据屏幕长宽比来判断是手机还是电脑 C:\\aisakaki\\themes\\next\\source\\css_common\\components\\header\\site-meta.styl .brand样式修改标题， .site-subtitle副标题样式 C:\\aisakaki\\themes\\next\\source\\css_common\\components\\header\\site-nav.styl 修改标题button C:\\aisakaki\\themes\\next\\source\\css_common\\components\\sidebar\\sidebar-author.styl 修改样式，添加sidebar头像 .site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; border-radius: 60%; transition: 2.5s all; &#125; 同目录下sidebar.styl修改按钮和links a &#123; //color: $grey-dark; //border-bottom-color: $black-light; //&amp;:hover &#123; color: $gainsboro; &#125; color: #fff; border-bottom-color: #fff; &amp;:hover &#123; color: $black-light; &#125; &#125; .sidebar-inner修改links小字样式 同目录下sidebar-nav修改描述样式 当时没有找到menu的样式表，所以我直接审计元素在主样式表里修改menu颜色… .menu .menu-item a &#123; padding: 1px 5px; background: transparent; border: none; color: #fff; //transition-property: background; //box-shadow: 5px 5px 5px #888; border-radius: 10px; &#125; &#125; C:\\aisakaki\\themes\\next\\source\\css_common\\components\\sidebar\\sidebar.styl修改侧边栏样式 为了让鼠标移到标题上变色，给标题添加一个hover(直接写在主样式里了)： .posts-expand .post-title-link:hover&#123; color: #49b1f5; &#125; 鼠标移到标题上时在其下面显示下划线效果： .posts-expand .post-title-link::before &#123; content: \"\"; position: absolute; width: 100%; height: 2px; bottom: 0; left: 0; background-color: #49b1f5; visibility: hidden; -webkit-transform: scaleX(0); -moz-transform: scaleX(0); -ms-transform: scaleX(0); -o-transform: scaleX(0); transform: scaleX(0); transition-duration: 0.2s; transition-timing-function: ease-in-out; transition-delay: 0s; &#125; 上面两个的样式都可以写在C:\\aisakaki\\themes\\next\\source\\css_common\\components\\post\\post-title中覆盖原样式 右下角两个也要改，直接审查元素吧 归档页面的小灰点在post-collapse.styl中的.post-header &amp;::before ，下面还有border-bottom-color:属性是下划线属性，&amp;::before中修改光标移上去的颜色 在archiev.styl中修改上面最大的灰点 post-collapse.styl里改了一堆，懒得记了 文章的侧边栏的目录结构在sidebar-nav.styl中修改 .sidebar-nav .sidebar-nav-active &#123; //color: $sidebar-highlight; color: #fff //border-bottom-color: $sidebar-highlight; border-bottom-color: #fff 对应了标题和下划线 目录样式在sidebar-toc.styl中 在post-expands.styl中修改h2，h3，….等的样式","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[]},{"title":"龙与虎·暑假·海边","slug":"Anime/龙与虎2","date":"2019-12-19T15:49:44.000Z","updated":"2019-12-23T15:58:51.000Z","comments":true,"path":"Anime/龙与虎2/","link":"","permalink":"https://aisaka.cloud/Anime/%E9%BE%99%E4%B8%8E%E8%99%8E2/","excerpt":"龙与虎七周目记录，图多","text":"龙与虎七周目记录，图多 暑假·海边第九集·海にいこうと君は·和你一起去海边然后，高二的暑假就开始了 在这个充满欢乐与青春的暑假之后，由大河，龙儿，佑作，实乃梨，亚美，他们这个小圈子算是彻底形成了，他们之间的关系得到了更进一步的成长。 不得不提一句，亚美在这里就已经看穿了佑作喜欢会长….给后面埋了个伏笔 亚美并没有放弃。 经典的幽灵一幕。这段对话彻底的显示出了小实的心境，也是男主第一次表达自己的情感 这段话也是我最喜欢的话之一 在听到男主后面回接的那段话之后，小实感受到了龙儿喜欢自己，但是她却没有这种情感，幽灵对她果然还是太遥远了。 那个梦就是暑假第一天男主和女主一起做到的同一个奇怪的梦。。 第十集·花火·烟花 在最后，实乃梨的回应 在探险与花火中，夏天结束了 实际上这之后，男主的情感已经微妙地完全改变了，这也是实乃梨后面行动的原因","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"[七周目]龙与虎","slug":"Anime/七周目-龙与虎","date":"2019-12-18T03:12:25.000Z","updated":"2019-12-19T02:05:09.000Z","comments":true,"path":"Anime/七周目-龙与虎/","link":"","permalink":"https://aisaka.cloud/Anime/%E4%B8%83%E5%91%A8%E7%9B%AE-%E9%BE%99%E4%B8%8E%E8%99%8E/","excerpt":"","text":"龙与虎第七周目中，发几篇记录，这次是从暑假开始看的，中途断了一阵子。圣诞节要到了，赶在圣诞夜之前补到第19集（圣夜祭） 这是我最喜欢的动画，我心中青春校园动画的巅峰，青春的主题：恋爱，家庭，班级，友谊，在这部细腻且温暖的动画里体现的淋漓尽致。 这是一部每个角色我都喜欢的动画，每个人的内心都那么细腻，每个人都有最闪耀的地方。 但也正因此，需要观众仔细去捕捉每个人微妙的情感与变化，所以很多台词和情感要多周目之后才能理解。 每一次看龙与虎，都会更心疼每一个角色，更喜欢每一个角色，更深刻地理解每一个角色的情感。 前几集不小心给删了，下一篇直接从暑假篇开始…","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"人间烂漫","slug":"Music/人间烂漫","date":"2019-12-17T00:18:14.000Z","updated":"2020-06-02T01:22:09.000Z","comments":true,"path":"Music/人间烂漫/","link":"","permalink":"https://aisaka.cloud/Music/%E4%BA%BA%E9%97%B4%E7%83%82%E6%BC%AB/","excerpt":"数花灯 折泥偶 行行走走 戴面具 哼着歌 晃晃悠悠 逢今日 哪家的 少年轻裘 擦肩而过 两相回眸 天涯忽如近 咫尺忽若远 裁熏风 赠我四季暖 悄悄地思念 轻轻地誓言 追春信 报你花满川","text":"数花灯 折泥偶 行行走走 戴面具 哼着歌 晃晃悠悠 逢今日 哪家的 少年轻裘 擦肩而过 两相回眸 天涯忽如近 咫尺忽若远 裁熏风 赠我四季暖 悄悄地思念 轻轻地誓言 追春信 报你花满川 音乐链接","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[{"name":"hanser","slug":"hanser","permalink":"https://aisaka.cloud/tags/hanser/"}]},{"title":"潜在狄利克雷分配","slug":"人工智能/潜在狄利克雷分配","date":"2019-12-12T01:23:56.000Z","updated":"2020-01-15T09:56:49.000Z","comments":true,"path":"人工智能/潜在狄利克雷分配/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%BD%9C%E5%9C%A8%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E9%85%8D/","excerpt":"Latent Dirichlet Allocation，LDA LDA是PLSA生成模型的扩展，可以看作引入贝叶斯的PLSA，也是文本集合的生成概率模型","text":"Latent Dirichlet Allocation，LDA LDA是PLSA生成模型的扩展，可以看作引入贝叶斯的PLSA，也是文本集合的生成概率模型 Latent Dirichlet AllocationPLSA的缺陷与LDA的改进LDA与PLSA生成模型都假设话题$z$是单词$w$的多项分布，文本$d$是话题$z$的多项分布，即$d\\to z \\to w$ 然而PLSA存在的缺陷：PLSA不使用先验分布，或者说假设先验分布为均匀分布。具体地，回忆PLSA生成模型公式：$P(w,d)=P(d)\\sum_zP(w|z)P(z|d)$，这里面的两个概率分布$P(w|z)$和$P(z|d)$（即这两个分布的参数）是没有先验分布的，或者说假设先验分布为均匀分布。 ①（改进）LDA则使用了狄利克雷分布作为先验分布，也就是概率分布的参数的分布是狄利克雷分布 即$P(w|z)$和$P(z|d)$两个分布的参数，满足两个各自的狄利克雷分布，由该分布给出 这样一来，两个多项分布的参数就不是确定的了，而是这个参数服从狄利克雷分布，而在PLSA中参数是确定的 这样可以防止学习过程中产生的过拟合 ②（不同）在文本生成过程中，PLSA基于极大似然估计（回看PLSA一节使用EM求解），而LDA是基于贝叶斯学习 核心思想在PLSA生成模型之上（先回看PLSA），根据贝叶斯原则，我们对$P(w|z)$和$P(z|d)$两个分布（多项分布）的参数引入先验分布，以防止学习中产生过拟合 为什么这样能防止过拟合？这就是贝叶斯学派和频率学派的争论。频率学派认为概率是确定存在客观的，也就是PLSA的做法：$P(w|z)$和$P(z|d)$的参数是确定的，我们用已有数据训练模型去拟合这个参数即可。然而贝叶斯学派认为，在引入了新的数据之后，概率也会因为先验的改变而改变，他们认为概率是“主观”的，也就是说概率分布$P(w|z)$和$P(z|d)$的参数是不确定的，于是就从PLSA引入了LDA。 回到问题，当数据量小的时候，PLSA的频率学派做法会导致频率与概率差得很远，导致我们的模型学到的是训练数据的分布与真实的分布差得很远（大数定律失效）！这时候基于贝叶斯学派的LDA的先验就有用了，加入参数的先验分布进去就等于有了一个先验的知识（这个初始先验分布的选择见下面），然后我们再反复迭代参数，由参数产生的新似然数据得到一个新的先验，再继续迭代，这样可以有效防止模型学脱了（过拟合） 显然当样本数据量大的时候，PLSA的效果和LDA会差不多。因为训练集的频率与真实概率分布越来越接近了（大数定律生效），也就是通过增大训练数据量来防止了模型的过拟合 于是我们的文本生成流程（概率计算）就是①通过先验分布生成多项分布的参数，②然后使用文本-主题多项分布生成一个主题，③再用主题-单词多项分布生成一个单词。④这时候数据集就改变了，吸收了似然成为了新的先验，通过上面所说的共轭先验的性质可以求得新的多项分布的参数（后验）然后再作为先验，⑤循环生成下一个单词（①~④步）成为文本 这个过程见“共轭分布-4-流程关系”用数学表示 上面只是模型的定义和概率计算（数据文本生成），如果我们想要从已有一堆文章中知道话题、单词分布，那么就是对模型进行参数估计，也即是模型学习过程 那么模型如何学习呢（参数估计）？首先有个误解，既然模型的参数都直接是已知超参数分布给出的了，那为啥还要求参数？因为我们要学习（参数估计）的是在这个反复试验过程中（也就是上面文本生成反复迭代生成单词）通用的模型参数的表达式。在迭代过程中，模型参数不是最初始的先验分布（狄利克雷）了，因为在迭代过程中，上一个先验分布决定的多项分布模型产生了新的似然数据，成为了后验，导致下一此迭代时候的模型参数的先验分布变了！ 所以我们想要方便地从多项分布的先验分布计算后验分布。但是这很难计算（根据上面引入贝叶斯先验的思想，难以计算后验概率，比如第一次试验由先验分布生成的参数是$\\theta_1$，那么现实数据已经改变，第二次分布生成的新参数$\\theta_2$时，需要吸收在上一个先验下生成的似然数据变成了求后验，要考虑$P(\\theta_2|\\theta_1,D)$，分布无时无刻都可能在变化）。于是我们通过选择引入具有满足是多项分布共轭先验性质的先验分布：狄利克雷分布，这样我们就可以很方便通过先验概率计算后验概率（具体见下） LDA的模型学习由于潜变量过多，直接用MLE是非常困难的，所以会有吉布斯抽样算法和变分EM算法，见下一篇“LDA的学习算法” 共轭分布 什么是共轭分布？共轭分布是一种分布的关系：如果后验分布与先验分布属于同一种分布（形式相同），则先验分布与后验分布称为共轭分布，先验分布即为共轭先验 为什么要有共轭分布？因为我们希望这个先验分布和数据似然得到的后验分布能够在后面还可以作为先验分布，也就是说我们希望先验分布和这个后验分布的形式是一样的。 换句话说，共轭分布能够保证先验分布被赋予的物理意义，在吸收了新的似然知识之后，传递到后验分布时，保持一致 共轭分布对LDA的意义？从“PLSA的缺陷与LDA的改进”一节可知，我们引入先验概率分布。如果多项分布$P(w|z)$和$P(z|d)$的参数的分布的先验分布与后验分布形式相同（也就是为共轭分布），那么我们在参数估计的时候就【便于从先验分布计算后验分布】（在下一篇：“LDA的学习算法”中会大量用到） 共轭分布是在学习过程中用来参数计算推导的 下面的就有几个重要分布和对应共轭分布的重要性质： 高斯分布是高斯分布的共轭先验，Beta分布是二项分布的共轭先验，狄利克雷分布是多项分布的共轭先验。结合3，因此，我们才在LDA中使用狄利克雷函数作为先验分布： X∽Mult(n,\\theta)，设\\theta的先验：p(\\theta|\\alpha)=Dir(\\theta|\\alpha) 于是由多项分布计算得到新的数据集（似然）D 则后验：p(\\theta|D,\\alpha)=Dir(\\theta|\\alpha+n)【流程关系】：$Dir(\\theta|\\alpha)\\to\\theta\\to Mult(n,\\theta) \\to D \\to Dir(\\theta|\\alpha+n)\\to loop[Dir(\\theta|\\alpha)]$ 这里面的$D$就是一次循环（生成了一个潜在的主题然后）生成了[一个]新的单词出来，就这么不断循环生成下一个单词形成一个文本 狄利克雷后验分布的参数等于狄利克雷先验分布参数$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_k)$加上多项分布的观测计数$n=(n_1,n_2,\\cdots,n_k)$，好像试验之前就已经观察到计数$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_k)$，因此也把$\\alpha$叫做先验伪计数 （推导：见后记-5） 注意表述 对上面关系中的$Dir(\\theta|\\alpha),Mult(n,\\theta),Dir(\\theta|\\alpha+n)$ $Dir(\\theta|\\alpha)$是$Mult(n,\\theta)$的先验分布，$Dir(\\theta|\\alpha+n)$是$Mult(n,\\theta)$的后验分布，$Dir(\\theta|\\alpha)$与$Dir(\\theta|\\alpha+n)$为共轭分布，$Dir(\\theta|\\alpha)$是$Mult(n,\\theta)$的共轭先验 如何理解概率分布的先验分布的意义 狄利克雷分布和Beta分布因为其特性（共轭分布）常常可以作为概率分布的先验分布 通过不断添加新的先验来改变概率分布的先验分布，进而影响到概率分布，可以满足贝叶斯学派的观点，引入到原来的PLSA中 具体可以看知乎：如何通俗理解 beta 分布？这篇文章以beta分布为例举了非常实际的例子。 beta分布是二维的，该例子中只有一个后验分布的参数，即打中概率受到先验beta分布影响；狄利克雷分布就是多维情况下的beta分布，在LDA中后验分布$P(w|z)$和$P(z|d)$存在大量参数所以是多维情况。当参数维度为多维的时候，概率分布图像可以用二维单纯形表示，可以自行想象。再和上面例子一样的原理，通过不断添加新的先验改变作为先验分布的狄利克雷分布的参数，再进而获得概率分布。 对于狄利克雷分布，这有个例子举得很好：知乎：如何简单易懂地解释狄利克雷过程（Dirichlet Process）？ 几个重要分布 二项分布：$X∽B(n,p)$ P(X=m)=B(m|n,p)=C_n^mp^m(1-p)^{n-m}$m$为事件出现的次数，$n$为随机独立事件的试验总次数，事件只有两种可能状态，$p$为事件出现的概率，$1-p$为事件不发生的概率。二项分布即随机独立试验$n$次，事件发生$m$次的概率，参数为$n,p$ Beta分布：$X∽Be(s,t)$ $X$为连续随机变量，取值为$[0,1]$，其概率密度函数为 p(x)= \\begin{cases} \\frac{1}{B(s,t)}x^{s-1}(1-x)^{t-1},0≤x≤1\\\\ 0,otherwise \\end{cases}其中【$s＞0,t＞0$是参数】，$B(s,t)$是beta函数，见后记2 多项分布：$X∽Mult(n,p)$ 若多元离散随机变量$X=(X_1,X_2,\\cdots,X_k)$的概率质量函数为 P(X_1=n_1,X_2=n_2,\\cdots,X_k=n_k)=\\frac{n!}{n_1!n_2!\\cdots n_k!}p_1^{n_1}p_2^{n_2}\\cdots p_k^{n_k}=\\frac{n!}{\\prod_{i=1}^kn_i!}\\prod_{i=1}^k p_i^{n_i}其中$p=(p_1,p_2,\\cdots,p_k),p_i≥0,i=1,2,\\cdots,k,\\sum_{i=1}^kp_i=1,\\sum_{i=1}^kn_i=n$，则称随机变量$X$服从参数为$(n,p)$的多项分布 举例：抛$n$次筛子，第1面朝上出现了$n_1$次，第二面朝上出现了$n_2$次，$\\cdots$，第$k$面朝上出现了$n_k$次的概率即为一个多项分布 狄利克雷分布：$\\theta∽Dir(\\alpha)$ 若多元连续随机变量$\\theta=(\\theta_1,\\theta_2,\\cdots,\\theta_k)$的概率密度函数为： p(\\theta|\\alpha)=\\frac{\\Gamma(\\sum_{i=1}^k \\alpha_i)}{\\prod_{i=1}^k \\Gamma(\\alpha_i)}\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}其中$\\sum_{i=1}^k\\theta_i=1,\\theta_i≥0,\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_k),\\alpha_i＞0,i=1,2,\\cdots,k$，则称随机变量$\\theta$服从【参数为$\\alpha$】的狄利克雷分布 （$\\Gamma(x)$是Gamma函数，见后记-3） 狄利克雷分布的密度函数可以用多元beta函数$B(\\alpha)$简记表示： p(\\theta|\\alpha)=\\frac{1}{B(\\alpha)}\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}这里$B(\\alpha)$视为规范化因子。由密度函数性质，对$\\theta$积分为1，于是可得：$B(\\alpha)=\\int\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}d\\theta$ 关于狄利克雷分布的参数的意义：各个$\\alpha_i$为各个参数为$\\theta_i$的后验分布的强度参数 关系与总结 LDA与PLSA都假设话题$z$是单词$w$的多项分布，文本$d$是话题$z$的多项分布 二项分布是多项分布的一种特殊情况：二项分布（二维）$\\to$ 多项分布（多维） Beta分布是狄利克雷分布的一种特殊情况：Beta分布（二维）$\\to$狄利克雷分布（多维） LDA模型定义单词集合：$W=\\{w_1,\\cdots,w_v,\\cdots,w_V\\}$，共[$V$个单词] 文本集合：$D=\\{\\mathbb w_1,\\cdots,\\mathbb w_m,\\cdots,\\mathbb w_M\\}$ （注意一个文本换成用向量$\\mathbb w$表示，以前用的是$d$表示），共[$M$个文本] 每个文本是一个单词序列：$\\mathbb w_m=(w_{m1},\\cdots,w_{mn},\\cdots,w_{mN_m})$ ，$N_m$是$\\mathbb w_m$中单词的个数 话题集合：$Z=\\{z_1,\\cdots,z_k,\\cdots,z_K\\}$，共[$K$个话题] 基于PLSA的两个分布：文档-话题分布$P(z|\\mathbb w_m)$和话题-单词分布$P(w|z_k)$，且这两个分布是独立的 话题-单词 ①[$z\\to w$]：每一个话题$z_k$由一个单词的条件概率分布$P(w|z_k)$决定，$w∈W$。 ②[$w∽Mult(\\phi_k)$]：分布$P(w|z_k)$是多项分布，其参数为$\\phi_k$（随机变量$w$服从多项分布） 话题参数向量：$\\phi_k=(\\phi_{k1},\\phi_{k2},\\cdots,\\phi_{kV})$，其中$\\phi_{kv}$表示话题$z_k$生成单词$w_v$的概率，即多项分布标准表示中每项（这里就是每个单词）的概率$p$，共$V$个（单词总数） 话题参数矩阵：$\\Phi=\\{\\phi_k\\}_{k=1}^K$，所有的话题参数向量构成话题参数矩阵，为$K×V$形状 ③[$\\phi_k∽Dir(\\beta)$]：$\\phi_k$服从狄利克雷分布（先验分布），其超参数为$\\beta$ 超参数是一个$V$维（单词个数）向量：$\\beta=(\\beta_1,\\beta_2,\\cdots,\\beta_V)$ 文本-话题 ①[$\\mathbb w_m \\to z$]：每一个文本$\\mathbb w_m$由一个话题的条件概率分布$P(z|\\mathbb w_m)$决定，$z∈Z$ ②[$z∽Mult(\\theta_m)$]：分布$P(z|\\mathbb w_m)$是多项分布，其参数为$\\theta_m$（随机变量$z$服从多项分布） 文本参数向量：$\\theta_m=(\\theta_{m1},\\theta_{m2},\\cdots,\\theta_{mK})$，其中$\\theta_{mk}$表示文本$\\mathbb w_m$生成话题$z_k$的概率，即多项分布标准表示中每项（这里就是每个话题）的概率$p$，共$K$个（话题总数） 文本参数矩阵：$\\Theta=\\{\\theta_m\\}_{m=1}^M$，所有文本参数向量构成文本参数矩阵，为$M×K$形状 ③[$\\theta_m∽Dir(\\alpha)$]：$\\theta_m$服从狄利克雷分布（先验分布），其超参数为$\\alpha$ 超参数是一个$K$维（话题个数）向量：$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_K)$ 综合1,2 [$\\mathbb w_m \\to z \\to w$]：每一个文本$\\mathbb w_m$中的每一个单词$w_{mn}$由该文本的话题分布$P(z|\\mathbb w_m)$以及所有话题的单词分布$P(w|z_k)$决定。 【注】LDA假设文本中的话题对一个随机参数是独立同分布的，也就是说LDA中的文本是无限可交换的。所以在参数给定的条件下，文本中的话题顺序可以忽略。（PLSA也一样） （单词顺序也可以忽略，所以PLSA和LDA的“生成”并不是生成一个顺序的文本，且更多的在于学习模型潜在的参数） 概率计算：LDA生成过程 [\\mathbb w_m],([\\alpha] \\to \\theta)\\to [z],([\\beta]\\to\\phi)\\to [w]注：概率计算过程中，先验分布的超参数与多项分布的参数都是已知的，不变的 根据定义和PLSA生成模型中一样的原理就可以写出LDA生成过程 $\\mathbb S_1$：$\\beta \\to\\phi_k$ 对于话题$z_k(k=1,2,\\cdots,K)$生成多项分布参数$\\phi_k∽Dir(\\beta)$，作为话题的单词分布$p(w|z_k)=Mult(\\phi_k)$ $\\mathbb S_2$：$\\alpha\\to \\theta_m $ 对于文本$\\mathbb w_m(m=1,2,\\cdots,M)$生成多项分布参数$\\theta_m∽Dir(\\alpha)$，作为文本的话题分布$p(z|\\mathbb w_m)=Mult(\\theta_m)$ $\\mathbb S_3$：$\\theta_m\\to z_{mn},\\quad \\phi_{z_{mn}}\\to w_{mn}$ 对于文本$\\mathbb w_m$的单词$w_{mn}(m=1,2,\\cdots,M,n=1,2,\\cdots,N_m)$ ①生成话题$z_{mn}∽Mult(\\theta_m)$，作为单词对应的话题 ②生成单词$w_{mn}∽Mult(\\phi_{z_{mn}})$ 【这就生成了一个单词】 注意理解：一次循环生成一个主题，这个主题生成一个单词；然后再生成下一个主题，这个主题生成下一个单词；这样反复多次就生成了一个文本 概率图模型略 整体概率分布（所有文本）： p(\\mathbb w,\\mathbb z,\\theta,\\phi|\\alpha,\\beta)=\\prod_{k=1}^Kp(\\phi_k|\\beta)\\prod_{m=1}^Mp(\\theta_m|\\alpha)\\prod_{n=1}^{N_m}p(z_{mn}|\\theta_m)p(w_{mn}|z_{mn},\\phi)第$m$个文本的联合概率分布： p(\\mathbb w_m,\\mathbb z_m,\\theta_m,\\phi|\\alpha,\\beta)=\\prod_{k=1}^Kp(\\phi_k|\\beta)p(\\theta_m|\\alpha)\\prod_{n=1}^{N_m}p(z_{mn}|\\theta_m)p(w_{mn}|z_{mn},\\phi)其中$\\mathbb w$是观测变量，$\\mathbb z,\\theta,\\phi$是隐变量 ，$\\alpha,\\beta,K,N_m,M$是超参数 （后半部分是所有单词的概率相乘为文本概率，前两个为先验概率，先获取得到后验分布参数$\\phi_k和\\theta_m$） 搞清每个单词，每篇文档是如何生成的，就通过对概率生成公式（上面的联合概率分布公式），在中间路径的变量上进行积分，以获取全路径的概率，来计算边缘分布求得$p(\\mathbb w_m|\\theta_m,\\phi)$，$p(\\mathbb w_m|\\alpha,\\beta)$，$p(\\mathbb w|\\alpha,\\beta)$ 如：$p(\\mathbb w_m|\\alpha,\\beta)=\\int_\\phi p(\\mathbb w_m,\\phi|\\alpha,\\beta)=\\int_\\phi\\int_\\theta p(\\mathbb w_m,\\theta,\\phi|\\alpha,\\beta)=\\int_\\phi\\int_\\theta\\int_z p(\\mathbb w_m,\\mathbb z,\\theta,\\phi|\\alpha,\\beta)$ $=\\prod_{k=1}^K\\int p(\\phi_k|\\beta)[\\int p(\\theta_m|\\alpha)\\prod_{n=1}^{N_m}[\\Sigma_{l=1}^K p(z_{mn}=l|\\theta_m)p(w_{mn}|\\theta_l)]d\\theta_m]d\\phi_k$ 确定$\\alpha,\\beta$后，消去概率生成路径上的隐变量 学习算法求解LDA模型参数 目标：已知文本集合$D=\\{\\mathbb w_1,\\cdots,\\mathbb w_m,\\cdots,\\mathbb w_M\\}$，其中$\\mathbb w_m$是第$m$个文本$\\mathbb w_m=(w_{m1},\\cdots,w_{mn},\\cdots,w_{mN_m})$，以$\\mathbb w $表示文本集合的单词序列，设定话题数$K$和狄利克雷分布初始超参数$\\alpha,\\beta$，求①文档-话题分布$P(z|\\mathbb w_m)$的参数$\\theta$和②话题-单词分布$P(w|z_k)$的参数$\\phi$（$[\\mathbb w_m],[\\alpha] \\to \\theta\\to [z],[\\beta]\\to\\phi\\to [w]$） 也就是求模型$p(\\mathbb w,\\mathbb z,\\theta,\\phi|\\alpha,\\beta)$的参数，其中$\\mathbb w$是观测变量，$\\mathbb z,\\theta,\\phi$是隐变量 ，$\\alpha,\\beta,K,N_m,M$是超参数（除$N_m$，$M$外的参数都是高维的，此表述为参数向量形式） 困难：由模型概率公式可知，生成公式中的中间路径存在三个隐变量$\\mathbb z,\\theta,\\phi$，导致直接对其求MLE是非常困难的，隐变量的存在导致我们在求MLE的时候需要消去三个隐变量，计算积分（$\\mathbb w=\\prod \\mathbb w_m$）： $p(\\mathbb w_m|\\alpha,\\beta)=\\int_\\phi\\int_\\theta\\int_z p(\\mathbb w_m,\\mathbb z,\\theta,\\phi|\\alpha,\\beta) $ $=\\prod_{k=1}^K\\int p(\\phi_k|\\beta)[\\int p(\\theta_m|\\alpha)\\prod_{n=1}^{N_m}[\\Sigma_{l=1}^K p(z_{mn}=l|\\theta_m)p(w_{mn}|\\theta_l)]d\\theta_m]d\\phi_k$ 这样做MLE求解最优化非常困难 超参数（初值事先给定）假定话题$K$给定，但实际上通常通过实验选定，没有一个固定的最优解。（话题超参数$K$在学习算法中不变） 狄利克雷分布的超参数$\\alpha,\\beta$的初始值通常也是事先给定的。在没有其他先验知识下，可以假定$\\alpha和\\beta$的所有分量均为1，这时文本的话题分布$\\theta_m$是对称的，话题的单词分布$\\phi_k$也是对称的。 超参数$\\alpha,\\beta$（维度也很高，与多项分布数量一样）相当于各个后验多项分布的权重 超参数$\\alpha,\\beta$是先验分布的初始参数，在学习过程中后验分布所服从的先验分布参数会改变： $Dir(\\theta|\\alpha)\\to\\theta\\to Mult(n,\\theta) \\to D \\to Dir(\\theta|\\alpha+n)\\to loop[Dir(\\theta|\\alpha)]$ (上一篇推得) 基于马尔科夫蒙特卡罗方法：吉布斯抽样蒙特卡罗方法就是为此而生的，它通过随机抽样来近似计算模型参数$\\theta,\\phi$ 思想已知$\\mathbb w,\\alpha,\\beta$，那么对$p(\\mathbb z|\\mathbb w,\\alpha,\\beta)$进行抽样，就可以获得该分布的样本集合。根据每个样本的概率生成路径：$[\\mathbb w_m],([\\alpha] \\to \\theta)\\to [z],([\\beta]\\to\\phi)\\to [w]$，只要我们抽样获取了主题$z$，那么就可以根据$\\mathbb w_m\\to z$的样本数量$n_{mk}$来估计参数$\\theta$，根据$z \\to w$的样本数量$n_{kv}$估计参数$\\phi$，这样一来就获得了模型$p(\\mathbb w,\\mathbb z,\\theta,\\phi|\\alpha,\\beta)$的所有待学习参数。 那么如何抽样获取话题$z$才是合理的，能够用它来估算真实的话题概率分布的参数呢？就要使用吉布斯抽样，①给定一个初始化状态（文本的单词序列$\\mathbb w$中的每一个单词$w$对应一个随机的隐藏主题），②然后不断进行多轮抽样，状态转移（使用已推导出的 公式$p(z_i|\\mathbb z_{¬i},\\mathbb w,\\alpha,\\beta)$，③直到进入燃烧期，在燃烧期的一轮抽样中获得抽样主题$z$和路径上的计数$n_{mk}$，$n_{kv}$ 具体略 变分推理：变分EM算法变分推理通过解析的方法计算模型的后验概率的近似值 通过证据下界最大化实现KL散度的最小化 求解证据下界最大化问题：$L(q,\\theta)=E_q[\\log p(x,z|\\theta)]-E_q[\\log q(z)]$ 具体略 后记 概率质量(mass)函数：各个分类的概率，用于离散随机变量 概率密度(density)函数：数据落在某一段连续的区间的概率 Beta函数 B(s,t)=\\frac{\\Gamma(s)\\Gamma(t)}{\\Gamma(s+t)} 定义为：B(s,t)=\\int_0^1x^{s-1}(1-x)^{t-1}dx 当$s,t$是自然数的时， B(s,t)=\\frac{(s-1)!(t-1)!}{(s+t-1)!} Gamma函数 \\Gamma(s)=\\int_0^∞x^{s-1}e^{-x}dx,\\quad s>0 性质：\\Gamma(s+1)=s\\Gamma(s) 当s是自然数的时候有：\\Gamma(s+1)=s!关于Gamma函数以前在微积分中不少遇到，可以看这篇文章 https://cosx.org/2013/01/lda-math-gamma-function 多元beta函数（拓展的beta函数） B(\\alpha)=\\frac{\\prod_{i=1}^k \\Gamma(\\alpha_i)}{\\Gamma(\\sum_{i=1}^k \\alpha_i)} 狄利克雷分布是多项分布的共轭先验的推导 设$\\mathbb W=\\{w_1,w_2,\\cdots,w_k\\}$是由$k$个元素组成的集合，随机变量$X$满足多项分布$X∽Mult(n,\\theta)$ 其中$n=(n_1,n_2,\\cdots,n_k)和\\theta=(\\theta_1,\\theta_2,\\cdots,\\theta_k)$是参数。参数$n$为从$\\mathbb W$中重复独立随机抽取样本的次数，$n_i$为样本$w_i$出现的次数$(i=1,2,\\cdots,k)$，参数$\\theta_i$为$w_i$出现的概率（该过程就是普通的多项分布实验，也是文档生成过程） 引入先验：设其参数$\\theta$服从狄利克雷分布：$\\theta∽Dir(\\alpha)$，即该多项分布参数的先验分布为$p(\\theta|\\alpha)=Dir(\\theta|\\alpha)$ 我们的目标：在已知先验分布参数$\\alpha$和先验数据$D$的情况下，推导后验概率：$p(\\theta|D,\\alpha)$ （在学习过程中，这个先验分布参数$\\alpha$和先验数据$D$是在不断实验中迭代变化的，$D$为在参数$\\theta$下多项分布计算出的似然数据，由此调整超参数，它们一直改变，影响着下一个新的参数和数据，也就是说共轭结论是在学习过程中用来参数推导的；在概率计算过程中，超参数与参数全都是已知固定的，没有参数变化过程[=]） 由贝叶斯公式$P(B_i|A)=\\frac{P(A,B_i)}{P(A)}=\\frac{P(B_i)P(A|B_i)}{\\sum_{j=1}^nP(B_j)P(A|B_j)}$，那么我们要求的后验概率即可展开为： $p(\\theta|D,\\alpha)=\\frac{p(D|\\theta)p(\\theta|\\alpha)}{p(D|\\alpha)}$ ①由多项分布可得其似然函数：$p(D|\\theta)=\\theta_1^{n_1}\\theta_2^{n_2}\\cdots\\theta_k^{n_k}=\\prod_{i=1}^k\\theta_i^{n_i}$ ②由狄利克雷分布的公式：$p(\\theta|\\alpha)=\\frac{1}{B(\\alpha)}\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}$ ③由全概率公式：$p(D|\\alpha)=\\int_\\theta p(D|\\theta)p(\\theta|\\alpha)d\\theta$ 将上述①②③代入后验式子中化简： $p(\\theta|D,\\alpha)=\\frac{p(D|\\theta)p(\\theta|\\alpha)}{\\int_\\theta p(D|\\theta)p(\\theta|\\alpha)d\\theta}=\\frac{\\prod_{i=1}^k\\theta_i^{n_i}\\frac{1}{B(\\alpha)}\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}}{\\int_\\theta\\prod_{i=1}^k\\theta_i^{n_i}\\frac{1}{B(\\alpha)}\\prod_{i=1}^k \\theta_i^{\\alpha_i-1}d\\theta}=\\frac{1}{B(\\alpha+n)}\\prod_{i=1}^k\\theta_i^{\\alpha_i+n_i-1}=Dir(\\theta|\\alpha+n)$ 最后计算得到后验概率分布也是一个狄利克雷分布（结论）： p(\\theta|D,\\alpha)=Dir(\\theta|\\alpha+n)于是多项分布的参数$\\theta$的先验分布和后验分布都是狄利克雷分布（参数不同），所以狄利克雷分布是多项分布的共轭先验。且狄利克雷后验分布的参数等于狄利克雷先验分布参数$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_k)$加上多项分布的观测计数$n=(n_1,n_2,\\cdots,n_k)$，好像试验之前就已经观察到计数$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_k)$，因此也把$\\alpha$叫做先验伪计数 LDA不止可以用于文本，也可以用于图片等，即把图片当做文本，像素当做文本里的一个词","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"概率潜在语义分析","slug":"人工智能/概率潜在语义分析","date":"2019-12-11T02:04:08.000Z","updated":"2019-12-19T05:55:58.000Z","comments":true,"path":"人工智能/概率潜在语义分析/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%A6%82%E7%8E%87%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90/","excerpt":"probabilistic latent semantic analysis ,PLSA 概率潜在语义分析是一种基于概率生成模型的对文本集合进行话题分析的无监督学习方法 在前面文章EM算法中举的例子就是PLSA问题，实际上PLSA就是运用EM算法来求解的","text":"probabilistic latent semantic analysis ,PLSA 概率潜在语义分析是一种基于概率生成模型的对文本集合进行话题分析的无监督学习方法 在前面文章EM算法中举的例子就是PLSA问题，实际上PLSA就是运用EM算法来求解的 PLSA模型文本集合$D$，单词集合$W$，话题集合$Z$，有$M$个单词，$N$个文本，$K$个话题 $d∈D$表示文档，$w∈W$表示词语，$z∈Z$表示隐含的主题。 $z$就是隐变量 于是文本-单词共现数据$T$的生成概率为所有单词-文本对$(w,d)$的生成概率的乘积： P(T)=\\prod_{(w,d)}P(w,d)^{n(w,d)}其中$n(w,d)$表示$(w,d)$同时出现的次数（注意理解此式的写法，这个乘积，所谓的共现数据$T$的生成概率，实际意义上就是一篇文章） 对于单词文本对$P(w,d)$，可以描述为生成模型或共现模型： （注意理解，有$M$个单词，所以就有$M$个单词文本对） 生成模型解释为首【先有文本的概率分布$P(d)$】，每个文本有自己的话题概率分布，每个话题有自己的单词概率分布，也就是说一个文本的内容由其相关话题决定，一个话题的内容由其相关单词决定，刻画了文本-单词共现数据的生成过程：【$d\\to z\\to w$】 在这种模型下，记$P(d)$表示生成文本$d$的概率，$P(z|d)$表示文本$d$生成话题$z$的概率，$P(w|z)$表示话题$z$生成单词$w$的概率，则有【每个】单词-文本对共现概率： $P(w,d)=P(w|d)P(d)$ $=P(d)\\sum_zP(w,z|d)$ (逆边缘化$z$) $=P(d)\\sum_zP(w|z)P(z|d)$ （假定条件独立：$P(w,z|d)=P(w|z)P(z|d)$） 共现模型解释为首【先有话题的概率分布$P(z)$】，然后在话题分布的条件下有文本的概率分布和单词的概率分布，文本和单词同时出现，刻画了文本-单词共现数据拥有的模式：【$z\\to d;z\\to w;d,w$共现】 在这种模型下，记$P(z)$表示话题$z$的概率，$P(d|z)$表示话题$z$下生成文本$d$的概率，$P(w|z)$表示话题$z$生成单词$w$的概率，则有【每个】单词-文本对共现概率： $P(w,d)=\\sum_{z∈Z}P(z)P(w|z)P(d|z)$ (假定条件独立：$P(w,d|z)=P(w|z)P(d|z)$) 根据公式可以推得生成模型和共现模型是等价的 性质 通过PLSA模型，模型的参数由直接定义的单词文本共现概率$P(w,d)$的参数$O(M·N)$个变为$O(M·K+N·K)$，其中$K$是话题数，现实中$K&lt;&lt;M$，PLSA通过使用话题，对数据进行了更简洁的表示，模型参数的减少使得不容易过拟合，并且能完成其目的：分析文章潜在的主题 模型中的概率分布$P(w|d)$可以由参数空间中的单纯形表示。$M$维参数空间中，单词单纯形表示所有可能的文本分布，在其中的话题单纯形表示在$K$个话题定义下的所有可能的文本分布。话题单纯形是单词单纯形的子集，表示潜在语义空间 PLSA也可以对应于LSA的奇异值分解矩阵形式，对于共现模型表示为矩阵乘积形式： $X’=U’\\Sigma’V’^T,X’=[P(w,d)]_{M×N},U’=[P(w|z)]_{M×K},\\Sigma’=[P(z)]_{K×K},V’=[P(d|z)]_{N×K}$ 【注】 概率分布$P(d|z),P(w|z),P(z|d)$都是多项分布，理解一下这个分布在PLSA的含义。 以主题-单词多项分布$P(w|z)$举例，这个分布就表示对于给定的主题$z$，不同的单词有不同的概率，比如: $P(只狼|GOTY)=0.3,P(死亡搁浅|GOTY)=0.3,P(大乱斗|GOTY)=0.3,P(控制|GOTY)=0.1$ 表示GOTY主题下所有可能出现的单词各自的概率 文本-主题同理 概率计算：在已知参数的情况下生成文本的概率 一个单词文本对$P(w_i,d_j)$代表文本中的一个单词为$w_i$的概率。我们要求得到一个文本的概率分布，也就是生成一个单词序列的概率，那么就是所有单词文本对概率的积组成的分布 至于如何求得每个单词的单词文本对$P(w_i,d_j)$概率，那才是生成模型和共现模型有不同的方案 学习算法：在已知文本的情况下求参数（话题-文本分布和话题-单词分布） 也就是在一堆文本中分析潜在的话题，单词分布 这就是下面的参数求解算法 PLSA学习算法——EM算法学习算法就是求解话题-文本分布和话题-单词分布的参数 一个单词文本对$P(w_i,d_j)$代表文本中的一个单词为$w_i$的概率。我们要在已知数据下求最可能的概率分布参数（也就是模型参数），就是要求已有文本概率的极大似然，也就是使得所有已有单词文本对概率的积的最大值下的模型参数（就朴素的MLE求参数估计原理啦） EM算法在前面文章EM算法中写的很详细，在HMM算法的求解过程中也应用过推导出了HMM的参数时估计算法，见前文 我们对目标函数(文本-单词共现数据$T$的生成概率)求极大似然： L(\\theta)=\\log P(D,Z;\\theta)=\\sum_{i=1,\\cdots,M}\\sum_{j=1,\\cdots,N}n(w_i,d_j)\\log P(w_i,d_j)对于生成模型，代入$P(w_i,d_j)$则为： L(\\theta)=\\log P(D,Z;\\theta)=\\sum_{i=1,\\cdots,M}\\sum_{j=1,\\cdots,N}n(w_i,d_j)\\log [\\sum_{k=1}^KP(w_i|z_k)P(z_k|d_j)]（这里代入后由于$P(d_j)$可以直接求出来为常数，所以省略掉了） 由于概率模型中含有隐变量（话题：$z$），我们无法直接求解MLE，所以必须使用EM算法，将$L(\\theta)$带入公式计算 注意生成模型中的关系：$d\\to z\\to w$ （别和共现模型的搞反啦） E步：计算$Q$函数 注意后验概率用贝叶斯公式将其转变为先验概率（待求导变量）： $P(B_i|A)=\\frac{P(A,B_i)}{P(A)}=\\frac{P(B_i)P(A|B_i)}{\\sum_{j=1}^nP(B_j)P(A|B_j)}$，则$P(z_k|w_i,d_j)=\\frac{P(z_k,w_i,d_j)}{P(w_i,d_j)}=\\frac{P(w_i|z_k)P(z_k|d_j)}{\\sum_{k=1}^KP(w_i|z_k)P(z_k|d_j)}$ M步：极大化$Q$函数（使用拉格朗日法引入乘子，并分离变量为子式，运用同时求和回代消乘子技巧，再对不同子式变量求0导。变量即为$P(w_i|z_k),P(z_k|d_j)$） 具体推导略 算法：①设置参数$P(w_i|z_k),P(z_k|d_j)$的初始值，作为EM算法开始迭代的初始分布 ②迭代计算$E步:P(z_k|w_i,d_j),M步:P(w_i|z_k),P(z_k|d_j)$ 求得模型参数 【注】PLSA属于频率学派思想，在数据量较小的时候容易过拟合","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"潜在语义分析","slug":"人工智能/潜在语义分析","date":"2019-12-10T01:02:34.000Z","updated":"2019-12-11T05:20:01.000Z","comments":true,"path":"人工智能/潜在语义分析/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90/","excerpt":"latent semantic analysis ,LSA 潜在语义分析是一种基于矩阵分解的构建话题向量空间的方法，话题就是潜在的语义","text":"latent semantic analysis ,LSA 潜在语义分析是一种基于矩阵分解的构建话题向量空间的方法，话题就是潜在的语义 Basic$D$是文本集，$d$是一个文本，$W$是单词集，$w$是一个单词，$D=\\{d_1,d_2,\\cdots,d_n\\},W=\\{w_1,w_2，\\cdots，w_m\\}$ $w$，word，单词；$d$，document，文本；$t$，topic，话题 单词向量空间 单词向量空间 单词向量空间模型(word vector space model) 一个向量表示一个文本$d$，每一个维度对应一个单词$w$；具体表示即单词文本矩阵 （注意不是词向量组成的空间） 具体地，该空间可由单词文本矩阵表示： 单词文本矩阵(word-document matrix)： X=\\begin{bmatrix} x_{11}&x_{12}&\\cdots&x_{1n}&\\\\ x_{21}&x_{22}&\\cdots&x_{2n}&\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ x_{m1}&x_{m2}&\\cdots&x_{mn}\\\\ \\end{bmatrix}_{m×n} [行代表一个单词，列代表一个文本] $x_{ij}$：单词$w_i$在文本$d_j$中出现的频数或权值。 权值通常用TFIDF表示 $X$是一个稀疏矩阵 $X$的一个列向量代表一个文本，第$j$列向量$x_j$表示文本$d_j$；$X$也可写作$X=[x_1,x_2,\\cdots,x_n]$ 两个单词向量的内积表示对应的文本之间的语义相似度：$x_i·x_j$（标准化内积）（两个文本中共同出现的单词越多，其语义内容就越接近，对应的单词向量同不为零的维度越多，内积就越大，两个文本的语义就越相似） 频率-逆文本频率 TFIDF (term frequency-inverse document frequency)： TFIDF=\\frac{tf_{ij}}{tf_{\\cdot j}}\\log \\frac{df}{df_i},\\quad i=1,2,\\cdots,m;j=1,2,\\cdots,n 频率 TF：$\\frac{tf_{ij}}{tf_{\\cdot j}}$，表示单词$w_i$在文本$d_j$出现的频率，越大代表单词$w_i$越重要 文本频率：$\\frac{df_i}{df}$，表示含有单词$w_i$的文本在文本集合$D$中出现的频率，越小代表单词$w_i$越重要，因为该单词在整个文本集中出现的越少，越能代表该文本的特点；$df$的$d$不是求导……. 逆文本频率 IDF：$\\frac{df}{df_i}$，文本频率的导数，所以越大代表单词$w_i$越重要 于是TF-IDF作为两种重要度的积整体表示了$w_i$的综合重要度 单词向量空间存在的问题：一词多义问题；多词一义问题 话题向量空间 话题向量空间 topic vector space 一个向量表示一个话题$t$，每一个维度对应一个单词$w$；具体表示即单词话题矩阵 于是多义词可以表示不同的话题，文本由话题表示，那么就解决了一词多义问题和多词一义问题 如果两个文本话题相似，那么文本的语义也应该相似 单词话题矩阵(word-topic matrix) T=\\begin{bmatrix} t_{11}&t_{12}&\\cdots&t_{1k}&\\\\ t_{21}&t_{22}&\\cdots&t_{2k}&\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ t_{m1}&t_{m2}&\\cdots&t_{mk}\\\\ \\end{bmatrix}_{m×k}[行代表一个单词，列代表一个话题]，该矩阵并没有直接表示文本 $t_{il}$：单词$w_i$在话题$t_l$的权值 $T$的一个列向量代表一个话题$t$，一共有$k$个话题，$T$也可以写作$T=[t_1,t_2,\\cdots,t_k]$ 话题文本矩阵(topic-document matrix) Y=\\begin{bmatrix} y_{11}&y_{12}&\\cdots&y_{1n}&\\\\ y_{21}&y_{22}&\\cdots&y_{2n}&\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ y_{k1}&y_{k2}&\\cdots&y_{kn}\\\\ \\end{bmatrix}_{k×n}[行代表一个话题，列代表一个文本] $y_{lj}$：文本$d_j$在话题$t_l$的权值 $Y$的一个列向量$y_j$代表一个文本$y$，一共有$n$个文本，$Y$也可以写作$Y=[y_1,y_2,\\cdots,y_n]$ 潜在语义分析：从单词向量空间到话题向量空间的线性变换于是可以看出，我们通过[话题向量空间：单词-话题-文本]的表示方法来近似表示[单词向量空间：单词-文本] 直接表示方法： X中的一个文本向量：x_j≈y_{1j}t_1+y_{2j}t_2+\\cdots+y_{kj}t_k=Ty_j,\\quad j=1,2,\\cdots,n X≈TY将[单词-文本矩阵]表示为[单词-话题矩阵]×[话题-文本矩阵]，此即潜在语义分析 具体操作就是对$X$进行矩阵分解 算法基于矩阵的奇异值分解算法SVD详见矩阵计算与矩阵分解-奇异值分解 将单词文本矩阵$X$进行截断奇异值分解，得到$X≈U_k\\Sigma_kV_k^T=U_k(\\Sigma_kV_k^T)$ 比照话题向量空间形式：$X=TY$ 那么可以看作，单词话题矩阵为：$T=U_k$，话题文本矩阵为：$Y=\\Sigma_kV_k^T$ LSA完毕 基于非负矩阵分解算法non-negative matrix factorization，NMF 将矩阵分解问题$X=WH$（$X$称为基矩阵，$H$称为系数矩阵）转化为 \\min_{W,H}||X-WH||^2 s.t.\\quad W,H≥0或 \\min_{W,H}D(X||WH) s.t.\\quad W,H≥0对其求解会遇到两个问题：①多变量$W,H$，那么目标函数只是对其中一个变量的凸函数，只能找到局部最优 ②如果使用梯度下降，收敛速度缓慢 提出了新的解决办法——乘法更新规则：基于梯度下降算法，[交替]更新$W,H$ （证略） 对于上面的目标函数，定义用于梯度下降的目标损失函数： J(W,H)=\\frac{1}{2}||X-WH||^2=\\frac{1}{2}\\sum[X_{ij}-(WH)_{ij}]^2然后对$X,H$分别求偏导计算梯度，选择步长，归一化（见下），交替更新梯度 每一次更新迭代对$W$的列向量归一化，使基向量为单位向量 具体算法略","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"to the moon","slug":"Game/moon","date":"2019-12-09T04:51:31.000Z","updated":"2019-12-09T06:29:08.000Z","comments":true,"path":"Game/moon/","link":"","permalink":"https://aisaka.cloud/Game/moon/","excerpt":"那么你认为这些星星是什么呢?我从未告诉任何人，但我一直认为它们是灯塔。成千上万的灯塔……闪耀着屹立在世界尽头。哇，那上面一定充满活力，热闹喧哗。不是这样的，它们看得到彼此，想交流聊天。可他们无能为力他们天各一方，无法听清对方的呼唤它们能做的……唯有努力地绽放光芒。让那光芒照耀着其他灯塔，也照耀着我。为什么是你?因为总有一天……我也会成为他们的朋友。 你明年还会来吗？会的。老时间？老地点？嗯。如果你忘记了，或是迷路了怎么办？傻瓜，我们总会在月亮上相遇的。","text":"那么你认为这些星星是什么呢?我从未告诉任何人，但我一直认为它们是灯塔。成千上万的灯塔……闪耀着屹立在世界尽头。哇，那上面一定充满活力，热闹喧哗。不是这样的，它们看得到彼此，想交流聊天。可他们无能为力他们天各一方，无法听清对方的呼唤它们能做的……唯有努力地绽放光芒。让那光芒照耀着其他灯塔，也照耀着我。为什么是你?因为总有一天……我也会成为他们的朋友。 你明年还会来吗？会的。老时间？老地点？嗯。如果你忘记了，或是迷路了怎么办？傻瓜，我们总会在月亮上相遇的。 无意间听到了主题曲变奏的钢琴曲，一瞬间就被旋律吸引住了，感觉跳动的音符后面有一个很悲伤但很温暖的故事 于是为了这首歌去玩了游戏，再因游戏更喜欢这首歌 深更半夜坐在电脑前，呆呆地看着结尾名单滚完，荧幕上的文字已经模糊不清 人生也不过如此吧 我的眼睛里进了月亮。","categories":[{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"}],"tags":[{"name":"indie game","slug":"indie-game","permalink":"https://aisaka.cloud/tags/indie-game/"}]},{"title":"风主题关卡设计","slug":"游戏设计/风主题关卡设计","date":"2019-12-08T10:36:13.000Z","updated":"2019-12-09T00:18:17.000Z","comments":true,"path":"游戏设计/风主题关卡设计/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E9%A3%8E%E4%B8%BB%E9%A2%98%E5%85%B3%E5%8D%A1%E8%AE%BE%E8%AE%A1/","excerpt":"这是我们组做的独立游戏第二关我的设计，就是有点太复杂了可能…. 主题——风 关卡设计","text":"这是我们组做的独立游戏第二关我的设计，就是有点太复杂了可能…. 主题——风 关卡设计 说明： 摄像机视角大小：垂直两层，水平两个房间 解法提示：先打开门1，再打开门2，再打开门3 获取钥匙$K1$，打开门1 按开关1，风扇1关闭，$A\\to B$ 按开关2，风扇2关闭，$B\\to A\\to D$ 按开关3，风扇3开启，风扇4开启，风扇5关闭 $D\\to E$，被风扇4吹到$C$，拿到钥匙$K1$ $C\\to B\\to A\\to D$ 按开关3，风扇3关闭，风扇4关闭，风扇5开启 $D\\to F$，用已获取的钥匙$K1$打开门1，$F\\to G$ 获取钥匙$K2$，打开门2 爬楼梯，$G\\to H$ 按开关4，风扇7关闭，风扇6开启，风扇8关闭 被风扇6吹到$G$，向左走拿到钥匙$K2$ 向右走被风扇5吹到$E$ $E\\to D$ 按开关3，风扇3开启，风扇4开启，风扇5关闭 $D\\to E$，被风扇吹到$C$，左走用钥匙$K2$开启门2 获取钥匙$K3$，打开门3 $C\\to I$，拿取钥匙$K3$ $I\\to C\\to B\\to A\\to D$ 按开关3，风扇3关闭，风扇4关闭，风扇5开启 这时候有多种途径到达$J$ 用钥匙$K3$打开门3 通关~","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"一个游戏文学策划的自我修养","slug":"游戏设计/一个游戏文学策划的自我修养","date":"2019-12-06T14:42:09.000Z","updated":"2019-12-06T15:28:17.000Z","comments":true,"path":"游戏设计/一个游戏文学策划的自我修养/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E4%B8%80%E4%B8%AA%E6%B8%B8%E6%88%8F%E6%96%87%E5%AD%A6%E7%AD%96%E5%88%92%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/","excerpt":"上周日腾讯游戏设计 第 N节课 框架笔记 上这节课的时候我有40个小时没睡觉了，人是ふわふわ的，所以笔记也是ふわふわ的","text":"上周日腾讯游戏设计 第 N节课 框架笔记 上这节课的时候我有40个小时没睡觉了，人是ふわふわ的，所以笔记也是ふわふわ的 本节课不解决任何执行层面的实际问题 游戏+文化1.设计/2.感受/3.意象/4.包装/5.价值 ——追求 略 游戏文学内容与设计游戏内世界构建 世界观构建：基调 你不需要把这个世界的设定展示给玩家。真正需要些的是设计团队，还有你自己。玩家只需要感受。 剧情、人设与台词：玩家话题与记忆点 系统包装：文字细节统一，营造真实感与氛围 世界观落地的呈现方式：不设限，所有表现都可以“表演” 文字，语音，动作…..等等 游戏内玩家体验设计交互氛围，创意文化，等 案例，略 游戏IP品牌建设品牌站：更多视频/资料/音乐集/漫画/英雄故事 官方漫画&amp;动画&amp;舞台剧：世界观延伸 官方合作：符合定位的异业合作 主题公园/主题乐园 官方电竞赛事 小说大赛/征文/cos大赛等 etc 案例略 游戏外（与玩家）共建亚文化生态COS，同人小说、网游文、同人画；自制音频、视频等；同人配音、自制广播剧、手办、游戏等 ；B站，抖音，微博，直播四大阵地 ps：需要检测舆情/重视引导 自我修养横向拓展：泛娱乐IP打造略 纵向拓展：叙事内容设计故事的起源与发展 从贫穷到富有(rags to riches) 从富有到贫穷(riches to rags or tragedy) 伊卡洛斯式故事(Icarus) 俄狄浦斯式故事(Oedipus) 灰姑娘式故事(Cinderella) 人在洞里式故事(man in a hole) 故事线与主题先确定故事主线，再拆分结构与情节 叙事结构与节奏故事有通用的叙事结构吗？ Freytag的金字塔理论 悉德菲尔德电影三幕理论 世界神话共通性的“英雄之旅” 故事有很多不断重复元素，有变化的重复，游戏也一样 举例，神秘海域2的叙事节奏和兴趣曲线/甚至星之旅人也有叙事结构 人物塑造所有故事，最后都是关于人的故事 “影片必须有一两个能够承载电影主题的人。 要以能最大程度发挥电影创意的主角来突出优秀的故事线” ——《救猫咪：电影编剧宝典》 推荐书目：《英雄之旅》/《作家之旅》 如何通过任务讲故事 这是关于谁的故事？他们是谁？（主要人物） 他们经历了什么？（故事线） 他们的外部危机和内部危机是？ （压力推动剧情） 他们的计划是什么？ 他们想要什么？ 如果他们失败了，会产生什么后果？ 反派同上 如何塑造好一个角色 人物标签 - who are they？ 外部目标与内在欲望 - what do they want ? 恐惧 - what do they fear ？ 热爱 - what do they love ？ 弱点与缺陷 - who are they need？ 救猫咪 （让人喜欢角色，并代入；观众害怕发生什么） 细节 对比 （让反派坏到家，好人有多好，坏人就有多坏） 情感共鸣“对于主角的情感的牵连真的让我们有一种代入感，在神秘海域设计中，我们想让玩家感受到这个世界 是真实的，是可信的，这样玩家才能和这个角色有情感世界。” “情节反转与呼应，比Boss战所带来的冲击更大” ——《神秘海域2》主策 Richard Lemarchand 用四大类感情来构建有情感关联的经历 恐惧、愉悦、愤怒、悲伤（愤怒和悲伤情绪容易失去控制） 用“张力”和“戏剧冲突”来操 纵玩家情绪 ①Tension 张力 对于清晰的目标/结果而产生的不确定性感受（紧张感） 非常想要一个明确的结果/非常害怕一个明确的结果； 在静待结果的过程中所产生的期待感受，就是张力 张力是一种感受，有无张力，张力大小，讨论的都是感受的效果 ②Conflict of dramaturgy 戏剧冲突 表现人与人之间矛盾关系和人的内心矛盾的特殊艺术形式 戏剧中矛盾产生、发展、解决的过程 四种特点：尖锐激烈、高度集中、进展激烈、曲折多变 三种形态：人与人、人物与内心、人物与环境 多种冲突可组合使用，但冲突必须合力、有铺垫、逻辑地呈现 每一个游戏事件/张力解决的落脚点，都要在情绪 充分利用叙事设计工具库：表演对白，视觉，音效，触觉，交互反馈 美感小说：文字的美感；电影：镜头的美感；漫画：线条的美感 游戏：美术风格+叙事风格+UI设计+整体动作流畅体验叙事的美感，体现在个人/作品叙事风格的统一性上 铺垫与呼应 文学策划需要广涉猎，羞耻心，玻璃心，同理心等等等等….","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"主成分分析（二）","slug":"人工智能/主成分分析（二）","date":"2019-12-05T12:38:26.000Z","updated":"2019-12-09T05:57:50.000Z","comments":true,"path":"人工智能/主成分分析（二）/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"主要部分在上一篇：主成分分析（一） 样本主成分分析总体PCA和样本PCA的关系总体PCA是定义在分布总体上的，只虑向量（随机变量）$\\mathbb x$，$\\mathbb x$满足某分布函数，其均值$\\mu$是$\\mathbb x$分布函数上的均值，可以直接得到。但在实际问题中一般不会直接给出分布函数。 实际问题中是在观测数据上进行PCA，也就是说知道$n$样本$\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n$，这就是样本主成分分析。可以看出，对于给定样本观测集求出的均值就是一个对总体分布参数的一个估计。 样本PCA和总体PCA性质完全相同，上一节的东西完全适用，不过我们可以直接在样本集上求平均和协方差了。","text":"主要部分在上一篇：主成分分析（一） 样本主成分分析总体PCA和样本PCA的关系总体PCA是定义在分布总体上的，只虑向量（随机变量）$\\mathbb x$，$\\mathbb x$满足某分布函数，其均值$\\mu$是$\\mathbb x$分布函数上的均值，可以直接得到。但在实际问题中一般不会直接给出分布函数。 实际问题中是在观测数据上进行PCA，也就是说知道$n$样本$\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n$，这就是样本主成分分析。可以看出，对于给定样本观测集求出的均值就是一个对总体分布参数的一个估计。 样本PCA和总体PCA性质完全相同，上一节的东西完全适用，不过我们可以直接在样本集上求平均和协方差了。 样本主成分分析对于真实观测样本，对随机变量$\\mathbb x=(x_1,x_2,\\cdots,x_m)^T$进行$n$次独立观测得到观测样本集$(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n)$，其中每一个样本为$m$维，表示为$\\mathbb x_j=(x_{1j},x_{2j},\\cdots,x_{mj})^T$，那么$x_{ij}$表示第$j$个观测样本的第$i$个变量（特征维度），那么观测数据的样本矩阵$X$记为: X_{m×n}=[\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n]= \\begin{bmatrix} {x_{11}}&{x_{12}}&{\\cdots}&{x_{1n}}\\\\ {x_{21}}&{x_{22}}&{\\cdots}&{x_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {x_{m1}}&{x_{m2}}&{\\cdots}&{x_{mn}}\\\\ \\end{bmatrix}注意以下描述【中$x_{ij}$是第$i$维，第$j$个样本&lt;=ATT!】 [某个维度$i$在样本集上的均值]为：$\\hat x=\\frac{1}{n}\\sum_{j=1}^nx_{ij}$ （具体来说就是一个属性值在样本集上的均值） 那么[均值向量]（替代总体PCA的$\\mu$）为：$\\hat {\\mathbb x}=\\frac{1}{n}\\sum_{j=1}^n\\mathbb x_{j}$ 对于样本PCA，要求在样本集$X_{m×n}$上的协方差矩阵。对于前面总体PCA，相当于$X=[\\mathbb x]$，有$cov(x,x)=\\frac{1}{n-1}xx^T$ 样本协方差矩阵$S$（替代总体PCA的$\\Sigma$）和矩阵里每个元素为：（推导略，见主成分分析（一）-矩阵计算-协方差矩阵；【$s_{ij}$表随机变量第$i$维与第$j$维的协方差在样本集上的期望】） S=[s_{ij}]_{m×m},\\quad s_{ij}=\\frac{1}{n-1}\\sum_{k=1}^n(x_{ik}-\\hat x_i)(x_{jk}-\\hat x_j),\\quad i,j=1,2,\\cdots,m定义第$j$个线性变换，$m$维向量$x=(x_1,x_2,\\cdots,x_m)^T$到$y=(y_1,x_2,\\cdots,y_m)^T$线性变换： \\mathbb y_j=A^T \\mathbb x_j A_{m×m}^T=[a_1,a_2,\\cdots,a_m]^T= \\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1m}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2m}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}}&{a_{m2}}&{\\cdots}&{a_{mm}}\\\\ \\end{bmatrix}^T与总体PCA一样可以推得： $var(y_i)=a_i^TSa_i$，$cov(y_i,y_k)=a_i^TSa_k$ 规范化：$x_{ij}^o=\\frac{x_{ij}-\\hat x_i}{\\sqrt{s_{ii}}},\\quad i=1,2,\\cdots,m;j=1,2,\\cdots,m$ 其中均值$\\hat x_i=\\frac{1}{n}\\sum_{j=1}^nx_{ij},\\quad i=1,2,\\cdots,m$，方差$s_{ii}=\\frac{1}{n-1}\\sum_{j=1}^n(x_{ij}-\\hat x_i)^2$，这个$s_{ii}$就是协方差矩阵$S$的对角线上的元素，显然自协方差=方差 样本相关矩阵$R$（这是前面没用的新东西）为 R=[r_{ij}]_{m×m},\\quad r_{ij}=\\frac{s_{ij}}{\\sqrt{s_{ii}s_{jj}}},\\quad i,j=1,2,\\cdots,m规范化$x_{ij}$后，规范化协方差矩阵$S$就是其相关矩阵$R$： O S^o=R=\\frac{1}{n-1}XX^T求样本PCA由上一节的性质—— 有了定理1及其推论：知道了协方差矩阵的【正交对角分解】即可获得主成分（最优解）。具体关系是：$\\mathbb x$的协方差矩阵$\\Sigma$的对角矩阵的特征值构成主成分$\\mathbb y$的方差，协方差矩阵的特征向量构成基矩阵$A$。那么问题就被转化为了协方差矩阵的正交对角化问题，直接数学的矩阵分解解决。于是我们就可以写出求PCA的两种算法了。 有了定理2：知道了如果我们要降维，怎么选能使主成分整体方差和最大 有了k取值：知道了选几个最好，能使得主成分整体方差和最大 然后根据上面一节的式子我们拓展到了样本PCA 注意理解：每个样本各自的主成分的值是不同的，但是哪个维度是第几主成分是已经确定了的，在每个样本中都是一致。我们根据样本集得到了一个协方差矩阵，其对角正交分解考虑了所有样本使方差最大化，也就是对所有样本都使用一套基变换$A$，表达就是$Y=A^TX$ 协方差矩阵$S$（相关矩阵$R$）的[特征值分解]算法特征值分解$A=P\\Lambda P^{-1}$，且①对角矩阵$\\Lambda$②正交矩阵$P$ 那么就满足是主成分的充分必要条件，于是$X$的求主成分等于求协方差矩阵$S$（相关矩阵$R$）的奇异值分解 规范化 计算协方差矩阵（相关矩阵） $R=[r_{ij}]_{m×m}=\\frac{1}{n-1}XX^T$ 求其特征值和对应的单位正交特征向量 解$R$的特征方程$|R-\\lambda I|=0$ 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前$k$行组成矩阵$A$ $k$的选取由方差贡献率决定 $Y=A^TX$ 得到各样本向量的主成分 数据矩阵$X$的[奇异值分解]算法奇异值分解$A=U\\Sigma V^T$，且①对角矩阵$\\Sigma$②正交矩阵$U,V$ 那么就满足是主成分的充分必要条件，于是$X$的求主成分可以用数据矩阵$X$的奇异值分解来求 于是我们运用奇异值分解算法（见前文矩阵计算与矩阵分解） 注意由于奇异值分解算法求解过程中是求$W=X^TX$的特征值和单位特征向量（不直接求），和我们的协方差矩阵$S=\\frac{1}{n-1}XX^T$是反过来的，且少了一个系数，于是要构造一下形式： 令$X’=\\frac{1}{\\sqrt{n-1}}X^T$ 因为这样一来，$X’^TX’=(\\frac{1}{\\sqrt{n-1}}X^T)^T(\\frac{1}{\\sqrt{n-1}}X^T)=\\frac{1}{n-1}XX^T$，也就是说$X’^TX’$等于$X$的协方差矩阵；而$X’^TX’$是求$X’$的奇异值分解的第一步。而我们要求PCA是要对协方差矩阵求特征值和特征向量，【那么问题归结于对$X’$做SVD】 构造新的$n×m$矩阵 $X’=\\frac{1}{\\sqrt{n-1}}X^T$ $X’$每一列的均值为0 那么$S_X=X’^TX’$为$X$的协方差矩阵 对矩阵$X’$进行截断奇异值分解，得到：$X’=U\\Sigma V^T$ 有$k$个奇异值、奇异向量 矩阵$V$的前$k$列构成$k$个样本主成分 求$k×n$样本主成分矩阵：$Y=V^TX$ $V$的列向量就是$X$的主成分 ($V$的列向量是$S_X=X’^TX’$的单位特征向量，见奇异值分解章节)","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"大数据相似度计算：局部敏感哈希算法","slug":"人工智能/局部敏感哈希算法","date":"2019-12-04T06:21:29.000Z","updated":"2020-01-08T12:32:56.000Z","comments":true,"path":"人工智能/局部敏感哈希算法/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B1%80%E9%83%A8%E6%95%8F%E6%84%9F%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/","excerpt":"以前做过几万数据求杰卡德相似度，计算要很久，多等等也能接受 但这次项目中有1000万样本…….每次比较计算杰卡德距离需要0.0015秒，算下来1000万样本需要计算………………………2379年（#捂脸） 所以找到了局部敏感哈希算法，可以有效加速大数据相似度比较计算","text":"以前做过几万数据求杰卡德相似度，计算要很久，多等等也能接受 但这次项目中有1000万样本…….每次比较计算杰卡德距离需要0.0015秒，算下来1000万样本需要计算………………………2379年（#捂脸） 所以找到了局部敏感哈希算法，可以有效加速大数据相似度比较计算 杰卡德相似系数Jaccard相似系数用于求集合相似度 Jaccard(A,B)=\\frac{|A∩B|}{|A∪B|}杰卡德距离：在占比中所取的是两个集合中不同元素。 Jaccard\\quad distance(A,B)=\\frac{|A∪B|-|A∩B|}{|A∪B|}注意：杰卡德的分母不包含$A与B$都没有的（都为0）的位置，分母只包含$A,B$元素为$11,10,01$的对 回顾hash分桶一种解决hash冲突的办法。在hash值冲突的时候，多个原数据被映射到同一个哈希值，那么就将映射到同一个哈希值的原key放入一个桶中（链表形式储存），该hash值作为该桶的索引。查询的时候通过哈希计算找到对应的桶之后，沿着桶链表一个一个比较key是否相同即可。 min-hash原始min-hashhash就是让不同长度的文本转化为相同长度的一串字符串，即使只是差一位，生成的字符串也会天差地别 然而我们要计算相似度就需要相似的文本生成相似的hash字符串，这就是min-hash 从另一个角度讲hash其实就是将数据从原空间映射到一个新的低维空间，传统hash是使得新空间的向量分散，没有关系；而min-hash则使得在原空间距离较近的向量在新空间距离也较近，在原空间距离较远的向量在新空间距离也较远 具体地，min-hash就是将行（不同向量的每一个维度）多次随机打乱，找出第一个非零行的索引序号，作为最小哈希值$h(i)$ $n$次随机打乱后得到$n$个最小哈希值组成的序列$h(1),h(2),\\cdots,h(n)$，此序列就是不同样本对应的哈希签名，显然向量越相似，生成的hash签名（字符串，序列）也越相似 （对于两个document，在Min-Hashing方法中，它们hash值相等的概率等于它们降维前的Jaccard相似度。可以从杰卡德的定义式子看出，杰卡德的定义式恰好就是第一次“遇到”1的概率。） 对不同样本的哈希签名求杰卡德相似度来替代直接对向量求杰卡德相似度 本质上就是随机抽样比较相似度 min-hash等同于降维 可操作min-hash我们原始目的：随机打乱之后，找出第一个非零行的索引行号 原始min-hash每次都要重新排序这样实在太耗时间空间了，所以我们采用了另一种办法：运动是相对的，我们不打散行，我们打散行号23333 。 具体怎么操作呢？打散行号之后，我们依然从原序号的顺序开始遍历，我们对行号进行hash不断的替换最小行号达到我们原始的目的。 比如：对于一个向量，进行一次打散，使用hash函数$hash(x)$计算行号，将原顺序行号映射到新的hash空间 顺序遍历，顺序1行为0：pass 顺序第2行为1：计算$hash(1)=5$，那么此时最小行号$hash_{min}=5$ 顺序第3行为0：pass 顺序第4行为1：计算$hash(1)=3\\quad,3&lt;当前最小行号hash_{min}=5$，于是替换最小行号！那么此时最小行号替换为$hash_{min}=3$ 顺序第5行为1：计算$hash(1)=8\\quad,8&gt;当前最小行号hash_{min}=3$，不替换，依然不变：$hash_{min}=3$ 以此类推，最后遍历完这个向量之后，就得到了最小行号，也即打乱行号之后出现第一个1的行号 第二次打散，就换一个$hash$函数进行打散 以此类推，打散了$n$次，就设置了$n$个不同的哈希函数来计算打散的行号，每个原向量就得到了$n$次min-hash结果，就得到了一个$n$维的新向量 一次随机打散行，其实就是一次对行号的散列，其实就是对行号计算一次哈希值。我们要打散多少次，实际上就是有多少个作用于行号的不同的哈希函数，也就是经过min-hash处理后向量的长度。 Locality Sensitive Hashing为什么要用LSHmin-hash只是降低了每一个向量的维度，并没有减少比较次数，当向量数量很大的时候，依然非常耗时间 假设原向量（文本）有$m$个，则时间复杂度没变$O(m^2)\\to O(m^2)$ 于是有了局部敏感哈希算法，LSH 原理LSH是一种基于min-hash的加速索引算法，建立一种新的索引 其基于思想：如果将两个向量以相同方法划分若干段，如果这两个向量相似，那么他们被划分出的对应若干段中存在某段完全相同（=段中每维完全相同=hash值相同=被分到同一个hash分桶）的概率也很高；同理不相似的向量，其哈希值只有很小的概率是相同的。那么我们就可以只比较可能相似的样本，不太可能相似的样本就不比较，这样就减小了比较次数 LSH具体地算法是： ①将每个原向量（一个数据点）通过min-hash得到的hash签名（下称：向量），划分为$b$段，每段有$r$行 如图矩阵$M$,每一列代表一个向量，每一行就是一个向量的维度，$r$个维度（行）组成一个段 ②对每行的每个段进行hash映射，不同样本（竖）的该段截取的部分段向量（横）如果相同就会被映射到一个桶中。 （每一行可以使用相同的hash函数，但是每一行各段都是被映射到不同的数组的，数组里的每一个元素就是桶） ③我们应用一个假设：我们称每个段的每一个桶内，即不同样本中至少有一个段相同（=hash值相同=被分到同一个hash分桶）的样本为候选相似样本。通过下面的证明可得，我们只对候选相似样本进行比较，便可以以极大概率找到所有可能相似样本。 假设的证明：我们假设AB 两个样本相似度为$a$，那么将A、B分成$b$段，每段$r$行。那么A、B在某段里，每一行的相似概率就为$a^r$， 那么A、B在该段每一行都不相似的概率就为$1-a^r$，A、B所有段都不同的概率为$(1-a^r)^b$，A、B至少有一个段相似的概率为$1-(1-a^r)^b$，最后这个式子就是两个样本可能相似的概率 $a∽1-(1-a^r)^b$画成图像是S形的，它表征了相似度$a$作为自变量与A、B至少有一个段相同的概率的关系，如下： （此图中$s$即相似度$a$，最陡的地方为$a=(1/b)^{1/r}$；$t$为相似判定阈值，设定大于该阈值则认为两个样本相似） 从$a∽1-(1-a^r)^b$图中可以看到，当两个样本的相似度$a$超过一定阈值的时候，$1-(1-a^r)^b$也就是A、B至少有一段相同的概率骤升，A,B任何一段都不相同的概率骤降，所以我们就排除出了不太可能相似的样本，而获得了可能相似的样本。也就是说，只要我们将至少存在一段相同的样本选做候选点，就可以以极大概率捕获相似样本。 于是我们就可以只比较可能相似的样本，也就是有段落在同一个桶内的样本了 理解名字：“局部敏感哈希”，这个局部就是指的这个分段。如果两个向量局部相同，根据上面证明，那么两个向量可能相似的概率就远远大于不可能相似的概率。 总结：Min-Hash降维，LSH减少查找范围；如何减少查找范围？通过找存在相同band的样本来找可能相似的样本。 （注意桶应该设置大一点，避免hash碰撞） 参数调节参数：分段数$b$，相似判定阈值$t$； 可以看出，分段数越多，返回的相似候选点越多，漏报率越低（当分段数=minhash后向量长度，那就退化成直接比较了） 我们可以通过调节这个$a∽1-(1-a^r)^b$曲线来满足我们的实际需求 如果我们想要尽量少漏掉相似样本：那么就应该调节分段数$b$和相似判定阈值$t$，尽量让我们的相似度判断阈值尽量在S曲线的右上角，这样一来候选点相似的概率大于该相似度阈值的概率就尽量大了 如果我们想要查询速度快：我们就应该调节分段数$b$和相似判定阈值$t$，尽量让S曲线中间的爬升坡度更陡峭，这样一来相似度没那么高的向量就很难成为候选点 于是就可以根据我们实际任务的需求，调节曲线的形状和阈值的位置 这里的参数调节分析可以见LSH举例子，写得很好 Tools sklearn.neighbors中实现了LSHForest(局部敏感随机投影森林) 也可以直接用lshash包： 对于py2，使用 lshash包；对于py3，使用lshash3包 但注意py3是默认没有future库的，需要自己安装 其官方文档:https://pypi.org/project/lshash3/ 用汉明距离代替杰卡德距离计算 实现lsh最好的开源工具是falconn 这个库基于论文 Practical and Optimal LSH for Angular Distance 是对原始LSH的极致优化 这是falconn py的说明文档https://falconn-lib.org/pdoc/falconn/ 注：图片来源斯坦福LSH课件","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"大数据","slug":"人工智能/大数据","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[]},{"title":"Fences—整理桌面利器","slug":"工具/Fences—整理桌面利器","date":"2019-12-02T14:13:45.000Z","updated":"2019-12-02T14:33:37.000Z","comments":true,"path":"工具/Fences—整理桌面利器/","link":"","permalink":"https://aisaka.cloud/%E5%B7%A5%E5%85%B7/Fences%E2%80%94%E6%95%B4%E7%90%86%E6%A1%8C%E9%9D%A2%E5%88%A9%E5%99%A8/","excerpt":"由于我喜欢什么东西都扔桌面上，所以得经常定期清理一次桌面，但桌面清理干净了找很多东西又很不方便 于是就经常对着凌乱的桌面感到绝望…","text":"由于我喜欢什么东西都扔桌面上，所以得经常定期清理一次桌面，但桌面清理干净了找很多东西又很不方便 于是就经常对着凌乱的桌面感到绝望… 于是在今天我找到了这么一个神奇的软件，Fences，实在T Q L surface是我学习用的笔记本，这是经过Fences整理后的surface桌面，太清爽了！ 下面和上面的小栏是我设置的链接到各处的快捷入口，可以像抽屉一样，鼠标放上去就会被拉出来，支持多种显示方式，可以完全像Explorer一样的操作 而且归纳区域的透明度也可以调整，还有非常多的细节功能 台式机再加上背景的wallpaper engine，感觉整个桌面赏心悦目又有实用性 妈妈再也不用担心我桌面凌乱辣！","categories":[{"name":"工具","slug":"工具","permalink":"https://aisaka.cloud/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"初雪","slug":"日记/初雪","date":"2019-11-29T12:21:57.000Z","updated":"2020-05-30T01:25:43.000Z","comments":true,"path":"日记/初雪/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%88%9D%E9%9B%AA/","excerpt":"","text":"晚上被老师留了下来，没法去桌游社玩期待好久的新桌游，但走的时候恰好遇到了初雪。今晚的初雪好美，路灯在飞雪的映衬下像圣诞树上的星星。作为在南方长大的人，是基本不可能看到雪的，所以每次看到雪还是会有些激动。 还记得第一次看到雪是一个人去东京的时候，坐在去往东京，乘客寥寥的电车上，窗外没有一丝雪的踪迹。车内的暖气让我打了个小盹，一抬头就发现雪花飞速从车窗划过，车外已是银装素裹，都边的矮别墅都顶着厚厚的积雪。从地铁口探出头就发现自己已经被雪所覆盖的世界层层包裹。我在那个地方迷路了，踏在湿滑的地面上四处跌跌撞撞地找路。后来才知道那个地方叫浅草。都过去这么久了。明天会更冷吧。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"雪","slug":"雪","permalink":"https://aisaka.cloud/tags/%E9%9B%AA/"}]},{"title":"主成分分析（一）","slug":"人工智能/主成分分析","date":"2019-11-27T11:20:43.000Z","updated":"2019-12-06T14:09:38.000Z","comments":true,"path":"人工智能/主成分分析/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/","excerpt":"Principal Component Analysis， PCA PCA的核心思想是①先对数据规范化，均值为0，方差为1。②再对原基下的数据进行正交基变换，将由线性相关变量表示的数据变成由线性无关变量表示的数据。变换过程遵循表示信息最大的原则，即选择使得变换后数据方差最大的变量（主成分）作为新变量，也就是新维度下的数据越分散越好。 这样的变换过程可以理解为转换观察数据的角度，揭示出数据内在的结构。 把数据依信息最大（方差最大）顺序由少量主成分表示即是对数据降维，其就是想用较少的没有相关性的变量来获取尽可能多的原始数据信息。 在数据总体上进行的主成分分析称为总体主成分分析，在有限样本上进行的主成分分析称为样本主成分分析。","text":"Principal Component Analysis， PCA PCA的核心思想是①先对数据规范化，均值为0，方差为1。②再对原基下的数据进行正交基变换，将由线性相关变量表示的数据变成由线性无关变量表示的数据。变换过程遵循表示信息最大的原则，即选择使得变换后数据方差最大的变量（主成分）作为新变量，也就是新维度下的数据越分散越好。 这样的变换过程可以理解为转换观察数据的角度，揭示出数据内在的结构。 把数据依信息最大（方差最大）顺序由少量主成分表示即是对数据降维，其就是想用较少的没有相关性的变量来获取尽可能多的原始数据信息。 在数据总体上进行的主成分分析称为总体主成分分析，在有限样本上进行的主成分分析称为样本主成分分析。 正交基变换见前文矩阵计算与矩阵分解-基本计算-12-基变换 [理解基变换的几何意义：向量在新基组上的投影] $X$为原矩阵下的向量（坐标），$X=(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n)$，有$n$个原基下的$\\mathbb x$向量 $A$为正交基矩阵 $A=(a_1,a_2,\\cdots,a_m)$，其中的每个向量就是一个新的基，新基是相互正交的 $\\mathbb x_i和a_j$都是$m$维列向量，$\\mathbb x_i$代表原基下的一个向量/坐标，那么 Y=A^TX即为基变换，新基下的向量为$Y=(\\mathbb y_1,\\mathbb y_2,\\cdots,\\mathbb y_n)$ $\\mathbb y_i$也是$m$维列向量，代表经过基矩阵$A$变换后新基下的坐标 也可以半展开写成：（这里转置易错，外面那层转置只是转置了外层的列，每列内部还要进行转置） (\\mathbb y_1,\\mathbb y_2,\\cdots,\\mathbb y_n)=(a_1,a_2,\\cdots,a_m)^T(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n) =\\begin{bmatrix} a_1^T\\\\ a_2^T\\\\ \\vdots\\\\ a_m^T\\\\\\end{bmatrix} \\begin{bmatrix}\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n\\end{bmatrix} =\\begin{bmatrix} a_1^T\\mathbb x_1&a_1^T\\mathbb x_2&\\cdots&a_1^T\\mathbb x_n\\\\ a_2^T\\mathbb x_1&a_2^T\\mathbb x_2&\\cdots&a_2^T\\mathbb x_n\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ a_m^T\\mathbb x_1&a_m^T\\mathbb x_2&\\cdots&a_m^T\\mathbb x_n\\\\ \\end{bmatrix}在该基变换中，每一个旧基下的向量$\\mathbb x_i$都左乘了基矩阵$A$ ，也就是： \\mathbb y=A^T\\mathbb x如果只有一个向量$x$做基变换，那便是： \\mathbb y=(a_1,a_2,\\cdots,a_m)^T\\mathbb x=\\begin{bmatrix} a_1^T\\\\ a_2^T\\\\ \\vdots\\\\ a_m^T\\\\\\end{bmatrix}\\mathbb x= \\begin{bmatrix} a_1^T\\mathbb x\\\\ a_2^T\\mathbb x\\\\ \\vdots\\\\ a_m^T\\mathbb x\\\\ \\end{bmatrix} =(a_1^T\\mathbb x,a_2^T\\mathbb x,\\cdots,a_m^T\\mathbb x)^T展开列向量$\\mathbb y$中的每一个维度表示：即$y_i=a_i^T\\mathbb x=a_1x_1+a_2x_2+\\cdots+a_mx_m$ 这样变换的原理： 可以看出变换得到的新基下的变量的每个维度都由基矩阵的一个列向量也就是一个基与原基下的变量内积得到，新向量的一个维度为基矩阵的一个基与原基变量的内积，就是上面这个式子 而内积的几何意义是：向量$A与B$的内积实质上就是$A$到$B$的投影长度乘以$B$的模，如果$B$为单位向量，那么$A与B$的内积就是$A$到$B$上的投影，也就是向量$\\mathbb x$在新基组$(a_1,a_2,\\cdots,a_m)$下的投影，也就得到了新基下的坐标/向量表示：$\\mathbb y$。原基下的向量$\\mathbb x$被投影到了每一个新基($a_i$)上，组成了新基下的向量表示（坐标）：$\\mathbb y$。 用图表示关系就是 各个颜色的变换就是内积，就是一次原基下的向量表示到某一个新基的投影过程 举例，对于一般的二维笛卡尔直角坐标系中，其基为$a_1=(0,1)^T,a_2=(1,0)^T$，其正交基矩阵就是 $A=\\begin{bmatrix}a_1,a_2\\end{bmatrix}=\\begin{bmatrix} 0&amp;1\\\\1&amp;0 \\\\ \\end{bmatrix}$，对于本来就在笛卡尔坐标系下的向量$\\mathbb x$,自然$\\mathbb x=A^T\\mathbb x$，新基和原基没变，那向量表示（坐标）自然也没变 总体主成分分析定义[PCA的核心]：对原来的基下的数据向量$\\mathbb x$做正交基变换($\\mathbb y=A^T\\mathbb x$)，求出使得变换后$\\mathbb y$的方差和[最大]的正交基矩阵$A$，得到新基下的新向量$\\mathbb y$，此新向量即主成分，此向量各个维度依方差大小排序为第$i$主成分。 为什么要方差最大？因为某新基下数据方差越大（$var(y_i)$），保留信息就越多，该新基就越重要，就是$\\mathbb x$越主要的成分。主成分$\\mathbb y$就是这个方差最大化问题的最优解。 [具体地]—— 一个数据$\\mathbb x$由一个向量也即一个坐标表示 $\\mathbb x$是$m$维向量（即特征是$m$维），$\\mathbb x=(x_1,x_2,\\cdots,x_m)^T$，其均值（向量）为$\\mu=\\mathbb E(x)$$=(\\mu_1,\\mu_2,\\cdots,\\mu_m)^T$ 总体PCA是什么以及和样本PCA的关系：在总体PCA中，已知向量（随机变量）$\\mathbb x$的分布，这时就可以直接求出其均值$\\mu$，这种情况对$\\mathbb x$求主成分就是总体PCA，是直接给出了$\\mathbb x$的分布函数，然后求$\\mathbb x$的主成分。而在实际问题中一般不会已知分布函数，而是已知一个样本集，我们从样本集中求出均值，对实际样本数据求主成分，这种就是样本PCA。可以看出对于给定样本集求出的均值就是一个对样本集的总体分布参数的一个估计，我们用观测的样本集的均值去估计了没有直接给出的分布参数。 $\\mathbb x$代表了一个（原基变量下的）随机变量（向量/数据样本)；下面我们要经过正交基变换（左乘基变换矩阵$A$）得到的$\\mathbb y$是一个（新基变量下的）随机变量（数据向量）。 根据上面的思想，我们要将一个随机变量$\\mathbb x$其经过一个线性变换（基变换）$A$，$\\mathbb x\\to \\mathbb y$： A_{m×m}=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_m),\\quad \\alpha_i=(\\alpha_{1i},\\alpha_{2i}\\cdots,\\alpha_{mi})^T,\\quad i=1,2,\\cdots,m \\mathbb y=A^T\\mathbb x \\mathbb y=(y_1,y_2,\\cdots,y_m)^T,y_i=\\alpha_i^T\\mathbb x_i=\\alpha_{1i}x_1+\\alpha_{2i}x_2+\\cdots+\\alpha_{mi}x_m[几何理解]：$A$就是基矩阵，其中的向量就是正交基。经过变换求得的$y_i$是个数，是原向量到新基$\\alpha_i$的投影（内积），$\\mathbb x$的每个维度在所有新基$(\\alpha_1,\\alpha_2,\\cdots,\\alpha_m)$上的投影$(y_1,y_2,\\cdots,y_m)$构成了新基下的向量$\\mathbb y$ 总结下来就是如下—— [满足以下条件]（下称—定义条件）： 系数向量$\\alpha_i^T$是单位向量，即$\\alpha_i^T\\alpha_i=1,\\quad i=1,2,\\cdots,m$ 新向量$\\mathbb y$的各个维度$y_i$与$y_j$互不相关，即$cov(y_i,y_j)=0\\quad(i≠j)$ $y_i$是①与前面求出来的新向量$\\mathbb y$的各个维度$y_1,y_2,\\cdots,y_{i-1}\\quad(i=1,2,\\cdots,m)$都不相关（也就是要确保是正交变换） ​ ②且是原向量$\\mathbb x$的所有线性变换（基变换）中方差最大的 得到的新向量$\\mathbb y$的各个维度$y_i$即是$\\mathbb x$的主成分，这时分别称$y_1,y_2,\\cdots,y_m$为$\\mathbb x$的第一主成分，第二主成分，$\\cdots$，第$m$主成分，组成的$\\mathbb y$就是总体主成分。 [理解]：线性变换得到的$\\mathbb y$有很多，只有满足以上条件得到的$\\mathbb y$才是主成分（我们想要的一种最能代表原向量结构的一种线性变换）。只有最优解叫主成分，其它线性变换都不叫主成分！ [为了避免混淆写一句]： 一个数据样本$\\mathbb x$经$A$基变换后求得一个$\\mathbb y$，$\\mathbb y$中的每个维$y_i$是主成分，即$\\mathbb x$在新基下各个维度的投影；一个数据样本有$m$维，所以有$m$个主成分 一组数据样本$X=(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n)$经$A$基变换后求得一组$Y=(\\mathbb y_1,\\mathbb y_2,\\cdots,\\mathbb y_n)$，每个样本都被变换到新基下，每个样本都有$m$个主成分，也即$\\mathbb x$在新基下各个维度的投影（这就是实际情况，样本PCA，考虑多个数据样本，这样就实际可以求出样本的均值了） 根据定义中的2,3就可以得出PCA的推导方法，实际上就是个约束最优化问题，见下 性质注意定义$\\alpha,\\mathbb x$都是列向量，分别代表一个向量和基变换矩阵里的一个基 $\\mathbb x=(x_1,x_2,\\cdots,x_m)^T,\\alpha_i=(\\alpha_{1i},\\alpha_{2i}\\cdots,\\alpha_{mi})^T,\\quad i=1,2,\\cdots,m$ 矩阵计算——协方差矩阵对于$n$个上述向量$\\mathbb x$的向量组，$X=(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n)$ 定义协方差矩阵为$cov(X,X)=\\begin{bmatrix}cov(\\mathbb x_1,\\mathbb x_1)&amp;cov(\\mathbb x_1,\\mathbb x_2)&amp;\\cdots&amp;cov(\\mathbb x_1,\\mathbb x_n)\\\\cov(\\mathbb x_2,\\mathbb x_1)&amp;cov(\\mathbb x_2,\\mathbb x_2)&amp;\\cdots&amp;cov(\\mathbb x_2,\\mathbb x_n) \\\\ \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\cov(\\mathbb x_n,\\mathbb x_1)&amp;cov(\\mathbb x_n,\\mathbb x_2)&amp;\\cdots&amp;cov(\\mathbb x_n,\\mathbb x_n) \\\\ \\end{bmatrix}$ 其中每个元素为：$cov(\\mathbb x_i,\\mathbb x_j)=\\mathbb E[(\\mathbb x_i-\\mathbb E(\\mathbb x_i))(\\mathbb x_j-\\mathbb E(\\mathbb x_j))]$，于是这个矩阵可以表示为： $cov(X,X)=\\mathbb E[(X-\\mathbb E(X))(X-\\mathbb E(X))^T]=\\frac{1}{n-1}(X-\\mu)(X-\\mu)^T$ $=\\frac{1}{n-1}\\begin{bmatrix} \\mathbb x_1-\\mu_1 &amp;\\mathbb x_2-\\mu_2 &amp; \\cdots &amp;\\mathbb x_n-\\mu_n\\\\ \\end{bmatrix}\\begin{bmatrix} \\mathbb (x_1-\\mu_1)^T\\\\ \\mathbb (x_2-\\mu_2)^T\\\\ \\vdots\\\\ \\mathbb (x_n-\\mu_n)^T\\\\ \\end{bmatrix}$ (分母为$n-1$：因为随机变量的数学期望未知，以样本均值代替，自由度减一) 以下设期望$\\mu=0$，则对协方差矩阵中的每一位有：$cov(\\mathbb x_i,\\mathbb x_j)=\\mathbb E[\\mathbb x_i·\\mathbb x_j]=\\frac{1}{n-1}\\mathbb x\\mathbb x^T$ cov(X,X)=\\frac{1}{n-1}XX^T$=\\frac{1}{n-1}\\begin{bmatrix} \\mathbb x_1 &amp;\\mathbb x_2 &amp; \\cdots &amp;\\mathbb x_n\\\\ \\end{bmatrix}\\begin{bmatrix} \\mathbb x_1^T\\\\ \\mathbb x_2^T\\\\ \\vdots\\\\ \\mathbb x_n^T\\\\ \\end{bmatrix}=\\frac{1}{n-1}(\\mathbb x_1\\mathbb x_1^T+\\mathbb x_2\\mathbb x_2^T+\\cdots+\\mathbb x_n\\mathbb x_n^T)$ 注意$\\mathbb x_i\\mathbb x_j^T$求得的是一个矩阵，左行右列：$\\mathbb x_{m×1}×\\mathbb x_{m×1}^T=\\mathbb x_{m×1}×\\mathbb x_{1×m}=[\\mathbb x\\mathbb x^T]_{m×m}$ 那么最终相加和之后的$XX^T$也是一个$m×m$的矩阵，每一位都是$x_i$和$x_j$的协方差的在所有样本向量上的期望 设$X_{m×n}$的协方差矩阵为$S_{m×m}$，则其中每一位为： s_{ij}=\\frac{1}{n-1}\\sum_k^n x_{ij}x_{jk},\\quad i,j=1,2,\\cdots,m【最后求出来的协方差为$m×m$形状的矩阵$S_{m×m}$表达了什么意义？这个矩阵的每一位（见上式）就是随机变量$\\mathbb x$中的第$i$维$x_i$和第$j$维$x_j$在整个样本集上的协方差的期望】 而对于总体PCA，就相当于$n=1,X={\\mathbb x}$，一个样本的期望（即平均）就是其本身，$s_{ij}=x_ix_j$ （后半部分都设了均值$\\mu$为0，不为0的表达式就多一项，每个维度计算的时候需要减去该维度在所有样本向量该维度上的均值，懒得写了） 对于只有一个向量$\\mathbb x$，就就相当于$n=1,X=[\\mathbb x]$。协方差矩阵：$cov(\\mathbb x,\\mathbb x)=\\frac{1}{1}×(\\mathbb x-\\mu)(\\mathbb x-\\mu)^T$. （在总体PCA中我们只需要求一个$\\mathbb x$的协方差矩阵，而在样本PCA中，考虑样本集，就是要求$n$个样本组成的向量组的协方差矩阵了） 若对$\\mathbb x$进行规范化（见后）使得$\\mathbb E(\\mathbb x)=0$$,var(\\mathbb x)=1$，则 cov(\\mathbb x,\\mathbb x)=\\mathbb x\\mathbb x^T这里只是求了一个向量$\\mathbb x$的协方差矩阵；对于下面的样本PCA，要求在样本集$X_{m×n}$上的协方差矩阵（见样本PCA） 为什么需要求$cov(\\mathbb x,\\mathbb x)$，因为后面在求$var(y_i)$和$cov(y_i,y_j)$的时候都导出了$cov(\\mathbb x,\\mathbb x)$表示的表达式，而且在定理一中得出了$\\mathbb x$的协方差矩阵和主成分之间的一个重要关系。（对角化的）协方差矩阵即包含了方差最大的优化目标，又包含了两两维度协方差为0 的目标 a)对于$\\mathbb x=(x_1,x_2,\\cdots,x_m)^T$,为$m$维变量非正交，$cov(\\mathbb x,\\mathbb x)=\\begin{bmatrix}{var(x_1)}&amp;{\\cdots}&amp;{cov(x_1,x_m)}\\\\{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\{cov(x_m,x_1)}&amp;{\\cdots}&amp;{var(x_m)}\\\\ \\end{bmatrix}$ b)对于$\\mathbb y=(y_1,y_2,\\cdots,y_m)^T$,为$m$维变量正交，$cov(\\mathbb y,\\mathbb y)=\\begin{bmatrix}{var(y_1)}&amp;{0}&amp;{0}\\\\{0}&amp;{\\ddots}&amp;{0}\\\\{0}&amp;{0}&amp;{var(y_m)}\\\\ \\end{bmatrix}$ 因为对于正交的$y_i,y_j,有cov(y_i,y_j)=0$ 矩阵计算——重要结论对于$y_i=\\alpha_i^T \\mathbb x,\\quad \\alpha_i^T=(\\alpha_{1i},\\alpha_{2i}\\cdots,\\alpha_{mi}),\\quad i=1,2,\\cdots,m$ $\\mathbb E(y_i)=\\mathbb E(\\alpha_i^T\\mathbb x)=\\alpha_i^T \\mathbb E(\\mathbb x)$ 若规范化，$\\mathbb E(y_i)=0$ $var(y_i)=var(\\alpha_i^T\\mathbb x)=\\alpha_i^T cov(\\mathbb x,\\mathbb x)\\alpha_i$ 推导：$var(\\alpha_i^T\\mathbb x)=(\\alpha_{i}^T\\mathbb x-\\mathbb E(\\alpha_{i}^T\\mathbb x))^2=(\\alpha_{i}^T\\mathbb x)^2$，这里求方差略去分母。 $\\alpha_{i}^T\\mathbb x$为向量内积，为一个数，一个数的转置还是本身，那么原式$=(\\alpha_{i}^T\\mathbb x)(\\alpha_{i}^T\\mathbb x)^T=\\alpha_{i}^T\\mathbb x\\mathbb x^T\\alpha_{i}$，而$cov(\\mathbb x,\\mathbb x)=\\mathbb x\\mathbb x^T$，则$var(\\alpha_i^T\\mathbb x)=\\alpha_i^T cov(\\mathbb x,\\mathbb x)\\alpha_i$ $cov(y_i,y_j)=cov(\\alpha_i^T\\mathbb x,\\alpha_j^T\\mathbb x)=\\alpha_i^T cov(\\mathbb x,\\mathbb x)\\alpha_j$ 推导：同上理 [注]： 显然2，3中的方差和协方差求出来的都是一个数，因为$cov(\\mathbb x,\\mathbb x)=\\frac{1}{m-1}\\mathbb x\\mathbb x^T$的形状为$m×m$，$\\alpha_i$的形状为$m×1$，则$[1×m][m×m][m×1]=1×1=constant$ 规范化 x^o_i=\\frac{x_i-\\mathbb E(x_i)}{\\sqrt{var(x_i)}},\\quad i=1,2,\\cdots,m$x_i^o$就是$\\mathbb x_i$的规范化随机变量。（性质略） 对各个维度规范化后$\\mathbb x^o=(x_1^o,x_2^o,\\cdots,x_m^o)^T$。于是$\\mathbb x^o$的$\\mathbb E(\\mathbb x^o)=0$$,var(\\mathbb x^o)=\\sigma=1$ 根据定义推导主成分应满足的条件定理一：总体主成分$\\mathbb y$与$\\mathbb x$的协方差矩阵$\\Sigma$（及其特征值$\\lambda$和特征向量$\\alpha$）的关系 设$\\mathbb x$是$m$维随机变量，$\\Sigma$是$\\mathbb x$的协方差矩阵($\\Sigma=cov(x,x)$)，$\\Sigma$的特征值分别是$\\lambda_1≥\\lambda_2≥\\cdots≥\\lambda_m≥0$。特征值对应的单位特征向量分别是$\\alpha_1,\\alpha_2,\\cdots,\\alpha_m$，则$\\mathbb x$的第$k$主成分表达式是： y_k=\\alpha_k^T\\mathbb x=\\alpha_{1k}x_1+\\alpha_{2k}x_2+\\cdots+\\alpha_{mk}x_m,\\quad k=1,2,\\cdots,m[结论]则其方差为：（注意理解此式子） var(y_k)=\\alpha_k^T\\Sigma\\alpha_k=\\lambda_k,\\quad k=1,2,\\cdots,m这个定理的意义是： ①主成分$y_k$的方差=$\\mathbb x$的协方差矩阵对应的特征值$\\lambda_k$ ②主成分$y_k$的正交变换$\\alpha_k$（基）对应协方差矩阵的特征向量 （注意回到定义-理解去理解一下主成分） 知道了主成分$\\mathbb y$的方差和原向量$\\mathbb x$的协方差矩阵$\\Sigma$的特征值$\\lambda_i$和特征向量$\\alpha_i$的等价关系，即在什么条件下是原问题的最优解（主成分），这样我们就能求解出主成分了。下面的推论给出了充分必要条件。 如果我们想要降维，这就引出了定理二 推导过程（简略）——方差最大化的约束最优化问题： 这个定理就是我们在推导求解PCA的过程中得到的，根据定义，求解PCA实质上是个方差最大化的约束最优化问题。 ①根据上节对PCA的定义，可以将求PCA（先求第一主成分$y_1$）转化为一个约束最优化问题： \\max_{\\alpha_1} var(\\alpha_1^T\\mathbb x)=\\max_{\\alpha_1}\\alpha_1^T\\Sigma\\alpha_1（定义条件-3-②，矩阵计算结论2） s.t.\\quad \\alpha_1^T\\alpha_1=1（定义条件-1） 对其使用拉格朗日乘子法，并对\\alpha_1求导可得：\\Sigma\\alpha_1-\\lambda\\alpha_1=0注意！发现这里求出来的是一个协方差矩阵$\\Sigma$的特征向量方程的形式！可以看成$\\lambda$是特征值，$\\alpha_1$是特征值对应的特征向量 也就是说：这个特征向量方程的解，也就是这个约束最优化问题的解 假定$\\lambda_1$是$\\Sigma$的最大特征值，其对应向量为$\\alpha_1$，于是： 在特征向量方程上变形：最优解\\to\\Sigma\\alpha_1-\\lambda\\alpha_1=0\\to\\alpha_1^T\\Sigma\\alpha_1=\\alpha_1^T\\lambda\\alpha_1=\\lambda\\alpha_1^T\\alpha_1=\\lambda_1所以$\\alpha_1^T\\mathbb x$构成了第一主成分$y_1$，其方差等于$\\mathbb x$的协方差矩阵$\\Sigma$的最大特征值： var(y_1)=var(\\alpha_1^T\\mathbb x)=\\alpha_1^T\\Sigma\\alpha_1=\\lambda_1②下面继续求第二主成分，问题转化为下一个约束最优化问题 由定义条件3-①可知，$y_2$要与$y_1$线性无关，也即协方差为0：那么写出求第二PCA的约束最优化问题：$cov(y_1,y_2)=0$ \\max_{\\alpha_2} var(\\alpha_2^T\\mathbb x)=\\max_{\\alpha_2}\\alpha_2^T\\Sigma\\alpha_2（定义条件-3-②，矩阵计算结论2） s.t.\\quad cov(y_1,y_2)=\\alpha_1^T \\Sigma\\alpha_2=\\alpha_2^T \\Sigma\\alpha_1=0（定义条件-3-①，矩阵计算结论3）, \\alpha_2^T\\alpha_2=1（定义条件-1）与①一样，用拉格朗日乘子法解这个最优化问题： 对其使用拉格朗日乘子法，并对\\alpha_2求导可得：2\\Sigma\\alpha_2-2\\lambda\\alpha_2-\\phi\\alpha_1=0左乘$\\alpha_1^T$有：$2\\alpha_1^T\\Sigma\\alpha_2-2\\alpha_1^T\\lambda\\alpha_2-\\phi\\alpha_1^T\\alpha_1=0$，又由于$\\alpha_1^T \\Sigma\\alpha_2=0$，$\\alpha_1^T \\lambda\\alpha_2$为前者的一个分量，也等于0，于是可以得到： \\Sigma\\alpha_2-\\lambda\\alpha_2=0这又是一个和①形式一样的特征向量方程，于是同样取第二大的特征值$\\lambda_2$，对应特征向量$\\alpha_2$ 最优解\\to\\Sigma\\alpha_2-\\lambda\\alpha_2=0\\to\\alpha_2^T\\Sigma\\alpha_2=\\alpha_2^T\\lambda\\alpha_2=\\lambda\\alpha_2^T\\alpha_2=\\lambda_2所以$\\alpha_2^Tx$构成了第一主成分$y_2$，其方差等于$x$的协方差矩阵$\\Sigma$的第二大特征值： var(y_2)=var(\\alpha_2^T\\mathbb x)=\\alpha_2^T\\Sigma\\alpha_2=\\lambda_2③对于后面的第$k$主成分都同理，有： var(y_k)=var(\\alpha_k^T\\mathbb x)=\\alpha_k^T\\Sigma\\alpha_k=\\lambda_k于是得到上面的定理 [核心结论]推论：主成分的充要条件推论：$m$维随机变量$\\mathbb y=(y_1,y_2,\\cdots,y_m)^T$的分量依次是$\\mathbb x$的第一主成分到第$m$主成分的充要条件是：（由定理一推导过程可得） 条件一：$\\mathbb y=A^T\\mathbb x$，$A$为正交矩阵 A=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_m)= \\begin{bmatrix} {\\alpha_{11}}&{\\alpha_{12}}&{\\cdots}&{\\alpha_{1n}}\\\\ {\\alpha_{21}}&{\\alpha_{22}}&{\\cdots}&{\\alpha_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {\\alpha_{m1}}&{\\alpha_{m2}}&{\\cdots}&{\\alpha_{mn}}\\\\ \\end{bmatrix} 条件二：$\\mathbb y$的协方差矩阵$cov(\\mathbb y,\\mathbb y)=\\frac{1}{n-1}\\mathbb y \\mathbb y^T$为对角矩阵： cov(\\mathbb y,\\mathbb y)=diag(var(y_1),var(y_2),\\cdots,var(y_m))=diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m)=\\Lambda,\\quad \\lambda_1≥\\lambda_2≥\\cdots≥\\lambda_m$\\lambda_k$是$\\mathbb x$的协方差矩阵$\\Sigma$的第$k$个特征值，$\\alpha_k$是对应的单位特征向量，$k=1,2,\\cdots,m$ （这里使用$\\mathbb y$的协方差是为了方便表示一个由所有$y_i$的方差所表示的对角矩阵，见矩阵计算-协方差矩阵-b)） 这里据前面的定理一可以得到：（定理一的右半部分$\\alpha_k^T\\Sigma\\alpha_k=\\lambda_k$换成矩阵表示） A^T\\Sigma A=\\Lambda\\quad,\\Sigma=A\\Lambda A^T 【核心总结】也就是说：通过协方差矩阵的【正交】【对角】分解（满足1,2条件）即可获得主成分（最优解）。具体关系是：$\\mathbb x$的协方差矩阵$\\Sigma$的对角矩阵的特征值构成主成分$\\mathbb y$的方差，协方差矩阵的特征向量构成基矩阵$A$。 根据这个推论（充要条件），问题就被转化为求矩阵正交对角化了。那数学上就可以用矩阵分解来解决，矩阵分解的办法就很多了。得到PCA的两种求解方法，见后面 由定理一和推论得到性质总结 总体主成分$\\mathbb y$的协方差矩阵是对角矩阵 cov(\\mathbb y,\\mathbb y)=\\Lambda=diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m) （此性质即为前面得出的核心结论）总体主成分$\\mathbb y$的方差之和等于随机变量$\\mathbb x$的方差之和，即 \\sum_{i=1}^m \\lambda_i=\\sum_{i=1}^m \\sigma_{ii}其中$\\sigma_{ii}$是随机变量$x_i$的方差，即协方差矩阵$\\Sigma$的对角元素 \\sum_{i=1}^m var(x_i)=tr(\\Sigma^T)=tr(A\\Lambda A^T)=tr(A^T\\Lambda A)=tr(\\Lambda)=\\sum_{i=1}^m\\lambda_i=\\sum_{i=1}^mvar(y_i) 第$k$个主成分$y_k$与变量$x_i$的相关系数$\\rho(y_k,x_i)$称为因子负荷量，表示第$k$个主成分与变量$x_i$的相关关系 \\rho(y_k,x_i)=\\frac{\\sqrt{\\lambda_k}\\alpha_{ik}}{\\sqrt{\\sigma_{ii}}},\\quad k,i=1,2,\\cdots,m由此可以得到一些关系，$\\sum_{i=1}^m\\sigma_{ii}\\rho^2(y_k,x_i)=\\lambda_k\\quad,\\quad \\sum_{k=1}^m\\rho^2(y_k,x_i)=1$ 具体略 定理二：选择方法——选取$k＜m$个主成分下如何选择主成分是最优选择由定理一将问题转化为求解最大化协方差矩阵的特征值之和，定理二就是为了解决这个问题——怎样才能使得协方差矩阵的特征值之和最大 注意这里容易误解：这个定理是证明了选取前$k$个（$y_1,y_2,\\cdots,y_k$）主成分这种选择方法是最优选择（方差最大化），其他选择还有比如：选择第1,4,5,6个主成分，选择第2,8,9,10个主成分，这些都不是最优选择 之所以要取前$k$个主成分是为了降维 定理二：对任意正整数$q,1≤q≤m$，考虑正交变换 \\mathbb y=B^T\\mathbb x其中$y$是$q$维变量，$B^T$是$q×m$矩阵，$\\mathbb x$依然是$m$维原向量，令$y$的协方差矩阵为 \\Sigma_y=B^T\\Sigma B则$\\Sigma_y$的迹$tr(\\Sigma_y)$（这个迹就是对角线和也就是方差和）在$B=A_q$时取最大值，其中矩阵$A_q$由正交矩阵$A$的前$q$列组成 这个定理证明了如果要降维($k＜m$)，选前$k$个主成分是最优选择 证略 $k$的取值：选择几个主成分——由累计方差贡献率决定这里才是分析应该选取的主成分变量的数量$k$ 方差贡献率定义：第$k$主成分$y_k$的方差贡献率定义为$y_k$的方差与所有方差之和的比，记作$\\eta_k$ \\eta_k=\\frac{\\lambda_k}{\\sum_{i=1}^m\\lambda_i}$k$个主成分$y_1,y_2,\\cdots,y_k$的累计方差贡献率定义为$k$个方差之和与所有方差之和的比 \\sum_{i=1}^k\\eta_i=\\frac{\\sum_{i=1}^k\\lambda_i}{\\sum_{i=1}^m\\lambda_i}通常取$k$使得累计方差贡献率达到规定的百分比以上，累计方差贡献率反映了主成分保留信息的比例，由此来决定选择几个主成分($k$的值选取) 对原向量的一个维度$x_i$保留信息的比例为 v=\\rho^2(x_i,(y_1,y_2,\\cdots,y_k))=\\sum_{j=1}^k\\rho^2(x_u,y_j)=\\sum_{j=1}^k\\frac{\\lambda_j\\sigma_{ij}^2}{\\sigma_{ii}}其实就是计算$x_i$与所有新维度$y_1,y_2,\\cdots,y_k$的相关系数之和，这就算出来$x_i$在变换后保留信息的比例 后记 期望，方差，协方差运算可以看这里：http://www.360doc.com/content/13/1124/03/9482_331690142.shtml 协方差矩阵可以参考：https://blog.csdn.net/xueluowutong/article/details/85334256 PCA通俗讲解：https://zhuanlan.zhihu.com/p/21580949 方差$\\sigma$。。。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"我知道光在哪里","slug":"阅读/写给法科生的信","date":"2019-11-26T07:50:21.000Z","updated":"2021-01-17T13:09:34.000Z","comments":true,"path":"阅读/写给法科生的信/","link":"","permalink":"https://aisaka.cloud/%E9%98%85%E8%AF%BB/%E5%86%99%E7%BB%99%E6%B3%95%E7%A7%91%E7%94%9F%E7%9A%84%E4%BF%A1/","excerpt":"在一个黑白混杂的世界里，你是选择描摹黑暗，还是在内心不够强大的时候，先去感知光明？如果我们对于这个世界的态度取决于那些最恶的人做了哪些最恶的事，而不是那些最善良的人做了哪些善良的事，我们与黑暗，就是一体的。 我，知道光在哪里。 《写给法科生的信》是中政法大学的陈少文教授写给学生的回信，虽然说是写给法科生，但是阅读之后发现实际上也适用其它科学生，也解答了我想过的一些的问题。上面是书的第一章，以下摘录一些书中原句。","text":"在一个黑白混杂的世界里，你是选择描摹黑暗，还是在内心不够强大的时候，先去感知光明？如果我们对于这个世界的态度取决于那些最恶的人做了哪些最恶的事，而不是那些最善良的人做了哪些善良的事，我们与黑暗，就是一体的。 我，知道光在哪里。 《写给法科生的信》是中政法大学的陈少文教授写给学生的回信，虽然说是写给法科生，但是阅读之后发现实际上也适用其它科学生，也解答了我想过的一些的问题。上面是书的第一章，以下摘录一些书中原句。 思想背后的利益 批判不是目的，经过反思的接受才是目的。批判性思维，我认为，它首先指的就是这种对思想和利益之间关系的敏锐感知，以及对普世理论的经验怀疑。思想的背后，其实是利益。只是，在你明晰了这个世界真实的利益逻辑之后，不要忘了保有最初的纯真。 法律人的知识沙文主义 任何一次读书都是对自身气质的平衡而非强化。重点不在阅读对象，而在于阅读比例。鸡汤本身没有对错，错在你分给它的时间。如果你成天都待在鸡汤里，只能说明，你就是一只鸡。 知识分子最应该修习的其实是两点，第一，不要太相信自己正确，第二，不要太认为自己重要。前者是自由精神，而后者是豁达胸怀。 言论自由 不是所有的言论都有公共价值。言论自由的真谛是思想自由。经过严肃论证的言论通过思想市场上的充分竞争，并最终为社会凝聚底线共识，这是言论自由最重要的价值所在。而如果一些言论仅仅是仇恨情绪的宣泄，根本无法与其他言论形成合力，并最终凝聚成有价值的共识的话，最终只会加深社会撕裂。 在一个尚缺乏公共论域的转型社会中，所谓的意见领袖、公共知识分子的作用更为特殊。一旦在公共领域发声，他就应该为公共讨论尽力凝聚共识，并在技术层面提供不同观点的深入论证，而不应该抓住公众情绪无限放大，将自己定位为分贝更高的骂街角色。 结构化做事是最好的时间管理 在年轻的时候，不论你听过多少减法生活的理论，实际上都是做不到的。一个正在追求和创造的年纪，怎么可能不断拒绝对外在世界的试探呢？ 但是，年轻的时候至少可以做到一种减法生活：合并同类项。能合并在一起的事情，可以尽量增加。而不能合并的，则尽量拒绝。无关的事情不做，有关的事情反而要多做。 读着读着就老了 有些事情不必问。做，就对了。有些结果不必急。等，就行了。其实，能有什么大不了的事情需要焦虑呢？人生苦短，读着读着，就老了。 可不可以不勇敢？ 不要让愤怒成为一种标尺。因为呐喊肯定是因为勇敢，但是沉默却未必仅仅因为胆怯。也许，仅仅是因为他们和你面对的经验世界，相差甚远。多元的价值远胜民主。和我不一样的，也可能是好的 思想的回归就是进步 而我们，在如此年轻的时候就开始淡泊名利，可问题是，你的名利在哪儿呢？连淡泊的客体都没有，你的淡泊，岂不是懒惰的代名词和遮羞布？所以，我对你的建议是：去努力！去创造！去经历，甚至去颓废！无论做些什么，但首先，你要先热起来！ to be continued","categories":[{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/categories/%E9%98%85%E8%AF%BB/"}],"tags":[]},{"title":"矩阵计算与矩阵分解","slug":"人工智能/矩阵计算","date":"2019-11-25T01:19:02.000Z","updated":"2019-12-09T01:22:22.000Z","comments":true,"path":"人工智能/矩阵计算/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/","excerpt":"矩阵范数和矩阵求导术以后完成 在线性代数和矩阵论都已经学过，这里只写一些常用的","text":"矩阵范数和矩阵求导术以后完成 在线性代数和矩阵论都已经学过，这里只写一些常用的 基本计算 $(AB)^T=B^TA^T$ $(AB)^{-1}=B^{-1}A^{-1}$ $A^{-1}A=AA^{-1}=I$ $(A^T)^{-1}=(A^{-1})^T$ $(ABC)^T=C^TB^TA^T$ 对称矩阵$A$。协方差矩阵、核矩阵、Hessian矩阵都是对称矩阵 有$A_{ij}=A_{ji}$ $A=A^T$，$A^{-1}$也是对称矩阵 一般情况下，矩阵的特征值是复数。但是对于对称矩阵，特征值$\\lambda_i$为实数。 正交矩阵$A$：$AA^T=A^TA=I$ 即矩阵中的各个组成向量/维度相互正交 高斯消元（略） 矩阵的逆 如何求逆（略） 对于可逆矩阵$A$，有$AA^{-1}=A^{-1}A=I$ 正交矩阵的逆等于其转置矩阵：$A^{-1}=A^T$ 特征向量方程：$Ax=\\lambda x,\\quad x$为特征向量；使得该式成立的$\\lambda$称为矩阵$A$的特征值，为常数 该表达式的特征方程为$|\\lambda I-A|=0$ 通过特征方程可解得特征向量和特征值 矩阵对角化 定义：若满足$S^{-1}AS=Λ,\\quadΛ$为一个对角矩阵，则此式子称为矩阵$A$的对角化。 $Λ$称为$A$的特征值矩阵，其对角线上的元素为$A$的所有特征值； $S$称为$A$的特征向量矩阵，其每一列都由$A$的特征向量构成。（证略） （矩阵对角化不唯一） 另一种表示：通过左右乘可表示为$A=S\\Lambda S^{-1}$ 正交对角化：只要满足①$S$为正交矩阵且②$S^{-1}AS=Λ$，那么$S^{-1}AS=Λ$就叫$A$的正交对角化。此时$S^{-1}=S^T$，见性质-5。（矩阵对角化的方式不止此一种，比如下面的SVD也是正交对角化一种方法） 于是$S^{-1}AS=S^TAS=Λ$，或表示为$A=S\\Lambda S^{-1}=S\\Lambda S^T$。 [矩阵的特征值分解]求解正交对角化： ①一般就先用特征方程求得特征值$\\lambda_1,\\lambda_2,\\cdots,\\lambda_n$和对应特征向量$x_1,x_2,\\cdots,x_n$，由特征值作为对角线元素得到$\\Lambda$，即$\\Lambda=diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)$。此时求得的特征向量还未正交标准化。 ②于是再对特征向量进行施密特正交化和单位化得到正交且标准的特征向量。$S$即由特征向量组成（特征向量的每一列即为$S$矩阵的每一列/每个向量），$S$中个每特征向量都正交。 ③$A=S\\Lambda S^{-1}$，此即一种正交对角化，也叫$A$的特征值分解 可对角化条件：求得特征值和特征向量，$A$的每个特征值对应的齐次线性方程组的基础解系所含向量个数等于特征值的重数（注意每个重根虽然特征值相同，但是不同的特征值）；矩阵不一定能对角化，但对称矩阵一定能对角化。 实对称矩阵A的属于不同特征值的特征向量一定是正交的。（所以对于实对称矩阵的不同特征值对应的特征向量就不用再求施密特正交化了，只需要单位化） 行列式 行列式仅适用于方阵 $|AB|=|A||B|$ $|A^{-1}|=\\frac{1}{|A|}$ 克莱姆法则解线性方程组（略） $|A_{M×M}|=\\prod_{i=1}^M \\lambda_i=A$的对角化矩阵$\\Lambda$的对角线元素之积 秩等价空间维度等价独立变量等价无关变量等价正特征值数量 正定矩阵和半正定矩阵 半正定矩阵：$A∈\\mathbb R^{n×n},x∈\\mathbb R^n$，对任意$x$，$x^TAx≥0$恒成立 正定矩阵：$A∈\\mathbb R^{n×n},x∈\\mathbb R^n$，对任意$x$，$x^TAx＞0$恒成立 一些等式 $(P^{-1}+B^TR^{-1}B)^{-1}B^TR^{-1}=PB^T(BPB^T+R)^{-1}$ $(I+AB)^{-1}A=A(I+BA)^{-1}$ Woodybury恒等式：$(A+BD^{-1}C)^{-1}=A^{-1}-A^{-1}B(D+CA^{-1}B)^{-1}CA^{-1}$ 都可以用左乘/右乘逆矩阵的逆推得 正交基变换 $X$为原矩阵下的向量（坐标），$X=(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n)$，有$n$个原基下的$\\mathbb x$向量 $A$为正交基矩阵 $A=(a_1,a_2,\\cdots,a_m)$，其中的每个向量就是一个新的基，新基是相互正交的 $\\mathbb x_i和a_j$都是$m$维列向量，$\\mathbb x_i$代表原基下的一个向量/坐标，那么 Y=A^TX即为基变换，新基下的向量为$Y=(\\mathbb y_1,\\mathbb y_2,\\cdots,\\mathbb y_n)$ $\\mathbb y_i$也是$m$维列向量，代表经过基矩阵$A$变换后新基下的坐标 也可以半展开写成：（这里转置易错，见13） (\\mathbb y_1,\\mathbb y_2,\\cdots,\\mathbb y_n)=(a_1,a_2,\\cdots,a_m)^T(\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n) =\\begin{bmatrix} a_1^T\\\\ a_2^T\\\\ \\vdots\\\\ a_m^T\\\\\\end{bmatrix} \\begin{bmatrix}\\mathbb x_1,\\mathbb x_2,\\cdots,\\mathbb x_n\\end{bmatrix} =\\begin{bmatrix} a_1^T\\mathbb x_1&a_1^T\\mathbb x_2&\\cdots&a_1^T\\mathbb x_n\\\\ a_2^T\\mathbb x_1&a_2^T\\mathbb x_2&\\cdots&a_2^T\\mathbb x_n\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ a_m^T\\mathbb x_1&a_m^T\\mathbb x_2&\\cdots&a_m^T\\mathbb x_n\\\\ \\end{bmatrix}在该基变换中，每一个旧基下的向量$\\mathbb x_i$都左乘了基矩阵$A$ ，也就是： \\mathbb y=A^T\\mathbb x如果只有一个向量$x$做基变换，那便是： \\mathbb y=(a_1,a_2,\\cdots,a_m)^T\\mathbb x=\\begin{bmatrix} a_1^T\\\\ a_2^T\\\\ \\vdots\\\\ a_m^T\\\\\\end{bmatrix}\\mathbb x= \\begin{bmatrix} a_1^T\\mathbb x\\\\ a_2^T\\mathbb x\\\\ \\vdots\\\\ a_m^T\\mathbb x\\\\ \\end{bmatrix} =(a_1^T\\mathbb x,a_2^T\\mathbb x,\\cdots,a_m^T\\mathbb x)^T展开列向量$\\mathbb y$中的每一个维度表示：即$y_i=a_i^T\\mathbb x=a_1x_1+a_2x_2+\\cdots+a_mx_m$ 这样变换的原理： 可以看出变换得到的新基下的变量的每个维度都由基矩阵的一个列向量也就是一个基与原基下的变量内积得到，新向量的一个维度为基矩阵的一个基与原基变量的内积，就是上面这个式子 而内积的几何意义是：向量$A与B$的内积实质上就是$A$到$B$的投影长度乘以$B$的模，如果$B$为单位向量，那么$A与B$的内积就是$A$到$B$上的投影，也就是向量$\\mathbb x$在新基组$(a_1,a_2,\\cdots,a_m)$下的投影，也就得到了新基下的坐标/向量表示：$\\mathbb y$。原基下的向量$\\mathbb x$被投影到了每一个新基($a_i$)上，组成了新基下的向量表示（坐标）：$\\mathbb y$。 用图表示关系就是 各个颜色的变换就是内积，就是一次原基下的向量表示到某一个新基的投影过程 举例，对于一般的二维笛卡尔直角坐标系中，其基为$a_1=(0,1)^T,a_2=(1,0)^T$，其正交基矩阵就是 $A=\\begin{bmatrix}a_1,a_2\\end{bmatrix}=\\begin{bmatrix} 0&amp;1\\\\1&amp;0 \\\\ \\end{bmatrix}$，对于本来就在笛卡尔坐标系下的向量$\\mathbb x$,自然$\\mathbb x=A^T\\mathbb x$，新基和原基没变，那向量表示（坐标）自然也没变 基变换的本质：投影 注意转置简写矩阵的时候易错 （设定$a$为向量） $(a_1,a_2,\\cdots,a_m)^T=\\begin{bmatrix} a_1^T\\\\ a_2^T\\\\ \\vdots\\\\ a_m^T\\\\\\end{bmatrix}$ 外面那层转置只是转置了外层的列，每列内部还没有进行转置，所以要这样！ 内积的几何意义 向量$A与B$的内积实质上就是$A$到$B$的投影长度乘以$B$的模，如果$B$为单位向量，那么$A与B$的内积就是$A$到$B$上的投影 奇异值分解定义singular value decomposition ，SVD 将一个非零的$m×n$实矩阵$A,A∈\\mathbb R^{m×n}$，表示为三个实矩阵乘积形式的运算： A=U\\Sigma V^T其中$U$为$m$阶正交矩阵，$V$为$n$阶正交矩阵，$\\Sigma$是由降序排列的非负的对角线元素组成的$m×n$矩形的对角矩阵 A=U_{m×m}\\Sigma_{m×n}V^T_{n×n} ①UU^T=I,②VV^T=I,③\\Sigma=diag(\\sigma_1,\\sigma_2,\\cdots,\\sigma_p),④\\sigma_1≥\\sigma_2≥\\cdots≥\\sigma_p≥0,⑤p=\\min(m,n)$\\sigma_i$称为矩阵$A$的奇异值，$U$的列向量称为左奇异向量，$V$的列向量称为右奇异向量 紧奇异值分解：分解得到的对角矩阵$\\Sigma$的秩与原式矩阵$A$的秩相等，即$rank(A)=rank(\\Sigma)$ 截断奇异值分解：分解得到的对角矩阵$\\Sigma$的秩小于原式矩阵$A$的秩，即$rank(A)&gt;rank(\\Sigma)$ （可以看出截断奇异值分解损失了信息） 性质 若$A$为实矩阵，则奇异值分解存在（证明用构造法，为$A$依次构造$U和V$，略） 几何意义：任意一个向量$x∈\\mathbb R^n$，经过基于$A=U\\Sigma V^T$的线性变换，等价于向量$x∈\\mathbb R^n$经过坐标系的旋转或反射变换$V^T$，坐标轴的缩放变换$\\Sigma$，以及坐标轴的旋转或反射变换$U$，得到向量$Ax∈\\mathbb R^m$ 设矩阵$A$的奇异值分解为$A=U\\Sigma V^T$，则 $A^TA=(U\\Sigma V^T)^T(U\\Sigma V^T)=V(\\Sigma^T\\Sigma)V^T$ $AA^T=(U\\Sigma V^T)(U\\Sigma V^T)^T=U(\\Sigma\\Sigma^T)U^T$ （推导）直接乘即可推导 由于$U,V$是正交矩阵，则右边的式子$V(\\Sigma^T\\Sigma)V^T$就是$A^TA$的正交对角分解，$AA^T$同理（因为根据计算-7，对于正交矩阵$V$满足$V^T=V^{-1}$，于是$A^TA=V(\\Sigma^T\\Sigma)V^{-1}$，根据定义这就是正交对角分解） 于是，矩阵$AA^T和A^TA$的[正交对角分解存在]且可以由[$A$的奇异值分解]的三个矩阵表示。由这个性质可以推出奇异值分解的计算方法。 奇异值，左奇异向量，右奇异向量之间的关系 [A]通过定义式$A=U\\Sigma V^T$可得右乘$V$得$AV=V\\Sigma$，则： $Av_j=\\sigma_ju_j,\\quad j=1,2,\\cdots,n$，[于是当$\\sigma≠0,u_j=\\frac{Av_j}{\\sigma_j},\\quad j=1,2,\\cdots,n$] [B]由$A^T=(U\\Sigma V^T)^T=V\\Sigma^T U^T,\\therefore A^TU=V\\Sigma^T$，则： ①$A^Tu_j=\\sigma_jv_j,\\quad j=1,2,\\cdots,n$ ②$A^Tu_j=0,\\quad j=n+1,n+2,\\cdots,m$，[于是当$\\sigma=0,A^Tu_j=0,\\quad j=n+1,n+2,\\cdots,m$] 奇异值唯一，$U,V$不唯一 $rank(A)=rank(\\Sigma)=[正]奇异值的个数$ 奇异值分解的计算由性质3，我们发现了$A^TA$的奇异值可以由$A$的奇异值分解得到的三个矩阵$U,\\Sigma,V$表示，即: A^TA=V(\\Sigma^T\\Sigma)V^T于是存在对应关系：$V$的列向量是$A^TA$的特征向量；$\\Sigma$的奇异$A^TA$的特征值的平方根。于是我们想到借助求解$A^TA$的特征向量和特征值求得$\\Sigma,V$(性质3)，再借助$A=U\\Sigma V^T$的关系求得$U$（性质4）。 步骤： 首先求$A^TA$的特征值和特征向量 $W=A^TA$，解特征方程$|\\lambda I-W|=0$ 求$n$阶正交矩阵$V$ 上面特征方程解后单位正交化后的特征向量构成$V$ 由于$W=A^TA$为实对称矩阵，其不同特征值对应的特征向量正交，对这样的特征向量不用再求施密特正交化了，只需要单位化 求$m×n$阶对角矩阵$\\Sigma$ $\\sigma_i=\\sqrt{\\lambda_i},\\quad i=1,2,\\cdots,n$ 求得对角矩阵后要加上零行向量以便于与$U,V$相乘计算 求$m$阶正交矩阵$U$ 根据性质4总结：①当$\\sigma≠0,u_j=\\frac{Av_j}{\\sigma_j},\\quad j=1,2,\\cdots,n$，得到$U_1$（对于正奇异值，直接用[A]求） ②当$\\sigma=0,A^Tu_j=0,\\quad j=n+1,n+2,\\cdots,m$，转变为求$A^T$零空间的一组标准正交基：$A^Tx=0$，求得的一组标准正交基$x$即是$u$，得到$U_2$（对于零奇异值，不能用①求了，于是用[B]方法求） $U=[U_1\\quad U_2]$ 得到奇异值分解$A=U\\Sigma V^T$ 在实际运用中不直接求$W=A^TA$，而是通过求$A^TA$的特征值进行 SVD与矩阵近似（证略） 佛罗贝尼乌斯范数（F范数）：$A∈\\mathbb R^{m×n},A=[A_{ij}]_{m×n}$，则定义矩阵$A$的佛罗贝尼乌斯范数为： ||A||_F=(\\sum_{i=1}^m\\sum_{j=1}^n(a_{ij}^2))^{\\frac{1}{2}}引理：$A$的奇异值分解为$A=U\\Sigma V^T,\\quad \\Sigma=diag(\\sigma_1,\\sigma_2,\\cdots,\\sigma_n)$，则： ||A||_F=(\\sigma_1^2+\\sigma_2^2+\\cdots+\\sigma_n^2)^{\\frac{1}{2}}F范数实际上就是衡量这个矩阵和对应的零矩阵的距离，就像二维平面上的一个点，和原点的距离就是它的f范数，那么下面的$A-X$其实就是衡量$A$到$X$的距离，也就是近似程度 定理1：设矩阵$A∈\\mathbb R^{m×n}$，矩阵的秩$rank(A)=r$，并设$\\mathbb M$为$\\mathbb R^{m×n}$中所有秩不超过$k$的矩阵的集合，$0＜k＜r$，则存在一个秩为$k$的矩阵$X∈\\mathbb M$使得 ||A-X||_F=\\min_{S∈\\mathbb M}||A-S||_F称矩阵$X$为矩阵$A$的佛罗贝尼乌斯范数意义下的最优近似。这里秩不超过$k$的矩阵也就是要用一个低秩矩阵去近似高秩原矩阵。证明了存在，那什么样的矩阵才是最优解呢？答案：SVD。见下。 定理2：设矩阵$A∈\\mathbb R^{m×n}$，矩阵的秩$rank(A)=r$，有奇异值分解$A=U\\Sigma V^T$，并设$\\mathbb M$为$\\mathbb R^{m×n}$中所有秩不超过$k$的矩阵的集合，$0＜k＜r$，若秩为$k$的矩阵$X∈\\mathbb M$满足 ||A-X||_F=\\min_{S∈\\mathbb M}||A-S||_F 则||A-X||_F=(\\sigma_{k+1}^2+\\sigma_{k+2}^2+\\cdots+\\sigma_{n}^2)^{\\frac{1}{2}}特别地，若$A’=U\\Sigma’V^T$，其中 \\begin{bmatrix} {\\sigma_1}&{}&{}&{}\\\\ {}&{\\sigma_2}&{}&{}\\\\ {}&{}&{\\ddots}&{}\\\\ {}&{}&{}&{0}&{}&{}\\\\ {}&{}&{}&{}&{\\ddots}&{}\\\\ {}&{}&{}&{}&{}&{0}\\\\ \\end{bmatrix} = \\begin{bmatrix} {\\Sigma_k}&{0}\\\\ {0}&{0} \\end{bmatrix} 则||A-A'||_F=(\\sigma_{k+1}^2+\\sigma_{k+2}^2+\\cdots+\\sigma_{n}^2)^{\\frac{1}{2}}=\\min_{S∈\\mathbb M}||A-S||_F定理2表明了在秩不超过$k$的$m×n$矩阵的集合中，存在矩阵$A$的佛罗贝尼乌斯范数意义下的最优近似矩阵$X$。 $A’=U\\Sigma’V^T$是达到最优值的一个矩阵，也就是说=&gt;【通过SVD求得的这个矩阵就是最优近似矩阵】&lt;=这是这里的核心，也就说明了可以用SVD求得低秩矩阵去近似原矩阵。且奇异值分解是在平方损失（佛罗贝尼乌斯范数）意义下对矩阵的最优近似，即最优的数据压缩 利用外积展开式对矩阵$A$进行近似——截断奇异值分解 对于秩为$n$的原矩阵$A=\\sigma_1u_1v_1^T+\\sigma_2u_2v_2^T+\\cdots+\\sigma_nu_nv_n^T$ 于是其近似矩阵可以取为秩为$k$的矩阵$A=\\sigma_1u_1v_1^T+\\sigma_2u_2v_2^T+\\cdots+\\sigma_ku_kv_k^T$ 这里其实就是取奇异值矩阵从大到小排列的奇异值的前$k$个，在第$k$个奇异值处截断，剩下的奇异值行全部删掉，见下面的截断奇异值分解的详细描述。这就是截断奇异值分解，是一种最优化的有损压缩。 截断奇异值分解： 截断奇异值分解得到的矩阵秩为$k$，通常远小于原始矩阵的秩$r$，所以是由低秩矩阵实现了对原始矩阵的压缩（近似）。具体地说就是：奇异值矩阵中的奇异值是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。也就是说，我们也可以用最大的$k$个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说： $A_{m×n}=U_{m×m}Σ_{m×n}V^T_{n×n}≈U_{m×k}Σ_{k×k}V^T_{k×n}$。其中$k$要比$n$小很多，也就是一个大的矩阵$A$可以用三个小的矩阵$U_{m×k},Σ_{k×k},V^T_{k×n}$来表示，对应于上面的$A’=U\\Sigma’V^T$。其秩低于原矩阵的秩。 这种近似是在佛罗贝尼乌斯范数意义下的最优近似，其在1中已经给出了 应用紧奇异值分解是在佛罗贝尼乌斯范数意义下的无损压缩 截断奇异值分解是在佛罗贝尼乌斯范数意义下的有损压缩 由于这个重要的性质，SVD可以用于PCA降维，来做数据压缩和去噪。 也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。 同时也可以用于NLP中的算法，比如潜在语义索引（LSI）。 奇异值分解与特征值分解的区别特征值分解可以看作一个空间到自身的映射，奇异值分解可以看作一个空间到另一个空间的映射。 奇异值分解把线性变换清晰地分解为旋转、缩放、投影这三种基本线性变换，特征值分解是对旋转和缩放两种效应的归并。 由于奇异值关于不同的基（两组基），所以可以扩展到任意线性变换，而特征值则只能描述线性算子。 可以看知乎这一篇：矩阵的奇异值与特征值有什么相似之处与区别之处？ - 赵文和的回答 - 知乎 https://www.zhihu.com/question/19666954/answer/54788626 矩阵范数 非负性 $||\\alpha A||=|\\alpha|·||A||$ $||A+B||≤||A||+||B||$ $||A||_1=\\max_j \\sum_{i=1}^m|a_{ij}|$ $||A||_2=\\sqrt{\\lambda_i}\\quad,\\lambda_i为A^HA的最大特征值$ $||A||_{∞}=\\max_i \\sum_{j=1}^n |a_{ij}|$ ​ 对于向量$x,||x||_2=(\\sum_{i=1}^nx_i^2)^{\\frac{1}{2}}$ 矩阵求导术向量$\\vec a$关于标量$x$的导数也是个向量，其分量为：$(\\frac{\\partial \\vec a}{\\partial x})_i=\\frac{\\partial a_i}{\\partial x}$ 同理，向量$x$关于矩阵$a$的导数为：$(\\frac{\\partial x}{\\partial a})_i=\\frac{\\partial x}{\\partial a_i}$ 向量$a$关于向量$b$的导数为$(\\frac{\\partial a}{\\partial b})_{ij}=\\frac{\\partial a_i}{\\partial a_j}$，也就是分子的每个分量对分母的每个分量求导 实质上就是多元微分，其结果为向量/矩阵 $x$为向量，$a$为向量，$\\frac{\\partial x^Ta}{\\partial x}=a$ 证明：设$x=[x_1,x_2,\\cdots,x_n],a=[a_1,a_2,\\cdots,a_n],\\therefore x^Ta=[x_1a_1,x_2a_2,\\cdots,x_na_n]$ $\\therefore \\frac{\\partial x^Ta}{\\partial x}=\\frac{\\partial[x_1a_1,x_2a_2,\\cdots,x_na_n]}{\\partial [x_1,x_2,\\cdots,x_n]}$，然后根据$(\\frac{\\partial a}{\\partial b})_{ij}=\\frac{\\partial a_i}{\\partial a_j}$： $\\frac{\\partial x^Ta}{\\partial x}=\\frac{\\partial x_ia_i}{\\partial x_j}=[a_1,a_2,\\cdots,a_n]=a$ 后记向量/矩阵在计算的时候一定要注意形态和下标！","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"绮凝盏(双笙xHanser)","slug":"Music/绮凝盏-双笙xHanser","date":"2019-11-24T23:51:10.000Z","updated":"2019-11-25T02:03:20.000Z","comments":true,"path":"Music/绮凝盏-双笙xHanser/","link":"","permalink":"https://aisaka.cloud/Music/%E7%BB%AE%E5%87%9D%E7%9B%8F-%E5%8F%8C%E7%AC%99xHanser/","excerpt":"你像银河的微光 绵绵的暗香 锁在玻璃的橱窗 盛着幻想乡 展牌落款的红章 结束了飘荡 你曾见闻的时光 饮三杯再唱","text":"你像银河的微光 绵绵的暗香 锁在玻璃的橱窗 盛着幻想乡 展牌落款的红章 结束了飘荡 你曾见闻的时光 饮三杯再唱 喜欢的两个唱见一起合唱了，好听死了","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[{"name":"hanser","slug":"hanser","permalink":"https://aisaka.cloud/tags/hanser/"},{"name":"双笙","slug":"双笙","permalink":"https://aisaka.cloud/tags/%E5%8F%8C%E7%AC%99/"}]},{"title":"第一关关卡设计","slug":"游戏设计/第一关关卡设计","date":"2019-11-23T07:16:18.000Z","updated":"2019-11-24T03:56:54.000Z","comments":true,"path":"游戏设计/第一关关卡设计/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E7%AC%AC%E4%B8%80%E5%85%B3%E5%85%B3%E5%8D%A1%E8%AE%BE%E8%AE%A1/","excerpt":"本文为腾讯游策游戏制作，我的第一关关卡设计构思；游戏类型为横版潜行解谜 第一关设计目的给玩家引入新机制——电力，强化第一关的作用于道具物品（如钥匙）的学习，通过道具改变环境给自己的潜行带来更多的优势，比如开着手电的守卫在黑暗的房间里视野会变短且容易被发现。","text":"本文为腾讯游策游戏制作，我的第一关关卡设计构思；游戏类型为横版潜行解谜 第一关设计目的给玩家引入新机制——电力，强化第一关的作用于道具物品（如钥匙）的学习，通过道具改变环境给自己的潜行带来更多的优势，比如开着手电的守卫在黑暗的房间里视野会变短且容易被发现。 第一关可用道具梯子[1]：玩家使用该道具后在朝向位置生成一个梯子，该梯子与楼梯中其他上下梯子功能想通过但可以作为道具回收 钥匙[2]：可以敲开门与保险柜 绳索[3]：可以向下面进行移动 漏电的手电筒[4]：玩家持有手电筒可以在黑暗区域看清前方扇形区域的敌人 剪刀[5]：可与一些物体（如电线）进行交互使得部分房间停电 可交互固定物品算作场景物品，不算作道具（如发电机，开关，门等） 主要是要考虑到在电力机制下，道具的可复用性 道具：[]，场景物品：（） 道具的交互设计——电力主题绳索基本用途：在攀爬点挂绳索以上下楼层移动；可以用来导电；绳索存在长度 基于导电的用途： (发电机)+(开关)+[绳子]+(水摊)=同层陷阱：可以使水带电具有攻击，但要注意操作先后顺序 (发电机)+(开关)+[绳子]+(食物)=引诱：可以电熟生食物，散发香气，吸引守卫 (发电机)+(开关)+[绳子]+(收音机/电视/洗衣机)=引诱：通电启动放声音，吸引守卫 (发电机)+(开关)+[绳子]+(开关)+(发电机)=停电：两台发电机同时运转，大楼电力超载宕机，电灯熄灭，经过若干房间主角可以不被任何守卫发现，若干房间后来电 (发电机)+(开关)+[绳子]=跨层陷阱：将绳子挂在楼上发电机，绳落下到楼下，守卫经过的时候手触碰就会被电 (发电机)+(开关)+[绳子]+(水)+[绳子]+(金属交互物品)=导电：水作为导线延长结点，启动电子设备 芯片部分发电机需要该芯片才能启动（一个芯片对应一个固定的发动机） 钥匙 打开任意宝箱和门 (漏电源)+[钥匙]（金属属性）+(金属交互物品)=导电：可以为金属物品提供电力，启动电子设备 剪刀 剪断电线，使房间/红外系统停电 刺杀工具 手电筒基本用途：视野距离更远 场景内交互物品设计——电力主题以下物品都算电子设备，需要电力启动 通过 铁链门（同层） 电力密码门（同层）：首先需要给电脑供电，打开电脑查看密码门的密码；再将给电脑供电的线接到密码门上，再输入密码 传送带（跨层）：启动传送带，抓住上面的扶手，可以把主角运到高层或低层去 信息​ 电脑/操作台：需要电力启动，打开后可以查看信息，该信息可以用来解密 场景物品位移​ 传送带：需要电力启动，启动后滑轨上的物体会移动到传送带另一头 位移辅助通关的扶梯到需要的位置 移开障碍物以通过 移动传送带上面的发电机，缩短需要导电的距离（导线距离不够长的情况） 场景变换作为大关切换，启动大电梯，以进入下一个大关卡 地图与关卡设计需要考虑解密和潜行的平衡性。可以设定剪刀作为刺杀武器设定声音很大，只能在房间里只有守卫一个人（被吸引走的守卫不算）且不正对主角的情况下使用。一般房间里为两个人，用陷阱干掉/引开一个人，另一个人刺杀。（一个人中了陷阱，另一个同房间的守卫会跑去看一会儿，然后又继续巡逻（这时候设定巡逻视野变大，巡逻速度加快，即刺杀难度更高）） Surface Pen丢了。。。没法在电脑上画图（#捂脸） Scene A引入电力机制，绳索连接发电机和铁链门，基础教学 Scene B目标是通过密码铁链门 ①用绳子连接发动机和传送带，启动发电机，驱动传送带，移开障碍物； ②取下绳子，将绳子从小洞放下楼，电晕左边的守卫； ③搭楼梯从小洞爬下去，用剪刀暗杀右边的守卫 ④拿取二楼右边的芯片和左边的绳 ⑤下三楼，将第一根绳从三楼发电机连接到水摊，将第二根绳从水摊连接到电脑，启动电脑，获取密码铁链门的密码 ⑥将三楼发电机与电梯电桩相连，进入电梯回到一楼 ⑦将绳插入无芯片发电机，将绳从插入了芯片的发电机连到密码铁链门，输入密码，打开门 通关 Scene C多路线设计每一个解谜关卡都设计另一种可以直接暗杀守卫的方式不解谜直接通关 但是如果杀人太多，会走向bad ending 这样可以合理降低难度又可以设计多结局","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"Boosting(XGBoost、LightGBM)","slug":"人工智能/Forest","date":"2019-11-19T09:15:30.000Z","updated":"2019-11-23T15:47:30.000Z","comments":true,"path":"人工智能/Forest/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Forest/","excerpt":"XGBoost和LightGBM都属于GBDT的变种，见上篇；读本篇需要先熟练理解和掌握CART回归树和GBDT算法。 XGBoost原论文： https://arxiv.org/abs/1603.02754 基于CART回归树的生成方法：依然是先确定最优树的结构，然后通过最小化损失函数确定叶子结点的输出值，XGBoost在GBDT上做了一定改进 引入正则化项来控制树的复杂度表记$T(x;\\Theta_{m})=w_{q(x)}$，$x$为一个样本，$q(x)$表示该样本所在的叶子结点，$w_q$为叶子节点$q$的回归输出；于是$w_{q(x)}$即表示每个样本的回归输出，即决策树的输出。定义集合$I_j=\\{i|q(x^{(i)})=j\\}$表示划分到叶结点$j$的所有训练样本的集合即上一篇的表示法：$\\{x|x∈R_{j}\\}$。$T$为叶子节点个数（即划分个数）$m$为步/轮数，$N$为样本个数。 定义每一步生成新决策树的损失函数的正则项： \\Omega(T(x;\\Theta_m))=\\gamma T+\\frac{1}{2}\\lambda||w||^2可以看出惩罚考虑了两项：$T$为叶子节点个数，$w$为每个样本的输出值 （也可以用$c$表示：$\\Omega(T(x;\\Theta_m))=\\gamma T+\\frac{1}{2}\\lambda||c||^2$，$c$即每个划分的输出值，也就对应了每个样本的输出） XGBoost向损失函数加入此正则项($L’$为不含正则项的原损失函数)变为（样本总体损失函数）： L(y_{i+1},f_{m+1}(x_i))=\\sum_iL'(y_{i+1},f_{m+1}(x_i))+\\Omega(T(x;\\Theta_{m+1}))","text":"XGBoost和LightGBM都属于GBDT的变种，见上篇；读本篇需要先熟练理解和掌握CART回归树和GBDT算法。 XGBoost原论文： https://arxiv.org/abs/1603.02754 基于CART回归树的生成方法：依然是先确定最优树的结构，然后通过最小化损失函数确定叶子结点的输出值，XGBoost在GBDT上做了一定改进 引入正则化项来控制树的复杂度表记$T(x;\\Theta_{m})=w_{q(x)}$，$x$为一个样本，$q(x)$表示该样本所在的叶子结点，$w_q$为叶子节点$q$的回归输出；于是$w_{q(x)}$即表示每个样本的回归输出，即决策树的输出。定义集合$I_j=\\{i|q(x^{(i)})=j\\}$表示划分到叶结点$j$的所有训练样本的集合即上一篇的表示法：$\\{x|x∈R_{j}\\}$。$T$为叶子节点个数（即划分个数）$m$为步/轮数，$N$为样本个数。 定义每一步生成新决策树的损失函数的正则项： \\Omega(T(x;\\Theta_m))=\\gamma T+\\frac{1}{2}\\lambda||w||^2可以看出惩罚考虑了两项：$T$为叶子节点个数，$w$为每个样本的输出值 （也可以用$c$表示：$\\Omega(T(x;\\Theta_m))=\\gamma T+\\frac{1}{2}\\lambda||c||^2$，$c$即每个划分的输出值，也就对应了每个样本的输出） XGBoost向损失函数加入此正则项($L’$为不含正则项的原损失函数)变为（样本总体损失函数）： L(y_{i+1},f_{m+1}(x_i))=\\sum_iL'(y_{i+1},f_{m+1}(x_i))+\\Omega(T(x;\\Theta_{m+1})) 修改拟合目标在AdaBoost中我们是拟合残差 在GBDT中我们是去拟合负梯度（一阶导数，泰勒公式一阶展开求导得出）来替代拟合残差 而XGBoost中， 直接用泰勒展开式将损失函数二阶展开，求其一阶梯度和二阶梯度，正因为使用损失函数的二阶泰勒展开，因此与损失函数更接近，比只使用了一阶展开的GBDT收敛速度更快（前提是函数一阶、二阶都连续可导，而且在这里计算一阶导和二阶导时可以并行计算） g_i=\\frac{\\partial L'(y_i,f(x_i))}{\\partial f(x_i)},h_i=\\frac{\\partial^2 L '(y_i,f(x_i))}{\\partial f(x_i)}于是用和GBDT一样的方法，对无正则的原损失函数（单个样本）$L’(y_{i+1},f_{m+1}(x_i))$在$\\hat f_m(x_i)$处进行泰勒二阶展开，这里简要推导： $L’(y_{i+1},f_{m+1}(x_i))=L’(y_{i+1},f_m(x_i)+T(x,\\Theta_{m+1}))$ 对右式在$\\hat f_m(x_i)$二阶泰勒展开，并令$x’=\\hat f_m(x_i)+T(x,\\Theta_{m+1})$，$y$为无关常量 $\\therefore 原式≈L’(y_{i+1},f_m(x_i))+g_i(x’-\\hat f_m(x_i))+\\frac{1}{2}h_i(x’-\\hat f_m(x_i))^2$ $=L’(y_{i+1},f_m(x_i))+g_iT(x,\\Theta_{m+1})+\\frac{1}{2}h_iT^2(x,\\Theta_{m+1})$ 由于对本轮优化来说，$L’(y_{i+1},f_m(x_i))$是个常数，不会影响损失函数，于是： $L’(y_{i+1},f_{m+1}(x_i))≈g_iT(x,\\Theta_{m+1})+\\frac{1}{2}h_iT^2(x,\\Theta_{m+1})$ 于是计算整个样本集的损失函数（前面的损失函数都是单个样本的）加上前面的正则构成目标损失函数： $Obj_{m+1}=\\sum_{i=1}^N[g_iT(x,\\Theta_{m+1})+\\frac{1}{2}h_iT^2(x,\\Theta_{m+1})]+\\gamma T+\\frac{1}{2}\\lambda||w||^2$，转换表示，见开头的表记方法 $=\\sum_{i=1}^N[g_iw_{q(x_i)}+\\frac{1}{2}h_iw^2_{q(x_i)}]+\\gamma T+\\frac{1}{2}\\lambda\\sum_{j=1}^Tw_j^2$ ，将对样本求和改为对划分求和，同一个叶子节点/划分$j$的输出值是相同的，即$w_{q(x_i)}=w_j\\quad if\\quad i∈I_j$，于是改写为： $Obj_{m+1}=\\sum_{j=1}^T[(\\sum_{i∈I_j} g_i)w_j+\\frac{1}{2}(\\sum_{i∈I_j}h_i+\\lambda)w_j^2]+\\gamma T$ 令G_j=\\sum_{i∈I_j} g_i \\quad ,H_j=\\sum_{i∈I_j}h_i\\quad,则： Obj_{m+1}=\\sum_{j=1}^T[G_jw_j+\\frac{1}{2}(H_j+\\lambda)w_j^2]+\\gamma T①于是【根据此损失函数先确定$(j,s)$划分，确定决策树的结构】 但是注意到实际上在确定决策树结构（选择最优特征和分割点）的时候，决策树结构数量是无穷的，所以实际上并不能穷举所有可能的决策树结构。什么样的决策树结构是最优的呢？通常使用贪心策略来生成决策树的每个结点。——因为对某个结点采取的是二分策略，分别对应左子结点和右子结点，除了当前待处理的结点，其他结点对应的$Obj_{m+1}$值都不变，所以对于收益的计算只需要考虑当前结点的$Obj_{m+1}$值即可。 （其它DT和基于DT的boosting通常也用贪心策略） 从深度为0的树开始对每个叶子结点穷举所有的可用特征； 针对每一个特征，把属于该结点的训练样本的该特征升序排列，通过线性扫描的方式来决定该特征的最佳分裂点，并采用最佳分裂点时的收益； 选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，把该结点生成出左右两个新的叶子结点，并为每个新结点关联新的样本集； 退回到第一步，继续递归操作直到满足特定条件。 不过原作者没有直接这样暴力枚举，因为即使贪心策略只考虑当前结点，该结点内可能的分裂点也很多。于是原作者通过加权分位数的算法选出了一些可能的分裂点（见后文）。 下面我们就要通过一个增益函数/打分函数来判断谁是最佳特征和分裂点了： 分裂前针对该结点的最优目标函数(这个最优目标函数是假设结构已经固定的情况下在第②步中先求出来的）为： Obj_{m+1}^{(before)}=-\\frac{1}{2}\\frac{G^2}{H+\\lambda}+\\gamma=-\\frac{1}{2}\\frac{(G_L+G_R)^2}{(H_L+H_R)+\\lambda}+\\gamma分裂后的最优目标函数为：（$G分为左G_L和右G_R,H同理$） Obj_{m+1}^{(later)}=-\\frac{1}{2}[\\frac{G_L^2}{H_L+\\lambda}+\\frac{G_R^2}{H_R+\\lambda}]+2\\gamma于是对于目标函数$Obj_m$，分裂后的收益为$Gain=Obj_{m+1}^{(before)}-Obj_{m+1}^{(later)}$： Gain=\\frac{1}{2}[\\frac{G_L^2}{H_L+\\lambda}+\\frac{G_R^2}{H_R+\\lambda}-\\frac{(G_L+G_R)^2}{(H_L+H_R)+\\lambda}]-\\gamma为了限制树的生长，我们可以加入阈值，当增益大于阈值时才让节点分裂，上式中的$\\gamma$即阈值，它是正则项里叶子节点数$T$的系数，所以XGBoost在优化目标函数的同时相当于做了预剪枝。 同时可以看出该式子中$\\lambda$起了对叶结点score做平滑的作用。（这俩参数定义见最前面的正则化公式）这两个参数在这里求分裂的时候也都起了正则化作用 故可用此公式决定最优分裂特征和分裂点，贪心地选择收益最大的作为分裂点 ②【根据损失函数确定每个结点的最优回归输出】 由于决策树的结构已经固定了，那么就知道了$q(),I_j$。（这里的①与GBDT的第③步一样的，先求出划分，结构就固定了，然后在GDBT中下一步③求出残差的替代让新决策树去拟合之（即缩小与残差的损失函数），求得每个结点的最优输出值；不过在XGBoost中这里推导出了一个由一阶导，二阶导构成的损失函数，于是XGBoost就是要去缩小这个损失函数，选取每个结点的最优输出值）； 又由于$g_i,h_i$是对当前已知模型(上一步/轮求出来的)$f_m(x_i)$的导数，那么$G_j,H_j$也是已知常数，于是让目标损失函数$Obj_{m+1}$对$w_j$求0导（我们原来是要对$T(x;\\Theta_{m})$求导的，而$T(x;\\Theta_{m})=w_{q(x)}$）可得 w^o=-\\frac{G_j}{H_j+\\lambda} 最优损失函数:Obj_{m+1}=-\\frac{1}{2}\\sum_{j=1}^T\\frac{G^2_j}{H_j+\\lambda}+\\gamma T$w^o=-\\frac{G_j}{H_j+\\lambda}$即为叶子节点的最优输出，相当于GDBT的第④步 引入学习率/缩减（Shrinkage）在更新前向分步模型的时候，在新树的输出引入学习率，以防止过拟合 f_{m+1}(x)=f_{m}(x)+\\epsilon T^o(x;\\Theta_{m+1})引入分布式加权分位数略图算法在决策树分裂的时候引入的减小计算量的方法：weighted quantile sketch。本质是基于权重的采样 决策树的分裂基本都是基于贪心的，也就是只考虑当前结点的最优特征和划分而不考虑全局最优，但这样依然需要穷举该结点内每个可能的分裂点。当数据没法全部加载到内存中时，这种方法会比较慢，XGBoost提出了一种近似的方法去高效的生成候选分割点——分布式加权分位数略图算法 先看加权分位数略图算法 对原目标式：$Obj_{m+1}=\\sum_{i=1}^N[g_iT(x,\\Theta_{m+1})+\\frac{1}{2}h_iT^2(x,\\Theta_{m+1})]+\\Omega(T(x;\\Theta_m))$变形，在里面添加一个常数： $=\\sum_{i=1}^N[g_iT(x,\\Theta_{m+1})+\\frac{1}{2}h_iT^2(x,\\Theta_{m+1})+\\frac{1}{2}\\frac{g_i^2}{h_i}]+\\Omega(T(x;\\Theta_m))+constant$ $=\\sum_{i=1}^n\\frac{1}{2}h_i[T(x,\\Theta_{m+1})-(-\\frac{g_i}{h_i})^2]+\\Omega(T(x;\\Theta_m))+constant$ 可以看出，最后的目标代价函数就是一个$h_i$的加权平均损失函数 于是进一步我们想要如何以分位数的方式划分区域来取候选点。 思想：我们将特征样本排序，划分成不同区域，对样本取分位数点，每个分位数点落在区域内，但由于样本权重越高的区域，预测结果越是不确定的样本区域，切分的粒度就应该越密集。 那么具体怎么实现呢： 对于数据集$D_k=\\{(x_{1k},h_1),(x_{2k},h_2),\\cdots,(x_{nk},h_n)\\}$，$k$表示某特征，$h$即为损失函数在该样本在$k$特征对应的二阶梯度 s在加权分位缩略图算法中，取值是按照Rank来取的： r_k(z)=\\frac{\\sum_{(x,h)∈D_k,x","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"11月游戏简评","slug":"Game/11月游戏简报","date":"2019-11-17T17:24:00.000Z","updated":"2019-11-18T15:47:30.000Z","comments":true,"path":"Game/11月游戏简报/","link":"","permalink":"https://aisaka.cloud/Game/11%E6%9C%88%E6%B8%B8%E6%88%8F%E7%AE%80%E6%8A%A5/","excerpt":"历来的年末都是各大厂商血拼的时候，今年也不例外。 在死亡搁浅搁浅之后，还以为今年的GOTY会陷入无人可领的地步，没想到横空杀出了个大黑马，星球大战：绝地真的是把我惊艳到了，或者说震惊到了。 星球大战：香星球大战：绝地武士陨落集各家游戏之所长，继承泰坦陨落的灵魂，以星战之衣钵，重生工作室又一次给玩家们交了一张几近满分的答卷（不是满分是因为发行商名字没取对，改名某某某就满分了）。我在这个游戏里看到了塞尔达，黑魂只狼，神海等等各家游戏的优点，又结合了自家出色的手感（可重生以前打击感做得好都是FPS的枪感好，并没有什么ACT的打击感开发经验，这是怎么做到一出手就如此优秀的？incredible. 仁王好好学学别人！！） 当然也有不少缺点。可以看出来这个游戏还是有很多地方欠打磨，比如各种神奇的穿模和bug…而且第一章画面辣眼睛（但第二章这EA的画面不是又回来了嘛！P.S.然后掉帧也回来了），多敌人战斗的时候有时候视角很奇怪等等 其实要认真来说，星球大战并没有一个非常突出的地方，但是为何如此之香？就是因为它的各方面不突出，但都很良好，也就是说基本没有短板，所以给玩家的体验非常好。 地图设计非常大而充实，可探索要素充足，而且地图也四通八达。","text":"历来的年末都是各大厂商血拼的时候，今年也不例外。 在死亡搁浅搁浅之后，还以为今年的GOTY会陷入无人可领的地步，没想到横空杀出了个大黑马，星球大战：绝地真的是把我惊艳到了，或者说震惊到了。 星球大战：香星球大战：绝地武士陨落集各家游戏之所长，继承泰坦陨落的灵魂，以星战之衣钵，重生工作室又一次给玩家们交了一张几近满分的答卷（不是满分是因为发行商名字没取对，改名某某某就满分了）。我在这个游戏里看到了塞尔达，黑魂只狼，神海等等各家游戏的优点，又结合了自家出色的手感（可重生以前打击感做得好都是FPS的枪感好，并没有什么ACT的打击感开发经验，这是怎么做到一出手就如此优秀的？incredible. 仁王好好学学别人！！） 当然也有不少缺点。可以看出来这个游戏还是有很多地方欠打磨，比如各种神奇的穿模和bug…而且第一章画面辣眼睛（但第二章这EA的画面不是又回来了嘛！P.S.然后掉帧也回来了），多敌人战斗的时候有时候视角很奇怪等等 其实要认真来说，星球大战并没有一个非常突出的地方，但是为何如此之香？就是因为它的各方面不突出，但都很良好，也就是说基本没有短板，所以给玩家的体验非常好。 地图设计非常大而充实，可探索要素充足，而且地图也四通八达。 配乐和音效是原汁原味的星战味，但音乐有点偏少，尤其缺少战斗音乐，光听见切肉和光剑愣愣愣的声音了 战斗部分深度并不高，但很爽。由于原力机制和判定并不严苛的防反存在，再厉害的怪也不会太难，作为一个ARPG已经完全足够了。 战斗的打击感很到位，光剑战斗真的是视觉和听觉的盛宴 画面优良。引擎使用的是虚幻4而不是寒霜，实在是非常遗憾。第一章画面不行，但到了第二章，画面又好了起来。据开发组说，最开始使用寒霜引擎遇到了很多致命的麻烦，因为寒霜引擎是专门为FPS等游戏设计的，本作中有很多攀爬等元素，得自己改引擎，最后走到死路，改用虚幻开发。 解谜和关卡设计优秀，可以看出借鉴了很多优秀的游戏设计，完美融合进了星战里。我甚至不敢相信这个关卡设计是出自EA之手，非常用心的解谜设计，是一个大大的加分项。 剧情总体平稳，介于我还没来得及通关，就先不扯淡了。 总结一下：好看又好玩，这样的游戏一定不会差。 重生，让EA重生EA这几年来走的并不顺利，很多工作室的表现都令人大跌眼镜，也许是内部管理的原因，这里不过多谈论。但是重生工作室的表现一直很稳定，前有TTF，APEX等佳作，EA也顺势将星球大战这等重量级的游戏交给重生开发。它也不负众望，交给EA也交给玩家们一张完美的答卷。 希望EA借着这一仗口碑的胜利，凤凰涅槃，继续下去，加油！ 又回过头来说说死亡搁浅 拿3A游戏来做革新，也只有小岛秀夫敢这么干众所周知，3A游戏的制作成本是非常昂贵的，也因为成本太高，很少有3A游戏厂商敢拿3A游戏来开刀革新的。所以我们看到很多非常有创意的游戏都是独立游戏或者以前的老游戏（在当时很有创意）。 但在死亡搁浅中，小岛秀夫把3A游戏的核心玩法拿来完全革新，而且这种创新不像战神4之于战神3对自我的革新，因为那是有路子可寻的，而死亡搁浅却是创造了一种全新的核心玩法。 这在游戏界，恐怕只有小岛秀夫敢这么干了——一个个人声望大过集体，游戏制作界的明星人物 下面谈谈死亡搁浅 Connect死亡搁浅的核心玩法简要的说就是共建。整个服务器的玩家一起共同在一片宽旷且到处都是阻碍的地面上建设设施，一起重建世界，玩家之间可以共享资源以及自己建设的设施，玩家之间可以相互为对方建的设施点赞。 这很好玩吗？不一定。但是如果你云通关，一定感受不到其中的乐趣。 这个点赞，其实就是Connect设计中的反馈，而且是一种正向的反馈。在FPS中，你杀人之后，你也会获得一种反馈，但这种反馈就是负面反馈，你每杀一个人，就会得到一次反馈，激励你杀更多的人。 死亡搁浅中的正向反馈就是你在游戏里干的事情，会被其他玩家感受到，其他玩家感受到你的帮助之后，会给你点赞。当你受到点赞的时候，就会有“我做的事情是有意义的，带给了其他人帮助”的感受。这种感受是一种很美妙的感觉，确实会促进玩家再去更多地为世界做建设——于是千千万万的connect就构建起了死亡搁浅的世界。 这是什么精神？这是社会主义精神！Make American Socialism Again！ 共建的核心玩法能否支撑起剧情与设定的厚度？这个问题有很多答案。有的玩家说有，有的玩家说没有（云玩家除外）。其实这个问题要回答很简单，那就是你是否喜欢这个玩法？如果喜欢，那它一定能支撑起这整个游戏，你会感觉到予人赞，其乐无穷，你会给这个游戏打9分甚至10分。但如果你不喜欢这个玩法，会感觉这个游戏的游戏性非常空洞，无聊，6.8分不能更多。 所以答案是，让时间证明吧。 一个新的游戏类型的提出，一般都不会立刻被所有玩家接受，就像小岛秀夫最开始创造潜行类游戏的时候一样。死亡搁浅也才发售不到半个月，未来，这种玩法会不会被广大玩家接受，甚至掀起潮流，谁知道呢？ 电影性小岛秀夫作为电影化游戏的开拓者，可以看出他一直致力于在模糊电影和游戏的界限。游戏里用了很多著名的演员，音乐也是到了游戏里的每一首歌都能单曲循环的程度。 有的玩家很喜欢这样，但有的玩家不喜欢，这就是游戏界很常见的争论——游戏性与艺术性之争 这个以后专门开一篇来写好了。 GF：我们重质量不重数量神奇GF重新定义“质量”。 这里我就打个滑稽，以下一万字略 XGN？你说的这个某GN，它厉害吗？厉害。可信吗？不好说。 经过多年观察，我发现某GN有几个明显的特点： ①喜欢同一系列作纵向，如果前作一般，但这次大大超越了前作，会给很高的分 ②对独立游戏异常宽容 ③不同类型的游戏，给分的标准完全不同 ④偏向给游戏性而非艺术性的游戏高分 ⑤不同编辑口味差别很大，甚至前后矛盾 ⑥打游戏打到心情不好会情绪化（比如Prey，真的就是彻底的不负责任） ⑦一般是以一种涉猎甚广的老玩家眼光来评价游戏 所以其实，IGN的评分重要吗？在这么多主观且漂浮不定的标准下，IGN能做到完全公平公正客观吗？ 再者，什么是客观？连艺术性和游戏性这两大流派之间都还没争出个谁更重要，IGN又凭什么说是什么就是什么呢？ 所以我一直认为，这种“客观”机构的打分机制就应该被革除，这种因为一个主观的评分，就能影响整个风向的机构，就应该消失。IGN的编辑最多也就是一个“身经百战，见得多了的老玩家”而已，他只能代表他这个人的看法，说出他的感受，但他并没有权力给游戏定分，定性 此文同步发在社团公众号","categories":[{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"}],"tags":[]},{"title":"Boosting(AdaBoost、DBT、GBDT)","slug":"人工智能/提升方法","date":"2019-11-17T09:11:27.000Z","updated":"2019-11-21T08:58:35.000Z","comments":true,"path":"人工智能/提升方法/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/","excerpt":"Boost算法在我的黑白判项目，动态项目都有用到，而且在实际中也非常常用，是一种非常有效的算法 Boosting思想：对于一个训练集，弱分类器可以比较容易地学习到比较粗糙的分类问题，而一个复杂的分类问题很难学习。于是我们想到将复杂的分类问题分而治之，由每个弱分类器负责学习一个相对比较简单的分类问题，于是每个弱分类器各有所长，将多个弱分类器组合成一个强分类器，就可以解决复杂分类问题。 具体地，我们在训练集上迭代学习多个弱分类器，每一次迭代学习出一个弱分类器，这个弱分类器对部分样本有较好的分类作用，而对有些样本分类效果很差。于是我们加大分类效果差的样本的权值，降低分类效果好的样本的权值，以学习一个新的弱分类器来分开它们（在整个训练集上学习），它能够较好的分出这些效果较差的样本中的一部分样本。于是为了分开那一部分类效果差的样本，继续迭代$\\cdots\\cdots$最后以每一个分类器的分类效果为依据，设计弱分类器之间的组合，最终得到强分类器 根据这个思想，Boost方法要考虑两个问题： ①每一轮训练数据的权值（广义的权值，即每个样本重要性）如何改变 ②如何将弱分类器组合成一个强分类器","text":"Boost算法在我的黑白判项目，动态项目都有用到，而且在实际中也非常常用，是一种非常有效的算法 Boosting思想：对于一个训练集，弱分类器可以比较容易地学习到比较粗糙的分类问题，而一个复杂的分类问题很难学习。于是我们想到将复杂的分类问题分而治之，由每个弱分类器负责学习一个相对比较简单的分类问题，于是每个弱分类器各有所长，将多个弱分类器组合成一个强分类器，就可以解决复杂分类问题。 具体地，我们在训练集上迭代学习多个弱分类器，每一次迭代学习出一个弱分类器，这个弱分类器对部分样本有较好的分类作用，而对有些样本分类效果很差。于是我们加大分类效果差的样本的权值，降低分类效果好的样本的权值，以学习一个新的弱分类器来分开它们（在整个训练集上学习），它能够较好的分出这些效果较差的样本中的一部分样本。于是为了分开那一部分类效果差的样本，继续迭代$\\cdots\\cdots$最后以每一个分类器的分类效果为依据，设计弱分类器之间的组合，最终得到强分类器 根据这个思想，Boost方法要考虑两个问题： ①每一轮训练数据的权值（广义的权值，即每个样本重要性）如何改变 ②如何将弱分类器组合成一个强分类器 AdaBoostAdaptive Boost 适应性提升算法 ①每一轮训练数据的权值如何改变：根据分类器效果，样本权值直接改变 ②如何将弱分类器组合成一个强分类器：分类器加权相加 AdaBoost Algorithm$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$，$y_i∈\\{-1,1\\}$ 开始进行第一轮迭代，$m$为迭代轮数 ①初始训练集每个样本的权值平均分布，学得第一个弱分类器$G_1$ $D_1=(w_{11},\\cdots,w_{1i},\\cdots,w_{1N})\\quad,w_{1i}=\\frac{1}{N}\\quad,i=1,2,\\cdots,N$ $G_1(x):\\mathbb X\\to\\{-1,+1\\}$ ②计算分类误差率$e_1$ e_1=\\sum_{i=1}^N P(G_1(x_i)≠y_i)=\\sum_{i=1}^N w_{1i}I(G_1(x_i)≠y_i)③通过$e_1$计算弱分类器$G_1$的权值$\\alpha_1$ 这个系数既用来作为分类器权重，也用来计算训练集权值 \\alpha_1=\\frac{1}{2}\\log\\frac{1-e_1}{e_1}这个公式恰好使得在$e=\\frac{1}{2}$的时候，$\\alpha=0$；$e$越大，则误差越大，就让权值$\\alpha$越小。 由于二分类问题的最差情况就是正确率$e≥50\\%$，所以这个式子实际上就是使得$\\alpha$的值域为$[0,1)$ ④通过$\\alpha_1$计算新的训练集每个样本的权值，每个样本用$w_{2i}$表示，在权值为$w_2$的训练集（依然是在整个训练集上学习）上学得第二个弱分类器$G_2$ w_{2i}=\\frac{1}{Z_1}w_{1i}e^{-\\alpha_1y_iG_1(x_i)}权值为概率，之和必为1，要归一化 其中$y_iG_1(x_i)=c(u)=\\begin{cases} 1\\quad,y_i=G_1(x_i)\\\\ -1\\quad,y_i≠G_1(x_i) \\end{cases}$。也就是说，[A]如果预测准确，指数部分为负，新的权值减小；如果预测[B]如果预测不准确，指数部分为正，新的权值增加。增加和减少都是$e^{\\alpha_1}$倍 ⑤进入第二轮迭代，计算$e_2,\\alpha_2,G_{3}$ ⑥$\\cdots$，进入第$m$轮迭代，迭代计算$e_m,\\alpha_m,G_{m+1}$ ⑦迭代结束后，得到强分类器 G(x)=sign(\\sum_m\\alpha_mG_m(x)) AdaBoost算法的训练误差分析：略 前向分步算法具体算法与公式略 思想：因为学习的是加法模型，如果能够从前往后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数式，那么就可以简化优化的复杂度。 AdaBoost算法的前向分布算法解释：AdaBoost算法是前向分步算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数就是指数函数（证略） Boost方法实质上是使用了加法模型与前向分步算法。 前向分步算法每一步相当于AdaBoost中的每一轮（但具体细节会有差别） 前向分步算法的求解本质是贪心方法 更多地可以通过提升树来理解，提升树就是直接用的前向分布算法。 BDT 提升树学习DBT需要对CART有深刻掌握 提升树是以决策树为基函数的提升方法。表示为决策树的加法模型： f_{M(x)}=\\sum_{m=1}^MT(x;\\Theta_m)$T(x;\\Theta_m)$表决策树，$\\Theta_m$为决策树的参数，$M$为树的个数 树的线性组合可以很好地拟合训练数据，即使输入与输出之间的关系很复杂也如此，于是提升树是一个很高功能的学习算法 于是根据前向分步算法，拟合初始训练数据集学得初始分类器$f_0(x)=T(x;\\Theta_0)$， 第$m+1$步的模型为：$f_{m+1}(x)=f_{m}(x)+T(x;\\Theta_{m+1})$$\\quad ,f_{m}(x)$即为当前第$m$步的已有模型，由上一步第$m-1$步学到 于是通过ERM确定下一个决策树的最优参数：$\\hat \\Theta_{m+1}=\\arg\\min_{\\Theta_{m+1}}\\sum_{i=1}^NL(y_i,f_{m}(x_i)+T(x_i,\\Theta_{m+1}))$ 根据不同的问题，使用不同的损失函数；回归问题用平方误差，分类问题用指数损失函数；一般决策问题用一般损失函数 ①二分类问题：线性分类器为二类分类树（CART分类树）的AdaBoost ②回归问题：基函数是CART回归树 对第$m$步 采用平方误差损失，则$L(y_i,f_{m}(x_i)+T(x,\\Theta_{m+1}))=(y_i-f_{m}(x_i)-T(x_i;\\Theta_{m+1}))^2$ 则第$m$步（轮）第$i$样本的残差$r_{mi}=y_i-f_{m}(x_i)$，这个残差算的当前已有模型（由上一步计算出的当前步）的残差，于是我们要求出下一个新的决策树$T(x;\\Theta_{m+1})$，就是去拟合这个残差，以使得损失函数最小化，求得最优参数的决策树$T(x;\\hat\\Theta_{m+1})$，也可以求出其输出值（回归值，具体怎么求出参考决策树章节） 然后更新分类器$f_{m+1}(x)=f_{m}(x)+T(x;\\Theta_{m+1})$ ，完成一次迭代 然后计算下一步$m+1$的残差，拟合下下步$m+2$的模型，更新线性模型$\\cdots\\cdots$ 最后得到的回归问题提升树就为$f_{M(x)}=\\sum_{m=1}^MT(x;\\Theta_m)$ 具体算法略 注意： ①分类器$f_m(x)$函数是用于迭代作用的，最后组合强分类器的时候和它无关，是将每一步迭代得到的决策树$T(x;\\Theta_m)$拿来组合。 ②为什么要每轮都要累加分类器，计算$f_m(x)$而不像AdaBoost一样每步直接用新学得的弱分类器进行分类？因为除了第一步求得的决策树是拟合训练数据集本身以外，以后每一步求得的决策树拟合的都是残差！而不是训练数据本身！举例：原始训练集 $(2,3,4,5)$，假设拟合得初始决策树：$\\begin{cases} 2.5\\quad,y_i＜3.5\\\\ 4.5\\quad,y_i≥3.5 \\end{cases}$，于是求得第一步的残差$r$为$(-0.5,0.5,-0.5,0.5)$，然后拟合这个残差求得下一步的决策树。所以用$f_m(x)$累加后才是分类器，因为其包含了初始训练集的完整数据，而不是仅是根据残差求得的那个决策树。（这个决策树只对当前步的残差起决策作用） 所谓A拟合B就是让A更接近B 总结（回归问题）： ①每一轮训练数据的权值如何改变：不直接设置权值，而是计算残差 ②如何将弱分类器组合成一个强分类器：拟合残差得到的决策树相加 BDT的求解过程一般化就是前向分步算法的求解过程，需要理解，以便后面变形方便使用 GBDT 梯度提升决策树（回归）GDBT Algorithm依然基于CART分类器，是回归问题提升树的改进 像前面的平方，指数损失函数都很容易最优化，但对于一般损失函数，如huber损失、quantile损失，每一步求最优化都不容易。于是使用梯度提升（不是梯度上升！梯度依然是下降以求最小损失函数）算法来求解损失函数最优化问题，其是最速下降法（搜索最佳步长的梯度下降法）的近似方法。 在提升树基础上修改：利用损失函数的[负梯度在当前模型的值]替代回归问题提升树算法中的残差 GBRT 几乎可用于所有的回归问题（线性/非线性） 问题O 过程： $m$代表步（轮）数 ①初始化： f_0(x)=\\arg\\min_c\\sum_{i=1}^NL(y_i,c)②对该步（轮）每个样本计算[负梯度在当前模型的值=残差的估计]为：（②其实为③的一个步骤） r_{mi}=-[\\frac{\\partial L(y_i,f(x_i))}{\\partial f(x_i)}]_{f(x)=f_{m}(x)}推导见下面【②中残差的推导】 ③拟合上面计算出的每个样本的[残差]，得到下一步用的新决策树的[结构]： 用这个新决策树对残差学习得到叶结点区域（划分）$R_{mj}\\quad,j=1,2,\\cdots,J$ 这里其实就是极小化损失函数$L(y_{i+1},f_{m+1}(x_i))=L(r_{mi},T(x=特征点与切割点;\\Theta_{m+1}))$（中间推导就是残差的推导那儿），以选取新决策树的最优特征和最优划分 [此时只是确定了树的结构，但是还未确定叶子节点中的最优输出值，下一步④中通过最小化损失函数: $L(y_i,f_{m}(x_i)+c)$，求得每个叶子节点中的输出值，和CART中的算法一样，不同的就在于下面求最优输出值的时候是让输出而不是残差去拟合$y_i$ ，也就是损失函数不一样] 。更多细节见下面的【注意理解】 ④对每个划分用线性搜索叶结点区域的最优值（最速下降法），使得损失函数最小化： c_{mj}=\\arg\\min_c\\sum_{x_i∈R_{mj}}L(y_i,f_{m}(x_i)+c) 更新：f_{m+1}(x)=f_{m}(x)+\\sum_{j=1}^Jc_{mj}I(x∈R_{mj})注意这里的表示方法。$I(x∈R_{mj})$就表示了新学得的决策树输出的结构，乘上该区域结点输出值$c_{mj}$，此即在当前步下最终学到的下一步用的新决策树$\\sum_{j=1}^Jc_{mj}I(x∈R_{mj})$ ⑤最终的强分类器为： \\hat f(x)=f_M(x)=\\sum_{m=1}^M\\sum_{j=1}^Jc_{mj}I(x∈R_{mj})于是新的决策树就去拟合这个残差，其它不变。 【注意理解】：这里需要好好回想生成CART回归树的步骤。将CART回归树表达式中是损失函数扩展为任意，则： $\\min_{j,s}[\\min_{c_1}\\sum_{x_i∈R_1(j,s)}L(y_i,c_1)+\\min_{c_2}\\sum_{x_i∈R_2(j,s)}L(y_i,c_2)]$ ③中就相当于通过拟合残差（也就是该式子损失函数中的拟合$y_i$替换为拟合$r_i$）先求了CART回归树的外围参数最小值$j,s$，即特征选择和划分（回看CART回归生成，遍历选择$j,s$最小化损失函数选最优特征和划分） ④中就是求在划分下，使得损失函数最小的$c$，而这个$c$就是对应划分的残差的回归输出（通过求该划分下的平均值求得，为CART中损失函数中的模型输出值），也就是上面所提到的叶结点区域的值。（回看CART回归生成，在一个划分（结点）内最小化损失函数选择一个最优的输出，使得该划分每个样本的损失最小） 由于前面求得决策树拟合的是残差（除了第一步决策树是拟合的训练集）以得到最优划分结构；下面要去拟合训练集的真实输出还要让新决策树的输出加上从第一颗决策树输出与中间决策树拟合残差输出迭代而来的前$m$步模型输出$f_{m}(x_i)$（第$m$轮），所以某划分的模型实际回归输出为$f_{m}(x_i)+c$。（前向分步算法的基本求法。）所以我们在每轮（第一轮除外）拟合决策树求划分的时候，是拟合残差（③）；但是在求划分得到的叶结点区域的输出值的时候，我们是要去拟合[真实输出值$y_i$]而不是残差，所以是用$f_{m}(x_i)+c$去拟合！得损失函数极值及极值的时候的$c$（④）可以看出③和④损失函数目标不一样。（但是同一个损失函数） 【②中残差的推导】：损失函数为（这里是单个样本的损失函数，多个样本加个求和符号即可，求出的每个样本的残差结论不变） $L(y_{i+1},f_{m+1}(x_i))=L(y_{i+1},f_{m}(x_i)+T(x,\\Theta_{m+1}))$，$y$为常数（样本真实输出） 令$x’=\\hat f_{m}(x_i)+T(x,\\Theta_{m+1})$，对于在$x_0$的泰勒展开： $f(x)=f(x_0)+\\cdots+\\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+R_n(x)$ (此$x’$即为泰勒展开式形式的自变量，为了区分损失函数中的$x$) 则该损失函数在当前模型$\\hat f_{m}(x_i)$处进行一阶泰勒展开： $L(y_{i+1},f_{m+1}(x_i))=L(y_{i+1},f_{m}(x_i)+T(x,\\Theta_{m+1}))≈L(y_{i+1},\\hat f_{m}(x_i))+\\frac{\\partial L(y_{i+1},\\hat f_{m}(x_i))}{\\partial f_{m}(x_i)}(x’-\\hat f_{m}(x_i))$ $=L(y_{i+1},\\hat f_{m}(x_i))+\\frac{\\partial L(y_{i+1},\\hat f_{m}(x_i))}{\\partial f_{m}(x_i)}T(x,\\Theta_{m+1})$ 所以要使损失函数最低，那么按照梯度下降思想，我们求出梯度，然后只需要令损失函数向梯度反方向增加即可。所以我们让损失函数对要优化的变量$T(x,\\Theta_{m+1})$求导（$L(y_{i+1},\\hat f_{m}(x_i))$显然为无关项）： $\\nabla L(y_{i+1},f_{m+1}(x_i))=\\frac{\\partial L(y_{i+1},f_{m+1}(x_i))}{\\partial T(x,\\Theta_{m+1})}=\\frac{\\partial L(y_{i+1},\\hat f_{m}(x_i))}{\\partial f_{m}(x_i)}$，于是我们就要让函数在： $r_{mi}=-[\\frac{\\partial L(y_i,f(x_i))}{\\partial f(x_i)}]_{f(x)=f_{m}(x)}$上梯度下降，该负梯度的在当前模型的值即为残差的估计。 残差其实是梯度提升中负梯度的一种特例，就是导数的近似值，将损失函数换为平方差损失可以推导出 具体算法略 GDBT分类算法O如果样本输出类别为$k$，则$y_k=1$；$p_k(x)$表示模型$f(x)$判定$x$属于第$k$类的概率：$p_k(x)=\\frac{e^{f_k(x)}}{\\sum_{l=1}^Ke^{f_l(x)}}$ 注意，对于多分类问题，回归树训练时，会为每一个类别训练一个决策树。 GDBT的正则化 与AdaBoost一样，每个决策树乘上一个弱化系数 对CART树剪枝，降低CART树复杂度 采用子采样，每次随机抽取部分样本（SGBT） GDBT 损失函数选择OReason 分类问题 指数损失函数、对数损失函数 回归问题 均方差损失函数、绝对损失函数 huber损失函数和分位数（quantile）损失函数，也用于回归问题，可以增加回归问题的健壮性，减少异常点对损失函数的影响 GDBT的优缺点可以处理各种类型的数据，预测准确率高，使用huber和分位数损失函数可以增加回归问题的健壮性（Huber函数 在值为0时也是可微分的 ） 但是由于基学习器存在依赖关系，难以并行化处理，不过通过子采样的SGBT来实现部分并行 后记 $I(True)=1,I(False)=0$ 更多资料可以看此文 https://blog.csdn.net/zhang15953709913/article/details/84586592 梯度下降法/最速下降法中用的就是加上负梯度（相当于减去梯度）以缩小损失函数，加梯度就越来越大了 这里有一个GDBT回归问题求解的一个例子： https://blog.csdn.net/zpalyq110/article/details/79527653 ，也可以作为自己练习O 表记轮数/步数下标的时候我都是观测的$m,m+1$，可以各自减一改为观测$m-1,m$","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"决策树","slug":"人工智能/决策树","date":"2019-11-13T07:08:22.000Z","updated":"2019-11-21T09:36:56.000Z","comments":true,"path":"人工智能/决策树/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%86%B3%E7%AD%96%E6%A0%91/","excerpt":"Decision Tree机器学习最基本模型之一，DT 决策树可以看成路径的集合，路径的集合可以看成$if-then$规则的集合，内部结点表示特征或属性，叶结点表示一个类别（结论）。决策树的$if-then$规则集合是互斥且完备的（每一个实例都被包含在DT里） 决策树也可以对应于一个条件概率分布","text":"Decision Tree机器学习最基本模型之一，DT 决策树可以看成路径的集合，路径的集合可以看成$if-then$规则的集合，内部结点表示特征或属性，叶结点表示一个类别（结论）。决策树的$if-then$规则集合是互斥且完备的（每一个实例都被包含在DT里） 决策树也可以对应于一个条件概率分布 数据集$D=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$ 其中$x_i=(x_i^{(1)},x_i^{(2)},\\cdots,x_i^{(n)})^T$为输入实例（特征向量），$n$为特征个数，$y_i∈\\{1,2,\\cdots,K\\}$为类别标记， $i=1,2,\\cdots,N$，$N$为样本容量。 目标就是学习到这个$if-then$规则集合，同时与训练数据矛盾较小（不欠拟合），又可以很好的预测位置数据（不过拟合）。DT学习算法是对训练数据分割的过程，也是特征空间划分的过程，也是决策树的构建过程。 DT算法一般三大步骤①特征选择②决策树生成③剪枝 剪枝的目的是防止过拟合（剪掉了树上过于细分的结点，使其退回到父节点或更高的结点） DT是一种启发式算法，求得的是近似最优解 特征选择熵特征用来划分特征空间，对数据进行实际分类。我们通过信息增益或信息增益比来选择特征。 $P(X=x_i)=p_i\\quad,P(X=x_i,Y=y_j)=p_{ij}\\quad,i=1,2,\\cdots,n;j=1,2,\\cdots,m$ 随机变量$X$的熵： H(X)=-\\sum_{i=1}^np_i\\log p_i熵表达了随机变量$X$的不确定性 由于只依赖$X$的分布而与$X$的取值没关系，则也可表示为$H(p)=-\\sum_{i=1}^np_i\\log p_i$ (对于$X=0,1$的熵表达式可以写为$H(p)=-p\\log_2p-(1-p)\\log_2(1-p)$) 给定$X$下随机变量$Y$的条件熵即为条件概率分布的熵$H(Y|X=x_i)$对$X$分布的数学期望（给每个$X_i$下的熵加了一个权值）： H(Y|X)=\\sum_{i=1}^nP(X=x_i)H(Y|X=x_i)条件熵表达了在已知条件$X$下随机变量$Y$的不确定性 信息增益(Information Gain)信息增益(Information Gain)：表示如果得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度 对于决策树，特征$A$对训练数据集$D$的信息增益$g(D,A)$为： g(D,A)=H(D)-H(D|A)$H(D)$为数据集的经验熵，$H(D|A)$为条件经验熵（$H(Y)-H(Y|X)$叫互信息，与决策树中的信息增益等价） 很明显可以理解，某特征的信息增益越大，该特征分类能力越强（因为IG越大，就代表我能够因此获得的确定性越多，也就是分类越好） 信息增益比(Information Gain Ratio)信息增益比(Information Gain Ratio)： g_R(D,A)=\\frac{g(D,A)}{H_A(D)}\\quad，H_A(D)=-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\log_2\\frac{|D_i|}{|D|}其中$n$为特征$A$的取值个数，$H_A(D)$为训练数据集$D$关于特征$A$的值的熵（$\\frac{1}{H_A(D)}$是一个惩罚系数，将特征$A$的取值作为随机变量，求的是特征$A$的熵，具体见下面-理解） 信息增益存在偏向选择取值较多的特征的问题，于是信息增益比可以对这一问题进行校正。 对于实际训练集：如果由数据估得则为经验熵，经验条件熵。那么设定$D$为数据集，$C_k$是类别为第$k$的样本集（真实标签），总共有$K$个类别；根据特征$A$可以将数据集划分为$n$个子集。$D_1,D_2,\\cdots,D_n$（根据特征判断的标签），第$i$个子集即为$D_i$，$D_{ik}$表示$D_{i}$中同属于类$C_k$样本集的样本即$D_{ik}=D_i∩C_k$（也就是该类别中标签打对了的样本），则： H(D)=-\\sum_{i=1}^K\\frac{|C_k|}{|D|}\\log_2\\frac{|C_k|}{|D|} H(D|A)=\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)=-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{i=1}^K\\frac{|D_{ik}|}{|D_i|}\\log_2\\frac{|D_{ik}|}{|D_i|}代入信息增益即可求得特征$A$对数据集$D$的信息增益 理解这里的$H(D)$表达了数据集整体的不确定性，随机变量为$p(第i类的样本集)$； 条件熵中求的依然是数据集的熵，只是先让特征$A$进行了划分，而不是特征的熵。我们在求被$A$划分成的第$i$个$H(D_i)$的时候，$H(D_i)=-\\sum_{i=1}^K\\frac{|D_{ik}|}{|D_i|}\\log_2\\frac{|D_{ik}|}{|D_i|}$。注意$H(D_i)$的随机变量是被$A$划分之后的条件下（这里就是条件熵多的东西）第$i$个数据集中属于$k$类的概率。 条件熵$H(D|A)$即表达了在用特征$A$对$D$进行划分为$D_1,D_2,\\cdots,D_n$，所有$D_i$的不确定性之和，即每个被$A$划分为$D_i$后的熵的和。然后再在求和的时候乘了一个权值——$A$取该第$i$个划分的概率（也就是期望，此即条件熵）。 不确定性即为我们对数据分类的预测的不确定性 $P(A取第i个取值)=\\frac{|D_i|}{|D|}$ 特征的熵$H_A(D)$：特征$A$的取值作为随机变量。通过数据集中被$A$打为第$i$个标签的数量与总数量的比即可求得特征$A$打第$i$个标签的概率，因此可以求得特征$A$的熵；见上面的IGR的惩罚系数 注意在计算每个子数据集$D_i$的经验熵时，随机变量为$D_i$中$D_{ik}$的概率，即$D_i$中属于$k$类（真实标签）的样本的概率。凡是求数据集的熵，随机变量必然都是该数据里某类（真实标签）的概率。 基尼指数(Gini)对于IGR，当特征取值较少时$H_A(D)$的值较小，因此其倒数较大，因而信息增益比较大。因而偏向取值较少的特征。 于是引入基尼指数。 分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为： Gini(p)=\\sum_{k=1}^Kp_k(1-p_k)=1-\\sum_{k=1}^Kp_k^2对于二分类问题，则为$Gini(p)=2p(1-p)$ 于是对于样本集合： Gini(D)=1-\\sum_{k=1}^K(\\frac{|C_k|}{|D|})^2基尼指数$Gini(D)$表示集合$D$的不确定性 若$D$被特征划分$D_1,D_2$，则在特征$A$的集合下，集合$D$的基尼指数定义为： Gini(D,A)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)式子中如$\\frac{|D_i|}{|D|}$与上面一样，也就是划分为$D_1$的概率（特征$A$取值为第一个的概率）。 $Gini(D,A)$表示经$A=a$划分后集合$D$的不确定性。基尼指数越大，样本集合的不确定性也越大，与熵一致。 决策树的生成以下ID3和C4.5都是生成多叉树，且只适用分类问题 ID3算法在决策树各个结点上用信息增益来选择特征 设置一个阈值$\\epsilon$，当$D_i$的IG小于该阈值的时候，表示该数据集可认为全是同一类别，无需再继续划分 只用于分类（离散数据） 举例： 有$K$个特征 ①对$D$，求$g(D,A_1),g(D,A_2),\\cdots,g(D,A_K)$ ②于是可以求得使得IG：$g(D,A_k)$最大的特征$A_{g_1}$ ③使用$A_g$将$D$划分为$D_1,D_2,\\cdots,D_n$；（假设$A_g$有$n$个取值） 已经确定特征$A_g$，则特征集$A\\to A-A_g$，特征数量变为$K-1$ ④对每一个$D_i$，求$g(D_i,A_1),g(D_i,A_2),\\cdots,g(D_i,A_{K-1})$ ⑤求使得IG最大的$A_{g_2}$ ⑤若此时$A_{g_2}＜\\epsilon$ ，则表示$D_i$可认为全是同一类别，无需再继续划分，该结点为叶子结点； 否则：再继续对$D_i$进行划分，上一个特征节点$A_g$为中间结点 再对每个划分的划分 ，求使得对应IG最大的$A_{g_k}$，判断继续划分or停止… ⑥依次类推$\\cdots\\cdots$ 其中第④步就是返回到了第①步，$D换成了D_i$。（不过注意这里默认$D$并不是同一类，默认要继续划分） 具体略 C4.5算法在决策树各个结点上用信息增益比来选择特征 设置一个阈值，当IGR小于该阈值的时候，算法停止 具体略 （连续属性值算法见后记-2） 以上两种算法容易过拟合，所以要剪枝 决策树的剪枝决策树的剪枝是从全局角度减小决策树复杂度以防止过拟合 通过极小化DT整体的损失函数来实现 设：树$T$，叶结点个数$|T|$，$t$为某叶结点，该叶结点上有$N_t$个样本点，其中$k$类样本点有$N_{tk}$个，$k=1,2,\\cdots,K$，$H_t(T)$为叶结点$t$上的经验熵，$\\alpha≥0$为参数。 DT学习的损失函数： C_\\alpha(T)=\\sum_{t=1}^{|T|}N_tH_t(T)+\\alpha|T|\\quad\\quad H_t(T)=-\\sum_k\\frac{N_{tk}}{N_t}\\log \\frac{N_{tk}}{N_t} 记C_\\alpha(T)右端第一项为：C(T)=\\sum_{t=1}^{|T|}N_tH_t(T)=-\\sum_{t=1}^{|T|}\\sum_{k=1}^KN_{tk}\\log \\frac{N_{tk}}{N_t} 则有简记：C_\\alpha(T)=C(T)+\\alpha|T|$C(T)$就是计算出每个叶子结点的已分类数据集的熵之和，熵越小，则DT整体的不确定性程度越低，就代表分类越确定。此项越小，就代表模型与训练集的拟合程度越高。 $|T|$是叶子结点的个数，它就能表征DT模型的复杂度。此项越小，模型的复杂度就越低，就越不容易过拟合。 于是$\\alpha≥0$就控制了两者之间的关系；如当$\\alpha=0$，就代表模型只考虑拟合度不考虑复杂度，etc。该损失函数就相当于一个正则化的极大似然估计 含有这两者的损失函数就代表了拟合度和复杂度的一个平衡关系。可以看到决策树的生成是学习局部模型的，但决策树的剪枝是学习整体的模型。该 剪枝算法的目的，就是在给定$\\alpha$下，求出使得损失函数$C_\\alpha(T)$最小的子树$T’$ 剪枝算法：（在用前面的算法生成完决策树之后） ①计算每个结点的经验熵 ②递归地从树的叶结点$t_{|T|}$向上回缩直到根节点$T$。具体地， 对于该叶结点，如果将其回缩到其父节点之后： ——如果树整体的损失函数变小，则回缩该结点； ——否则，不回缩该结点。 ③以此迭代 由于回缩计算差值的时候，树上只有局部有改变，所以在计算损失函数差值的时候只需要在局部进行 CART算法CART: classification and regression tree 分类与回归树。CART既可以用于分类也可以用于回归。 生成CART算法生成的是二叉决策树。（二叉决策树不是哈夫曼树形式，别搞错了） 思想：使用启发式算法，不断地寻找最优特征和最优切割点$(j,s)$，对数据集进行二元切分。 多值/多段回归特征很明显可以重复使用，一次无法将多值的某特征从数据集分离开（二值特征使用一次就不能再使用）（多段回归特征类似于分类中的多值特征，只不过预测的连续变量可以被划分为多个段） 分类： （使用基尼指数来衡量最优特征和最优切分点，基尼指数越小，不确定越低，每个样本分类越相同） 通过对数据集$D_m$求$D_m$对每个特征$A_i$的基尼系数：即遍历$i,k$，求使得$Gini(D,A_i=k)$最小的最优特征和最优特征的切分点$(j,s)$组合（对应于遍历组合的标号$i,k$）。求出一个$D_m$的$(j,s)$就能将其划分为两个子数据集。再对两个子数据集重复迭代上述过程，若结点中的样本个数小于预订阈值/样本集的基尼指数低于预定阈值（样本基本属于同一类）/没有更多特征，该结点就是叶子结点。 具体算法略 回归：【重要，是Boosting中许多模型的基础】 CART回归树生成是先确定结构（划分），再确定回归值(CART分类树就只有前面那个步骤)，以此到Boosting（GDBT XGBoost)也是这个求法 在回归问题中，模型输出一个连续变量。 $D=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$，数据集被划分为了$M$个单元$R_1,R_2,\\cdots,R_M$，在每个单元上有一个固定的输出值为$c_m$ 在回归中用平方误差来替代分类中的基尼指数：使用该结点数据集的每个样本中的【每个真实输出$y_i$与模型输出$f(x_i)$的均值$c_m$】的平方误差$\\sum_{x_i}(y_i-c_m)^2$来找最优特征和最优切分点$(j,s)$。平方误差越小，样本分类越准确。（这个是回归与分类不同的关键）【平方误差即是这里CART使用的损失函数，也可以用其它损失函数，比如Boosting里的损失函数就都不一样】 与分类中一样的思路： ①根据损失函数选定最优特征和切割第$j$个特征和其取值$s$为切分点，将父节点数据集$R$切分成了两个子节点（子数据集）： $R_1(j,s)=\\{x|x^{(j)}≤s\\}$，$R_2(j,s)=\\{x|x^{(j)}＞s\\}$ 以$R_1$为例，$\\{x|x^{(j)}≤s\\}$是指数据集中第$j$个特征的取值$≤s$的样本组成的新数据集，也就是一个划分，$R_2$同理。 这里就确定了决策树的结构，于是： ②根据损失函数选取最优回归输出值 这里损失函数为平方误差，对其就0导容易推得最优回归输出$c$就是划分上的均值 设$c_m=ave(y_i|x∈R_m)=\\frac{1}{N_m}\\sum_{x_i∈R_m(j,s)}y_i$，表示被特征与切分组合$(j,s)$切分后数据集上模型输出$y$的均值，则这个$c_m$就是该节点的最优回归输出 于是我们想要求得能够使得平方误差最小的特征与划分选取组合$(j,s)$以及其对应的最优输出（均值$\\hat c_m$）： \\min_{j,s}[\\min_{c_1}\\sum_{x_i∈R_1(j,s)}(y_i-c_1)^2+\\min_{c_2}\\sum_{x_i∈R_2(j,s)}(y_i-c_2)^2]于是再对两个被划分的子节点重复上面的步骤，直到满足停止条件 这样生成的树叫最小二乘回归树 理解： ①【选特征与切割】：求得$(j,s)$就告诉我们决策树怎么生成，选什么特征怎么切分（同分类），遍历选择$j,s$选最优划分。即【确定了决策树的结构】【这时候计算损失就是根据左\\右划分（结点）的[所有点各自的真实输出]与切割点（一个回归输出值）之间的损失之和，来选取使共损失最小的特征与切割。】 ②【决定回归输出】：每确定一个最优结点划分（即确定一组$(j,s)$），就能根据损失函数求出该结点内的最优输出：在各自每一个划分（结点）内选择一个最优的输出（即计算结点内的各点真实输出到选择的输出回归值的损失之和），使得该划分每个样本的损失最小。 由于这里用的损失函数是平方误差，可以求得其最优值就是样本均值，对应特征$j$在划分数据集上的均值$\\hat c_{1}$（特征值$≤s$的子结点）和$\\hat c_2$（特征值$＞s$的子节点），所以这个均值就是特征值$j$的回归输出。 【注意①和②在求最优切割和最优均值中求的损失都是用的[同一个损失函数计算]！看这个公式说得很明白，理解透这个公式】 对于使用一般损失函数的形式： \\min_{j,s}[\\min_{c_1}\\sum_{x_i∈R_1(j,s)}L(y_i,c_1)+\\min_{c_2}\\sum_{x_i∈R_2(j,s)}L(y_i,c_2)] （连续属性值算法见后记-2） （注意，如果每个训练样本是一维的，就不需要选切分特征（切分变量）了，回归和分类都是。如$x∈[0.5,10.5]$，在实数轴上，特征维度为1） 剪枝思想：尝试所有的$\\alpha$对树进行剪枝，找出最佳子树 过程： 迭代$\\alpha$，剪枝，求每个$\\alpha$下的最小子树 ①对一棵树$T$，令$\\alpha$从0从小到大开始进行一次迭代。 对一个$\\alpha$，对从下到上对每一个结点$t$，以$t$为单结点（即$t$以下的树结点全部剪掉）的损失函数为： $C_\\alpha(t)=C(t)+\\alpha|t|=C(t)+\\alpha$ 以$t$为根节点（即不剪枝）的树$T_t$的损失函数为：$C_\\alpha(T_t)=C(T_t)+\\alpha|T_t|$ 当$C_\\alpha(T_t)=C_\\alpha(t)$的时候，联立以上两式得：$\\alpha^o=\\frac{C(t)-C(T_t)}{|T_t|-1}$，这个式子即表示剪枝与不剪枝损失函数相等的时候$\\alpha$的值$\\alpha^o$，我们把它用$g(t)$表示。 根据上述式子推可得，$\\alpha$越大，那么不剪枝的整体损失函数就会大于剪枝的整体损失函数（因为$C_\\alpha(T_t)$的$\\alpha$项后面跟着$|T_t|≥1$)，那么就该剪（因为目的是最小化损失函数），反之就不该剪。于是$g(t)$就可以作为一个用来判断对于一个结点$t$，给定$\\alpha$下该不该剪枝的阈值。 于是对于本次迭代的$\\alpha$下，计算树$T$中每个结点$t$的剪枝判断阈值$g(t)$值： g(t)=\\frac{C(t)-C(T_t)}{|T_t|-1}于是从下往上对树中的每个结点$t$作阈值判断：如果$\\alpha≥g(t)，剪；\\alpha＜g(t)，不剪$ ②继续增大$\\alpha$，选择下一个$\\alpha$重复上述过程 ③迭代结束，得到一个子树序列：$\\{T_0,T_1,\\cdots,T_n\\}$，每个子树对应于不同的$\\alpha$值，每个子树都是对应$\\alpha$值的最小子树 对获取的最小子树序列进行选择最优$\\alpha$和最优子树 利用独立验证数据集测试各子树的平方误差或基尼指数，求得最优解 比较ID3/C4.5和CART来理解 划分 在ID3和C4.5中，通过IG或IGR求出最优特征之后，直接将特征的所有可能取值作为切分点，那么就成了多分类。那么ID3/C4.5生成的是一个多叉树 而CART要求出最优特征和最优切分点的组合，以将该特征下的取值切分成二类。CART生成一个二叉树。 举例：特征为年龄，取值为青年、中年、老年，那么ID3/C4.5就可能分成$O\\{青年\\}\\{中年\\}\\{老年\\}$，CART就可能分为$O\\{青年\\}\\{中年、老年\\}$ （$O$代表父节点，$\\{\\}代表子节点集合$） 特征变量的使用 特征变量的使用中，多分的分类变量ID3和C4.5层级之间只单次使用，CART可多次重复使用 举例：继续上面的例子，在ID3/C4.5中，该特征（年龄）被一次划分为三个子数据集$\\{青年\\}\\{中年\\}\\{老年\\}$，于是该特征被删除特征集，不再使用。继续迭代就在其它特征中来选择最优特征 而在CART中，两个子节点为$O\\{青年\\}\\{中年、老年\\}$，对于这两个子节点进行迭代的时候，由于特征（年龄）并没有将所有年龄特征分开，则还可以再使用用过的特征（年龄）来继续二分类！（假设在右节点使用年龄的基尼系数相比其他特征和划分最低的话，那么下次就再使用年龄特征，只有二分类所以直接划分为$\\{中年\\}\\{老年\\}$）不过再次使用该特征并不一定是接着使用，这需要根据基尼指数最小/平方误差最小计算。 也因此CART一般比ID3/C4.5深 输入与输出 ID3和C4.5只能做分类，CART可以做回归和分类 ID3只能作用离散值属性，C4.5和CART可以作用连续值属性 注意区别见后记-3 计算代价 CART计算更快，消耗资源更少，因为CART不需要进行熵中的log运算（基尼指数和熵效果差不多，但没用log，这就是用基尼指数的原因） 缺失值 ID3对缺失值敏感，而C4.5和CART对缺失值可以进行多种方式的处理 O 剪枝方法不同 C4.5是通过枝剪来修正树的准确性，而CART是直接利用全部数据发现所有树的结构进行对比 C4.5是ID3的优化 IGR替代了IG 因为信息增益的缺点是倾向于选择取值较多的屬性，在有些情况下这类属性可能不会提供太多有价值的信息。 样本量 只从样本量考虑，小样本建议考虑c4.5、大样本建议考虑cart。而cart本身是一种大样本的统计方法，小样本处理下泛化误差较大 后记 缺失值处理 ①抛弃缺失值 ②补充缺失值 ③概率化缺失值（C4.5使用此方式， 对缺失值的样本赋予该属性所有属性值的概率分布） ④缺失值单独分支 属性为连续值的划分问题 离散化技术 C4.5用于连续值属性的算法：（于是就成了二叉树了） 采用离散化技术（如二分法）进行处理。将属性值从小到大排序，然后选择中间值作为分割点，数值比它小的点被划分到左子树，数值不小于它的点被分到又子树，对所有可能的分割法，计算分割的信息增益率，选择信息增益率IGR最大的属性值进行分割。 CART的连续值属性的算法：只是把IGR换成了基尼指数或平方误差，其它一样 【注意】回归预测与连续值属性的区别 回归预测指输出（预测）的是一个连续变量的值，比如要求输出概率（又比如说要预测房价） 属性为连续值指的是输入的属性是连续的，即取值无限，如输入的$x是实数$，那就得用离散化方法，C4.5采用了二分，即把$x是实数\\to \\{x&lt;A_i\\},\\{x≥A_i\\}$两个结点。（或者如输入的值是房价） 属性就是特征，属性的值即特征的取值 CART回归树的例可以见Boosting的GDBT后记 寻找最优切分和特征一般都是贪心算法，只考虑当前结点下的最优特征和最优分割 决策树以及基于Boosting的算法的优点 ①天然对缺失值和噪音有很好的鲁棒性 ②天然可以很好的处理各种类型的特征 ③天然对离群值有很好的鲁棒性 ④（对Boosting DT）数据规模影响不大，因为我们对弱分类器的要求不高 但也有缺点，就在于假设无噪音的情况下，性能不如SVM，LR等，但如果数据集有噪音的话，这个弱势就不能么明显了。而且，可以用Boosting嘛，一个DT不给力，多个DT一起干，效果就更强","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"非线性支持向量机与序列最小最优化算法","slug":"人工智能/非线性支持向量机","date":"2019-11-12T06:18:03.000Z","updated":"2019-11-13T06:32:11.000Z","comments":true,"path":"人工智能/非线性支持向量机/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/","excerpt":"（只突出与线性SVM不同的地方，具体的推导大部分过程相似见前面的讲线性SVM的文章） 线性（可分）SVM的分类平面是线性的，这就无法对如椭圆形特征空间进行分类，于是我们想到将原来特征空间$\\mathbb X$（欧式空间$\\mathbb R^n$或离散集合）上的非线性问题（超曲面模型），映射到新的高维特征空间$\\mathbb H$（希尔伯特空间）成为线性可分（超平面模型）问题，这样我们就可以对新的线性可分的特征空间使用线性支持向量机的学习算法来解决非线性支持向量机的学习问题。（核技巧思想一）","text":"（只突出与线性SVM不同的地方，具体的推导大部分过程相似见前面的讲线性SVM的文章） 线性（可分）SVM的分类平面是线性的，这就无法对如椭圆形特征空间进行分类，于是我们想到将原来特征空间$\\mathbb X$（欧式空间$\\mathbb R^n$或离散集合）上的非线性问题（超曲面模型），映射到新的高维特征空间$\\mathbb H$（希尔伯特空间）成为线性可分（超平面模型）问题，这样我们就可以对新的线性可分的特征空间使用线性支持向量机的学习算法来解决非线性支持向量机的学习问题。（核技巧思想一） 核技巧kernel trick 运用核技巧思想一，会发现如果我们想要直接计算映射，会非常困难。于是我们选择计算内积（将输入空间中的内积转换为输出空间的内积），恰好在使用SVM学习算法的时候，无论是目标函数还是决策函数都只涉及输入实例与实例之间的内积，于是有以下方法—— 在学习和预测中只定义核函数$K(x,z)$，而不显式定义映射函数$\\phi$。因为通常直接计算核函数$K(x,z)$比较容易，而直接计算映射$\\phi(x)和\\phi(z)$并不容易。 观察到线性SVM的对偶问题中，无论是目标函数还是决策函数都只涉及输入实例与实例之间的内积，于是在对偶问题的目标函数中的内积$x_i·x_j$可以用核函数$K(x_i,x_j)=\\phi(x_i)·\\phi(x_j)$来代替。此时： 对偶问题目标函数：\\min_\\alpha\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^N\\alpha_i 最后的分类决策函数也修改：f(x)=sign(\\sum_{i=1}^N\\alpha_i^oy_iK(x_i,x_j)+b^o)然后就只需要按照原来的线性可分SVM的学习算法，求对偶问题的外部问题，即求极值下的最优参数$\\alpha^o$（可用SMO），然后再用KKT或等价求得$w^o,b^o$，得到超平面表达式 这等价于经过映射函数$\\phi$将原来的输入空间变换到一个新的特征空间，将输入空间中的内积$x_i·x_j$变换为特征空间中的内积$\\phi(x_i)·\\phi(x_j)$ 总结一下，核方法做了两件事：①样本空间映射到特征空间②计算了两样本在特征空间的内积（核技巧） 核技巧并不是SVM专用，可以用在其它地方 寻找核函数-正定核函数$F(x,z)$满足什么条件才能成为核函数？也就是说对于映射函数$\\phi$，直接计算$F(x,z)$即可而不用计算$\\phi(x),\\phi(z)$的条件是什么？ 这种核函数一般都是正定核，直接给出结论： 正定核的充要条件：设$K:\\mathbb X×\\mathbb X\\to \\mathbb R$是对称函数，则$K(x,z)$为正定核函数的充要条件是对任意$x_i∈\\mathbb X,i=1,2,\\cdots,m,K(x,z)$对应的Gram矩阵： K=[K(x_i,x_j)]_{m×m}是半正定矩阵（见后记-1） 正定核的等价定义：设$\\mathbb X \\subset \\mathbb R^n,K(x,z)$是定义在$\\mathbb X×\\mathbb X$上的对称函数，如果对任意 $x_i∈\\mathbb X,i=1,2,\\cdots,m,K(x,z)$对应的Gram矩阵： K=[K(x_i,x_j)]_{m×m}是半正定矩阵，则称$K(x,z)$是正定核 推导和证明略（先定义映射，构造向量空间；再构造内积空间；再完备化为希尔伯特空间；再在此之上证明） 这一定义在构造核函数的时候很有用，但要验证某函数是否为正定核函数是不容易的，因为要对所有输入集验证$K$对应的Gram矩阵是否为半正定矩阵。所以在实际问题中一般使用已有的核函数，见下 常用核函数 多项式核函数 K(x,z)=(x·z+1)^p 高斯核函数 K(x,z)=e^{-\\frac{||x-z||^2}{2\\sigma^2}} 字符串核函数 O $k_n(s,t)$给出字符串$s$和$t$中长度为$n$的所有子串组成的特征向量的余弦相似度。两个字符串相似的字串越多，它们就越相似，字符串核函数的值就越大。 非线性支持向量机算法第一部分即讲了与线性支持向量机算法的区别，用核函数替换内积即可，其它一样，略 序列最小最优化算法sequential minimal optimization，SMO 思想：不断地将原多变量的二次规划问题分解为只有两个变量的二次规划子问题，并对子问题进行解析求解，直到所有变量满足KKT条件为止（因为KKT条件是下面要求的最优化问题的充分必要条件） 目的：SMO算法主要是为了求解SVM中对偶问题的外部问题： 目标函数：\\min_\\alpha\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^N\\alpha_i s.t.\\quad \\sum_{i=1}^N\\alpha_iy_i=0 0≤\\alpha_i≤C\\quad,i=1,2,\\cdots,N其中$\\alpha=(\\alpha_1,\\alpha_2,\\cdots,\\alpha_N)^T$，那么如何才能求得一个$\\alpha_i$序列（也即向量$\\alpha$）使得该问题为最优解呢？也即如何使得序列最小最优化。 SMO是一个启发式算法，通过循环迭代的方式求得序列最优最小值。SMO输出的是一个近似解。 算法： 知乎上看到一个讲得很好的，直接贴上来 两个二次规划变量的求解： https://zhuanlan.zhihu.com/p/78599113 将其中一个作为变量来求解 求解过程中设定的记号$v,g(x_i),E,\\eta$都是为了方便表示求解过程，实际上求解思路就是 ①将目标函数改写为记号表示形式（这里很复杂），$x_i,x_j分别为\\alpha_1,\\alpha_2$ ②根据约束条件表示出$\\alpha_1$，代入目标函数中，于是目标函数就只含$\\alpha_1$变量 ③对目标函数用对$\\alpha_2$的0导数法，求得最优的$\\alpha_2$表示 ④上面求出的是未经剪辑的最优解，下一步求出经过剪辑的最优解即可 注意：$k=\\alpha_1^{old}-\\alpha_2^{old}，k=\\alpha_1^{old}+\\alpha_2^{old}$这个表示方法理解 变量的选择： https://zhuanlan.zhihu.com/p/78788836 ①选取第一个变量$\\alpha_1$的过程称为外层循环，选取违反KKT条件最严重的点 ②选取第二个变量$\\alpha_2$的过程称为内层循环，选取能使$\\alpha_2$变化足够大的点（加快计算速度，使得目标函数尽快变小。根据公式$\\alpha_2$依赖于$y_2(E_1-E_2)$，由于$\\alpha_1$已定，那么$E_1$就定了，那么就可以选择合适的$\\alpha_2$） 如果第二个$\\alpha_2$不能够使得目标函数有足够的下降，那就遍历数据集选取$\\alpha_2$，如果遍历完了还没找到，那就通过外层循环重新寻找另外的$\\alpha_1$ 先选择变量，然后计算最优解，然后就要更新阈值$b$和差值$E_i$ 总结： 先选择两个变量，再求解析解，直到达到停机条件（检验是否所有样本点都符合KKT条件，在精度$\\epsilon$下进行） 具体略 后记 正定矩阵和半正定矩阵 半正定矩阵：$A∈\\mathbb R^{n×n},x∈\\mathbb R^n$，对任意$x$，$x^TAx≥0$恒成立 正定矩阵：$A∈\\mathbb R^{n×n},x∈\\mathbb R^n$，对任意$x$，$x^TAx＞0$恒成立","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"矩阵论","slug":"矩阵论","permalink":"https://aisaka.cloud/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"},{"name":"SVM","slug":"SVM","permalink":"https://aisaka.cloud/tags/SVM/"}]},{"title":"Unity2D基础","slug":"开发/Unity2D基础","date":"2019-11-10T03:42:45.000Z","updated":"2019-11-11T02:14:56.000Z","comments":true,"path":"开发/Unity2D基础/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/Unity2D%E5%9F%BA%E7%A1%80/","excerpt":"施工中 如行走，跌倒等动画是绘图之后创建unity2d动画素材，导入后进行裁剪和选取动画导入的 给实体分组归类是好习惯，在Hierarchy建立一个新的empty game object：create object，然后将组件拖入即可","text":"施工中 如行走，跌倒等动画是绘图之后创建unity2d动画素材，导入后进行裁剪和选取动画导入的 给实体分组归类是好习惯，在Hierarchy建立一个新的empty game object：create object，然后将组件拖入即可 重力与碰撞给物体添加重力组件：Add Component-Rigidbody 2D 但是拥有重力的物体会一直往下坠，所以我们要给地面和物体都添加一个碰撞（各种组件都需要碰撞体） 给物体添加Box碰撞组件：Add Component-Box Collider 2D，然后点击Edit Collider，拖动绿色长方形来选取碰撞体积。碰撞体有很多种类型，这里只是Box类型 速度想给主角添加一个运动速度，通过脚本实现。 创建脚本：Add Component-new script 右键edit script，打开IDE编写脚本（写C#我用的VS） 打开后会发现已经是： using System.Collections; using System.Collections.Generic; using UnityEngine; public class aisaka : MonoBehaviour &#123; &#x2F;&#x2F; Start is called before the first frame update void Start() &#123; &#125; &#x2F;&#x2F; Update is called once per frame void Update() &#123; &#125; &#125; 其中void Update()方法是不停地执行的方法，Start()方法仅在实例化完成后调用一次 我们为其加入速度，写如下代码： GetCompoment &lt;T&gt;()从当前游戏对象获取组件T（返回该组件），只在当前游戏对象中获取，没得到的就返回null，不会去子物体中去寻找。 GetCompomentInChildren&lt;T&gt;()先从本对象中找，有就返回，没就子物体中找，知道找完为止。 GetComponents&lt;T&gt;()获取本游戏对象的所有T组件，不会去子物体中找。 GetComponentsInChildren&lt;T&gt;()=GetComponentsInChildren&lt;T&gt;(true)取本游戏对象及子物体的所有组件 GetComponentsInChildren&lt;T&gt;(false)取本游戏对象及子物体的所有组件 除开非活跃的游戏对象，不是该组件是否活跃。 注意当前游戏对象指的是这个脚本的对象，比如这里就是获取该脚本对象（主角）的Rigidbody2D组件 坑如果IDE无法联想Unity组件和函数，有两种可能（可能都存在） ①需要在Unity中，Edit-Preferences-External Tools中在External Script Editor里选择对应的IDE ②VS报错OmniSharp failed 版本兼容问题 神奇的Unity使用心得unity下载就个残废，那个hub这么烂还好意思摆出来，明明有本体直接下载放到一个巨巨巨巨巨小的地方非要宣传一个破烂hub；中国官网一万年备案中，国外官网打开就是一片空白，速度慢得堪比IE；程序退出经常未响应；老版本Unity就直接和VS新版本不兼容了；装了新版本之后竟然老版本清除不干净，快捷方式打不开新版；然后装了新版本老版本的project打不开了，提示我得同时存在老版本才能打开，然后又没法从程序里调用VS了。。。什么破软件我吃你萌，贵司程序员全体去吃屎！！！！","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"},{"name":"Unity","slug":"开发/Unity","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/Unity/"}],"tags":[]},{"title":"夢に僕らで帆を張って　来るべき日のために夜を越え","slug":"Anime/天气之子2","date":"2019-11-09T16:59:52.000Z","updated":"2019-11-09T17:02:28.000Z","comments":true,"path":"Anime/天气之子2/","link":"","permalink":"https://aisaka.cloud/Anime/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%902/","excerpt":"","text":"当大地渐渐失去了重力，在千年一遇的今天 乘着花火的声音，我们离开这颗星球吧 在他睁开眼的那一瞬间，向着那无法返回的地方 齐声喊着「1、2...」跳出大地，向着其他行星前进 ........ 出发吧！ 出发吧！ 出发吧！ 为了那个梦我们扬帆起航、为了理应到来的那天跨越无尽黑夜","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"线性（可分）支持向量机","slug":"人工智能/支持向量机（一）","date":"2019-11-07T00:38:10.000Z","updated":"2019-11-12T08:14:03.000Z","comments":true,"path":"人工智能/支持向量机（一）/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"Support Vector Machines支持向量机，SVM SVM应用于二分类问题。 输入空间和特征空间为两个不同的空间。输入空间为欧式空间或离散集合，特征空间为欧式空间或希尔伯特空间。 线性可分SVM和线性SVM在两个空间的元素一一对应，非线性SVM是非线性映射。","text":"Support Vector Machines支持向量机，SVM SVM应用于二分类问题。 输入空间和特征空间为两个不同的空间。输入空间为欧式空间或离散集合，特征空间为欧式空间或希尔伯特空间。 线性可分SVM和线性SVM在两个空间的元素一一对应，非线性SVM是非线性映射。 本篇中的SVM都指线性可分SVM，其它SVM可能会有一些变化 线性可分支持向量机假定训练集线性可分。 数据集：假定特征空间上的训练集$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$，其中 $x_i∈\\mathbb R^n,y_i∈\\{+1,-1\\},i=1,2,\\cdots,N$，$x_i$为第$i$个特征向量，$y_i$为类标记。当$y_i=+1$，称$x_i$为正例；当当$y_i=-1$，称$x_i$为负例。$(x_i,y_i)$称为样本点。 具体举例：如正例点$x_i=(3,5),y_1=+1$，$(3,5)$存在于欧式空间而$(x_1,+1)$存在于特征空间。 学习目标：在特征空间上找到一个分离超平面，能将实例分到不同的类。分离超平面对应于方程$w·x+b=0$，由法向量$w$和截距$b$决定，可以用$(w,b)$表示。其将特征空间划分为两部分：法向量指向的一侧为正类，另一侧为负类。 理解这个超平面：$w·x+b=0$中$w,x,b$都是向量，向量中每一个位置都是一个特征维度，可以理解为这个超平面有很多个维度，在每一个维度都有一个分界线，从而整体构成一个高维度的超级分界面。 这个超平面就是分类器 显然这种超平面是有无穷个的。对于感知机，则是使用误分类最小策略来求得超平面；对于线性可分SVM，则使用间隔最大化来求得最优超平面，解是唯一的。 线性可分支持向量机：给定线性可分训练数据集，通过间隔最大化等价地求解相应的凸二次规划问题学习得到的分离超平面为（学习得到的最优参数就是$w^o,b^o$） w^o·x+b^o=0对应的分类决策函数为： f(x)=sign(w^o·x+b^o)也就是： f(x)=\\begin{cases} +1,w^o·x+b^o≥0\\\\ -1,w^o·x+b^o＜0 \\end{cases}称为线性可分支持向量机。注意其中的决策函数只有两种取值：$+1,-1$，对应了决策函数通过$f(x)=sign(w^o·x_i+b^o)$来判断点$x_i$是正例还是负例。$sign$是符号函数。 确信度：一个点如果距离超平面越远，那么表示其预测的确信度越高，反之反之。假设一个样本点越正向远离分界面，那么我们越认为其为正例的概率越大，方向远离分界面那么负例的概率越大。 点$x$距离超平面的距离 $=|w·x+b|$ $w·x_i+b$的符号若与训练样本$x_i$的标签$y_i$一致，则分类正确；不一致则分类错误。 从逻辑斯谛回归LR来理解SVMLR的输出是一个概率输出，LR实际上就是将通过线性分类器$w·x+b,x∈\\mathbb R^n$将输入$x$映射到概率空间$(0,1)$上，其越靠近上边界$1$，就认为其标签为$1$的概率越高；其越靠近下边界$0$，就认为其标签为$0$的概率越高，这时候我们可以给一个决策标准$th=0.5$，对于一个样本$x_i$和逻辑斯谛回归分类器$f(w·x+b)$（也可以表示为$P(Y=1|x)$)，此时对$x_i$的决策结果就是$f(x_i)=\\begin{cases} 1,f(w·x_i+b)≥0.5\\\\ 0,f(w·x_i+b)＜0.5 \\end{cases}$ 如果我们将LR中的决策标准的阈值改为$0$，分类器改为$f(w·x+b)=w·x+b$，标签从$0,1$改为$-1,+1$，此时对$x_i$的分类结果就是：$f(x)=\\begin{cases} +1,w·x_i+b≥0\\\\ -1,w·x_i+b＜0 \\end{cases}$。震惊，这不就是个标准的SVM了吗！ ①LR中的$0$相当于SVM的负例，$1$相当于SVM的正例； ②LR中的阈值$0.5$，而SVM的阈值为$0$，即在SVM中，分类器的输出$≥0$，就判断为正例，$＜0$就判断为负例；分类器输出越大则样本为正例的概率越大（确信度越高），输出越小则样本为负例的概率越大（确信度越高）。（SVM分类器输出的绝对值乘以标签($+1 or-1$)：$y_i|w·x_i+b|$即为函数间隔） ③LR的分类器输出在$(0,1)$上，且决策阈值为$0.5$；而SVM的分类器输出可以在$(-∞,+∞)$，决策阈值为$0$。为什么分类器输出差别这么大？因为LR的输出值是线性分类器$w·x+b$的逻辑斯谛分布作为映射，就是它将输出映射到了$(0,1)$上，其恰好就是概率。而线性SVM的分类器就直接是一个线性函数映射，它的输出映射到了整个实域 结论：LR和SVM本质是一样的。借LR可以更好地理解SVM（这段写得有点啰嗦）。 间隔表示前面引出了间隔，这里具体定义。对于样本点$(x_i,y_i)∈T$到超平面$(w,b)$。 某点到超平面面的函数间隔： \\hat\\gamma_i=y_i(w·x_i+b)样本集$T$所有点到面的函数间隔：这就是前面所说的我们最想要的最优超平面的标准（见上）： \\hat\\gamma=\\min_{i=1,\\cdots,N}\\hat\\gamma_i如果$w,b$成比例改变，那么实际上超平面$\\lambda w·x_i+\\lambda b=0=w·x_i+b=0$并没有变，但是函数间隔却番倍了，所以我们要统一让超平面的参数标准化，使得该间隔确定。所以标准化后，得： 某点到超平面面的几何间隔：（其实就是欧式空间中的点到平面的距离公式再加个正负来判断分类正确性） \\gamma_i=y_i(\\frac{w}{||w||}·x_i+\\frac{b}{||w||})样本集$T$所有点到面的几何间隔： \\gamma=\\min_{i=1,\\cdots,N}\\gamma_i函数间隔和几何间隔的特点：同时表示了分类的「正确性」和「确信度」（确信度见上文理解，正确性是因为如果分类错误，那么算出来的间隔会是负；分类正确才会得出正值，根据式子容易看出来） 函数间隔无论如何改变，几何间隔都是不变的。表征特征空间上的关系的是几何间隔。（也就是SVM最常见的那个图） 显然有函数间隔$\\hat \\gamma$与几何间隔$\\gamma$的关系：$\\gamma_i=\\frac{\\hat \\gamma_i}{||w||},\\gamma=\\frac{\\hat \\gamma}{||w||}$ （$||w||$为向量$w$的第二范数，即$||w||=\\sqrt{w_1^2+w_2^2+\\cdots+w_n^2} $），后面取其平方以去掉根号方便计算） 硬间隔最大化学习SVM的过程就是学习最优超平面的过程，也就是确定超平面$w·x+b$的参数$w,b$ 什么是我们想要的最优的超平面（分类器）：「尽可能提高最难以分类的点的分类确信度」。 从几何角度解释：使得离超平面最近的样本点到超平面的距离最大的超平面，「也就是说要尽量扩大超平面与离超平面最近点的间隔」。这就是间隔最大化 间隔最大化可以表述为：（推导起点，从最大化几何间隔开始） \\max_{w,b}\\gamma s.t.\\quad y_i(\\frac{w}{||w||}·x_i+\\frac{b}{||w||})≥\\gamma,i=1,2,\\cdots,N即：尽量提高几何间隔的下限 需求解使得目标函数最优的参数$w,b$ 为了由$\\gamma_i=\\frac{\\hat \\gamma_i}{||w||},\\gamma=\\frac{\\hat \\gamma}{||w||}$，可把问题改写（但实际还是几何间隔）为用函数间隔表示为： $\\max_{w,b}\\frac{\\hat\\gamma}{||w||}$ $s.t.\\quad y_i(w·x_i+b)≥\\hat\\gamma,i=1,2,\\cdots,N$ 前面说过，函数间隔不会影响解的结果，也就是将$w,b$按比例改变，函数间隔虽然变了，但超平面是没变的。 于是，我们想到直接将函数间隔人为设定为1，就相当于让$w,b$以一个比例缩放，使得函数间隔$\\hat\\gamma=1$，这个乘上的比例因子是多少我们不需要求它，因为即使$w,b$以一个未知的比例等比缩放了，求得的超平面还是一样的，约束优化问题还是等价的，（此时几何间隔为$\\gamma=\\frac{1}{||w||}$），也就是将问题等价简化为： $\\max_{w,b}\\frac{1}{||w||}$ $s.t.\\quad y_i(w·x_i+b)≥1,i=1,2,\\cdots,N$ 显然$\\max_{w,b}\\frac{1}{||w||}$等价于$\\min_{w,b}\\frac{1}{2}||w||^2$，则原问题改写为一个易于求解的凸二次规划问题： \\min_{w,b}\\frac{1}{2}||w||^2 s.t.\\quad y_i(w·x_i+b)-1≥0,i=1,2,\\cdots,N求得该凸二次规划问题即可得到最优解$w^o,b^o$。注意这里是不等式约束问题，而前面比如在MEM中的是等式约束问题。 由此得到分离超平面$w^o·x+b^o=0$，分类决策函数$f(x)=sign(w^o·x+b^o)$ 这个求解过程就是线性可分SVM的学习算法：最大间隔法(maximum margin method) 线性可分SVM的最大间隔分离超平面存在且唯一（证略） 支持向量(support vector)：训练数据集中的样本点与分离超平面距离最近的样本点的实例 支持向量点$(x_i,y_i)$是使得约束条件取等号：$y_i(w·x_i+b)-1=0$的点 对于正例：$y_i=+1,支持向量在超平面\\quad w·x+b=1$上； 对于负例：$y_i=-1,支持向量在超平面\\quad w·x+b=-1$上 支持向量到超平面的距离就是几何间隔$\\gamma=\\frac{\\hat \\gamma}{||w||}$，由于设定了$\\hat \\gamma=1$，则$\\gamma=\\frac{1}{||w||}$ 两个超平面的距离称为间隔(margin)。$\\therefore 间隔 =\\frac{2}{||w||}$，两个超平面称为间隔边界。 支持向量在确定分离超平面上取决定性作用，SVM实际上是由很少的重要的训练样本——支持向量所确定的，所以才得名支持向量机(Support Vector Machines) 通过拉格朗日对偶性求解硬间隔最大化也叫线性可分SVM的对偶算法(dual alogorithm)。这样做①对偶问题往往更容易求解②自然引入核函数，可以进而推广到非线性SVM 见前面拉格朗日乘子与对偶性专题，这里就不详细解释了。 对于上一节的凸二次规划问题，首先引入拉格朗日函数(这里$w,b$是我们的目标变量，相当于标准形式中的$x$) 这里是减去拉格朗日乘子项（加乘子项也可以，但推理表示会麻烦一些，所以记得用减乘子项！） L(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^N\\alpha_i[y_i(w·x_i+b)-1]注意这里设置减去算子项，是为了后面用KKT条件的时候，构造出$\\alpha_i≥0$（不等式约束的乘子$\\alpha$要规定$\\alpha≥0$，是为了满足后文KKT的对偶可行条件） 根据拉格朗日对偶性，KKT条件是凸问题的充要条件，转换为等价对偶问题： \\min_{w,b}\\frac{1}{2}||w||^2=L(w,b,\\alpha)=\\min_{w,\\beta}\\max_\\alpha L(w,b,\\alpha)=\\max_\\alpha \\min_{w,\\beta}L(w,b,\\alpha)于是求内部问题$\\min_{w,\\beta}L(w,b,\\alpha)$： 对两个独立变量的子式使用零导数法： $\\nabla_w L(w,b,\\alpha)=w-\\sum_{i=1}^N\\alpha_iy_ix_i=0$（注意第二范数求导：见后记2） $\\nabla_b L(w,b,\\alpha)=-\\sum_{i=1}^N\\alpha_iy_i=0$ $\\therefore w=\\sum_{i=1}^N\\alpha_iy_ix_i$ $\\sum_{i=1}^N\\alpha_iy_i=0$（不能丢，作为对偶问题的约束条件！除非是像第一个能够将原式所有的$w$全部替换的形式，这样该约束条件实质就已经被完全包含在代入后的式子中而失效了，才可以丢） 回代$L(w,b,\\alpha)$得： $L(w,b,\\alpha)=\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i·x_j)-\\sum_{i=1}^N\\alpha_iy_i((\\sum_{j=1}^N\\alpha_jy_jx_j)·x_i+b)+\\sum_{i=1}^N\\alpha_i$ $=-\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i·x_j)+\\sum_{i=1}^N\\alpha_i$ 这里注意①2-范数运算，见后记3 ②无关求和代入的时候，求和符号的迭代变量要换一个以免重合 内部问题求解出来了，于是问题等价为外部问题，求： $\\max_\\alpha-\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i·x_j)+\\sum_{i=1}^N\\alpha_i$ $s.t.\\quad \\quad\\sum_{i=1}^N\\alpha_iy_i=0,\\quad \\alpha_i≥0,\\quad i=1,2,\\cdots,N$ 转化为易求的$\\min$形式，此为求解算法的第一步公式： \\min_\\alpha\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i·x_j)-\\sum_{i=1}^N\\alpha_i s.t.\\quad \\quad\\sum_{i=1}^N\\alpha_iy_i=0,\\quad \\alpha_i≥0,\\quad i=1,2,\\cdots,N于是这里就用通用的算法来求解此二次规划问题(用SMO求解，见后面的专题) 假设已经求出对偶最优化的最优解为$\\alpha^o$，于是可以求得原始最优化对$(w,b)$的解：$w^o,b^o$ KKT条件是凸问题的充要条件，则原始问题与对偶问题完全等价，$w^o,b^o$就是最优解（前面已经说明过等价，这里再强调一下） 于是可以得到：（可以由等价关系得：拉格朗日表达式对$w$求导得到见上求对偶问题最小化的时候，就已经求出来了内部极值$w^o,b^o$与$\\alpha$的关系表达式；也可以由对偶问题的KKT的$w$梯度条件： $\\nabla_wL(w^o,\\beta^o,\\alpha^o)=0$得到）（顺便后记-6附上了这里的所有KKT条件表达式）： w^o=\\sum_{i=1}^N\\alpha_i^oy_ix_i对于$\\alpha_i≥0$，至少存在一个$\\alpha_j＞0$（反证法，若全$=0$，则回代上面公式得$w=0$，非解，矛盾；另外该乘子对应的样本点就是支持向量） 将此$\\alpha_j$代入$y_j(w^o·x_j+b^o)-1=0$中，又由于$y_j^2=1$，$y_i$取值只有$1或-1$，则： b^o=y_j-\\sum_{i=1}^N\\alpha_i^oy_i(x_i·x_j)根据前面原始问题中超平面的定义，将两个参数代入超平面公式和决策函数公式即可， 最优超平面：w^ox+b^o=0\\quad,最优决策函数：f(x)=sign(w^ox+b^o) \\therefore 于是分离超平面可以写成:\\quad\\sum_{i=1}^N\\alpha_i^oy_i(x·x_i)+b^o=0（称作可分支持SVM的对偶形式） 分类决策函数:\\quad f(x)=sign(\\sum_{i=1}^N\\alpha_i^oy_i(x·x_i)+b^o)支持向量的导出：将训练数据集中对应于$\\alpha^o_i＞0$的样本点$(x_i,y_i)$的实例$x_i∈\\mathbb R^n$称为支持向量 （容易知道，因为仅对$\\alpha_i^o＞0$的实例有$y_i(w^o·x_i+b^o)-1=0$，则该点$x_i$一定在间隔边界上） 可以看到： ①分类决策函数只依赖于输入$x$和训练样本中的支持向量的内积。 ②训练的时候，$b^o,w^o$的取值只与$\\alpha_i^o＞0$的样本$x_i$有关，也就是只和支持向量有关。 这与前面定义的概念相符 线性可分SVM学习算法总结由上可得，线性可分支持向量机学习算法：略（整理整理就是了） 线性支持向量机我们引入松弛变量$\\epsilon_i≥0$，使得$y_i(w·x_i+b)+\\epsilon_i≥1$，也即$y_i(w·x_i+b)≥1-\\epsilon_i$ 同时目标函数变为$\\frac{1}{2}||w||^2+C\\sum_{i=1}^N\\epsilon_i$（引入目的是使得对每个松弛变量$\\epsilon_i$都支付一个代价$\\epsilon_i$，代价也可以设定为$\\epsilon^2$等） $C&gt;0$是惩罚参数，值越大则对误分类的惩罚越大，反之反之 $C$是需要自己设定的 问题变成了软间隔最大化： \\min_{w,b,\\epsilon}\\frac{1}{2}||w||^2+C\\sum_{i=1}^N\\epsilon_i s.t.\\quad y_i(w·x_i+b)≥1-\\epsilon_i\\quad,i=1,2,\\cdots,N \\epsilon_i≥0\\quad,i=1,2,\\cdots,N需求解使得目标函数最优的参数$w,b,\\epsilon$ 此目标函数即包含了①前项表使得间隔尽量小②后项表使得误分类点尽量少，$C$即是二者的调和系数 注意用拉格朗日乘子法依然是减去乘子项，依然注意求得的对偶问题约束条件 对于求得的对偶约束条件被用来消去之后，$C-\\alpha_i-\\mu_i=0,\\alpha_i≥0,\\mu_i≥0$会被合写为$0≤\\alpha_i≤C$，且可以证得不能取等号，即为：$0＜\\alpha_i＜C$ 最后推得的结果会发现，与线性可分SVM的区别在于约束条件多了一个限制：$0＜\\alpha_i＜C,i=1,2,\\cdots,N$，在计算$w^o$的时候，选取的$\\alpha^o_j$需要考虑此条件（也就是说不符合此条件的$\\alpha^o_j$对应的$x_j$会被忽略掉，或者说不拿来训练模型。这些点就是不可分点、误分类点、非支持向量点。我们可以类比线性可分SVM，在线性可分SVM中计算$w$时候，选$\\alpha_j$的约束条件为$\\alpha^o_j＞0$，也就是说只获取支持向量（事实上此约束不成立的点即$\\alpha^o_j=0$，回代$w$即发现$x_j$与原式无关，自然也就等同于“选择$\\alpha^o_j＞0$”，但在线性SVM的约束$0＜\\alpha_i＜C,i=1,2,\\cdots,N$中，就真的是要选择了）） 具体来说：对于实例$x_i$到间隔边界的距离为$\\frac{\\epsilon_i}{||w||}$。 若$\\alpha^o_i＜C$，则$\\epsilon_i=0$，支持向量$x_i$恰好落在间隔边界上； 若$\\alpha^o_i=C,0＜\\epsilon_i＜1$，则分类正确，$x_i$在间隔边界与分离超平面之间； 若$\\alpha^o_i=C,\\epsilon_i=1$，则$x_i$在分离超平面上；若$\\alpha^o_i=C,\\epsilon_i＞1$，则$x_i$位于分离超平面误分类一侧。 $b$的解可能不是唯一的（但一般实践只会出现一种情况） 整体推导方法和线性可分SVM差不多，这里略 合页损失函数是线性SVM的另一种结束，这里略 后记 凸二次规划问题 \\min_w f(w) s.t. \\quad g_i(w)≤0\\quad,i=1,2,\\cdots,k s.t. \\quad h_i(w)=0\\quad,i=1,2,\\cdots,l 其中目标函数$f(w)$和约束函数$g_i(w)$都是$\\mathbb R^n$上的连续可微凸函数，约束函数$h_i(w)$是$\\mathbb R^n$上的仿射函数。 在此之上，当目标函数$f(w)$是二次函数且约束函数$g_i(w)$是仿射函数时，上述凸最优化问题转化为凸二次规划问题。 凸二次规划问题满足拉格朗日对偶性中的Slater条件和KKT条件 2-范数求导 $\\frac{\\partial\\frac{1}{2}||w||^2}{\\partial w}=\\frac{\\frac{1}{2} \\partial(\\sqrt{w_1^2+w_2^2+\\cdots+w_n^2})^2}{\\partial (w_1,w_2,\\cdots,w_n)}=\\frac{\\frac{1}{2} \\partial (w_1^2+w_2^2+\\cdots+w_n^2)}{\\partial (w_1,w_2,\\cdots,w_n)}$ $=(\\frac{\\frac{1}{2} \\partial w_1^2}{\\partial (w_1,w_2,\\cdots,w_n)},\\frac{\\frac{1}{2} \\partial w_2^2}{\\partial (w_1,w_2,\\cdots,w_n)},\\cdots,\\frac{\\frac{1}{2} \\partial w_n^2}{\\partial (w_1,w_2,\\cdots,w_n)})$ 对于每个子分子中的求导变量$w_i$，分母中只有$w_i$为对应维度的变量，所以是对每个维度分别求导 $\\therefore 原式 = (w_1,w_2,\\cdots,w_n)=w$ 范数计算 $x$是向量，$x$的2-范数：$||x||=||x·x^T||$ $\\therefore ||w||^2=w^Tw$ $\\therefore ||\\sum_{i=1}^N\\alpha_iy_ix_i||=(\\sum_{i=1}^N\\alpha_iy_ix_i)·(\\sum_{j=1}^N\\alpha_jy_jx_j)^T=\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i·x_j)$ 和式就两两交叉相点乘 这个式子中只有$x$是向量，$\\alpha,y$都视为$x$向量的系数 注意求和函数的作用域，如果作用域内还有迭代变量，不能直接局部求和 $w·x=w^Tx$ 上面学习算法中对偶问题的KKT表达式 $\\nabla_w(w^o,b^o,\\alpha^o)=w^o-\\sum_{i=1}^N\\alpha_i^oy_ix_i=0$ $\\nabla_b(w^o,b^o,\\alpha^o)=-\\sum_{i=1}^N\\alpha_i^oy_i=0$ $\\alpha_i^o(y_i(w^o·x_i+b^o)-1)=0\\quad,i=1,2,\\cdots,N$ $y_i(w^o·x_i+b^o)-1≥0\\quad,i=1,2,\\cdots,N$ $\\alpha_i^o≥0\\quad,i=1,2,\\cdots,N$","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"SVM","slug":"SVM","permalink":"https://aisaka.cloud/tags/SVM/"},{"name":"凸优化","slug":"凸优化","permalink":"https://aisaka.cloud/tags/%E5%87%B8%E4%BC%98%E5%8C%96/"}]},{"title":"逻辑斯谛回归模型","slug":"人工智能/逻辑斯谛回归模型","date":"2019-11-06T01:10:12.000Z","updated":"2020-03-08T16:16:00.000Z","comments":true,"path":"人工智能/逻辑斯谛回归模型/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/","excerpt":"Binomial Logistic Regression ModelLR是最基本的模型之一。 二项逻辑斯谛回归模型 P(Y=1|x)=\\frac{e^{wx+b}}{1+e^{wx+b}} P(Y=0|x)=\\frac{1}{1+e^{wx+b}}$x∈\\mathbb R^n$为输入，$Y∈\\{0,1\\}$为输出，$w∈\\mathbb R^n$和$b∈R$是参数，$w$为权值，$b$为偏置，$wx$是$w·x$的简写，为内积","text":"Binomial Logistic Regression ModelLR是最基本的模型之一。 二项逻辑斯谛回归模型 P(Y=1|x)=\\frac{e^{wx+b}}{1+e^{wx+b}} P(Y=0|x)=\\frac{1}{1+e^{wx+b}}$x∈\\mathbb R^n$为输入，$Y∈\\{0,1\\}$为输出，$w∈\\mathbb R^n$和$b∈R$是参数，$w$为权值，$b$为偏置，$wx$是$w·x$的简写，为内积 $P(Y=0|x)=1-P(Y=1|x)$ 简写：有时候可以把$b$包含进$w$里，$wx+b$写成$wx$，此时： $w=(w^{(1)},w^{(2)},\\cdots,w^{(n)},b)^T$，$x=(x^{(1)},x^{(2)},\\cdots,x^{(n)},1)$ P(Y=1|x)=\\frac{e^{wx}}{1+e^{wx}},P(Y=0|x)=\\frac{1}{1+e^{wx}}对数几率：$\\log(p=1)=\\log\\frac{p}{1-p}=\\log\\frac{P(Y=1|x)}{1-P(Y=1|x)}=wx$（内积 $w·x$） 也就是说：输出$Y=1$的对数几率是输入$x$的线性函数，或者说输出$Y=1$的对数几率是由输入$x$的线性函数表示的模型，也就是逻辑斯谛回归模型。所以说LR模型是一个线性对数模型（MEM也是个对数线性模型） 理解：$wx$为一个对$x$进行分类的线性函数（线性分类器），使用LR的定义将其转化为了一个概率： $P(Y=1|x)=\\frac{e^{wx}}{1+e^{wx}}$。线性函数的值越接近于正无穷，概率值越接近于1；其值越小，概率值越趋近于0。 更本质地理解：其实逻辑斯谛模型就是$P(Y=1|x)=g(wx)$，相当于将线性分类器$wx,x∈\\mathbb R^n$映射到了概率区间$(0,1)$上，即$g(wx)∈(0,1)$。见S形曲线。 LR分布与LRM曲线，略 逻辑斯谛分布的分布函数属于逻辑斯谛函数，逻辑斯谛回归模型$P(Y=1|x)$函数也属于逻辑斯谛函数。 逻辑斯谛函数都呈S形曲线 对于决策：分类器输出的是概率，那么给定阈值如$th=0.5$，则$x_i$的输出标签为： $f(x_i)=\\begin{cases} 1,f(wx)≥0.5\\\\ 0,f(wx)＜0.5 \\end{cases}$ 学习算法：参数估计对给定训练集：$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\},x_i∈\\mathbb R^n,y_i∈\\{0,1\\}$ 设$P(Y=1|x)=\\pi(x)$，则$P(Y=0|x)=1-\\pi(x)$ $y_i$表示第$i$项的输出 注意这里如何构造MLE式子表示： LR的构造MLE表示的想法和MEM一样，都是想构造指数函数来表示多分类的多项之积，但具体的构造方式「完全不同」 l(\\theta)=\\prod_{i=1}^N[\\pi(x_i)]^{y_i}[1-\\pi(x_i)]^{1-y_i} MLE：\\arg\\max_\\theta l(\\theta)【其中，$\\pi(x_i)$即为预测标签（模型输出），$y_i$即为对应的真实标签】 【这个式子将多分类的多项之积的MLE写成一个式子，当$y_i=1$时，只有$[\\pi(x_i)]^{y_i}$会生效，$[1-\\pi(x_i)]^{1-y_i}$由于指数部分为0使得该子项等于1；反之$y_i=0$时，只有后半部分会生效。】 【于是当比如真实标签$y_i=1$时，左边部分生效，那么$\\pi(x_i)$的输出越小，即输出概率越偏离真实值，MLE整体就越小，而我们就是要在整体样本之上极大化MLE，也就是尽量让输出概率整体接近真实值，得到整体最优解，此即MLE的意义】 于是其对数似然函数为$L(w)=\\log MLE_{P(y|x)}$，即： L(w)=\\sum_{i=1}^N[y_i\\log \\pi(x_i)+(1-y_i)\\log(1-\\pi(x_i))]化简之：$=\\sum_{i=1}^N[y_i\\log \\pi(x_i)+\\log(1-\\pi(x_i))-y_i\\log(1-\\pi(x_i))]$ $=\\sum_{i=1}^N[y_i\\log\\frac{\\pi(x_i)}{1-\\pi(x_i)}+\\log(1-\\pi(x_i))]$ 所以可得 L(w)=\\sum_{i=1}^N[y_i(w·x)-\\log(1+e^{w·x})]以此对数似然函数为极大化目标求出$w$即为模型参数 MLR的相反数其等价于ERM方法的损失函数（$m$为mini-batch size）： J(w)=-\\frac{1}{m}L(w)但往往直接求0导得极值无法做到，因为参数众多无法求解，于是常用牛顿拟牛顿法，梯度下降法解决 以梯度下降法为例，对损失函数用参数$w$求偏导：$\\nabla_wL(w)$，然后在各个$w_i$的方向上梯度下降，这里写总式：$w\\to w+\\epsilon\\nabla_wL(w)$ 多项逻辑斯谛回归$Y$的取值集合为$\\{1,2,\\cdots,K\\}$ P(Y=k|x)=\\frac{e^{w_kx}}{1+\\sum_{k=1}^{K-1}e^{w_kx}},k=1,2,\\cdots,K-1 P(Y=K|x)=\\frac{1}{1+\\sum_{k=1}^{K-1}e^{w_kx}}$x∈\\mathbb R^{n+1},w_k∈\\mathbb R^{n+1}$ 这里的MLE构造就可以用和MEM一样的构造方法来构造了","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"拉格朗日乘子与对偶性","slug":"人工智能/拉格朗日对偶性","date":"2019-11-05T09:27:53.000Z","updated":"2019-11-11T11:52:47.000Z","comments":true,"path":"人工智能/拉格朗日对偶性/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/","excerpt":"Intro假设$f(x),c_i(x),h_j(x)$是定义在$\\mathbb R^n$上的连续可微函数。考虑约束最优化问题 \\min_{x∈\\mathbb R^n}f(x) s.t.\\quad c_i(x)≤0,i=1,2,\\cdots,k s.t.\\quad h_j(x)=0,j=1,2,\\cdots,l称此约束最优化问题为原始最优化问题或原始问题","text":"Intro假设$f(x),c_i(x),h_j(x)$是定义在$\\mathbb R^n$上的连续可微函数。考虑约束最优化问题 \\min_{x∈\\mathbb R^n}f(x) s.t.\\quad c_i(x)≤0,i=1,2,\\cdots,k s.t.\\quad h_j(x)=0,j=1,2,\\cdots,l称此约束最优化问题为原始最优化问题或原始问题 拉格朗日乘子法对于原始问题，要求解就用拉格朗日乘子法： $L(x,\\alpha,\\beta)=f(x)+\\sum_{i=1}^k\\alpha_ic_i(x)+\\sum_{j=1}^l\\beta_jh_j(x)$ 这里$x=(x^{(1)},x^{(2)},\\cdots,x^{(n)})^T∈\\mathbb R^n\\quad\\alpha_i≥0,\\beta_j$是拉格朗日乘子。（不等式约束的乘子$\\alpha$要规定$\\alpha≥0$，是为了满足后文KKT的对偶可行条件） 「拉格朗日乘子法将有约束问题转化为了无约束问题」 那么我们就要对$L(x,\\alpha,\\beta)$求极值。这个式子$x,\\alpha,\\beta$都是变量，也就是说我们要求出多元变量式子的极值。 有的情况可以求出极值（给了足够多个方程可以解出算子，如HMM的EM中包含一个隐藏方程可以解出算子），但有的就无法直接求了。于是我们想要分离$x$和算子，于是我们将表达式改写为广义拉格朗日极小极大。 同时由于$\\nabla_xL(x,\\alpha,\\beta)=\\nabla_xf(x)$，所以这么转换是等价的，但$\\nabla_\\alpha L(x,\\alpha,\\beta)=0,则c(x)=0$，显然约束条件不等价，改写成了广义拉格朗日极小极大才使得式子和原式完全等价。 广义拉格朗日极小极大形式尝试构造这个最大化 $\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)=\\max\\{f(x)+\\sum_{i=1}^k\\alpha_ic_i(x)+\\sum_{j=1}^l\\beta_jh_j(x)\\}$ 会发现一个特点： 如果原始问题的约束条件$c_i(x)≤0,h_j(x)=0$不成立，也就是说$c_i(x)≥0,h_j(x)≠0$，那为了让$L$最大，$\\alpha_i$就会取$+∞$，$\\beta_j$就会取$-sign(h_j(x))·∞$，这时候$\\max_{\\alpha,\\beta:\\alpha≥0}=+∞$ 显然这是不可以的。 只有当约束条件$c_i(x)≤0,h_j(x)=0$成立的时候，才不会出现这种情况。因为这种情况下为了让$L$最大，$\\alpha_i$就会取$0$，同时$h_j(x)=0$ 所以当约束条件成立的时候，可以得到这个等式：$\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)=f(x)$ 也就是说，Intro中的那串定义，包含约束条件的$f(x)$可以由一个式子表示：$\\max_{\\alpha,\\beta:\\alpha_i≥0} L(x,\\alpha,\\beta)$，成功地将算子和$x$分离开来，同时与原式完全等价。里面求使$L$最大化的算子，外面求使$L$最小化的$x$。 于是我们要求约束$c_i(x)≤0,h_j(x)=0$下的最优化问题$\\min_x f(x)$，即是要求$\\min_x\\max_{\\alpha,\\beta:\\alpha_i≥0} L(x,\\alpha,\\beta)$ 这就是广义拉格朗日极小极大问题： 原始问题等价于\\min_x\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)设$d^o=\\arg \\min_x\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)$ 「为什么要转化为极小极大形式：使得与原式完全等价，且对所有情况都可以求解。如果直接求拉格朗日乘子式的极值，在乘子多于已知方程的情况下无法求解」 对偶问题原始问题的广义拉格朗日极小极大问题$\\min_x\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)$的对偶问题为： \\max_{\\alpha,\\beta:\\alpha≥0} \\min_x L(x,\\alpha,\\beta)设$p^o=\\max_{\\alpha,\\beta:\\alpha≥0} \\min_x L(x,\\alpha,\\beta)$ 「为什么要有对偶问题：对偶问题都是凸优化问题，而凸优化问题局部极值=全局极值而且更好求解。」 （在ML中的凸优化是指函数呈U型！） 举例：在MEM中的含等式约束问题，就是先求里面的极小化问题以$x$为变量求出最小的$P_w$，然后回代，只需要再求出能使$P_w$极大化的$w$即可，外部极大化$P_w$可证等于MLE，具体的方法，如IIS，牛顿法与伪牛顿法，梯度下降。 弱对偶性定理$1^o$：若原始问题和对偶问题都有最优值，则： 对偶问题≤原始问题（或其广义拉格朗日极小极大问题） p^o=\\max_{\\alpha,\\beta:\\alpha≥0} \\min_x L(x,\\alpha,\\beta)≤\\arg \\min_x\\max_{\\alpha,\\beta:\\alpha≥0} L(x,\\alpha,\\beta)=d^o很容易理解，因为$L$中最小的一个的最大值肯定比最大的一个的最小值要小。此式即为弱对偶性。 此式就可以求出原始问题的下限。 何时相等（①强对偶性②是最优解）？即何时「解原始问题最优化=解对偶问题最优化」所以需要KKT定理，下面一步一步引出： 推论$1^o$： 设$x^o$和$\\alpha^o,\\beta^o$分别是原始问题和对偶问题的可行解，并且$d^o=p^o$，则$x^o$是原始问题的最优解，$\\alpha^o,\\beta^o$是对偶问题的最优解。 注意解是$\\alpha,\\beta,x$，值是式子的值$p^o,d^o$ 翻译：如果原始问题的值和对偶问题的值相等，那么两个问题对应的参数是最优解 强对偶性（还不等价）-Slater条件定理$2^o$：考虑原始问题和对偶问题，假设函数$f(x)$和$c_i(x)$是凸函数（凸优化问题），$h_j(x)$是仿射函数；并且假设不等式约束$c_i(x)$是严格可行的，即存在$x$，对所有$i$有$c_i(x)&lt;0$，则存在$x^o$和$\\alpha^o,\\beta^o$，使$x^o$是原始问题的解，$\\alpha^o,\\beta^o$是对偶问题的解，并且有$p^o=d^o=L(x^o,\\alpha^o,\\beta^o)$。此即Slater条件。 翻译：在某些条件下，存在解（不一定是最优解）且使得原始问题=对偶问题，即强对偶性成立： 原始问题等价于\\max_{\\alpha,\\beta:\\alpha≥0} \\min_x L(x,\\alpha,\\beta)「也就是说只要满足目标函数和不等式约束为凸函数+等式约束为仿射函数，那么强对偶性就成立」 注意：强对偶性存在的参数解可能有很多个（鞍点），并不能保证是极值点（最优解）！ 于是下面KKT条件便是确保鞍点便是原函数最优解的充分条件 强对偶性+是最优解=完全等价-KKT条件一个问题是不等式约束/等式问题，它的最优解就一定满足KKT条件。（必要条件，非充分；但如果是凸函数约束优化（强对偶成立），就变成了充分必要条件） 定理$3^o$：在定理2的条件的基础上，$x^o,α^o,β^o$分别是原始问题和对偶问题的解（是最优解，且强对偶）的充分必要条件是$x^o,α^o,β^o$满足下面的KKT(Karush-Kuhn-Tucker)条件： 定理$3^o$：在定理2的条件的基础上，$x^o,\\alpha^o,\\beta^o$分别是原始问题和对偶问题的解的充分必要条件是，$x^o,\\alpha^o,\\beta^o$ 满足下面的KKT(Karush-Kuhn-Tucker)条件： \\nabla_xL(x^o,\\alpha^o,\\beta^o)=0 \\quad① \\alpha^o_ic_i(x^o)=0,i=1,2,\\cdots,k\\quad② c_i(x^o)≤0,i=1,2,\\cdots,k\\quad③ \\alpha_i^o≥0,i=1,2,\\cdots,k\\quad④ h_j(x^o)=0,j=1,2,\\cdots,l\\quad⑤可以看出有几大类条件：①梯度为0条件；③⑤原约束条件（③是不等式约束，⑤是等式约束）；②对偶互补条件（ 互补松弛条件 ）；④ 对偶可行条件 （注意哪些是不等式约束条件，哪些是等式约束条件，不一样的） 第二个式子称为KKT的对偶互补条件，由此条件可知，若对偶可行条件成立：$\\alpha_i^o＞0,则c_i(x^o)=0$。 （这个性质导出了SVM中的支持向量） 任何满足强对偶性的优化问题，只要其目标函数与约束函数可微，任一对原始问题与对偶问题的解都是满足 KKT 条件的。 「KKT条件是凸问题的充分必要条件」（凸函数=&gt;KKT，KKT=&gt;凸函数） 这是个充分必要条件， 一般仅用KKT条件来「验证」找到的解是最优解 对于凸优化，由于与KKT条件是充要条件，那么就可以用KKT条件求出最优解，也可以用回代原始问题求最优解（因为等价） KKT的推导过程可以看 深入理解拉格朗日乘子法和KKT条件 关于零导数法求极值对于极值问题，使用零导数法。 假定求$\\min_{x,y,z}L(x,y,z),\\quad L(x,y,z)=f(x)+g(y)+q(z)$ 就可以对各个变量分别求偏导零导数： $\\nabla L(x,y,z)=0 \\to \\nabla_x f(x)=0,\\nabla_y g(y)=0,\\nabla_z q(z)=0 $ 但如果各个子式之间变量无法分离，如： $\\min_{x,y,z}L(x,y,z),\\quad L(x,y,z)=f(x,y)+g(y,z)+q(x,y,z)$ 那就得考虑如$\\nabla_{x,y}f(x,y)=0$同时满足$x,y$，需要用多元函数求极值的方法。 具体就是 ①解$\\nabla_{x}f(x,y)=0,\\nabla_{y}f(x,y)=0$，求出一切驻点。 ②对于每一个驻点$(x_0，y_0)$，求出二阶偏导数的值A、B、C ③定出$AC-B^2$的符号，按充分条件进行判定$f(x_0，y_0)$是否是极大值、极小值。 这只是二元不独立的情况，如果变量更多，是很难求甚至没法求的。所以这种情况下一般不用零导数法（比如IIS中就是因为这个原因要构造第二下界来求解） （另外也要根据函数本身判断）","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"最大熵模型（二）","slug":"人工智能/最大熵模型（二）","date":"2019-11-04T12:21:07.000Z","updated":"2019-11-11T08:36:07.000Z","comments":true,"path":"人工智能/最大熵模型（二）/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"最大熵模型求解$\\mathbb S1^o$拉格朗日乘子法与拉格朗日对偶性使用拉格朗日乘子法： $L(P,w)=-H(P)+w_0(1-\\sum_yP(y|x))+\\sum_{i=1}^nw_i(\\mathbb E_{\\hat P}(f_i)-\\mathbb E_{P}(f_i))$ $=\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y|x)+w_0(1-\\sum_yP(y|x))$ $+\\sum_{i=1}^nw_i(\\sum_{x,y}\\hat P(x,y)f_i(x,y)-\\sum_{x,y} \\hat P(x)P(y|x)f_i(x,y))$ 难以求极值，转化为广义拉格朗日极大极小问题，于是我们需要优化： \\min_{P∈\\mathbb C}\\max_wL(P,w)由于拉格朗日函数$L(P,w)$是$P$的凸函数，满足KKT条件，于是该优化问题等价于其对偶问题： \\max_w \\min_{P∈\\mathbb C}L(P,w)（更多阅读拉格朗日乘子和对偶性专题）","text":"最大熵模型求解$\\mathbb S1^o$拉格朗日乘子法与拉格朗日对偶性使用拉格朗日乘子法： $L(P,w)=-H(P)+w_0(1-\\sum_yP(y|x))+\\sum_{i=1}^nw_i(\\mathbb E_{\\hat P}(f_i)-\\mathbb E_{P}(f_i))$ $=\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y|x)+w_0(1-\\sum_yP(y|x))$ $+\\sum_{i=1}^nw_i(\\sum_{x,y}\\hat P(x,y)f_i(x,y)-\\sum_{x,y} \\hat P(x)P(y|x)f_i(x,y))$ 难以求极值，转化为广义拉格朗日极大极小问题，于是我们需要优化： \\min_{P∈\\mathbb C}\\max_wL(P,w)由于拉格朗日函数$L(P,w)$是$P$的凸函数，满足KKT条件，于是该优化问题等价于其对偶问题： \\max_w \\min_{P∈\\mathbb C}L(P,w)（更多阅读拉格朗日乘子和对偶性专题） $\\mathbb S2^o$内部求仅含$x$变量的0导数先解决内部的极小化问题。 由于$L(P,w)$是凸函数，那对其直接求0导数即可 记$\\Phi(w)=\\min_{P∈\\mathbb C}L(P,w)=L(P_w,w)$，$\\Phi(w)$称为对偶函数 则对偶函数的解$P_w=\\arg\\min_{P∈\\mathbb C}L(P,w)=P_w(y|x)$ ，即：求使得$L(P,w)$最小的$P(y|x)$ 于是使用0导数法： （易错。见HMM中求和函数求导） $\\frac{\\partial L(P,w)}{\\partial P(y|x)}=\\hat P(x)\\log P(y|x)+\\hat P(x)-w_0-\\hat P(x)\\sum_{i=1}^nw_if_i(x,y)=0$ 为了利用更多分布信息，左右两边同时求$\\sum_{x,y}$（就可以给$w_0$项再凑一个$\\hat P(x)$来消去所有的$\\hat P(x)$） $\\therefore \\sum_{x,y}\\hat P(x)\\log P(y|x)+\\sum_{x,y}\\hat P(x)-\\sum_{x,y}w_0-\\sum_{x,y}\\hat P(x)\\sum_{i=1}^nw_if_i(x,y)=0$ 由于$\\sum_{x,y}\\hat P(x)=1且w_0与x,y不相关$，$\\therefore \\sum_{x,y}w_0=w_0\\sum_{x,y}=w_0\\sum_{x,y}\\hat P(x)$ $\\therefore \\sum_{x,y}\\hat P(x)(\\log P(y|x)+1-w_0-\\sum_{i=1}^nw_if_i(x,y))=0$ 又经验分布$\\hat P(x)&gt;0$，那么该乘式必然右边部分$=0$ $\\therefore \\log P(y|x)+1-w_0-\\sum_{i=1}^nw_if_i(x,y)=0$ $\\therefore P(y|x)=e^{\\sum_{i=1}^nw_if_i(x,y)+w_0-1}=\\frac{e^{\\sum_{i=1}^nw_if_i(x,y)}}{e^{1-w_0}}$ $\\because \\sum_{y}P(y|x)=1$，所以为了归一化$P(y|x)$，引入归一化因子 $\\therefore P_w(y|x)=\\frac{1}{Z_w(x)}e^{\\sum_{i=1}^nw_if_i(x,y)}$，$Z_w(x)=\\sum_y e^{\\sum_{i=1}^nw_if_i(x,y)}$ （注意$Z_w(x)$式子中$y$被边缘化了，所以$Z_w(x)$只与$x$有关） 其中$Z_w$称为规范化因子，$f_i(x,y)$是特征函数，$w_i$是特征的权值。 $P_w=P_w(y|x)$就是最大熵模型，$w$是最大熵模型中的参数向量 $\\mathbb S3^o$外部恰好等价于求极大似然估计于是我们下一步要求的就是对偶问题外部极大化问题： \\max_w \\Phi(w) w^o=\\arg\\max_w\\Phi(w)（发现这个式子就可以用最优化算法来求了） 对偶函数的极大化等价于最大熵模型的极大似然估计：$\\Phi(w)=L_{\\hat P}(P_w)$ 证明：将$\\mathbb S2^o$中求出来的$P_w(y|x)$表达式代入$\\mathbb S2^o$中的$L(P,w)$，即为对偶函数，恰好等于$P_w(y|x)$的似然函数$L_{\\hat P}(P_w)$（见$\\mathbb S4^o$中）。 也就是说，我们对上面已经求得的内部最小化一般形式MEM：$P_w$，求出$w$使得$MLE_{P_w}$最大即可，也是MEM学习过程 可以将MEM表示为更一般的形式【重要】： P_w(y|x)=\\frac{1}{Z_w(x)}e^{\\sum_{i=1}^nw_if_i(x,y)} Z_w(x)=\\sum_y e^{\\sum_{i=1}^nw_if_i(x,y)}$x∈\\mathbb R^n$为输入，$y∈\\{1,2,\\cdots,K\\}$为输出，$w∈\\mathbb R^n$为权值向量，$f_i(x,y),i=1,2,\\cdots,n$为任意实值的特征函数 【MEM的学习目标就转为学$w$】 形象化地举例： 假如我们知道昨天天气是雨$x_1$，今天天气是雷暴$x_2$，那么想要预测明天天气$y$，就可以给出： $P(y|x_1,x_2,subject)=\\frac{e^{w_1(x_1,x_2,y)+w_2(subject,y)}}{Z(x_1,x_2,subject)}$ 这里$f_1(x_1,x_2,y),f_2(subject,y)$即为特征函数，即是约束条件，比如可以设定$f_1(x_1,x_2,y)=$三天都是坏天气（自己定义什么是坏天气）不同时发生，等等。$w_1,w_2$即为权重 确定参数$w$的过程就是训练模型的过程 于是我们开始求MLE表达式： 先求出$P_w$的对数似然估计函数： $L_{\\hat P}(P_w)=\\log\\prod_{i=1}^nP(y_i|x_i)=P(y_1|x_1)P(y_2|x_2)\\cdots P(y_n|x_n)$ 将相同的样本乘在一起。【注意这里构造MLE表达式】对相同的一组$x,y$，那么有$t$组指数就会为$t$，也就相当于乘了$t$次，这样对所有相同的$x,y$，都可以表示为$P(y|x)^{||(x,y)||_0}$，则对所有不同和相同的$x,y$，最终表示成了：$L_{\\hat P}(P_w)=\\log\\prod_{x,y}P(y|x)^{||(x,y)||_0}$ 极大化这个$L_{\\hat P}(P_w)$也等同于极大化（指数部分分母除以$N$）：$L_{\\hat P}(P_w)=\\log\\prod_{x,y}P(y|x)^{\\hat P(x,y)}$ 于是MLE可以表示为【重要】： L_{\\hat P}(P_w)=\\log\\prod_{x,y}P(y|x)^{\\hat P(x,y)}=\\sum_{x,y}\\hat P(x,y)\\log P(y|x)$\\therefore L_{\\hat P}(P_w)=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_{x,y}\\hat P(x,y)\\log Z_w(x)$ $=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x)-\\sum_{x}\\log Z_w(x)\\sum_y\\hat P(x,y)$ （拆离只含$x$变量的$Z_w(x)$） $=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x)-\\sum_{x}\\hat P(x)\\log Z_w(x)$ （$y$被边缘化） （注意这里MLE的化简！） 最终形式： L(w)=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x)-\\sum_{x}\\hat P(x)\\log Z_w(x)$\\mathbb S4^o$求解外部的极大似然估计MEM的学习目标就转为学$w$后，我们就求解其$MLE_w$即可 IIS，梯度下降，牛顿法或拟牛顿法都可以求解，可以看前面的文章 IIS： 展开似然函数表达形式：$L(w)=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_x\\hat P(x)\\log Z_w(x)$为目标函数 求$\\arg\\max_wL(w)$ 牛顿法： 展开似然函数表达形式：$L_1(w)=\\sum_x\\hat P(x)\\log \\sum_y e^{\\sum_{i=1}^nw_if_i(x,y)}-\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)$为目标函数 求$\\arg\\min_wL_1(w)$ 梯度下降法： 略 后记 回顾理解复合函数期望：$\\mathbb E_{g(x)}f(x)=\\int_x g(x)f(x)$ 若$f(x)$理解为关于$x$的概率分布，那么$g(x)$可以理解为$x$的权重 为什么要用对数的似然？——对数函数将乘法变为和 拉格朗日对偶性见专题 拉个朗日对偶性求解的外部$\\max_{w}$为什么不用零导数法？因为将内部求出的表达式代入回去之后发现无法分离出独立变量的子式，无法用零导法来求","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"天气之子","slug":"Anime/天气之子","date":"2019-11-03T12:06:34.000Z","updated":"2019-12-19T15:29:24.000Z","comments":true,"path":"Anime/天气之子/","link":"","permalink":"https://aisaka.cloud/Anime/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90/","excerpt":"Weathering With You 何もない僕たちに なぜ夢を見させたか 为何要让一无所有的我们怀揣梦想？ 終わりある人生に なぜ希望を持たせたか 为何要让我们对有尽头的人生抱有希望？ なぜこの手をすり抜ける ものばかり与えたか 为何赐予我们的一切只在手中一掠而过？ それでもなおしがみつく 僕らは醜いかい 即便如此还要紧紧抓住的我们 丑陋吗？ それとも、きれいかい 还是说 很美呢？","text":"Weathering With You 何もない僕たちに なぜ夢を見させたか 为何要让一无所有的我们怀揣梦想？ 終わりある人生に なぜ希望を持たせたか 为何要让我们对有尽头的人生抱有希望？ なぜこの手をすり抜ける ものばかり与えたか 为何赐予我们的一切只在手中一掠而过？ それでもなおしがみつく 僕らは醜いかい 即便如此还要紧紧抓住的我们 丑陋吗？ それとも、きれいかい 还是说 很美呢？ --- 《天气之子》真的是很不诚哥，结局真的很出乎意料，少了时间的错位所造成的悲剧感。 但这大概也是诚哥对自我的一个突破吧。","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"新海诚","slug":"新海诚","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E6%B5%B7%E8%AF%9A/"}]},{"title":"Utopia","slug":"随笔/Utopia","date":"2019-11-02T11:23:36.000Z","updated":"2019-12-05T02:08:41.000Z","comments":true,"path":"随笔/Utopia/","link":"","permalink":"https://aisaka.cloud/%E9%9A%8F%E7%AC%94/Utopia/","excerpt":"那是我第一次爬到教学楼的楼顶。平时挂在门上的锁不见了顶层储物间的门外即是天台。我坐在天台边双手向后撑在地面上仰着身子朝向碧青色的澄澈天空。","text":"那是我第一次爬到教学楼的楼顶。平时挂在门上的锁不见了顶层储物间的门外即是天台。我坐在天台边双手向后撑在地面上仰着身子朝向碧青色的澄澈天空。 轻轻嗅到的是夏日的清香视野所及是微风拂过的草原伸一伸手可以够得着天上粉色的云彩。我喜欢这里于是我每每下午放学后就来到这里。有时会有青鸟飞过停留在我的身边叽叽喳喳；有时会有松鼠露出头和我一样坐在天台边感受夏风的温凉。 我种下了星辰花她们渐渐地开满了整个天台他们成为了我的伙伴。有时会有阵雨掠过但他每次很快就离开。我张开内心的柔软，追忆过去描绘着门里面发生的故事倾诉理想和未来。那是这个世界唯一的乌托邦。 可是有一天门被锁上了。——原来是因为食堂的厨师想起很久以前落了汤勺在储物间回去拿的时候发现门没锁就顺带锁上了。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[]},{"title":"最大熵模型（一）","slug":"人工智能/最大熵模型","date":"2019-11-01T02:44:02.000Z","updated":"2019-11-05T12:22:46.000Z","comments":true,"path":"人工智能/最大熵模型/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/","excerpt":"Maximum Entropy Theory Intro最大熵原理：学习概率模型时，所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以最大熵原理也可以表述为在给定已知信息下，满足约束条件的模型集合中，选取熵最大的模型。 也就是说，在目前已观测到的所有信息下，最合理的对未知信息的预测就是对所有未知信息最不确定的推断（每种未知情况等可能）。$H(P)$表示$P$的不确定性，最不确定的情况=熵最大的情况=每种未知情况都等可能发生，这就给出了最好模型选择的准则 H(P)=-\\sum_xP(x)\\log P(x),其中0≤H(P)≤\\log|X|表示随机变量$X$的概率分布$P(X)$的熵，$|X|$表示$X$的取值个数。当且仅当$X$的分布是均匀分布时右边等号成立，这时候条件熵最大。即：在已知信息下，$P(X)$的熵最大 对于模型$P(X)$，能够最大化熵$H(P)$的模型$P(X)$即是最好的模型","text":"Maximum Entropy Theory Intro最大熵原理：学习概率模型时，所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以最大熵原理也可以表述为在给定已知信息下，满足约束条件的模型集合中，选取熵最大的模型。 也就是说，在目前已观测到的所有信息下，最合理的对未知信息的预测就是对所有未知信息最不确定的推断（每种未知情况等可能）。$H(P)$表示$P$的不确定性，最不确定的情况=熵最大的情况=每种未知情况都等可能发生，这就给出了最好模型选择的准则 H(P)=-\\sum_xP(x)\\log P(x),其中0≤H(P)≤\\log|X|表示随机变量$X$的概率分布$P(X)$的熵，$|X|$表示$X$的取值个数。当且仅当$X$的分布是均匀分布时右边等号成立，这时候条件熵最大。即：在已知信息下，$P(X)$的熵最大 对于模型$P(X)$，能够最大化熵$H(P)$的模型$P(X)$即是最好的模型 Maximum Entropy Model给定训练数据集:$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$ 我们要求最准确的模型：$P(y|x)$ $1^o$ 特征函数与经验分布 ①特征函数(feature function)（$X$的约束）： $f(x,y)$表示训练数据中输入$x$和输出$y$之间的一个事实（关系），只要满足事实（一般存在很多对满足该事实的$(x_i,y_i)$，特征函数也有很多$f_i$，即有多个事实约束），则$(x_i,y_i)$就能用该特征函数$f(x,y)$表示一组数据 f(x,y)= \\begin{cases} 1,x与y满足某一事实\\\\ 0,否则 \\end{cases}此函数为一个二值函数，要么0要么1（也可以是任意实值函数）。事实可以来源于先验知识等。 举几例：①$f(x,y)= \\begin{cases}1,x为抛硬币出现正面,y为\\frac{1}{2}\\\\ 0,否则 \\end{cases}$ ②已知从箱子里顺序两次抽出红球和白球的概率为$\\frac{3}{10}$： $f(x_1,x_2,y)= \\begin{cases}1,x_1=红且x_2=白,或x_1=白且x_2=红,y=\\frac{3}{10}\\\\ 0,否则 \\end{cases}$ ③也可以想CRF中的特征函数的意义，是一样的 注：输入$x$可以是很多个随机变量，所以实际应该表示为$f(\\vec x,y)$或写成$f(x_1,x_2,\\cdots,x_n,y)$，为了方便写，全都记成$f(x,y)$，同时一个模型中的特征函数也是可以有很多的，每个特征函数都表述了一组数据。 理解特征函数的意义：一是泛化表示，一个特征函数可以表示多组数据，相当于“从输入和输出中抽取了特征”，其实就是用来形式化表示X的相关知识信息。（比如从箱子里顺序两次抽出红球和白球的概率为$\\frac{3}{10}$，就可以用特征函数来形式化的表示它） 二是放入公式中这样也相当于给数据添加了一个约束条件，即是在Maximum Entropy Theory Intro部分所述的约束条件，其也可以相当于是一个已知的前提信息，先验知识。（比如从箱子里顺序两次抽出红球和白球的概率为$\\frac{3}{10}$就是一个先验知识，这就是个模型约束条件） 这里的特征feature，和机器学习中的特征feature不是一个概念 ②经验分布即已知训练集的分布（$X$的分布）： \\hat P(X=x,Y=y)=\\frac{||(X=x,Y=y)||_0}{N} \\hat P(X=x)=\\frac{||(X=x,Y)||_0}{N}其中$||||_0$表该数据样本出现的次数。 为什么要有经验分布？经验分布即训练集现在已知的分布，是在Maximum Entropy Theory Intro部分所述的已知部分前提信息。其中包含了已知信息$x,y$出现的概率，根据最大熵原理，这是我们应该作为已知事实考虑的。 那么如何将经验分布考虑进最大熵？只需要求概率分布期望的时候是对经验分布求期望即可，$x,y$的经验分布就相当于$x,y$的权重，见$2^o$。 ③特征函数与经验分布一起构成了已知信息 所谓最大化条件熵，其中的“条件”就是指的这已知信息，包含$X$的分布和约束 $2^o$ 分布的期望 回顾理解复合函数期望（见后记） 特征函数$f(x,y)$(表征了已知$X$的约束）关于经验分布$\\hat P(X,Y)$（表征了已知$X$的分布）的期望值构成已知信息，也即经验分布中样本满足某个特征函数$f(x,y)$的期望： \\mathbb E_{\\hat P}(f)=\\sum_{x,y}\\hat P(x,y)f(x,y)关键：根据最大熵原理，我们观察到的已知信息已经成为事实，在真实分布也应该符合在经验分布中的已知信息。换句话说——这个已知信息的期望无论在经验分布中还是真实分布中都应该是同样的。 通过贝叶斯公式展开构造出$P(y|x)$，正好是我们要求的模型。这就形成了一个对我们要求的模型$P(y|x)$的约束条件。只有符合这个条件，才能是我们想要的模型。 即： \\mathbb E_{P}(f)=\\mathbb E_{\\hat P}(f) 或,\\sum_{x,y}\\hat P(x)P(y|x)f(x,y)=\\sum_{x,y}\\hat P(x,y)f(x,y)$3^o$最大熵模型 在$2^o$中根据已知信息得到了模型的约束条件，于是我们就可以得到满足这样的约束条件的模型集合。 $Def.$ 最大熵模型 Maximum Entropy Model：假设满足所有约束条件的模型集合为 \\mathbb C=\\{P∈\\mathbb P|E_P(f_i)=E_{\\hat P}(f_i),i=1,2,\\cdots,n \\}定义条件概率分布$P(Y|X)$上的条件熵为 H(P)=-\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y|x)则模型集合$\\mathbb C$中条件熵$H(P)$最大的模型称为最大熵模型。式中的对数为自然对数。 最大熵模型的学习满足这样的模型有很多，哪个才是最好的？在Maximum Entropy Theory Intro部分已述，熵最大的时候最好。 最大熵模型的学习过程就是求解最大熵模型的过程，也就是在满足约束条件的模型中求取最大熵模型的过程 所以， 对于给定的训练数据集$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$以及特征函数$f_i(x,y),i=1,2,\\cdots,n$，最大熵模型的学习等价于约束最优化问题： \\max_{P∈\\mathbb C}H(P)=-\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y|x) 使得,\\mathbb E_{P}(f_i)=\\mathbb E_{\\hat P}(f_i),i=1,2,\\cdots,n \\sum_yP(y|x)=1按照优化问题的习惯，将其改写为等价的求最小值问题： \\min_{P∈\\mathbb C}-H(P)=\\sum_{x,y}\\hat P(x)P(y|x)\\log P(y|x) 使得,\\mathbb E_{P}(f_i)-\\mathbb E_{\\hat P}(f_i)=0,i=1,2,\\cdots,n \\sum_yP(y|x)=1求得上述问题的解即是MEM学习的解","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"Game Month!","slug":"Game/month","date":"2019-10-31T14:37:16.000Z","updated":"2019-10-31T15:48:55.000Z","comments":true,"path":"Game/month/","link":"","permalink":"https://aisaka.cloud/Game/month/","excerpt":"","text":"纪念一下 [10月25日]the outer world [10月31日]路易吉鬼屋3 [11月8日] 死亡搁浅 [11月8日] 极品飞车：热度 [11月15日] 宝可梦：剑盾 [11月15日] 星球大战：组织陨落 这20天只能用暴力形容...真是活久见... 定一个小目标，全部通关","categories":[{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"}],"tags":[{"name":"3A","slug":"3A","permalink":"https://aisaka.cloud/tags/3A/"},{"name":"震惊","slug":"震惊","permalink":"https://aisaka.cloud/tags/%E9%9C%87%E6%83%8A/"},{"name":"暴力","slug":"暴力","permalink":"https://aisaka.cloud/tags/%E6%9A%B4%E5%8A%9B/"}]},{"title":"改进的迭代尺度法","slug":"人工智能/Scaling","date":"2019-10-31T04:44:07.000Z","updated":"2019-11-01T02:57:41.000Z","comments":true,"path":"人工智能/Scaling/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Scaling/","excerpt":"IntroIIS和EM一样，也是一种构造下界计算近似MLE的优化算法。事实上IIS算法就是对GIS（Generalized Iterative Scaling，通用迭代法，本质也是一种EM算法）算法进行改进而来的。 IIS利用$\\log$函数的性质，以及指数函数的凸性，对目标函数进行了两次缩放，来求解下界函数。 对于MEM和CRF，使用IIS比GIS收敛快很多。 在EM算法中，每次迭代获取到新的边界$B(\\theta,\\theta^i)$后，需要求$\\theta^{i+1}=\\arg\\max_\\theta B(\\theta,\\theta^i)$，简化$B$成$Q$函数后，即是要求$\\frac{\\partial Q}{\\partial \\theta}=0$，然后$\\theta^i\\to\\theta^{i+1}$。在这种方法下，如果$\\theta$维度很高又不独立的话（即模型参数很多，含有多个变量）的话，就不能对各参数分别求0偏导，需要全局优化。于是IIS另辟蹊径，采用了一次只优化$\\theta$中的一个变量$\\delta_i$，而固定其他变量$\\delta_j$的方法。 IIS可以用在CRF，MEM等模型中（HMM属于一种特殊的CRF，也可以用，但效果没EM好）","text":"IntroIIS和EM一样，也是一种构造下界计算近似MLE的优化算法。事实上IIS算法就是对GIS（Generalized Iterative Scaling，通用迭代法，本质也是一种EM算法）算法进行改进而来的。 IIS利用$\\log$函数的性质，以及指数函数的凸性，对目标函数进行了两次缩放，来求解下界函数。 对于MEM和CRF，使用IIS比GIS收敛快很多。 在EM算法中，每次迭代获取到新的边界$B(\\theta,\\theta^i)$后，需要求$\\theta^{i+1}=\\arg\\max_\\theta B(\\theta,\\theta^i)$，简化$B$成$Q$函数后，即是要求$\\frac{\\partial Q}{\\partial \\theta}=0$，然后$\\theta^i\\to\\theta^{i+1}$。在这种方法下，如果$\\theta$维度很高又不独立的话（即模型参数很多，含有多个变量）的话，就不能对各参数分别求0偏导，需要全局优化。于是IIS另辟蹊径，采用了一次只优化$\\theta$中的一个变量$\\delta_i$，而固定其他变量$\\delta_j$的方法。 IIS可以用在CRF，MEM等模型中（HMM属于一种特殊的CRF，也可以用，但效果没EM好） Improved Iterative ScalingIIS，改进迭代尺度法（本文求的是MEM模型的IIS） 首先已知MEM：$P_w(y|x)=\\frac{1}{Z_w(x)}e^{\\sum^n_{i=1}w_if_i(x,y)}$，$Z_w(x)=\\sum_ye^{\\sum_{i=1}^nw_if_i(x,y)}$ 则对数似然函数为：$L(w)=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nw_if_i(x,y)-\\sum_x\\hat P(x)\\log Z_w(x)$ 求：$\\arg_w\\max L(w)$ 思想：对MEM模型参数向量$w=(w_1,w_2,\\cdots,w_n)^T$，寻找一个新的参数向量$w\\to w+\\delta$： $w+\\delta=(w_1+\\delta_1,w_2+\\delta_2,\\cdots,w_n++\\delta_n)^T$，使得$L(w+\\delta)&gt;L(w)$，以此迭代 推导：前面思想和EM基本一样，先算出$\\Delta L$ $\\Delta=L(w+\\delta)-L(w)=\\sum_{x,y}\\hat P(x,y)\\log P_{w+\\delta}(y|x)-\\sum_{x,y}\\hat P(x,y)\\log P_{w}(y|x)$ $=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^n\\delta_if_i(x,y)-\\sum_{x}\\hat P(x)\\log\\frac{Z_{w+\\delta}(x)}{Z_{w}(x)}$ $\\because -\\log\\alpha≥1-\\alpha,\\alpha&gt;0$（这一步就把麻烦的$\\log$给干掉了，使得原式可以计算，代价是要构造下界做近似MLE，同EM的思想） $\\therefore \\Delta≥\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^n\\delta_if_i(x,y)+1-\\sum_{x}\\hat P(x)\\frac{Z_{w+\\delta}(x)}{Z_{w}(x)}$ $=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^n\\delta_if_i(x,y)+1-\\sum_{x}\\hat P(x)\\sum_yP_w(y|x)e^{\\sum_{i=1}^n\\delta_if_i(x,y)}$ （下界） 这个时候已经可以对$\\Delta$求0导数来获取最大值以获取$\\delta^{(n+1)}$了（这样就和EM一样，只是用了不同的下界不等式）。但是对目前的$\\Delta$求$\\frac{\\partial \\Delta}{\\partial \\delta_i}=0$会发现仍然存在$\\sum_i\\delta_i$形式（对负项中的$e^{\\sum_{i=1}^n\\delta_if_i(x,y)}$求导后根据链式法则显然无法消去$\\sum_i\\delta_i$部分），导致0导数式包含多个不同$i$的$\\delta_i$变量，很难同时优化。（注意对求和函数求导，见EM算法专题中） (想想为什么HMM中使用EM算法中对每个变量参数求0偏导就可行？因为在HMM中，$(A,B,\\pi)$三个变量参数是独立的且求得的$Q$函数已经将三个变量放在三个子式中独立分开，满足 $\\max_{A,B,\\pi}Q=\\{\\max_A ④,\\max_B ⑤,\\max_ \\pi ③\\}$，每个子式子中只包含本要优化的变量）而本式中，各参数变量$\\delta_i$之间根本不独立（求导式中就存在$\\sum_i\\delta_i$），不能分别求0偏导，传统做法只能让求一组$\\delta_i$使得整体满足最大。 于是我们想只将其中一个变量$\\delta_i$作为变量，其它$\\delta_j$作为固定常数$i≠j$，如何做到呢？那就要在求导中干掉$\\sum_i\\delta_i$形式，于是下面开始整骚操作： 构造Jensen不等式，以创造第二个下界。Jensen不等式可以将函数的作用范围缩小，这样就可以将$\\sum$抛出$e$的指数部分，避免求导的时候链式法则再产生$\\sum_i\\delta_i$。 令$f^o(x,y)=\\sum_if(x,y)$，MEM中$f_i(x,y)∈\\{0,1\\}$，是一个二值函数，于是$f^o(x,y)$表示所有特征在$(x,y)$出现的次数，这样就可以拼凑出一个求和等于1的分式并满足Jensen不等式形式。这里很需要技巧。 下面就是拼凑出的Jensen不等式形式（Jensen不等式见下面大标题）： $\\lambda_i=\\frac{f_i(x,y)}{f^o(x,y)},x_i=\\delta_if^o(x,y),f(\\sum_i\\lambda_ix_i)=e^{\\sum_i\\lambda_ix_i}$ 其中$\\lambda_i&gt;0,\\sum_i\\lambda_i=1,f(X)=e^X$为凸函数，则$e^{\\sum_i\\lambda_ix_i}≤\\sum_i\\lambda_ie^{x_i}$ $\\therefore \\Delta=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^n\\delta_if_i(x,y)+1-\\sum_{x}\\hat P(x)\\sum_yP_w(y|x)e^{\\sum_{i=1}^n \\frac{f_i(x,y)}{f^o(x,y)}\\delta_if^o(x,y)}$ $≥\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^n\\delta_if_i(x,y)+1-\\sum_{x}\\hat P(x)\\sum_yP_w(y|x)\\sum_{i=1}^n\\frac{f_i(x,y)}{f^o(x,y)}e^{ \\delta_if^o(x,y)}$（新下界） （注意前面有个负号！$-e^{\\sum_i\\lambda_ix_i}≥-\\sum_i\\lambda_ie^{x_i}$） 记右式为$B(\\delta|w),\\therefore L(w+\\delta)-L(w)≥B(\\delta|w)$ $\\therefore \\frac{\\partial B(\\delta|w)}{\\partial \\delta_i}=\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nf_i(x,y)-\\sum_{x}\\hat P(x)\\sum_yP_w(y|x)\\sum_{i=1}^nf_i(x,y)e^{ \\delta_if^o(x,y)}$ 于是该式中只有指定$i$的$\\delta_i$是变量，达到目的。令$\\frac{\\partial B(\\delta|w)}{\\partial \\delta_i}=0$即可求得$\\delta_i$ 其中$\\sum_{x,y}\\hat P(x,y)\\sum_{i=1}^nf_i(x,y)=\\mathbb E_{\\hat P}(f_i)$ 于是计算每一大步迭代，$\\delta$中的每一个参数$\\delta_i$的公式为： $\\sum_{x}\\hat P(x)\\sum_yP_w(y|x)\\sum_{i=1}^nf_i(x,y)e^{ \\delta_if^o(x,y)}=\\mathbb E_{\\hat P}(f_i)$，其中$f^o(x,y)=\\sum_if(x,y)$ 一个公式计算一个$\\delta_i$，依次计算$\\delta_i$就可以求得$\\delta$ Improved Iterative Scaling Algorithm对于MEM 输入：特征函数$f_1,f_2,\\cdots,f_n$；经验分布$\\hat P(X,Y)$，模型$P_w(y|x)$ 输出：最优参数$w_i^o$；最优模型$P_{w^o}$ （1）对所有$i∈\\{1,2,\\cdots,n\\}$，取初值$w_i=0$ （2）对每一$i∈\\{1,2,\\cdots,n\\}$ （a）令$\\delta_i$是方差 \\sum_{x}\\hat P(x)\\sum_yP_w(y|x)\\sum_{i=1}^nf_i(x,y)e^{ \\delta_if^o(x,y)}=\\mathbb E_{\\hat P}(f_i)​ 的解，其中 f^o(x,y)=\\sum_if(x,y)（b）更新$w_i$的值：$w_i \\leftarrow w_i+\\delta_i$ （3）如果不是所有$w_i$都收敛，重复（2） 在（a）中计算$\\delta_i$的时候，若$f^o(x,y)$是常数（即对所有的$(x,y)$，$f^o(x,y)$都相等。一般都不会是常数），那么 \\delta_i=\\frac{1}{M}\\log\\frac{E_{\\hat P}(f_i)}{E_P(f_i)}若$f^o(x,y)$不是常数，那就必须直接计算$\\delta_i$，可以使用牛顿法计算。 以$g(\\delta_i)=0$表示原方程，牛顿法通过迭代求得$\\delta_i^o$，使得$g(\\delta_i^o)=0$，迭代公式为 \\delta_i^{(k+1)}=\\delta_i^{(k)}-\\frac{g(\\delta_i^{(k)})}{g^{'}(\\delta_i^{(k)})}只要适当选取初始值$\\delta_i^o$，由于原方程有单根，因此牛顿法恒收敛，且收敛速度很快 Jensen不等式由凸函数性质可得：$\\lambda f(x_1)+(1-\\lambda)f(x_2)≥f(\\lambda x_1+ (1-\\lambda)x_2)$ $\\therefore$ 对于任意点集$\\{x_i\\}$，若$\\lambda_i≥0$，且$\\sum_i\\lambda_i=1$ 通过数学归纳法可以证明凸函数$f(x)$满足$f(\\sum_{i=1}^M\\lambda_ix_i)≤\\sum_{i=1}^M\\lambda_if(x_i)$ 对于凹函数，$\\lambda f(x_1)+(1-\\lambda)f(x_2)≤f(\\lambda x_1+ (1-\\lambda)x_2)$则相反 即： 若\\lambda_i≥0，\\sum_i\\lambda_i=1 若f(x)为凸函数，f(\\sum_{i=1}^M\\lambda_ix_i)≤\\sum_{i=1}^M\\lambda_if(x_i) 若f(x)为凹函数，f(\\sum_{i=1}^M\\lambda_ix_i)≥\\sum_{i=1}^M\\lambda_if(x_i)若$\\lambda_i$看成取值为$x_i$的离散变量$x$的概率分布，则可以写成： 若凸函数：$f(\\mathbb E[x])≤\\mathbb E[f(x)]$，若为凹函数：$f(\\mathbb E[x])≥\\mathbb E[f(x)]$ 凸则大作用域≤小作用域，凹则大作用域≥小作用域 构造Jensen不等式经常用拼凑法（IIS和EM）","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"条件随机场","slug":"人工智能/条件随机场","date":"2019-10-29T11:05:15.000Z","updated":"2019-10-31T04:43:28.000Z","comments":true,"path":"人工智能/条件随机场/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/","excerpt":"Conditional Random Field在我前面的文章中有一些概率图模型的基础知识：深度学习中的结构化概率模型 如果数据量极大，配分函数有可能会遇到无法直接求和问题参看前文：配分函数，其中用到了蒙特卡罗方法，参看前文：蒙特卡罗方法 将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解(factorization) 标注问题：在条件概率模型$P(Y|X)$中，$Y$是输出变量，表示输出的标记序列（或状态序列），$X$是输入变量，表示需要标注的观测序列。注意被标注的是标记序列/状态序列，不是观测序列。HMM和CRF都可以用于标注问题（只是其中一个应用）。 条件随机场(conditional random field,CRF)：给定随机变量$X$条件下，随机变量$Y$的马尔可夫随机场 线性链条件随机场(linear chain conditional random field,Linear-Chain CRF)：定义如下 设$X=\\{X_1,X_2,\\cdots,X_n\\},Y=\\{Y_1,Y_2,\\cdots,Y_n\\}$均为线性链表示的随机变量序列，若在给定随机变量序列$X$的条件下，随机变量序列$Y$的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性： P(Y_i|X,Y_1,\\cdots,Y_{i-1},Y_{i+1},\\cdots,Y_n)=P(Y_i|X,Y_{i-1},Y_{i+1}),i=1,2,\\cdots,n则称$P(Y|X)$为线性链条件随机场。意思是$Y_i$只与$X$(观测序列)，$Y_{i-1},Y_{i+1}$有关","text":"Conditional Random Field在我前面的文章中有一些概率图模型的基础知识：深度学习中的结构化概率模型 如果数据量极大，配分函数有可能会遇到无法直接求和问题参看前文：配分函数，其中用到了蒙特卡罗方法，参看前文：蒙特卡罗方法 将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解(factorization) 标注问题：在条件概率模型$P(Y|X)$中，$Y$是输出变量，表示输出的标记序列（或状态序列），$X$是输入变量，表示需要标注的观测序列。注意被标注的是标记序列/状态序列，不是观测序列。HMM和CRF都可以用于标注问题（只是其中一个应用）。 条件随机场(conditional random field,CRF)：给定随机变量$X$条件下，随机变量$Y$的马尔可夫随机场 线性链条件随机场(linear chain conditional random field,Linear-Chain CRF)：定义如下 设$X=\\{X_1,X_2,\\cdots,X_n\\},Y=\\{Y_1,Y_2,\\cdots,Y_n\\}$均为线性链表示的随机变量序列，若在给定随机变量序列$X$的条件下，随机变量序列$Y$的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性： P(Y_i|X,Y_1,\\cdots,Y_{i-1},Y_{i+1},\\cdots,Y_n)=P(Y_i|X,Y_{i-1},Y_{i+1}),i=1,2,\\cdots,n则称$P(Y|X)$为线性链条件随机场。意思是$Y_i$只与$X$(观测序列)，$Y_{i-1},Y_{i+1}$有关 Linear-Chain CRF形式化表示参数化形式要先画状态路径图来理解公式 设$P(Y|X)$为线性链CRF，则在随机变量$X$的取值为$x$（状态序列）的情况下，随机变量$Y$取值为$y$（取值/观测值序列）的条件概率具有如下形式： P(y|x)=\\frac{1}{Z(x)}e^{(\\sum_{i,k}\\lambda_kt_k(y_{i-1},y_i,x,i)+\\sum_{i,l}\\mu_ls_l(y_i,x,i))} Z(x)=\\sum_ye^{(\\sum_{i,k}\\lambda_kt_k(y_{i-1},y_i,x,i)+\\sum_{i,l}\\mu_ls_l(y_i,x,i))}$i$就是序列位置标号，见上面Linear-Chain中的定义（设$q,p∈\\Gamma$，$\\Gamma$为$Y_i$的取值空间（观测空间）） $t_k(y_{i-1}=q,y_i=p,x,i)$，也写成$t_k(y_{i-1},y_i,x,i)$：特征函数，对应的权值为$\\lambda_k$，定义为边上的特征函数，称为转移特征，依赖当前和前一个位置：[表示在第$i$位置上，序列第$i$位置$x$所对应的$y$取值（观测值）为$q$，到序列第$i-1$位置$x$对应的$y$取值（观测值）为$p$这条路径的转移特征，权值为$\\lambda_k$] $s_l(y_i=p,x,i)$，也写成$s_l(y_i,x,i)$：特征函数，对应的权值为$\\mu_l$，定义为结点上的特征函数，称为状态特征，依赖当前位置：[表示在第$i$位置上，序列第$i$位置的$x$所对应的$y$的取值（观测值）为$p$的结点的状态特征，该结点的权值为$\\mu_l$] $k$表示边的转移特征函数数量，$l$表示结点的状态特征函数数量 一般特征函数$t_k,s_l$取值为0或1 此求和其实就是对所有路径求和（所有可能的输出序列） 举例理解： 对于$X=(X_1,X_2,X_3),Y=(Y_1,Y_2,Y_3),Y_i$的取值集合为$\\Gamma=\\{1,2\\}$ 可以得到一个二维图，横坐标$i_1,i_2,i_3$表序号，纵坐标$Y=1,Y=2$表$y$的两个取值 则图中所有坐标点（结点）为 $(Y_1=2,X,1),(Y_1=2,X,2),(Y_1=2,X,3)$ $(Y_1=1,X,1),(Y_1=1,X,2),(Y_1=1,X,3)$ 如$(Y_1=2,X,1)$就表示在$i=1$的$X$序列位置上，$Y$的取值（观测值）为2，也可以写成$Y(X_1)=2$ 然后就可以通过上面的结点和边特征函数以及权重将概率图绘制出来，一切求和就得出CRF的概率分布 其它形式拼接$：K_1$个转移特征，$K_2$个状态特征，$K=K_1+K_2$ 求和：对同一特征在各个位置求和（同一特征在不止一个位置上有定义） $f_k(y_{i-1},y_i,x,i)=\\begin{cases} t_k(y_{i-1},y_i,x,i),k=1,2,\\dots,K_1\\\\ s_l(y_i,x,i),k=K_1+l;l+1,2,\\dots,K_2\\end{cases}$——① 组一： $f_k(y,x)=\\sum_{i=1}^n f_k(y_{i-1},y_i,x,i),k=1,2,\\dots,K$ （对同一特征函数$f_k$在所有位置$\\sum_i^n~$上求和） $F(y,x)=(f_1(y,x),f_2(y,x),\\dots,f_K(y,x))^T$（上面那个求和组成的向量，方便用于下面简化形式的内积形式）——③ 组二： $F_i(y_{i-1},y_i|x)=(f_1(y_{i-1},y_i,x,i),f_2(y_{i-1},y_i,x,i)，\\cdots,f_K(y_{i-1},y_i,x,i))$ (某一位置$i$下所有特征函数组成的向量） $\\therefore w·F_i(y_{i-1},y_i|x)=\\sum_{k=1}^Kw_kf_k(y_{i-1},y_i,x,i)$ （与上上面的$f_k(y,x)$刚好反过来，先对一个位置$i$积分所有特征函数$f_k$，再积分所有位置$i$）——④ 注意这一组的$F$下标和上面那组的含义是不一样的，一个是$k:$特征函数数量一个是$i:$位置数量 $w_k=\\begin{cases} \\lambda_k,k=1,2,\\dots,K_1\\\\ \\mu_l,k=K_1+l;l+1,2,\\dots,K_2\\end{cases}$——② $w=(w_1,w_2,\\dots,w_K)^T$ 简化形式—对每个特征函数求其在所有位置的和由②③： $\\therefore$特征*权重可以看成求正交化（内积）可以看成是先对每个特征函数$f_k$在所有位置$i$积分，再积所有特征函数$f_k$ P_w(y|x)=\\frac{e^{w·F(y,x)}}{Z_w(x)} Z_w(x)=\\sum_ye^{w·F(y,x)}矩阵形式—在每个位置求所有特征函数的和由②④： $W_i(y_{i-1},y_i|x)=\\sum_{k=1}^Kw_kf_k(y_{i-1},y_i,x,i)$ $M_i(y_{i-1},y_i|x)=e^{W_i(y_{i-1},y_i|x)}$ （所以可以对每个位置$i$求$M$矩阵） P_w(y|x)=\\frac{1}{Z_w(x)}\\prod_{i=1}^{n+1}M_i(y_{i-1},y_i|x) Z_w(x)=[M_1(x)M_2(x)\\dots M_{n+1}(x)]_{start,stop}由于矩阵表示可以很直观的表示序列上每个位置的矩阵，所以很好用，下面概率计算的时候直接累乘即可 非矩阵形式可以表示为：（注意这个式子的$f_i(x,y)=$组二中的$F_i(y_{i-1},y_i|x)$） P_w(y|x)=\\frac{e^{\\sum_{i=1}^nw_if_i(x,y)}}{\\sum_y e^{\\sum_{i=1}^nw_if_i(x,y)}}此形式即最大熵模型形式！对Linear-Chain CRF参数的学习与对最大熵模型参数的学习一样 概率计算—求$\\max\\{P(Y_i=y_i|x)\\},\\max\\{P(Y_{i-1}=y_{i-1},Y_i=y_i|x)\\}$与HMM一样使用前向-后向算法，递归计算，用矩阵形式表达方便 前向算法： 前向右乘$M$矩阵（$\\alpha^T$将原横着的序列变列向量与$M$矩阵相乘） 初始化：$\\alpha_0(y|x)=\\begin{cases} 1, y=start\\\\ 0,otherwise\\end{cases}$ 递推公式：$\\alpha_i^T(y_i|x)=\\alpha_{i-1}^T(y_{i-1}|x)[M_i(y_{i-1},y_i|x)],i=1,2,\\dots,n+1$ 后向算法： 后向左乘$M$矩阵 初始化：$\\beta_{n+1}(y_{n+1}|x)=\\begin{cases} 1, y_{n+1}=stop\\\\ 0,otherwise\\end{cases}$ 递推公式：$\\beta_i(y_i|x)=[M_{i+1}(y_i,y_{i+1}|x)]\\beta_{i+1}(y_{i+1}|x),i=0,1,2,\\dots,n+1$ 概率计算： $P(Y_i=y_i|x)=\\frac{1}{Z(x)}\\alpha_i^T(y_i|x)\\beta_i(y_i|x)$ $P(Y_{i-1}=y_{i-1},Y_i=y_i|x)=\\frac{1}{Z(x)}\\alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x)\\beta_i(y_i|x)$ 其中$Z(x)=\\alpha_n^T\\vec1=\\vec1\\beta_1(x)$，$\\vec1$为元素均为1的$m$维向量 [O]期望值计算： $\\mathbb E_{P(Y|X)}[f_k]=\\sum_yP(y|x)f_k(y,x)=略$ $\\mathbb E_{P(X|Y)}[f_k]=\\sum_{x,y}P(x,y)\\sum_{i=1}^{n+1}f_k(y_{i-1},y_i,x,i)=略$ 学习算法—求模型参数$\\hat w$Linear-Chain CRF的位置求和形式，也即最大熵模型形式，于是可以用与MEM一样的方法来求模型参数 Improved Iterative ScalingIIS，改进的迭代尺度法，具体略 注意模型参数是$w$，而$f_k$（或者全局特征向量$F(y,x)$）是先验参数！ 经验概率$\\hat P(X,Y)$即为在训练集上直接通过观测法求得的经验概率，如通过多次抛硬币频数法求得概率一样 极大化训练数据的条件概率对数似然函数： $L(w)=L_{\\hat P}(P_w)=\\log\\prod_{x,y}P_w(y|x)^{\\hat P(x,y)}=\\sum_{x,y}\\hat P(x,y)\\log P_w(y|x)$ 将简化形式$P_w(y|x)$代入求极大 对其使用IIS，略 拟牛顿法可以见我以前写的文章牛顿法求解非线性优化和拟牛顿法 直接对$P_w(y|x)$求对数似然得优化目标函数 依然使用简化形式$P_w(y|x)$ 对其使用BFGS，略 预测算法—求$y^*=\\arg_y\\max P_w(y|x) $给定输入序列/观测序列$x$，求条件概率最大输出序列$y^*$，即求$\\arg_y\\max P_w(y|x)$ 与HMM一样的维比特算法，动态规划，注意递推式。 由于要确定路径，则使用在每个位置求特征和的积分方法，即上面的非矩阵形式公式，化简后可得： 求$\\max_y\\sum_{i=1}^nw·F_i(y_{i-1},y_i,x) $ （即求$\\max_y ④$) $F_i(y_{i-1},y_i|x)$为局部特征向量 递推式：$\\max\\{\\delta_{i-1}+w·F_i(y_{i-1},y_i,x)\\}$ 具体略 HMM和CRF的对比区别 HMM是生成模型，CRF是判别模型 （本图来自知乎） CRF的优化函数，可以做到全局最优 定义 CRF可以看成一组随机变量的集合，当给每一个位置按照某种分布随机赋予一个值之后，其全体就叫做随机场。这些随机变量之间可能有依赖关系 。 如果给定的马尔科夫随机场（MRF）中每个随机变量下面还有观察值，我们要确定的是给定观察集合下，这个MRF的分布，也就是条件分布，那么这个MRF就称为 Conditional Random Fields (CRF)。它的条件分布形式完全类似于MRF的分布形式，只不过多了一个观察集合X。所以, CRF本质上是给定了条件(观察值observations)集合的MRF。 HMM可以由CRF表达，CRF的范围更广。也就说，每一个HMM都可以被CRF表示 CRF要归一化而HMM不需要 因为CRF的权重值是任意的，而HMM是概率值必须满足概率约束条件 CRF可以依赖更多全局特征（Linear-Chain CRF的依赖也比较有限） HMM只能依赖前一个状态和当前观测，而CRF可以定义更远的依赖关系 CRF可以看成MEMM（最大熵马尔可夫模型）在标注问题上的推广","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"海","slug":"日记/海","date":"2019-10-29T00:10:45.000Z","updated":"2019-11-05T12:02:18.000Z","comments":true,"path":"日记/海/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%B5%B7/","excerpt":"","text":"未来へ","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"隐马尔可夫模型（二）","slug":"人工智能/隐马尔可夫模型（二）","date":"2019-10-27T12:46:25.000Z","updated":"2019-11-05T06:58:35.000Z","comments":true,"path":"人工智能/隐马尔可夫模型（二）/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"学习算法—预测模型参数$\\lambda=(A,B,\\pi)$若知$\\{(O_1,I_1),(O_2,I_2),\\cdots,(O_S,I_S)\\}$求$(A,B,\\pi)$，用监督学习方法 若知$\\{O_1,O_2,\\cdots,O_S\\}$求$(A,B,\\pi)$，用非监督学习方法Baum-Welch算法","text":"学习算法—预测模型参数$\\lambda=(A,B,\\pi)$若知$\\{(O_1,I_1),(O_2,I_2),\\cdots,(O_S,I_S)\\}$求$(A,B,\\pi)$，用监督学习方法 若知$\\{O_1,O_2,\\cdots,O_S\\}$求$(A,B,\\pi)$，用非监督学习方法Baum-Welch算法 监督学习方法通过转移状态与观测出现的频率来估算参数 但这样就需要人工标注，有时候代价过高 Baum-Welch算法使用MLE，由于隐变量的存在，很难求，所以用EM算法来近似MLE 假定训练数据为$S$个长度为$T$的观测序列$\\{O_1,O_2,\\cdots,O_S\\}$，不知其状态序列（隐变量） 目标：学习$\\lambda=(A,B,\\pi)$ 需要用到上一篇的公式$\\gamma_t(i)=P(i_t=q_i|O,\\lambda)=\\frac{P(i_t=q_i,O|\\lambda)}{P(O|\\lambda)}=\\frac{\\alpha_t(i)\\beta_t(i)}{P(O|\\lambda)}=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}$——① $\\epsilon_t(i,j)=P(i_t=q_i,i_{t+1}=q_j|O,\\lambda)=\\frac{P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}{P(O|\\lambda)}=\\frac{P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}{\\sum^N_{i=1}\\sum^N_{j=1}P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}$——② 手推（键盘推O_O）Baum-Welch公式： $P(O,I|\\lambda)=P((\\pi_{i_1} b_{i_1}(o_1)) (a_{i_1i_2}b_{i_2}(o_2)) \\cdots(a_{i_{T-1}i_T}b_{i_T}(o_T))$ 由$Q(\\lambda,\\hat \\lambda)=\\mathbb E_I(\\log P(O,I|\\lambda)|O,\\hat \\lambda)$ $=\\sum_I \\log P(O,I|\\lambda)P(I|O,\\hat \\lambda)$ $=\\sum_I \\log P(O,I|\\lambda)\\frac{P(I,O|\\hat \\lambda)}{P(O|\\hat \\lambda)}$，由于$P(O|\\hat \\lambda)$为常数，可以省略掉 $\\therefore Q(\\lambda,\\hat \\lambda)=\\sum_I \\log P(O,I|\\lambda)P(O,I|\\hat \\lambda)$ 将$P(O,I|\\lambda)$代入$Q$函数得： $Q(\\lambda,\\hat \\lambda)=\\sum_I \\log \\pi_{i} P(O,I|\\hat \\lambda)+\\sum_I\\sum_{t=1}^{T-1}\\log a_{i_ti_{t+1}}P(O,I|\\hat \\lambda)+\\sum_I\\sum_{t=1}^T\\log b_{i_t}(o_t)P(O,I|\\hat \\lambda)$ 将三个参数分布归到三个子项后，下面根据参数的需要对$P(O,I|\\hat \\lambda)$中的$I$变量进行对应的逆边缘化，注意时间和状态空间的关系，是独立的 $=\\sum_{i=1}^N \\log \\pi_i P(O,i_1=i|\\hat \\lambda)$——③ $+\\sum_{i=1}^N\\sum_{j=1}^N\\sum_{t=1}^{T-1}\\log a_{ij}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)$——④ 时间连续，但状态空间是任意组合的 $+\\sum_j^N\\sum_{t=1}^T\\log b_j(o_t)P(O,i_t=j|\\hat \\lambda)$——⑤ 由于$\\lambda=(A,B,\\pi)$中的三个参数变量都相互独立且求得的$Q$的三个子式只包含一个独立的变量，于是 $\\max_{A,B,\\pi}Q=\\{\\max_A ④,\\max_B ⑤,\\max_ \\pi ③\\}$ 于是用拉格日朗子乘数法分别对各变量求0偏导（否则算出负概率） Ⅰ.对于$\\pi_i :\\sum_{i=1}^N \\log \\pi_i P(O,i_1=i|\\hat \\lambda)$ （③式） $\\sum_{i=1}^N \\pi_i=1$ $\\pi$是初始概率向量，表初始的时候各状态的概率，别搞混了 $\\therefore \\mathbb L=\\sum_{i=1}^N \\log \\pi_i P(O,i_1=i|\\hat \\lambda)+\\gamma(\\sum_{i=1}^N \\pi_i-1)$ 令$\\frac{\\partial \\mathbb L}{\\partial \\pi_i}=0,\\therefore \\frac{\\partial(\\sum_{i=1}^N \\log \\pi_i P(O,i_1=i|\\hat \\lambda)+\\gamma(\\sum_{i=1}^N \\pi_i-1))}{\\partial \\pi_i}=0$ $\\therefore \\frac{1}{\\pi_i}P(O,i_1=i|\\hat \\lambda)+\\gamma=0$ （这里容易求错，见下面的求和函数求导） $\\therefore P(O,i_1=i|\\hat \\lambda)+\\gamma\\pi_i=0$ ——⑥ 左右两边同时求和：$\\sum_{i=1}^NP(O,i_1=i|\\hat \\lambda)+\\sum_{i=1}^N\\gamma\\pi_i=0$ ，$I$被边缘化（求和可以使用更多信息以消去$\\gamma$） $\\therefore P(O|\\hat \\lambda)+\\gamma=0$ $\\therefore \\gamma=-P(O|\\hat \\lambda)$，代入回⑥得： $P(O,i_1=i|\\hat \\lambda)-\\pi_iP(O|\\hat \\lambda)=0$ $\\therefore \\pi_i=\\frac{P(O,i_1=i|\\hat \\lambda)}{P(O|\\hat \\lambda)}=P(i_t=i_1|O,\\lambda)$，由①得：$\\pi_i=\\gamma_1(i)$ ——⑦ Ⅱ.对于$a_{ij}:\\sum_{i=1}^N\\sum_{j=1}^N\\sum_{t=1}^{T-1}\\log a_{ij}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)$ （④式） $\\sum_j^Na_{ij}=1$ $\\therefore \\mathbb L=\\sum_{i=1}^N\\sum_{j=1}^N\\sum_{t=1}^{T-1}\\log a_{ij}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)+\\gamma(\\sum_j^Na_{ij}-1)$ 令$\\frac{\\partial \\mathbb L}{\\partial a_{ij}}=0,\\therefore \\frac{\\sum_{i=1}^N\\sum_{j=1}^N\\sum_{t=1}^{T-1}\\log a_{ij}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)+(\\sum_j^Na_{ij}-1)}{\\partial a_{ij}}=0$ $\\therefore \\sum_{t=1}^{T-1}\\frac{1}{a_{ij}}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)+\\gamma =0$ $\\therefore \\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)+\\gamma a_{ij}=0$ 两边同时求和：$\\sum_j^N\\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)+\\gamma \\sum_j^Na_{ij}=0$ $\\therefore\\gamma=-\\sum_{t=1}^{T-1}P(O,i_t=i|\\hat \\lambda)$，回代原式 $\\therefore \\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)-\\sum_{t=1}^{T-1}P(O,i_t=i|\\hat \\lambda) a_{ij}=0$ $\\therefore a_{ij}=\\frac{\\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j|\\hat \\lambda)}{\\sum_{t=1}^{T-1}P(O,i_t=i|\\hat \\lambda)}$ 由①②得： $a_{ij}=\\frac{\\sum_{t=1}^{T-1}\\epsilon_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}$ ——⑧ Ⅲ.对于$b_j(o_t):\\sum_j^N\\sum_{t=1}^T\\log b_j(o_t)P(O,i_t=j|\\hat \\lambda)$ （⑤式） 注意这里有所不同，$b_j(k)$的观测空间为$(o_1,o_2,\\cdots,o_M)$。约束条件为$\\sum_{k=1}^Mb_j(k)=1$ $\\mathbb L=\\sum_j^N\\sum_{t=1}^T\\log b_j(o_t)P(O,i_t=j|\\hat \\lambda)+\\gamma(\\sum_{k=1}^Mb_j(k)-1)$ 令$\\frac{\\partial \\mathbb L}{\\partial b_j(k)}=0,\\therefore \\frac{\\partial(\\sum_j^N\\sum_{t=1}^T\\log b_j(o_t)P(O,i_t=j|\\hat \\lambda)+\\gamma(\\sum_{k=1}^Mb_j(k)-1)}{\\partial b_j(k)}=0$ 仅在$o_t=v_k$的时候$(b_j(o_t)=b_j(k))$，$\\frac{\\partial b_j(o_t)}{\\partial b_j(k)}≠0$，以$I(o_t=v_k)$表示，$I(o_t=v_k)=1,I(o_t≠v_k)=0$ $\\therefore \\sum_{t=1}^T\\frac{1}{b_j(o_t)}P(O,i_t=j|\\hat \\lambda)I(o_t=v_k)+\\gamma =0$ $\\therefore \\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)I(o_t=v_k)+\\gamma b_j(k)=0$ 左右两边同时求和$\\therefore \\sum_{k=1}^M\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)I(o_t=v_k)+\\gamma \\sum_{k=1}^Mb_j(k)=0$ $\\therefore \\sum_{k=1}^M\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)I(o_t=v_k)+\\gamma =0$ 对这个式子进行化简，其等价于：$\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)+\\gamma=0$ (有疑问) $\\therefore \\gamma=-\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)$，回代 $\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)I(o_t=v_k)-\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)b_j(k)=0$ $\\therefore b_j(k)=\\frac{\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)I(o_t=v_k)}{\\sum_{t=1}^TP(O,i_t=j|\\hat \\lambda)}$，由①得 $b_j(k)=\\frac{\\sum_{t=1,o_t=v_k}^T \\gamma_t(j)}{\\sum_{t=1}^T \\gamma_t(j)}$ ——⑨ 综上所述：$\\frac{\\partial Q}{\\partial \\pi_i}=⑦,\\frac{\\partial Q}{\\partial a_{ij}}=⑧,\\frac{\\partial Q}{\\partial b_j(k)}=⑨$ 于是可以写出Baum-Welch算法：（仅对一个观测序列$O∈\\{O_1,O_2,\\dots,O_S\\}$） 输入观测数据$O=(o_1,o_2,\\dots,o_n)$，求$\\lambda=(A,B,\\pi)$ 初始化：对$n=0$，选取$a_{ij}^{(0)},b_j(k)^{(0)},\\pi_i^{(0)}$，得到模型$\\lambda^{(0)}=(A^{(0)},B^{(0)},\\pi^{(0)})$ 递推： \\pi_i^{(n+1)}=\\gamma_1(i) a_{ij}^{(n+1)}=\\frac{\\sum_{t=1}^{T-1}\\epsilon_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)} b_j(k)^{(n+1)}=\\frac{\\sum_{t=1,o_t=v_k}^T \\gamma_t(j)}{\\sum_{t=1}^T \\gamma_t(j)}(每一个参数矩阵的中要计算出多个上述三式子（所有$i,j$情况）才能得到新迭代的模型参数) 其中各值按观测$O=(o_1,o_2,\\dots,o_n)$和模型$\\lambda^{(n)}=(A^{(n)},B^{(n)},\\pi^{(n)})$计算 最终得到模型参数$\\lambda^{(n+1)}=(A^{(n+1)},B^{(n+1)},\\pi^{(n+1)})$ 预测算法—预测序列状态$I=\\arg_I\\max\\{P(I|O,\\lambda)\\}$近似算法思想：选出在每一个时刻最有可能出现的状态来构成状态序列，用前面正反向算法推导出的单独概率公式求解 由在$t$时刻处于状态$q_i$的概率公式：$\\gamma_t(i)=P(i_t=q_i|O,\\lambda)=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}$ 在每一时刻$t$最有可能的状态$i^*_t=\\arg\\max_{1≤i≤N}[\\gamma_t(i)],t=1,2,\\dots,T$（计算出当前$t$下哪个$i$使得$\\gamma_t(i)$最大） 以此得到状态序列$I^{}=(i^{}_1,i^{}_2,\\dots,i^{}_T)$ 但存在问题：可能存在$\\gamma_t(i)=0$也就是情况不发生的情况，那么该公式就会失效了 但尽管如此近似算法依然是有用的 维比特算法动态规划，类似传统的Dijkstra算法，本文不细展开了，略 需要注意的就是递推公式的时候，概率最大化的是观测概率也就是$\\max\\{\\delta_i(t)a_{ij}b_j(o_{t+1})\\}$，而不是状态 求和函数求导 求解：$\\frac{\\partial(\\sum_{i=1}^N\\log\\pi_i)}{\\partial\\pi_i}$ 将$\\sum_{i=1}^N\\log\\pi_i$展开： $\\sum_{i=1}^N\\log\\pi_i=\\log \\pi_1+\\log \\pi_2+\\cdots+\\log \\pi_N$ $\\therefore \\frac{\\partial(\\sum_{i=1}^N\\log\\pi_i)}{\\partial\\pi_i}=\\frac{\\partial(\\log \\pi_1+\\log \\pi_2+\\cdots+\\log \\pi_N)}{\\partial \\pi_i}$ 若$i=1$，则$\\frac{\\partial(\\log \\pi_1+\\log \\pi_2+\\cdots+\\log \\pi_N)}{\\partial\\pi_1}=\\frac{1}{\\pi_1}$ 若$i=2$，则$\\frac{\\partial(\\log \\pi_1+\\log \\pi_2+\\cdots+\\log \\pi_N)}{\\partial\\pi_2}=\\frac{1}{\\pi_2}$ 若$i=i$，则$\\frac{\\partial(\\log \\pi_1+\\log \\pi_2+\\cdots+\\log \\pi_N)}{\\partial\\pi_i}=\\frac{1}{\\pi_i}$ $\\therefore \\frac{\\partial(\\sum_{i=1}^N\\log\\pi_i)}{\\partial\\pi_i}=\\frac{1}{\\pi_i}$ 同理$\\frac{\\partial(\\sum_{i=1}^N\\pi_i)}{\\partial\\pi_i}=1$ 一次只能对一个变量求导，其余视为不相关常数 理解对$\\pi_i$求导的意义，即无论被求导式为何，对其结果对$\\pi_i$求导 $\\sum_y×1=||y||_0×1$ 就像$\\sum_{i=1}^nm=nm,\\sum_{y}^n×1=n$一样，求和的参数决定了循环求和次数 于是：$\\sum_{y}d=\\sum_{x,y}d$，只有当$||y||_0=||(x,y)||_0$才成立","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"项目管理基础","slug":"游戏设计/项目管理基础","date":"2019-10-27T07:39:43.000Z","updated":"2019-10-27T08:57:51.000Z","comments":true,"path":"游戏设计/项目管理基础/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%9F%BA%E7%A1%80/","excerpt":"week3 项目管理基础 粗略大纲笔记","text":"week3 项目管理基础 粗略大纲笔记 游戏开发模型 产品愿景 产品线路图 发布规划 迭代计划 功能开发 项目章程：项目目标 定义做什么 项目目的 产品白皮书 里程碑计划 交付标准 职能架构 = 职责定义 1234=目标定义 项目执行 定义怎么做 配置管理 需求管理 迭代管理 进度管理 质量关系 本节课内容不止适用于游戏开发","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"隐马尔可夫模型（一）","slug":"人工智能/隐马尔可夫模型","date":"2019-10-25T01:37:14.000Z","updated":"2019-10-31T03:39:40.000Z","comments":true,"path":"人工智能/隐马尔可夫模型/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/","excerpt":"Hidden Markov Model隐马尔可夫模型，HMM，属于生成模型 HMM存在两个随机过程，且两个过程是相互联系的，具体来说就是第一个随机过程为状态序列随机过程，这和一般的马尔可夫链一致（具有马尔可夫性，当前状态只与前一个状态有关，与其它状态、观测无论未来还是过去都无关），第二个随机过程为观测序列的随机过程，它的当前值（观测值）由每一时刻的状态序列随机过程下的当前状态生成，且观测序列当前值只与状态序列随机过程的当前状态有关，与随机过程中其它观测和状态无论未来还是过去无关。即： P_{状态}(i_t|i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(i_t|i_{t-1}),t=1,2,\\cdots,T P_{观测}(o_t|i_t,i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(o_t|i_t),t=1,2,\\cdots,T HMM观测序列每生成一个新的状态就生成一次新观测","text":"Hidden Markov Model隐马尔可夫模型，HMM，属于生成模型 HMM存在两个随机过程，且两个过程是相互联系的，具体来说就是第一个随机过程为状态序列随机过程，这和一般的马尔可夫链一致（具有马尔可夫性，当前状态只与前一个状态有关，与其它状态、观测无论未来还是过去都无关），第二个随机过程为观测序列的随机过程，它的当前值（观测值）由每一时刻的状态序列随机过程下的当前状态生成，且观测序列当前值只与状态序列随机过程的当前状态有关，与随机过程中其它观测和状态无论未来还是过去无关。即： P_{状态}(i_t|i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(i_t|i_{t-1}),t=1,2,\\cdots,T P_{观测}(o_t|i_t,i_{t-1},o_{t-1},\\cdots,i_1,o_1)=P(o_t|i_t),t=1,2,\\cdots,T HMM观测序列每生成一个新的状态就生成一次新观测 符号表记HMM中符号较多 $\\lambda=(A,B,\\pi)$表记一个HMM，$A$：状态转移概率矩阵，$B$：观测概率矩阵，$\\pi$：初始状态概率向量(比如$\\pi=[0.2,0,4,0,4]$即表示在$t=1$时状态为$q_1,q_2,q_3$的初始概率分别为$0.2,0,4,0,4$ $i_t$：一个状态，$I=(i_1,i_2,\\cdots,i_T)$：状态序列，经过指定状态序列$i_1,i_2,\\cdots,i_T$后到达指定最终状态$i_T$的概率 $o_k$：一个观测，$O=(o_1,o_2,\\cdots,o_T)$：观测序列，对指定状态序列过程中产生的每一时刻状态进行观测（产生一个观测），这些观测构成指定序列的概率 $N$：可能的状态数，$Q=\\{q_1.q_2.\\cdots,q_N\\}$：可能的状态集合 $M$：可能的观测数，$V=\\{v_1,v_2,\\cdots,v_M\\}$：可能的观测集合 注意$i∈(i_1,\\cdots,i_t)$但$q∈(q_1,\\cdots,q_N),v∈(v_1,\\cdots,v_M)$ $a_{ij}=P(i_{t+1}|i_t)$：$t$时刻下状态$i_t$到$t+1$时刻下状态$i_{t+1}$的转移概率 $b_{i_t}(o_t)$：$t$时刻下，由状态$i_t$产生的观测$o_t$的概率，具体的，$b_{q_{i_t}}(o_t)$即状态$i_t$取值为$q_{i_t}$时候，观测为$o_t$的概率 注意 对于当前状态$\\sigma_t$，状态转移矩阵$A$,回到上一状态$\\sigma_{t-1}=A\\sigma_t$，到达下一状态$\\sigma_{t+1}=\\sigma_tA$ 概率计算算法—预测观测概率$\\max\\{P(O|\\lambda)\\}$直接计算$T$时间后到达某状态序列概率：$P(I|\\lambda)=\\pi a_{i_1i_2}a_{i_2i_3},\\cdots,a_{i_{T-1}i_T}$ 在$I$状态序列下，$T$时间后输出某观测序列$O=(o_1,o_2,\\cdots,o_T)$的概率：$P(O|I,\\lambda)=b_{i_1}(o_1)b_{i_2}(o_2)\\cdots b_{i_T}(o_T)$ $\\therefore$$T$时间后到达某状态序列$I$后输出某观测序列的概率为联合分布： P(O,I|\\lambda)=P(O|I,\\lambda)P(I|\\lambda)=((\\pi_{i_1} b_{i_1}(o_1)) (a_{i_1i_2}b_{i_2}(o_2)) \\cdots(a_{i_{T-1}i_T}b_{i_T}(o_T))（加括号仅为表明每个观测的状态对位关系） $\\therefore$ 为了求得$T$时间后观测得指定观测序列$O=(o_1,o_2,\\cdots,o_T)$的概率，需要边缘化联合概率公式中的$I$，$I=(i_1,i_2,\\cdots,i_N),i_1,i_2,\\cdots,i_t=1,2,\\cdots,N$ $\\therefore P(O|\\lambda)=\\sum_{i_1,i_2,\\cdots,i_T}P(O,I|\\lambda)=\\sum_{i_1,i_2,\\cdots,i_T}((\\pi_{i_1} b_{i_1}(o_1)) (a_{i_1i_2}b_{i_2}(o_2)) \\cdots(a_{i_{T-1}i_T}b_{i_T}(o_T))$ 注意表示法$\\sum_{i_1,i_2,\\cdots,i_T},其中i_1,i_2,\\cdots,i_t=1,2,\\cdots,N$(每个状态$i_t$下都有$N$种取值)，意思是对所有可能的$I$序列取值组合，计算右边式子之后，再对所有式子结果求和 关系为$\\lambda\\to I\\to O$，所以求$O$的时候可以看成一个全链接路径图或FC DNN 观察这个式子，对于$,i_1=1,2,\\cdots,N$： $t=1: P_1(O|\\lambda)=\\sum_{i_1}\\pi_{i_1} b_{i_1}(o_1)=\\pi_{q_1}b_{q_1}(o_1)+\\pi_{q_2}b_{q_2}(o_1)+\\cdots+\\pi_{q_N}b_{q_N}(o_1)$ $t=2: P_2(O|\\lambda)=\\sum_{i_1,i_2}((\\pi_{i_1} b_{i_1}(o_1))a_{i_1i_2}b_{i_2}(o_2)$ $=((\\pi_{q_1}b_{q_1}(o_1))a_{q_1q_1}b_{q_1}(o_2)+((\\pi_{q_1}b_{q_1}(o_1))a_{q_1q_2}b_{q_2}(o_2)+\\cdots+((\\pi_{q_1}b_{q_1}(o_1))a_{q_1q_N}b_{q_N}(o_2)+$​ $((\\pi_{q_2}b_{q_2}(o_1))a_{q_2q_1}b_{q_1}(o_2)+((\\pi_{q_2}b_{q_2}(o_1))a_{q_2q_2}b_{q_2}(o_2)+\\cdots+((\\pi_{q_2}b_{q_2}(o_1))a_{q_2q_N}b_{q_N}(o_2)+$ $\\cdots+$ $((\\pi_{q_N}b_{q_N}(o_1))a_{q_Nq_1}b_{q_1}(o_2)+((\\pi_{q_N}b_{q_N}(o_1))a_{q_Nq_2}b_{q_2}(o_2)+\\cdots+((\\pi_{q_N}b_{q_N}(o_1))a_{q_Nq_N}b_{q_N}(o_2)$ $\\cdots$ $t=T:\\cdots$ 这样算下去就很麻烦了，路径非常多，计算量非常大 结论：8行 前向算法观测到式子中存在大量重复子式，如$t=2$时，重复了在$t=1$中的子式$\\pi_{q_1}b_{q_1}(o_1),\\pi_{q_2}b_{q_2}(o_1),\\cdots,\\pi_{q_N}b_{q_N}(o_1)$各$N$次，于是想到可以用BP一样的解决办法，即 核心思想：可以观察到计算图如同一张全连接的深度神经网络，状态空间维度$N$即为每层隐藏神经元个数，时间序列运行时间$T$即为网络深度，于是我们只要保存每一个结点的计算结果，就可以大幅减少计算量 于是可以写出算法： 定义到时刻$t$部分观测序列为$o_1,o_2,\\cdots,o_t$且状态为$q_i$的概率为前向概率： $\\alpha_t(i)=P(o_1,o_2,\\cdots,o_t,i_t=q_i|\\lambda)$ 初始值：$\\alpha_1(i)=\\pi_ib_i(o_1),i=1,2,\\cdots,N$ 递推式：$\\alpha_{t+1}(i)=[\\sum^N_{j=1}\\alpha_t(j)\\alpha_{ji}]b_i(o_{t+1}),i=1,2,\\cdots,N$ 终止：$P(O|\\lambda)=\\sum^N_{i=1}\\alpha_T(i)$ 很像DNN的前向传递 前向算法最小结构就是当前时刻所有状态$i_t$转移到下一时刻的某状态$i_{t+1}$，有$N$个这一时刻的状态$i_t$，1个下一时刻的某状态$i_{t+1}$和1个对下一时刻状态的观测$b_i(o_{t+1})$（观测是先验） 注意一个理解：整个概率的计算是在时间$t$过程的前向转播中不断迭代产生的，每一个结点的计算都包含了全路径状态的转移概率和某一时刻的先验观测概率，所以完整的先验需要运行整个过程。当在$t=T$，最后一层结点计算完的时候，那么再对全状态路径求和才能求得先验$O=(o_1,o_2,\\cdots,o_T)$下的概率。若对所有可能存在的观测序列$O$计算那必然$P(O|\\lambda)=1$。 后向算法同理 定义在时刻$t$状态为$q_i$的条件下，从$t+1$到$T$的部分观测序列$o_{t+1},o_{t+2},\\cdots,o_T$的概率为后向概率： $\\beta_t(i)=P(o_{t+1},o_{t+2},\\cdots,o_T|i_t=q_i,\\lambda)$ 初始值：$\\beta_T(i)=1,i=1,2,\\cdots,N$ 递推式：$\\beta_{t}(i)=\\sum^N_{j=1}a_{ij}b_j(o_{t+1})\\beta_{t+1}(j),i=1,2,\\cdots,N$ 终止：$P(O|\\lambda)=\\sum_{i=1}^N\\pi_ib_i(o_1)\\beta_1(i)$ 很像DNN的反向传递… 后向算法最小结构就是下一时刻的所有状态$i_{t+1}$回退到当前时刻某状态$i_{t}$，有1个这一时刻的某状态$i_t$，有$N$个下一时刻的状态$i_{t+1}$，和$N$个对下一时刻状态的观测$b_j(o_{t+1})$（观测是先验） 同理，整个概率的计算是在时间$t$过程的后向转播中不断迭代产生的，这个先验需要运行整个过程，只不过这个过程是反着运行的。 其它应用利用前向概率与后向概率的定义，可以将观测序列概率统一可写成： $P(O|\\lambda)=\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j),t=1,2,\\cdots,T-1$ 式中$\\alpha_t(i)$即为$i$状态下$t$时刻以前的概率，$\\beta_{t+1}(j)$即为$i$状态下$t+1$时刻以后的概率，这个式子等于枚举出了网络中所有的路径 给定模型$\\lambda$和观测$O$，求在时刻$t$处于状态$q_i$的概率$\\gamma_t(i)$ 记$\\gamma_t(i)=P(i_t=q_i|O,\\lambda)=\\frac{P(i_t=q_i,O|\\lambda)}{P(O|\\lambda)}$ 由前向概率和后向概率定义可得 $\\alpha_t(i)\\beta_t(i)=P(o_1,o_2,\\cdots,o_t,i_t=q_i|\\lambda)*P(o_{t+1},o_{t+2},\\cdots,o_T|i_t=q_i,\\lambda)=P(i_t=q_i,O|\\lambda)$ $\\therefore \\gamma_t(i)=P(i_t=q_i|O,\\lambda)=\\frac{P(i_t=q_i,O|\\lambda)}{P(O|\\lambda)}=\\frac{\\alpha_t(i)\\beta_t(i)}{P(O|\\lambda)}=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}$ 对各个时刻求和，于是可以求出在观测$O$下状态$i$出现的期望值$=\\sum_{t=1}^T \\gamma_t(i)$ 同理，在观测$O$下由状态$i$转移的期望值$=\\sum_{t=1}^{T-1} \\gamma_t(i)$ 给定模型$\\lambda$和观测$O$，在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率$\\epsilon_t(i,j)$ $\\epsilon_t(i,j)=P(i_t=q_i,i_{t+1}=q_j|O,\\lambda)=\\frac{P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}{P(O|\\lambda)}=\\frac{P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}{\\sum^N_{i=1}\\sum^N_{j=1}P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}$ 由于$P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)=\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)$ $\\therefore \\epsilon_t(i,j)=P(i_t=q_i,i_{t+1}=q_j|O,\\lambda)=\\frac{P(i_t=q_i,i_{t+1}=q_j,O|\\lambda)}{P(O|\\lambda)}=\\frac{\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}{\\sum^N_{i=1}\\sum^N_{j=1}\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}$ 在观测$O$下由状态$i$转移到状态$j$的期望值$=\\sum_{t=1}^{T-1} \\epsilon_t(i,j)$","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"上帝算法：EM","slug":"人工智能/EM算法","date":"2019-10-23T01:11:22.000Z","updated":"2019-12-12T03:21:54.000Z","comments":true,"path":"人工智能/EM算法/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/EM%E7%AE%97%E6%B3%95/","excerpt":"现实中的例子对于NLP中的PLSA模型，$d∈D$表示文档，$w∈V$表示词语，$z$表示隐含的主题。 由于隐变量的存在， 则$P(d_i,w_j)=P(d_i)P(w_j|d_i)=P(d_i)\\sum_{k=1,\\cdots,K}P(w_j|z_k)P(z_k|d_i)$ 这里$z$就是不知道的变量=潜变量=隐变量 样本集分布为$P(D,V)=\\prod_{i=1,\\cdots,N}\\prod_{j=1,\\cdots,M}P(d_i,w_j)^{n(w_j,d_i)}$ $n(w,d)$表示$w$在$d$中出现的次数 于是对其求对数最大似然 $L(\\theta)=\\log P(D,V;\\theta)=\\sum_{i=1,\\cdots,M}\\sum_{j=1,\\cdots,N}n(w_j,d_i)\\log P(d_i,w_j)$ 其中$\\theta=\\{P(w_j|z_k),P(z_k|d_i)\\}$ 要求$\\theta^*=\\arg\\max L(\\theta)$ 则令$\\frac{\\partial L(\\theta)}{\\partial \\theta}=0$以求解 由于隐变量的存在，我们需要对隐变量求边缘化（见第一个式子），于是求解MLE需要对和的对数：$\\log P(d_i,w_j)$求导（其中$P(d_i,w_j)$是一个和式）。这样先求和再求导下来表达式一长串，导致求导非常困难，所以才要用近似MLE方法","text":"现实中的例子对于NLP中的PLSA模型，$d∈D$表示文档，$w∈V$表示词语，$z$表示隐含的主题。 由于隐变量的存在， 则$P(d_i,w_j)=P(d_i)P(w_j|d_i)=P(d_i)\\sum_{k=1,\\cdots,K}P(w_j|z_k)P(z_k|d_i)$ 这里$z$就是不知道的变量=潜变量=隐变量 样本集分布为$P(D,V)=\\prod_{i=1,\\cdots,N}\\prod_{j=1,\\cdots,M}P(d_i,w_j)^{n(w_j,d_i)}$ $n(w,d)$表示$w$在$d$中出现的次数 于是对其求对数最大似然 $L(\\theta)=\\log P(D,V;\\theta)=\\sum_{i=1,\\cdots,M}\\sum_{j=1,\\cdots,N}n(w_j,d_i)\\log P(d_i,w_j)$ 其中$\\theta=\\{P(w_j|z_k),P(z_k|d_i)\\}$ 要求$\\theta^*=\\arg\\max L(\\theta)$ 则令$\\frac{\\partial L(\\theta)}{\\partial \\theta}=0$以求解 由于隐变量的存在，我们需要对隐变量求边缘化（见第一个式子），于是求解MLE需要对和的对数：$\\log P(d_i,w_j)$求导（其中$P(d_i,w_j)$是一个和式）。这样先求和再求导下来表达式一长串，导致求导非常困难，所以才要用近似MLE方法 Expectation Maximization原理期望最大化，EM算法 思想：通过迭代增大下界的最大对数似然的方式逐步近似极大化$L(\\theta)$，每一次迭代$L(\\theta)&gt;L(\\theta^{i+1})&gt;L(\\theta^i)&gt;\\cdots$，计算迭代式的最大对数似然（最大化下界，该下界表达式里使得原式中的对和的对数求导被转化为对对数的和求导）非常容易，以此来逐渐接近$L(\\theta)$；那么如何构造下界？Jensen不等式！ 设$Y$为观测数据（不完全数据），$Z$是未观测数据，$\\theta^i$表示第$i$次迭代的模型参数$\\theta$ 可以理解为$\\theta\\to Z\\to Y$ $L(\\theta)=\\log P(Y|\\theta)=\\log \\sum_Z P(Y,Z|\\theta)$(逆边缘化+贝叶斯公式) $=\\log (\\sum_ZP(Z,\\theta)P(Y|Z,\\theta))$（全概率公式） 那么计算第$i$次迭代后的差 $L(\\theta)-L(\\theta^i)=\\log (\\sum_ZP(Z,\\theta)P(Y|Z,\\theta))-\\log P(Y|\\theta^i)$ 下面拼凑一个$(Z|Y,\\theta^i)$出来，拼凑的目的是为了构造出Jensen不等式的形式以创造出一个表示下界的不等式，因为显然$\\sum_Z P(Z|Y,\\theta^i)=1$ $=\\log(\\sum_Z P(Z|Y,\\theta^i)\\frac{P(Z,\\theta)P(Y|Z,\\theta)}{P(Z|Y,\\theta^i)})-\\log P(Y|\\theta^i)$ 由Jensen不等式，$\\log \\sum_j\\lambda_jy_j≥\\sum_j\\lambda_j\\log y_j,\\lambda_j≥0,\\sum_j\\lambda_j=1$ $\\therefore L(\\theta)-L(\\theta^i)≥=\\sum_Z P(Z|Y,\\theta^i)\\log\\frac{P(Z,\\theta)P(Y|Z,\\theta)}{P(Z|Y,\\theta^i)}-\\log P(Y|\\theta^i)$ $\\because\\sum_Z P(Z|Y,\\theta^i)=1$，于是可以在负部凭空构造出此求和以合并两式 $\\therefore L(\\theta)-L(\\theta^i)=\\sum_Z P(Z|Y,\\theta^i)\\log\\frac{P(Z,\\theta)P(Y|Z,\\theta)}{P(Z|Y,\\theta^i)}-\\sum_ZP(Z|Y,\\theta^i)\\log P(Y,\\theta^i)$ $=\\sum_Z [P(Z|Y,\\theta^i)\\log\\frac{P(Z,\\theta)P(Y|Z,\\theta)}{P(Z|Y,\\theta^i)}-P(Z|Y,\\theta^i)\\log P(Y,\\theta^i)]$ $=\\sum_Z P(Z|Y,\\theta^i)\\log\\frac{P(Y|Z,\\theta)P(Z,\\theta))}{P(Z|Y,\\theta^i) P(Y|\\theta^i)}$ 这里通过Jensen不等式同时也将和的对数，转换成了对数的和，$\\log$被拿进了$\\sum$里面，计算其导数（求最大似然）（对每个参数求偏导）就容易多了 $\\Delta =\\sum_Z P(Z|Y,\\theta^i)\\log\\frac{P(Y|Z,\\theta)P(Z,\\theta))}{P(Z|Y,\\theta^i) P(Y|\\theta^i)}$ 令$B(\\theta,\\theta^i)=L(\\theta^i)+ \\Delta$ 则$L(\\theta)≥B(\\theta,\\theta^i)$，即$B(\\theta,\\theta^i)$为$L(\\theta)$的一个下界。那么极大化$B(\\theta,\\theta^i)$下界自然也等同于极大化$L(\\theta)$ $\\therefore \\theta^{i+1}=\\arg \\max_\\theta B(\\theta,\\theta^i)≤\\arg\\max L(\\theta)$ 同时注意到$L(\\theta^i)=B(\\theta^i,\\theta^i)$，很显然，如果$\\theta=\\theta^i$，即通过迭代$i$次之后模型参数已经完全一样，那自然是极大对数似然=近似极大对数似然 $\\therefore \\theta^{i+1}=\\arg \\max_\\theta(L(\\theta^i)+\\sum_Z P(Z|Y,\\theta^i)\\log\\frac{P(Y|Z,\\theta)P(Z,\\theta))}{P(Z|Y,\\theta^i) P(Y|\\theta^i)})$ 该式子中$P(Z|Y,\\theta^i) P(Y|\\theta^i)和L(\\theta)$与极大化$\\theta$没有关系，所以可以直接忽略（注意$\\log$外的$P(Z|Y,\\theta^i)$不忽略，因为有它方便计算），$P(Z|Y,\\theta^i)$是一个可以求得的潜变量后验概率 且$\\because P(Y,Z|\\theta)=P(Y|Z,\\theta)P(Z,\\theta))$ $\\therefore \\theta^{i+1}=\\arg\\max_\\theta(\\sum_Z P(Z|Y,\\theta^i)\\log P(Y,Z|\\theta))$， 记为$\\arg\\max_\\theta Q(\\theta,\\theta^i)$ $Q(\\theta,\\theta^i)=\\sum_Z P(Z|Y,\\theta^i)\\log P(Y,Z|\\theta)=\\mathbb E_Z[\\log P(Y,Z|\\theta)|Y,\\theta^i]$ $\\theta^i$是要迭代的参数，初始为$\\theta^0$ 即：完全数据的对数似然在后验潜变量上的期望，此式子为EM算法的核心 敛散性定理一：设$P(Y|\\theta)$为观测数据的似然函数，$\\theta^i(i=1,2,\\cdots)$为EM算法得到的参数估计序列，$P(Y|\\theta^i)(i=1,2,\\cdots)$为对应的似然函数序列，则$P(Y|\\theta^i)$是单调递增的，即 P(Y|\\theta^{i+1})≥P(Y|\\theta^i)（也就是说每一次迭代的预测必然比上一次迭代更好，这是EM算法的核心之一，从道理上能理解，这里数学证明） 定理二：设$L(\\theta)=\\log P(Y|\\theta)$为观测数据的对数似然函数，$\\theta^i(i=1,2,\\cdots)$为EM算法得到的参数估计序列，$L(\\theta^i)(i=1,2,\\cdots)$为对数函数似然序列 如果$P(Y|\\theta)$有上界，则$L(\\theta^i)=\\log P(Y|\\theta^i)$收敛到某一值（单调有界定理） 在函数$Q(\\theta,\\hat\\theta)$与$L(\\theta)$满足一定条件下，由EM算法得到的参数估计序列$\\theta^i$的收敛值$\\theta^*$是$L(\\theta)$的稳定点 证略 显然EM算法不能保证找到全局最优值，只能收敛到稳定点，也因此初值选择非常重要 Expectation Maximization Algorithm于是根据原理推导出来的公式可以给出EM算法： 对于观测变量数据$Y$，隐变量数据$Z$，联合分布$P(Y,Z|\\theta)$，条件分布$P(Z|Y,\\theta)$，选择初值$\\theta^0$开始迭代 E-step：在第$i+1$步的时候，计算在第$i$次迭代的参数估计值$\\theta^i$的$Q$函数： Q(\\theta,\\theta^i)=\\sum_Z P(Z|Y,\\theta^i)\\log P(Y,Z|\\theta)=\\mathbb E_Z[\\log P(Y,Z|\\theta)|Y,\\theta^i]M-step： \\theta^{i+1}=\\arg\\max_\\theta Q(\\theta,\\theta^i)迭代直到$||\\theta^{i+1}-\\theta^i||或||Q(\\theta^{i+1},\\theta^i)-Q(\\theta^{i},\\theta^i)||$足够小 后记 边缘化：实际上就是求出边缘概率以消去变量 $p(x)=\\int_{-∞}^{+∞}p(y)dy$，那么$y$就被消去了，通过边缘化可以获得我们想要的任何属性（推理） 概率论中的条件期望：$\\mathbb E_Z[P(X)|C]=\\int_ZP(X)P(Z|C)dZ$ 在推导中常犯的一个马虎错误：看清楚积分的作用域，比如$\\sum_xf(x)g(x)$，如果$\\sum_x f(x)=1$，别直接就给求和了= =，后面还有一个带积分变量$x$的函数呢！ 求极大值可以用求0导数法也可以用拉格朗日乘数法将边界条件限制（经常需要如此！）进去 算Q可以借助期望运算的性质来减小运算量 EM算法实在是非常的美妙，很多人称其为“上帝的算法”；更多扩展可以看知乎上的这篇文章：EM算法存在的意义是什么？，包含了诠释EM算法的九层境界 为什么要构造下界？是因为我们想要消去和的对数这种很难计算的东西使用了Jensen不等式，而Jensen不等式的副作用就是产生了不等式，所以才会想着通过迭代容易计算的下界的方法来逼近 $P(Z|Y,\\theta^i)$是一个可以求得的潜变量后验概率，在实际应用的时候注意这个潜变量后验概率如何计算，通常使用贝叶斯公式将这个潜变量后验概率转变为先验概率（待求导变量）表示的式子： P(B_i|A)=\\frac{P(A,B_j)}{P(B_j)}=\\frac{P(A|B_i)P(B_i)}{\\sum_{j=1}^nP(B_j)P(A|B_j)}​ $A$可以是多个参数，用同样的方法运用贝叶斯公式","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks","slug":"论文阅读笔记/NETWORKS","date":"2019-10-21T01:01:32.000Z","updated":"2019-12-23T10:57:53.000Z","comments":true,"path":"论文阅读笔记/NETWORKS/","link":"","permalink":"https://aisaka.cloud/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/NETWORKS/","excerpt":"《Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks》Alec Radford&amp;Luke Metz ,Soumith ChintalaICLR 2016 RELATED WORK Unsupervised representation learning 无监督表示学习领域（聚类，AE，DBN） Generative image models生成模型（参数化模型，非参数化模型） Variational sampling approach (2013) 模糊 GAN(2014) 噪点多，难以理解 A recurrent network approach(Gregor et al.,2015, a deconvolution network approach(Dosovitskiy et al.,2014) 未用生成器监督 VISUALIZING THE INTERNALS OF CNNS 通过反卷积和最大池化可以找到网络中每个卷积核学到的内容 (Zeiler &amp; Fergus, 2014) ，对输入使用梯度下降可以推断出卷积核的理想子集(Mordvintsev et al.).","text":"《Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks》Alec Radford&amp;Luke Metz ,Soumith ChintalaICLR 2016 RELATED WORK Unsupervised representation learning 无监督表示学习领域（聚类，AE，DBN） Generative image models生成模型（参数化模型，非参数化模型） Variational sampling approach (2013) 模糊 GAN(2014) 噪点多，难以理解 A recurrent network approach(Gregor et al.,2015, a deconvolution network approach(Dosovitskiy et al.,2014) 未用生成器监督 VISUALIZING THE INTERNALS OF CNNS 通过反卷积和最大池化可以找到网络中每个卷积核学到的内容 (Zeiler &amp; Fergus, 2014) ，对输入使用梯度下降可以推断出卷积核的理想子集(Mordvintsev et al.). APPROACH AND MODEL ARCHITECTURECore to our approach is adopting and modifying three recently demonstrated changes to CNN architectures. 模型采用CNN all convolutional net (Springenberg et al., 2014) 不使用池化层 在判别模型中用步长卷积 (strided convolutions )替代 在生成模型中用转置卷积/微步卷积（fractionally-strided convolutions）替代 这样可以允许生成和判别模型学习自己空间的下采样，使得网络可微。 trend towards eliminating fully connected layers on top of convolutional features 不使用FC层，替而代之使用global pooling（全局池化层） 目的是减轻运算量，提高了模型的稳定性，但不利于收敛速度。 Batch Normalization 批归一化 (Ioffe &amp; Szegedy, 2015) （BN现在已经是非常常用的工具了） 有效解决GANs训练中常遇到的梯度消失问题，也解决初始化问题，并防止生成模型把所有样本都收敛到一个点 但不要对生成模型的输出层和判别模型的输入层使用，否则会导致模型不稳定 activation 激活函数的选择 生成模型中使用ReLU，除了输出层用tanh 判别模型使用Leaky ReLU，尤其在高分辨率模型中效果非常好 生成模型结构： 实验结论与方法总结 对于无监督表示学习算法通常的验证方法： apply them as a feature extractor on supervised datasets and evaluate the performance of linear models ﬁtted on top of these features. 在监督学习数据集中，将训练好的模型当成特征提取器，使用线性模型用来匹配特征以衡量性能（相当于将监督学习训练好的模型作为判别器） 作者使用在ImageNet-1K上训练得到的生成模型，使用所有层的所有CNN特征作为输入，将每一层的CNN特征使用最大池化的方式降到4×4，扁平化成一个28672维的向量，输入到L2-SVM中，明显DCGAN效果优于其他无监督表示模型 对于隐空间，可以对经过生成模型之前的初始向量进行差值的方式探索隐空间 如果图像急剧变化，可能是因为没有学习到特征，只是记住了图像；如果缓慢渐变，说明学习到了特征 在标签数据较少的情况下，DCGAN效果最好。 使用 guided backpropagation ( Striving for Simplicity: The All Convolutional Net Springenberg et al.,2014)可视化判别模型中的特征 GAN中可以类似word2vec一样进行向量运算，直接对输入生成模型的那个向量进行加减 如vector(”King”)-vector(”Man”)+vector(”Woman”) 去除掉某物体 对窗户特征进行dropout 补充： 全局平均池化：global average pooling（GAP） $W×H×C\\to1×1×C$ 即将一个Channel变成成一个值，原Channel每个位置的权值为$\\frac{1}{W×H}$ GAP的真正意义是:对整个网路在结构上做正则化防止过拟合。其直接剔除了全连接层中黑箱的特征，直接赋予了每个channel实际的内别意义。 反卷积/转置卷积/微步卷积（fractionally-strided convolutions） 判别模型输入维度&gt;输出维度，需要用卷积，下采样； 但生成模型输入维度&lt;输出维度，就需要用卷积的逆过程，也就是反卷积，也就是上采样 反卷积的输出公式： $O=S(I-1)+K-2P$ (O=output, S=Stride,I=Input,K=Kernel,P=Padding) 上采样(upsampling) 一般两种方法： ①图像缩放，如双线性插值 ②逆卷积/转置卷积","categories":[{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://aisaka.cloud/tags/GAN/"}]},{"title":"游戏中的心理学","slug":"游戏设计/游戏中的心理学","date":"2019-10-20T06:30:45.000Z","updated":"2019-10-22T00:38:27.000Z","comments":true,"path":"游戏设计/游戏中的心理学/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6/","excerpt":"week2-游戏中的心理学 课堂总结 乐趣原理人为什么需要玩游戏？为什么在漫长的进化过程中，只有人类有对游戏的需要？ 游戏的本质：人类对现实或超现实世界里 某种模式 （对事物的规律的抽象提炼）的仿真和模仿 掌握和学习模式其实是人类进化的需求。人类的大脑有一种其他生物不具备的能力和喜好，就是从现实环境中不断识别和仿真模式","text":"week2-游戏中的心理学 课堂总结 乐趣原理人为什么需要玩游戏？为什么在漫长的进化过程中，只有人类有对游戏的需要？ 游戏的本质：人类对现实或超现实世界里 某种模式 （对事物的规律的抽象提炼）的仿真和模仿 掌握和学习模式其实是人类进化的需求。人类的大脑有一种其他生物不具备的能力和喜好，就是从现实环境中不断识别和仿真模式 少年，你爱玩游戏的原因其实是你的基因里被赋予了重大的种族使命！ WTCAF心理循环（W循环） W（watch）：玩家会观察目标事件，观察并尝试理解相关事务的运行，尝试从中发现潜在的模式 T（Think）：玩家理解模式后会尝试发现其中存在的规则，以分析思考如何对其进行仿真 C（Choose）：玩家需要找到一个目标来进行判断和自己的行为选择 A（Action）：玩家决定付诸行动，向系统输出的自己选择的行为 F（Feedback）：系统根据玩家输入继续运行，并输出给玩家一个反馈来告诉玩家游戏结果 =》乐趣（多巴胺） 当WTCAF循环到极限状态：心流（技能与挑战都到达对等极限，最佳游戏状态） 成瘾原理 一个好的游戏模式至少需要具备几个特点： 具有可以被识别并易于模拟的模式 这个模式具有比较多样的结果，不容易被玩家穷尽所有可能 模式具有一定的变化性，让玩家始终需要调整和学习 其他的：目标，奖惩机制 构建基本乐趣循环三项基本要素（缺一不可）——W三角：模式、目标、奖惩 五大核心乐趣元素基本乐趣循环 内容探索发现 角色环境代入 成长目标追求 社群交互价值 一般来说，一个游戏不会拥有所有五大核心，如果真的要做这样一个五边形游戏，那必然极其复杂且小众，因为五大核心之间存在矛盾 所以一个游戏的基本玩法需要有一个可被玩家理解的玩法模式，并提供可以供玩家理解和思考的规则和目标，并提供可以输入行为决策的入口，并根据玩家输入和系统规则给出玩家胜负的反馈 乐趣空间依靠难度和奖惩机制，我们可以为一个玩法模式构建出一个乐趣空间 这个空间的衡量尺度是用户能力，我们一般用主要目标市场的平均水平来衡量 乐趣空间的范围：思维与操作（大脑与小脑的能力） 庸众的胜利举例：FPS进化史 ①雷神之锤 10把武器，3维地图，必须掌控全场，“空战”FPS，门槛极高 ②三角洲 ③CS CS的每一个版本都在削弱上限 ④CF 复活时间短，降低WTCAF ⑤PUBG 枪法已经不重要了 难度不断降低，门槛不断降低，受众不断变广 这个趋势会持续下去吗？不会，看图 如何寻找合适的目标市场，并且找到他们的Point点，圈住最主流的用户，一直是制作人们最头疼的问题 后记今天选出了PM，真是各路大佬各显神通….人均做过游戏，人均拿奖到手软，人均编程美术策划全能….甚至有个负责的游戏DAU 0.5亿的大佬，还有上来就展示导过的电影的……. 瑟瑟发抖………. 下周开始就要正式分组进行Mini-game制作了，我也是加把劲骑士！","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"且听风吟","slug":"随笔/且听风吟","date":"2019-10-18T17:12:21.000Z","updated":"2019-11-18T03:54:18.000Z","comments":true,"path":"随笔/且听风吟/","link":"","permalink":"https://aisaka.cloud/%E9%9A%8F%E7%AC%94/%E4%B8%94%E5%90%AC%E9%A3%8E%E5%90%9F/","excerpt":"尝试着给主页换了很多副标题，但最后还是用了「且听风吟」这四个字。 「且听风吟」来自村上春树的同名小说《且听风吟》 原文是「 風の歌を聴け」，其实字面意思与原意有一些差别。 「 且 」字给原意加入了一层浪漫与释然的情感， 但我觉得这是符合书意的。 其实我不是很喜欢村上春树讲故事的风格，充满后现代主义风格和西式的文风，少了些日本传统文学的物哀之情。但《且听风吟》的故事性本身就不是很强，或者说故事本身并不重要。 村上春树在他20岁的尽头写下了这本书 好久没有感觉出夏日的气息了。海潮的清香，遥远的汽笛，女孩肌体的感触，洗发香波的气味，傍晚的和风，缥缈的憧憬，以及夏日的梦境……然而，这一切宛若移动过的复写纸，无不同原有位置有着少许然而却是无可挽回的差异。 21岁的村上经历了百无聊赖的夏天，遇到了三个女孩，和鼠在酒吧里一起喝着酒聊着各种各样的话题··· 但夏天结束了，就像一场梦境一样。他还会去那个阶梯看看，去聆听那个夏天的声音，闻一闻海潮的清香，去感受夏天的和风。可是无论如何，都不能回到那个夏天了。 时光就是这样流逝着，如穿过指尖的沙一般，无论如何焦急地想要挽留，于己，无论是14岁那年，还是17岁那年，还是现在。","text":"尝试着给主页换了很多副标题，但最后还是用了「且听风吟」这四个字。 「且听风吟」来自村上春树的同名小说《且听风吟》 原文是「 風の歌を聴け」，其实字面意思与原意有一些差别。 「 且 」字给原意加入了一层浪漫与释然的情感， 但我觉得这是符合书意的。 其实我不是很喜欢村上春树讲故事的风格，充满后现代主义风格和西式的文风，少了些日本传统文学的物哀之情。但《且听风吟》的故事性本身就不是很强，或者说故事本身并不重要。 村上春树在他20岁的尽头写下了这本书 好久没有感觉出夏日的气息了。海潮的清香，遥远的汽笛，女孩肌体的感触，洗发香波的气味，傍晚的和风，缥缈的憧憬，以及夏日的梦境……然而，这一切宛若移动过的复写纸，无不同原有位置有着少许然而却是无可挽回的差异。 21岁的村上经历了百无聊赖的夏天，遇到了三个女孩，和鼠在酒吧里一起喝着酒聊着各种各样的话题··· 但夏天结束了，就像一场梦境一样。他还会去那个阶梯看看，去聆听那个夏天的声音，闻一闻海潮的清香，去感受夏天的和风。可是无论如何，都不能回到那个夏天了。 时光就是这样流逝着，如穿过指尖的沙一般，无论如何焦急地想要挽留，于己，无论是14岁那年，还是17岁那年，还是现在。 门外已经听到了冬天沉重的脚步声 又要到失去色彩的季节，人们穿着笨重的衣服，戴着大耳机，在仅属于自己的世界里蜷缩着 世界变得很小 我讨厌这样。 想起在云村看到的一段话 日语里“夏天结束了”这句话，包含了多少不可言说的含义，是一夜长大的意思，是恋爱无疾而终的预兆，是青春消失殆尽的季节，是从梦想跌入到现实的分界点，是失去童真变成大人的夜晚，也是人生从充满期待的未知陷落到无可改变的已知的无所适从。 纵然夏天已经结束了罢，再也回不到曾经的夏天了罢， 无论是热闹还是孤独，坚定还是彷徨，或懊悔，或怀念，或思忆，或迷茫，都终将幻化成风 可是穿越了秋冬春，终会迎来下一个新生的夏天，无论它是否还会如此绚烂 我还会回到那条夕阳下的街道去，胸口还会因为当时突如其来的偶遇而震动； 我还会回到午后惬意的校园，捂住耳朵，能听到放学后活动室内的喧嚣； 在夜幕之下抬头，闭上眼睛，我还会回忆起第一次穿着浴衣看到满天花火在夜幕中绽放的热泪盈眶。 也许这种情感本身，早已成为生命的一部分。 且静静地倾听着时光如风般流逝着，与生命交汇所发出的轻轻吟唱 且听风吟","categories":[{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/tags/%E9%9A%8F%E7%AC%94/"},{"name":"村上春树","slug":"村上春树","permalink":"https://aisaka.cloud/tags/%E6%9D%91%E4%B8%8A%E6%98%A5%E6%A0%91/"}]},{"title":"配分函数","slug":"人工智能/配分函数","date":"2019-10-18T06:33:28.000Z","updated":"2019-10-23T01:42:14.000Z","comments":true,"path":"人工智能/配分函数/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E9%85%8D%E5%88%86%E5%87%BD%E6%95%B0/","excerpt":"本文为 Deep Learning Ch.18 学习后总结的笔记 配分函数配分函数是统计物理学中常使用的概念，在前面深度学习的结构化概率模型中出现了配分函数：$p(x)=\\frac{1}{Z}\\hat{p}(\\vec x)$ $x$为模型中的所有参数组成的向量，记为： p(x)=\\frac{1}{Z}\\hat{p}(x;\\theta)为归一化此式子我们需要等比缩放，将$\\hat{p}(x)$缩放到1，即： Z=\\int \\hat{p}(x;\\theta)dx or,Z=\\sum_{\\vec x}\\hat{p}(x;\\theta)对其求对数似然梯度： \\therefore \\nabla_{MLE}=\\nabla_\\theta \\log \\hat{p}(x;\\theta)=\\nabla_\\theta \\log \\frac{\\hat{p}(x)}{\\int \\hat{p}(x;\\theta)dx} =\\nabla_\\theta\\log \\hat{p}(x)-\\nabla_\\theta\\log \\int \\hat{p}(x;\\theta)dx前半部分分为正相，后半部分称为负相","text":"本文为 Deep Learning Ch.18 学习后总结的笔记 配分函数配分函数是统计物理学中常使用的概念，在前面深度学习的结构化概率模型中出现了配分函数：$p(x)=\\frac{1}{Z}\\hat{p}(\\vec x)$ $x$为模型中的所有参数组成的向量，记为： p(x)=\\frac{1}{Z}\\hat{p}(x;\\theta)为归一化此式子我们需要等比缩放，将$\\hat{p}(x)$缩放到1，即： Z=\\int \\hat{p}(x;\\theta)dx or,Z=\\sum_{\\vec x}\\hat{p}(x;\\theta)对其求对数似然梯度： \\therefore \\nabla_{MLE}=\\nabla_\\theta \\log \\hat{p}(x;\\theta)=\\nabla_\\theta \\log \\frac{\\hat{p}(x)}{\\int \\hat{p}(x;\\theta)dx} =\\nabla_\\theta\\log \\hat{p}(x)-\\nabla_\\theta\\log \\int \\hat{p}(x;\\theta)dx前半部分分为正相，后半部分称为负相 正相很好解决，对于一个mini-batch中的样本直接计算即可 负相就非常难或者无法计算了，可以看到$\\int \\hat{p}(x;\\theta)dx$实际上就是对概率图网络中的所有可能出现的$\\vec x$求积分 MCMC求负相从离散表达式开始推导 \\nabla_\\theta \\log Z=\\frac{\\nabla_\\theta Z}{Z} =\\frac{\\nabla_\\theta\\sum_{\\vec x}\\hat{p}(x;\\theta)}{Z} =\\frac{\\sum_{\\vec x}\\nabla_\\theta\\hat{p}(x;\\theta)}{Z}显然$e^{\\log \\hat{p}(x;\\theta)}=\\hat{p}(x;\\theta)$，这里要这样变换的目的是为了凑出$\\mathbb{E}_{x～p(x)}=\\int p(x)f(x)$形式，以使用MCMC算法来模拟 \\therefore \\nabla_\\theta \\log Z=\\frac{\\sum_{\\vec x}e^{\\log \\hat{p}(x;\\theta)}\\nabla_\\theta\\hat{p}(x;\\theta)}{Z} =\\frac{\\sum_{\\vec x}\\hat{p}(x)\\nabla_\\theta\\log \\hat{p}(x)}{Z} =\\sum_{\\vec x}p(x)\\nabla_\\theta\\log \\hat{p}(x) =\\mathbb{E}_{\\vec x～p(\\vec x)}\\nabla_\\theta\\log \\hat{p}(\\vec x)这样就可以用MCMC方法对一个mini-batch的数据运用MCMC算法来求$\\nabla_\\theta \\log Z$了，连续情况同理 在深度学习中，经常采用能量函数$p(x)=e^{-E(x)}$来参数化$p(x)$，这种情况下正相可以解释为压低训练样本的能量，负相可以解释为提高模型抽取出的样本的能量。确切地说就是正相推高了数据点未归一化的概率，负相压低了数据点未归一化的概率，当数据分布和模型分布相等时，正相推高数据点和负相压低数据点的机会相等，这时候就不会有任何梯度了，训练停止。 于是就可以求得$\\nabla_\\theta \\log \\hat{p}(x;\\theta)$然后使用梯度算法更新模型参数$\\theta$ 随机最大似然和对比散度如果对每个batch都做MCMC算法直到马尔科夫过程收敛才开始采样，磨合过程太花时间。 以下两种算法都是基于一个思想：初始化马尔科夫链为一个非常接近模型分布的分布，从而大大减小磨合过程 对比散度（contrastive divergence）：在每个步骤中初始化马尔科夫链为采样自数据分布中的样本（具有$k$个Gibbs步骤的叫CD-$k$）。在开始的时候随着正相学习到模型的概率越来越精准，负相也会相应有所提高。 随机最大似然（stochastic maximum likelihood）也叫 持续对比发散（persistent contrastive divergence）：在每个梯度步骤中初始化马尔科夫链为先前梯度步骤的状态值（每个更新中具有$k$个Gibbs步骤的叫PCD-$k$） 一般来说PCD的方法好于CD 以下几种方法是绕过了对配分函数进行求值 伪似然无向图模型是非贝叶斯网络，所以在计算中会出现$\\frac{p(a)}{p(b)}=\\frac{\\frac{1}{Z}\\hat{p}(a)}{\\frac{1}{Z}\\hat{p}(b)}=\\frac{\\hat{p}(a)}{\\hat{p}(b)}$形式，抵消掉了配分函数 假设$x=\\{a,b,c\\}$，$a$包含想要的条件分布变量，$b$包含所有想要条件化的变量，$c$包含除此之外的变量。于是根据贝叶斯公式，$p(a|b)$可以表示为概率相除的形式： p(a|b)=\\frac{p(a,b)}{p(b)}=\\frac{p(a,b)}{\\sum_{a,c}p(a,b,c)}=\\frac{\\frac{1}{Z}\\hat{p}(a,b)}{\\sum_{a,c}\\frac{1}{Z}\\hat{p}(a,b,c)}=\\frac{\\hat{p}(a,b)}{\\sum_{a,c}\\hat{p}(a,b,c)}最理想的情况是$a=1,c=0$，这样计算起来就洒洒水了。但实际在计算对数似然$\\log p(x)$的时候，即使使$a$足够小，$c$依然可非常以大。那么一个假设就是将$c$移动到$b$中以减少计算代价。Marlin and de Freitas(2011)证得了这种方法的有效性。 得分匹配在前面的文章Autoencoder中用到过 定义得分（score）：$\\nabla_x\\log p(x)$ 其训练策略是最小化模型对数密度和数据对数密度关于输入的导数之间的平方差期望 这样就可以避免了$Z$带来的问题，因为$Z$不是$x$的函数，所以$\\nabla_xZ=0$ $L(x,\\theta)=\\frac{1}{2}||\\nabla_x\\log p_{model}(x;\\theta)-\\nabla_x\\log p_{data}(x)||_2^2$ $J(\\theta)=\\frac{1}{2}\\mathbb{E}_{p_{data(x)}}L(x;\\theta)$ $\\theta^*=\\min_{\\theta}J(\\theta)$ 比率匹配将得分匹配推广到离散情况，主要运用在二元模型 L^{RM}(x,\\theta)=\\sum^n_{j=1}(\\frac{1}{1+\\frac{p_{model}(x;\\theta)}{p_{model}(f(x,j);\\theta)}})^2$f(x,j)$为$j$处位置取反的$x$ 配分函数会在两个概率的比例中被抵消 比例匹配还可以作为处理高维稀疏数据的基础（如词计数向量） 噪声对比估计Noise Contrastive Estimation, NCE 思路：用一个变量来代替负相 \\nabla_{\\theta}\\log p_{model}(x)=\\nabla_{\\theta}\\log \\hat{p}_{model}(x)+c$c$作为模型训练学习的参数之一，问题在于如何训练 不能使用最大似然估计方法了，因为$c$会被无限扩大。于是将问题转化为一个概率二分类器的监督学习问题，通俗地说就是通过训练可以让模型分得清噪声和数据。 引入等概率二值分布$p_{noise}$，使得$p_{joint}(x|y=1)=p_{model}(x),p_{joint}(x|y=0)=p_{noise}(x)$ \\therefore p_{joint}(y=1|x)\\frac{p_{model}(x)}{p_{model}(x)+p_{noise}(x)} =\\frac{1}{1+\\frac{p_{noise}(x)}{p_{model}(x)}}=\\frac{1}{1+e^{\\log \\frac{p_{noise}(x)}{p_{model}(x)}}} =\\sigma(\\log p_{model}(x)-\\log p_{noise}(x))可以看到实际上是最大化模型与噪声分布之间的对数概率之差，也就是使得真实数据与噪声之间的差异最大，这便是好的模型，也是GAN的基本思想 估计配分函数在评估模型相对性能的时候，可能需要计算$\\sum_i\\log p_A(\\vec x;\\theta_A)&gt;\\sum_i\\log p_B(\\vec x;\\theta_B)$是否成立，如果成立则A更优，这时候经过变化可以求得一个比值，求得该比值就可以判断谁大谁小。于是如果知道配分函数的比值，就可以判断该式子的大小关系。 如何获得配分函数的值？根据重要采样，使用提议分布$p(x)=\\frac{1}{Z_0}\\hat{p}_0(x)$ $Z_1=\\int\\hat{p}_1(x)dx$ $=\\int\\frac{p_0(x)}{p_0(x)}\\hat{p}_1(x)dx$ $=Z_0\\int p_0(x)\\frac{\\hat{p}_1(x)}{\\hat{p}_0(x)}dx$ 于是使用蒙特卡罗方法： Z_1=\\frac{Z_0}{K}\\sum^K_{k=1}\\frac{\\hat{p}_1(x^{(k)})}{\\hat{p}_0(x^{(k)})}可以计算得到配分函数比值为$\\frac{1}{K}\\sum^K_{k=1}\\frac{\\hat{p}_1(x^{(k)})}{\\hat{p}_0(x^{(k)})}$ 当$KL(p_0||p_1)$较小的时候，可以有效估计出比值。但实际情况是 但实际情况中$p_1$通常是高维空间的复杂分布，很难找到一个简单的分布$p_0$既易于评估又接近$p_1$的分布，如果$p_0$与$p_1$不接近，那么$p_0$的大多数采样将在$p_1$中出现的概率较低，此时由于$\\frac{\\hat{p}_1(x^{(k)})}{\\hat{p}_0(x^{(k)})}$很大，导致方差很大，导致估计结果很差（方差大，采样欠估计）。 退火重要采样（Annealed Importance Sampling AIS） 目前是估计无向概率模型的配分函数的最常用方法 思想是引入中间分布来缩小$p_0$与$p_1$的差距 考虑分布序列$p_{\\eta_0},\\cdots,p_{\\eta_n},0=\\eta_0&lt;\\eta_1&lt;\\cdots&lt;\\eta_{n-1}&lt;\\eta_n=1$ $\\therefore \\frac{Z_1}{Z_0}=\\frac{Z_1}{Z_0}\\frac{Z_{\\eta_1}}{Z_{\\eta_1}}\\cdots\\frac{Z_{\\eta_{n-1}}}{Z_{\\eta_{n-1}}}$ $=\\frac{Z_{\\eta_{1}}}{Z_0}\\frac{Z_{\\eta_{2}}}{Z_{\\eta_{1}}}\\cdots\\frac{Z_{\\eta_{n-1}}}{Z_{\\eta_{n-2}}}\\frac{Z_{\\eta_{1}}}{Z_{\\eta_{n-1}}}$ $=\\prod^{n-1}_{j=0}\\frac{Z_{\\eta_{j+1}}}{Z_{\\eta_j}}$ 只要保证每个中间$p$之间足够近，就可以用低方差的重要采样来求得每一个$\\frac{Z_{\\eta_{j+1}}}{Z_{\\eta_j}}$，上式也就求解了。 通用的流行选择是用目标分布$p_1$的加权几何平均，$p_0$为$p_{\\eta_j}∝p_1^{\\eta_j}p_0^{1-\\eta_j}$ 桥式采样（Bridge Sampling） 相比AIS，只使用一个中间分布$p$ 最优的桥为$p_*^{(opt)}(x)∝\\frac{\\hat{p}_0(x)\\hat{p}_1(x)}{r\\hat{p}_0(x)+\\hat{p}_1(x)}$ $r=\\frac{Z_1}{Z_2}$ 我们可以从粗糙的$r$开始迭代来估计最好的$r$ 本章各种五花八门的方法真是复杂，看得我眼花缭乱….","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://aisaka.cloud/tags/%E6%95%B0%E5%AD%A6/"},{"name":"统计物理学","slug":"统计物理学","permalink":"https://aisaka.cloud/tags/%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86%E5%AD%A6/"}]},{"title":"绽放之后","slug":"Anime/绽放之后","date":"2019-10-17T14:12:22.000Z","updated":"2019-10-24T14:11:03.000Z","comments":true,"path":"Anime/绽放之后/","link":"","permalink":"https://aisaka.cloud/Anime/%E7%BB%BD%E6%94%BE%E4%B9%8B%E5%90%8E/","excerpt":"如花火般短暂，如花火般绚烂","text":"如花火般短暂，如花火般绚烂","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"青春","slug":"青春","permalink":"https://aisaka.cloud/tags/%E9%9D%92%E6%98%A5/"},{"name":"新海诚式","slug":"新海诚式","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E6%B5%B7%E8%AF%9A%E5%BC%8F/"}]},{"title":"失眠飞行","slug":"Music/失眠飞行","date":"2019-10-13T23:40:31.000Z","updated":"2019-10-26T00:51:31.000Z","comments":true,"path":"Music/失眠飞行/","link":"","permalink":"https://aisaka.cloud/Music/%E5%A4%B1%E7%9C%A0%E9%A3%9E%E8%A1%8C/","excerpt":"","text":"我想和你 一起闯进森林潜入海底 我想和你 一起看日出到日落天气 我想和你穿过格林威治和时间飞行 我想见你 穿过教堂和人海拥抱你","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[{"name":"hanser","slug":"hanser","permalink":"https://aisaka.cloud/tags/hanser/"},{"name":"kb","slug":"kb","permalink":"https://aisaka.cloud/tags/kb/"}]},{"title":"寒露","slug":"随笔/寒露","date":"2019-10-13T15:11:54.000Z","updated":"2019-10-13T16:07:07.000Z","comments":true,"path":"随笔/寒露/","link":"","permalink":"https://aisaka.cloud/%E9%9A%8F%E7%AC%94/%E5%AF%92%E9%9C%B2/","excerpt":"","text":"眼眸里流动着窗外的街景，打了一个寒战之后才意识到，深秋的冰冷正从自己倚靠在车窗上的头侧侵袭而来。 四面八方依稀传来的的轮胎与湿漉漉的地面的拍打声不绝于耳，淅淅沥沥的雨点与溅起的水花构成车外寂寥的白噪，在白茫茫的天际下，这座庞大的城市显得格外的孤独。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"秋","slug":"秋","permalink":"https://aisaka.cloud/tags/%E7%A7%8B/"}]},{"title":"腾讯游戏策划培训课堂笔记-week1","slug":"游戏设计/腾讯游戏策划培训课课堂笔记-week1","date":"2019-10-13T10:30:32.000Z","updated":"2019-11-23T16:10:19.000Z","comments":true,"path":"游戏设计/腾讯游戏策划培训课课堂笔记-week1/","link":"","permalink":"https://aisaka.cloud/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/%E8%85%BE%E8%AE%AF%E6%B8%B8%E6%88%8F%E7%AD%96%E5%88%92%E5%9F%B9%E8%AE%AD%E8%AF%BE%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0-week1/","excerpt":"很幸运能通过面试进入腾讯的策划课程，时间是每周日下午 week 1 揭开游戏设计师的神秘面纱—开课典礼 下周开始组队研发一款mini-game 策划策划：制定游戏规则，怎么玩 想好要做什么样的游戏 沟通获得各种制作资源 组合资源成为想要的游戏","text":"很幸运能通过面试进入腾讯的策划课程，时间是每周日下午 week 1 揭开游戏设计师的神秘面纱—开课典礼 下周开始组队研发一款mini-game 策划策划：制定游戏规则，怎么玩 想好要做什么样的游戏 沟通获得各种制作资源 组合资源成为想要的游戏 电子游戏研发流程综述 提炼游戏创意 语言简洁精炼 眼前一亮，令人深刻 聚焦用户体验 方法：头脑风暴 然后分类整理，进行评估，初步筛选可行，进一步评估 设计游戏概念 基于游戏创意进行概念设计 可以组成游戏概念设计小组，1~2人 概念：平台，目标用户，类型，描述，玩法，卖点，竞品，美术概念等 制作纸面原型/物理原型 帮助思考，高效沟通，快速试错 纸面原型相比数字原型优点在于成本低，直观，效率高，便于试错 自己试玩原型 设定规则集 确保运行良好 游戏逻辑合乎常理，所有游戏事件，结果，游戏挑战的平衡，游戏乐趣，顺序呈现 修正结构性问题 模拟测试易用性和游戏性 数字化开发 构建内容 将纸面原型的逻辑和内容进行数字化 构建内容不要超过游戏内容的20% 创建的游戏内容，未必会很好玩 少构建些内容，万一不好玩造成损失也能够让损失最小化 替代素材 图像，人物简单化 关卡素材足够简单 保证运作 团队协作 策划团队（枢纽），美术团队，程序团队，测试团队 版本管理 vs,SVN,git 需求管理 TAPD(腾讯敏捷项目管理平台) 游戏引擎是如何工作的 略 数字测试易用性和游戏性 半结构化测试 检测任务完成情况 收集测试数据 技巧：开放式提问，提前设问，有声思维 修正游戏玩法和内容 基于用户测试 关注系统问题 从大到小修正 完成第一个迭代，可以玩的数字版本 创建下一个迭代 进入螺旋开发模型 The Spiral Model（3~9循环） 持续迭代过程中，也在不断对游戏的玩法，美术进行迭代 打磨游戏 打磨核心元素 打磨细节 提升美术表现品质（所有的UI，素材，人物，图像，场景，道具，动画效果等等） 检查文字 继续打磨 自己当新手试玩 找旁人试玩 再三打磨，直到出类拔萃 将自己当作某个别人 终于有一天，看吐了… 完整测试 真实用户 用户调研 修正调优 修正遗留漏洞 微调提升玩法，手感 do best 版本发布（运营策划这个时候最忙） 发布完整版本 版本跟踪 打磨和打补丁 案例学习：尼山萨满（By Next Studio）略 电子游戏类型介绍(Video Game Genres)Genres 来自法语 游戏类型，游戏流派 基于游戏玩法交互的差异来分类 不是基于视觉或叙事差异，不像电影或者小说按照题材内容来分类 类型的本质：世上本没有路，走的人多了，就成了路……… 分类并无统一标准，只是约定俗成方便沟通 几大类： 动作 Action 强调物理挑战，手眼协调，反应时间 细分：平台，射击，格斗，清版，生存 冒险 Adventure 嵌入在叙事框架中的谜题，战斗和行动挑战有限 细分：文字冒险，视觉小说，图形冒险，互动电影，混合冒险 动作冒险 Action-Adventures 物理挑战，手眼协调，反应时间 + 故事情节，众多角色，储存系统 细分：潜行，恐怖，类GTA，银河恶魔城，通常 角色扮演 Role-Playing 玩家扮演一个或多个角色 沉浸在给定世界中 细分：动作，回合，大型多人在线，类rogue，战术，沙盒，地下城…… 模拟 Simulation 从现实生活中复制各种活动，用于各种目的 细分：经营，生活，交通工具 策略 Strategy 强调思维技巧，计划性，针对1~N个对手，很少涉及物理挑战 细分：4X（eXplore,eXpand,eXploit,eXterminate)（如文明），炮术，即时战略，即时战术，多人在线战术竞技，塔防，回合制策略（TBS），回合制战略，战争，大型战略 运动 Sports 细分：竞速，体育，竞技，体育格斗 其他 Others 聚会，卡牌，益智，等等等等 Tips: 文字冒险与视觉小说的区别 前者如BatMUD（鼻祖级MUD） 后者如一票日本Galgame（演示：交响乐之雨），是以各种多媒体为主，图片为主的 类银河恶魔城 突破了传统平台游戏的局限性，在传统平台游戏的基础上，任天堂的银河战士引入了非线性卷轴设计，KONOMI的恶魔城引入了RPG的部分系统，以此诞生的经典游戏类型。 演示 : Cave Story By Pixel Studio 炮术游戏 俗称打炮游戏（误），如百战天虫WMD （2016 By Team17） 课后作业略 书籍推荐：The Art of Game Design 《全景探秘 游戏设计艺术》（中文版）","categories":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/tags/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"}]},{"title":"蒙特卡罗方法","slug":"人工智能/蒙特卡罗方法","date":"2019-10-12T03:43:29.000Z","updated":"2019-10-23T01:42:01.000Z","comments":true,"path":"人工智能/蒙特卡罗方法/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/","excerpt":"采样与蒙特卡罗方法为什么要采样？比如假设我们要计算积分$\\int_a^bh(x)dx$，我们需要枚举$x∈[a,b]$，这是非常困难的；又比如使用mini-batch进行模型训练的时候需要采样 蒙特卡罗采样的思想就是在这种很难进行枚举的时候，使用采样来近似它。这种想法把和或者积分视作某分布下的期望，然后通过估计对应的平均值来近似这个期望（也就是说把原函数$h(x)$分解成某个函数与概率密度函数$p(x)$的乘积，即$f(x)$在$p(x)$分布上的均值） s = \\int_a^bh(x)dx=\\int_a^bp(x)f(x)dx=E_p(f(x))从样本集中抽取$n$个样本$(x_1,\\cdots,x_n)～p(x)$（同期望证明略，使用大数定理可证得）来近似之，则 \\int_a^bh(x)dx=E_p(f(x))≈\\frac{1}{n}\\sum_{i=1}^nf(x_i)蒙特卡罗方法是一种随机模拟技术 马尔科夫链蒙特卡罗方法（MCMC）Markov Chain Monte Carlo 马尔科夫链是随机过程中的重要角色，不多赘述 马尔科夫过程各态遍历性需要满足：①非周期 ②不可约 非周期即存在某个取值从它出发转移回自身所需要的转移次数总是整数$d(&gt;1)$的倍数，使得能够“连续”转移，这保证了马尔科夫过程的连续性，否则必须走特定步长（即周期）才能转移，使得马尔科夫过程不连续 不可约即为任意两个取值之间总是能以非零的概率相互转移 若马尔科夫过程是各态遍历的，无论初始值为何，随机变量的最终取值分布会收敛于一个唯一的平稳分布$\\pi^*$ \\lim_{t\\to ∞ }\\pi^{(0)}P^t=\\pi^*意味着马尔科夫过程经过多次转以后，随机变量的分布会一直逼近该平稳分布 可以从这个角度证明： \\pi_t=P^t\\pi_0=(Pdiag(\\lambda)P^{-1})^t\\pi_0=Pdiag(\\lambda)^tP^{-1}\\pi_0可见这个过程将导致$P$中不为1的特征值全部衰减到0，因此该过程就收敛到平稳分布 \\pi^*=\\pi P得到一个特征向量方程，收敛之后的$\\pi^*$是特征值为1所对应的特征向量 于是就可以利用马尔科夫链来进行蒙特卡罗估计，这类算法被称为马尔科夫链蒙特卡罗方法（MCMC）","text":"采样与蒙特卡罗方法为什么要采样？比如假设我们要计算积分$\\int_a^bh(x)dx$，我们需要枚举$x∈[a,b]$，这是非常困难的；又比如使用mini-batch进行模型训练的时候需要采样 蒙特卡罗采样的思想就是在这种很难进行枚举的时候，使用采样来近似它。这种想法把和或者积分视作某分布下的期望，然后通过估计对应的平均值来近似这个期望（也就是说把原函数$h(x)$分解成某个函数与概率密度函数$p(x)$的乘积，即$f(x)$在$p(x)$分布上的均值） s = \\int_a^bh(x)dx=\\int_a^bp(x)f(x)dx=E_p(f(x))从样本集中抽取$n$个样本$(x_1,\\cdots,x_n)～p(x)$（同期望证明略，使用大数定理可证得）来近似之，则 \\int_a^bh(x)dx=E_p(f(x))≈\\frac{1}{n}\\sum_{i=1}^nf(x_i)蒙特卡罗方法是一种随机模拟技术 马尔科夫链蒙特卡罗方法（MCMC）Markov Chain Monte Carlo 马尔科夫链是随机过程中的重要角色，不多赘述 马尔科夫过程各态遍历性需要满足：①非周期 ②不可约 非周期即存在某个取值从它出发转移回自身所需要的转移次数总是整数$d(&gt;1)$的倍数，使得能够“连续”转移，这保证了马尔科夫过程的连续性，否则必须走特定步长（即周期）才能转移，使得马尔科夫过程不连续 不可约即为任意两个取值之间总是能以非零的概率相互转移 若马尔科夫过程是各态遍历的，无论初始值为何，随机变量的最终取值分布会收敛于一个唯一的平稳分布$\\pi^*$ \\lim_{t\\to ∞ }\\pi^{(0)}P^t=\\pi^*意味着马尔科夫过程经过多次转以后，随机变量的分布会一直逼近该平稳分布 可以从这个角度证明： \\pi_t=P^t\\pi_0=(Pdiag(\\lambda)P^{-1})^t\\pi_0=Pdiag(\\lambda)^tP^{-1}\\pi_0可见这个过程将导致$P$中不为1的特征值全部衰减到0，因此该过程就收敛到平稳分布 \\pi^*=\\pi P得到一个特征向量方程，收敛之后的$\\pi^*$是特征值为1所对应的特征向量 于是就可以利用马尔科夫链来进行蒙特卡罗估计，这类算法被称为马尔科夫链蒙特卡罗方法（MCMC） 由于要保证各态遍历性，于是MCMC方法最适用于基于能量的模型（见上一篇笔记） 马尔科夫链的磨合过程：运行马尔科夫过程直到收敛 马尔科夫过程中的混合时间：在未收敛前的那段时间 连续的马尔科夫链也叫哈里斯链 难以预测马尔科夫链是否收敛，目前方法： ①看$P$的特征值是否趋近于0 （但通常$P^t$计算难度极大，难以表示） ②启发式方法（手动检查样本；衡量样本间的相关性） 但注意一个问题：在一个马尔科夫链的一个抽样序列无法完全表达均衡分布！ 因为在一个马尔科夫链达到平稳状态后，两个连续样本之间会高度相关。（在马尔科夫过程平稳后，$P$使得每次转移使得样本的分布不变，但是$P$会改变每一次转移后的样本的形态，但同一时间下的样本形态是高度相关的） 解决办法之一是间隔抽样，另一个是使用多条马尔科夫链，每个样本从不同的马尔科夫链抽样，在深度学习中的通用实践是选取的马尔科夫链数目和小批量中的样本数相近。 如何采样？（采样方法）对于$uniform(0,1)$，我们可以使用线性同余发生器算法LCG：$R=(A*R+B)\\%M$，推导略 对于常见的概率分布，可以使用逆采样方法，将其他概率分布映射到$uniform(0,1)$，推导略（大体思路是将CDF的反函数代入$uniform(0,1)$的概率密度函数） 这需要是常见概率分布，因为必须要求累计概率分布CDF可以求逆，所以 对于非常见概率分布，可以使用接受—拒绝采样，但对MCMC使用接受—拒绝采样效果并不好 （以上的采样方法可以以后单独写篇笔记） 那MCMC该如何采样呢？我们需要采样目标概率分布$p(x)$，而目标概率分布是由转移概率决定的，所以也就是说我们要构造一个转移概率矩阵$P$，使得$p(x)$恰好是我们想要的目标概率分布 Metropolis Hasting采样为了满足能够构造一个转移概率矩阵$P$，使得$p(x)$恰好是我们想要的目标概率分布，我们设定马尔科夫链满足细致平稳条件 \\pi(i)P_{ij}=\\pi(j)P_{ji}, \\forall i,j若满足，则马尔科夫链为平稳分布。 细致平稳条件可理解为从$i$状态转移到$j$状态的付出消耗与从$j$转移回$i$的吸收消耗相同，所以状态$i$上的概率质量$\\pi(i)$是稳定的。 那么一般情况下 p(i)q(i,j)≠p(j)q(j,i)$Q$为转移矩阵，$q$为转移概率。为了强行让它相等，即满足细致平稳条件，则设计一个$\\alpha$（称作跳转的接受率）使得$\\alpha(i,j)=p(j)q(j,i),\\alpha(j,i)=p(i)q(i,j)$（对称性） p(i)q(i,j)\\alpha(i,j)=p(j)q(j,i)\\alpha(j,i)$\\hat{Q}(i,j)=q(i,j)\\alpha(i,j),\\hat{Q}(j,i)=q(j,i)\\alpha(j,i)$ $q$称为提议概率，$Q$称为提议转移矩阵，自己选择一种简单的分布即可 于是原来的转移矩阵$Q$变成了现在可以保证细致平稳条件的转移矩阵$\\hat{Q}$，此转移矩阵的平稳分布就是$p(x)$了 以上称为Metropolis抽样 那么$\\alpha$该如何更好地取值呢？太小的话会导致拒绝率太高，收敛速度太慢。发现如果在等式两边同时扩大相同的倍数，等式依然成立，于是想到将等式两边同比例放大使得最大的一边放大到1（概率最大为1），即 \\alpha^*(i,j)=\\min\\{\\frac{\\alpha(j,i)}{\\alpha(i,j)},1\\}=\\min\\{\\frac{p(j)q(j,i)}{p(i)q(i,j)},1\\}（这里的推导：当$\\alpha(i,j)&gt;\\alpha(j,i),则\\alpha(i,j)先到1，\\alpha^(j,i)=\\frac{1}{\\alpha(i,j)}·\\alpha(j,i)&lt;1$ *缩放 当$\\alpha(j,i)&gt;\\alpha(i,j),则\\alpha(j,i)先到1，\\alpha^(i,j)=\\frac{\\alpha(i,j)}{\\alpha(j,i)}$ *缩放 整合上两式记得上面的等式） 于是$p(x)$是目标平稳概率分布，自设已知；$q(x)$为提议概率分布，自设已知，那么就可以求出转移概率$\\alpha$了 从$uniform(0,1)$中采样$u$，如果$u&lt;\\alpha(i,j)$，（相当于在拒绝采样中，随机采样点落入函数范围内），则该跳转成功，否则该跳转失败，以此迭代（这里使用接受-拒绝采样算法的思想，用提议转移矩阵$Q$去求得转移矩阵$\\hat{Q}$） 这就是Metropolis Hasting采样算法 算法如下： Gibbs采样（深度学习中的最佳选择）针对高维的情形，发现在高维情况下自然成立一个式子使得细致平稳条件成立，也就可以不拒绝，使得收敛迅速。Gibbs采样每一步都只更新变量的一个小部分 对平面上任意两点$X,Y$ p(X)=Q(X,Y)=p(Y)Q(Y,X) ​","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"采样","slug":"采样","permalink":"https://aisaka.cloud/tags/%E9%87%87%E6%A0%B7/"},{"name":"数学","slug":"数学","permalink":"https://aisaka.cloud/tags/%E6%95%B0%E5%AD%A6/"},{"name":"统计数学","slug":"统计数学","permalink":"https://aisaka.cloud/tags/%E7%BB%9F%E8%AE%A1%E6%95%B0%E5%AD%A6/"},{"name":"马尔科夫链","slug":"马尔科夫链","permalink":"https://aisaka.cloud/tags/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE/"}]},{"title":"深度学习中的结构化概率模型","slug":"人工智能/深度学习中的结构化概率模型","date":"2019-10-11T02:28:45.000Z","updated":"2019-10-23T01:42:07.000Z","comments":true,"path":"人工智能/深度学习中的结构化概率模型/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BB%93%E6%9E%84%E5%8C%96%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/","excerpt":"本文为 Deep Learning Ch.16 学习后整理的笔记 结构化概率模型概率图模型（PGM）描述概率有助于减少表示概率分布，学习和推断的成本。间接表示间接关系而不是直接表示 有向图模型=信念网络=贝叶斯网络方向仅表示依赖关系而不表明如何依赖 通过有向无环图和一系列局部条件概率分布定义 p(x)=\\prod_ip(x_i|P(x_i))其中$P(x_i)$表示结点$x_i$的所有父节点。 无向图模型=马尔可夫随机场=马尔科夫网络对无向模型$M$中的一个团$C$称为一个因子$\\phi(C)$，也叫团势能，势能函数 它们一起定义了未归一化概率函数： p(\\hat{x})=\\prod_{C∈M}\\phi(C)(图的一个团是图中结点的一个子集，并且其中的点是全连接的) 为了使得未归一化概率函数归一化，我们需要使用对应的归一化概率分布 p(x)=\\frac{1}{Z}\\hat{p(x)}其中$Z$是使得所有概率之和或者积分为1的常数，且满足 Z=\\int \\hat{p}(x)dx归一化常数$Z$被称为配分函数。计算$Z$需要对$x$的所有可能状态求联合概率分布，所以通常非常难计算，于是可以用一些近似方法求得。 但有时候积分是发散的，不存在一个$F(x)$，这时候$Z$就不存在 但注意如果指定发散函数的某定义域内是收敛的，那是OK的 无向图在表示上存在模糊性，即“多大的团？”，这时候可以引入因子图解决，它将随机变量绘为圆形，将未归一化概率函数因子$\\phi$绘为方形，仅当随机变量对应该函数因子的时候存在连接，连接该函数的随机变量构成一个团 基于能量的模型(Energy-Based model,EBM)无向模型依赖一个假设$\\forall x,\\hat{p}(x)&gt;0$，使得这个条件满足的一个简单方式是使用EBM \\hat{p}(x)=e^{-E(x)}服从该形式的任意分布都是玻尔兹曼分布的一个实例，也因此我们把许多基于能量的模型成为玻尔兹曼机 $E(x)$被称作能量函数(energy function) 由于$e^{(a+b)}=e^a·e^b$，于是可以发现无向模型中不同的团对应于能量函数的不同项，也就是说EBM只是一种特殊的马尔科夫网络，这种网络满足求幂使能量函数中的每项对应于不同团的一个影子。 比如对于一个MAP d-a-b-e,b-e,e-f(只写了连接关系)，通过为每个团选择适当的能量函数$E(a,b,c,d,e,f)$可以写成$E_{a,b}(a,b)+E_{b,c}(b,c)+E_{a,d}(a,d)+E_{b,e}(b,e)+E_{e,f}(e,f)$ 能量函数可以视为专家之积，其中每一项看作决定一个特定的软约束是否满足的“专家” 公式中幂的负号只是为了保持机器学习文献与物理学文献之间的兼容性（能量无符号），对于机器学习来说可以自由决定符号 很多对概率模型进行操作的算法是计算$\\log p(x)$的，于是对于具有潜变量$h$的EBM，这些算法有时会将该量的负数称为自由能(free energy)： F(x)=-\\log \\sum_h e^{-E(x,h)}","text":"本文为 Deep Learning Ch.16 学习后整理的笔记 结构化概率模型概率图模型（PGM）描述概率有助于减少表示概率分布，学习和推断的成本。间接表示间接关系而不是直接表示 有向图模型=信念网络=贝叶斯网络方向仅表示依赖关系而不表明如何依赖 通过有向无环图和一系列局部条件概率分布定义 p(x)=\\prod_ip(x_i|P(x_i))其中$P(x_i)$表示结点$x_i$的所有父节点。 无向图模型=马尔可夫随机场=马尔科夫网络对无向模型$M$中的一个团$C$称为一个因子$\\phi(C)$，也叫团势能，势能函数 它们一起定义了未归一化概率函数： p(\\hat{x})=\\prod_{C∈M}\\phi(C)(图的一个团是图中结点的一个子集，并且其中的点是全连接的) 为了使得未归一化概率函数归一化，我们需要使用对应的归一化概率分布 p(x)=\\frac{1}{Z}\\hat{p(x)}其中$Z$是使得所有概率之和或者积分为1的常数，且满足 Z=\\int \\hat{p}(x)dx归一化常数$Z$被称为配分函数。计算$Z$需要对$x$的所有可能状态求联合概率分布，所以通常非常难计算，于是可以用一些近似方法求得。 但有时候积分是发散的，不存在一个$F(x)$，这时候$Z$就不存在 但注意如果指定发散函数的某定义域内是收敛的，那是OK的 无向图在表示上存在模糊性，即“多大的团？”，这时候可以引入因子图解决，它将随机变量绘为圆形，将未归一化概率函数因子$\\phi$绘为方形，仅当随机变量对应该函数因子的时候存在连接，连接该函数的随机变量构成一个团 基于能量的模型(Energy-Based model,EBM)无向模型依赖一个假设$\\forall x,\\hat{p}(x)&gt;0$，使得这个条件满足的一个简单方式是使用EBM \\hat{p}(x)=e^{-E(x)}服从该形式的任意分布都是玻尔兹曼分布的一个实例，也因此我们把许多基于能量的模型成为玻尔兹曼机 $E(x)$被称作能量函数(energy function) 由于$e^{(a+b)}=e^a·e^b$，于是可以发现无向模型中不同的团对应于能量函数的不同项，也就是说EBM只是一种特殊的马尔科夫网络，这种网络满足求幂使能量函数中的每项对应于不同团的一个影子。 比如对于一个MAP d-a-b-e,b-e,e-f(只写了连接关系)，通过为每个团选择适当的能量函数$E(a,b,c,d,e,f)$可以写成$E_{a,b}(a,b)+E_{b,c}(b,c)+E_{a,d}(a,d)+E_{b,e}(b,e)+E_{e,f}(e,f)$ 能量函数可以视为专家之积，其中每一项看作决定一个特定的软约束是否满足的“专家” 公式中幂的负号只是为了保持机器学习文献与物理学文献之间的兼容性（能量无符号），对于机器学习来说可以自由决定符号 很多对概率模型进行操作的算法是计算$\\log p(x)$的，于是对于具有潜变量$h$的EBM，这些算法有时会将该量的负数称为自由能(free energy)： F(x)=-\\log \\sum_h e^{-E(x,h)} 分离与d-分离—条件独立无向图中隐含的条件独立性称为分离，有向图中则被称为d-分离。（d代表依赖） 如何判断哪些变量子集（d-）分离/彼此条件独立？ ①两个随机变量之间没有路径，或 ②两个随机变量之间所有路径都包含可观测变量 举个例子：一个房子的好坏（C）是由大小（A）和装潢（B）决定的，此时的图结构为A-&gt;C,B-&gt;C，如果我们知道了这个房子是好房子，也就是C为可观测变量（条件），那么A和B是C条件下的独立随机变量 记$a⊥b|c$表示给定$c$条件下$a$与$b$条件独立 关于图模型条件独立的推导可以看这篇文章 https://my.oschina.net/liyangke/blog/2986515 有向图和无向图的转化 有向模型和无向模型的一个重要区别在于有向模型是通过从起始点的概率分布直接定义的，而无向模型的定义显得更加宽松，通过$\\phi$函数转化为概率分布定义 有向图可以使用不道德图结构而无向图不行 将有向模型图转换为无向模型图：①有向边变无向边 ②对于不道德（immorality)情况(a$\\to$c，b$\\to$c）需要在不道德的节点互相连线，变成道德图。由于道德化的过程中会加入很多边，因而会损失一些独立性条件 无向图可以使用环结构而有向图不行 将环结构的无向图转化为有向图需要添加弦（环序列中任意两个非连续变量的连接），转化后的图称为弦图或三角形化图。但如果存在长度大于3的环，则转化过来会损失独立性条件。（注意不能出现有向环，否则无法定义有效的有向概率模型） 从图模型中采样 有向图：原始采样，根据拓扑排序顺序采样。 缺点：不是每次采样都是条件采样操作 无向图：①转化为有向图作原始采样 ​ ②Gibbs采样 有已知值的变量被称为显变量，而值未被观察到的变量被称为隐变量 深度学习模型可以看作一类特殊的图概率模型，拥有大量的潜变量，且在设计的时候不表示任何特定含义；而传统模型大多使用高阶项和结构学习来捕获变量之间复杂的非线性作用，即使有潜变量，数量也通常很少，且会被赋予特定的含义 潜变量=隐变量=未观测变量","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"https://aisaka.cloud/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"}]},{"title":"Autoencoder","slug":"人工智能/Autoencoder","date":"2019-10-09T11:52:07.000Z","updated":"2019-10-23T01:43:45.000Z","comments":true,"path":"人工智能/Autoencoder/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Autoencoder/","excerpt":"","text":"AutoencoderAE可以看为一个单隐藏层的NN 目标函数为重构误差（reconstruction error)，目标是使得解码器的输出与编码器的输入同分布 隐藏层单元数&lt;输入层单元数即可用于降维，如果编码的激活函数为线性函数就成为了PCA 但现在一般隐藏层单元数&gt;=输入层单元数比较多，这样可以挖掘更多高维特征，但容易造成神经网络的输出为输入的直接“复制”，为了解决这个问题，引入了正则和随机性等等，且可以组合使用 Regularized Autoencoder正则项自编码器 神经网络的输入直接“复制”输出的一个具体表现就在于一些神经元权重过大，使得神经网路直接变成直连通路 于是可以直接向损失函数正则项 L(x,g(f(x)))+\\Omega(h)实现方法：使用传统的加入正则项实现方法 Sparse Autoencoder稀疏自编码器 使得参数变得稀疏，避免过多神经元被激活 引入稀疏度公式 \\hat{\\rho}_j = \\frac{1}{N} \\Sigma_{i=1}^N h_j(x^{(i)})此公式计算了第$j$个神经元在训练集$\\{x^{i}\\}$上激活度的平均值，那么就可以取一个足够小的$\\rho$，保证$\\hat{\\rho}_j=\\rho,j=1,2,3,\\cdots$ 对于$\\hat{\\rho}_j&gt;&gt;\\rho$，对其使用KL散度进行惩罚，KL散度可以用于衡量两个分布的相似度（在前面这篇论文的阅读笔记：Explaining and Harnessing Adversarial Examples中使用到了这个数学工具。 向损失函数中加入KL散度 J=L(x,g(f(x)))+\\Sigma_{j=1}^mKL(\\hat{\\rho}_j||\\rho) KL(\\hat{\\rho}_j||\\rho)=\\rho·\\log \\frac{\\rho}{\\hat{\\rho}_j}+(1-\\rho)·\\log \\frac{1-\\rho}{1-\\hat{\\rho}_j}实现方法：可以设置一个三维矩阵，第一维为$||\\{x^{(i)}\\}||$，第二和第三维对应神经网络每一个神经元。然后在数据流经一次模型后抽取出每一层神经元的参数，作平均。抽取方法可以用我以前写的pytorch获取中间层参数、输出与可视化/一文中提到的中间层参数可视化方法 Denoising Autoencoder降噪自编码器（DAE） 向输出加入噪声$\\hat{x}$，并设置损失函数尽量减少输出的噪声，目标使得模型学习重构分布$p_{decoder}(x|\\hat{x})$，增强模型健壮性 最小化 L(x,g(f(\\hat{x})))也就是要使得正确输入与加噪声的输入经过模型后还原得到的输出尽量一样 实现方法：加入噪声的方法可以有多种，比如增加高斯分布随机扰动$x\\to x+\\epsilon,\\epsilon ～ N(μ,\\sigma^2)$，也可以使用掩码方法遮蔽部分特征 补充：得分匹配是最大似然的代替。它提供了概率分布的一致性估计，使得模型在各个数据点$x$上获得与数据分布相同的得分，在这种情况下，得分是一个特定的梯度场： \\nabla_x\\log p(x)DAE的训练目标可以使得AE学到能估计数据分布得分的向量场$(g(f(x))-x)$ Contractive Autoencoder收缩自编码器(CAE) 是正则自编码器的一个变形，将正则项设置为惩罚导数——隐藏层函数对输入求导，也即其Jacobi矩阵$J_h$ J=L(x,g(f(x)))+\\lambda\\Sigma_i||\\nabla_xh_i||_F^2注意这里是矩阵的F-范数，即矩阵每项平方求和 可以看出收缩惩罚目标是使得学习到的参数在所有方向上不变，而是在整体上进行参数的缩放，其使得函数梯度很小，所以能够很好的学习到流形结构，（而使得$J_x$很大的方向$x$，会快速改变$h$，则很可能是近似流形切平面的方向）","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"自编码器","slug":"自编码器","permalink":"https://aisaka.cloud/tags/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/"}]},{"title":"行って、振り向かないで","slug":"日记/不要回头，一直向前","date":"2019-10-03T10:40:27.000Z","updated":"2019-10-15T15:57:19.000Z","comments":true,"path":"日记/不要回头，一直向前/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%B8%8D%E8%A6%81%E5%9B%9E%E5%A4%B4%EF%BC%8C%E4%B8%80%E7%9B%B4%E5%90%91%E5%89%8D/","excerpt":"","text":"“不要回头，一直向前 ” ——《千与千寻的神隐》","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"另一种提取中间层输出的办法与风格迁移的改进","slug":"人工智能/另一种提取中间层输出的办法与风格迁移的改进","date":"2019-09-30T04:38:19.000Z","updated":"2019-10-23T01:44:02.000Z","comments":true,"path":"人工智能/另一种提取中间层输出的办法与风格迁移的改进/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%8F%90%E5%8F%96%E4%B8%AD%E9%97%B4%E5%B1%82%E8%BE%93%E5%87%BA%E7%9A%84%E5%8A%9E%E6%B3%95%E4%B8%8E%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%E7%9A%84%E6%94%B9%E8%BF%9B/","excerpt":"提取中间层输出除了在我前面的文章pytorch获取中间层参数、输出与可视化 提到的使用hook函数获取中间层输出以外，还可以用更直接的办法，不使用hook函数 方法一：将model中的每层拆解出来依次在监控下让数据流过可以借助isinstance(layer, nn.Conv2d)判断层类型 def extract_layers(layers,img,model): layer_index &#x3D; 0 res &#x3D; [] for layer in model: if layer_index &#x3D;&#x3D; 0: out &#x3D; layer(img) else: out &#x3D; layer(out) if layer_index in layers: res.append(out) layer_index +&#x3D; 1 return res 方法二：直接在定义模型的时候输出中间层数据 class model(nn.Module): def __init__(self): super().__init__() self.linear1 = nn.Linear(64,32) self.linear2 = nn.Linear(32,16) def forward(self,input): linear1_out = self.linear1(input) linear2_out = self.linear2(linear1_out) return linear1_out,linear2_out 对于噪点的改进-降噪修改方程，向方程中加入总变差损失(total variation denoising) L_{total}(S,C,G) = \\alpha L_{content}(C,G)+\\beta L_{style} (S,G)+\\gamma L_{noise}(C,G) L_{noise}(C,G)=\\Sigma_{i,j}|x_{i,j}-x_{i+1,j}|+|x_{i,j}-x_{i,j+1}|class TotalVariationLoss(nn.Module): def __init__(self,weight): super().__init__() self.weight = weight def forward(self,inputs): #矩阵计算，一步到位 loss = 0.5*((inputs[:, :, 1:, :]-inputs[:, :, :-1, :]).abs().mean()+(inputs[:, :, :, 1:]-inputs[:, :, :, :-1]).abs().mean()) return loss * self.weight 在loss function中对应作修改 #总变差损失计算 noise_loss = TotalVariationLoss(noise_weight) noise_loss_this = noise_loss(input_param) loss = style_loss_this + content_loss_this + noise_loss_this","text":"提取中间层输出除了在我前面的文章pytorch获取中间层参数、输出与可视化 提到的使用hook函数获取中间层输出以外，还可以用更直接的办法，不使用hook函数 方法一：将model中的每层拆解出来依次在监控下让数据流过可以借助isinstance(layer, nn.Conv2d)判断层类型 def extract_layers(layers,img,model): layer_index &#x3D; 0 res &#x3D; [] for layer in model: if layer_index &#x3D;&#x3D; 0: out &#x3D; layer(img) else: out &#x3D; layer(out) if layer_index in layers: res.append(out) layer_index +&#x3D; 1 return res 方法二：直接在定义模型的时候输出中间层数据 class model(nn.Module): def __init__(self): super().__init__() self.linear1 = nn.Linear(64,32) self.linear2 = nn.Linear(32,16) def forward(self,input): linear1_out = self.linear1(input) linear2_out = self.linear2(linear1_out) return linear1_out,linear2_out 对于噪点的改进-降噪修改方程，向方程中加入总变差损失(total variation denoising) L_{total}(S,C,G) = \\alpha L_{content}(C,G)+\\beta L_{style} (S,G)+\\gamma L_{noise}(C,G) L_{noise}(C,G)=\\Sigma_{i,j}|x_{i,j}-x_{i+1,j}|+|x_{i,j}-x_{i,j+1}|class TotalVariationLoss(nn.Module): def __init__(self,weight): super().__init__() self.weight = weight def forward(self,inputs): #矩阵计算，一步到位 loss = 0.5*((inputs[:, :, 1:, :]-inputs[:, :, :-1, :]).abs().mean()+(inputs[:, :, :, 1:]-inputs[:, :, :, :-1]).abs().mean()) return loss * self.weight 在loss function中对应作修改 #总变差损失计算 noise_loss = TotalVariationLoss(noise_weight) noise_loss_this = noise_loss(input_param) loss = style_loss_this + content_loss_this + noise_loss_this 风格迁移的其它损失函数优化算法我最先采用的LBFGS算法是因为原论文是使用的该算法，使用LBFGS的优点在于能够快速收敛，但缺点也很明显，非常耗显存，图片大一点的话泰坦的12G显存迅速被耗尽 另外以下为两种优化算法对同样风格层迁移效果的对比 原图：风格图： LBFGS：Adam： Denoise Adam： 加入降噪训练之后效果好很多","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"风格迁移","slug":"风格迁移","permalink":"https://aisaka.cloud/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"}]},{"title":"Redis持久化","slug":"数据库与中间件/Redis持久化","date":"2019-09-28T15:52:38.000Z","updated":"2020-04-28T15:55:57.000Z","comments":true,"path":"数据库与中间件/Redis持久化/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志","text":"Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志 快照（RDB）快照是一次全量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑。快照方式采用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化。（因为快照化遍历数据，需要进行IO操作，而Redis 单线程IO的，这样就没法处理客户端请求了；而且由于数据还会被客户端修改；所以直接本地化是行不通的）COW机制先fork一个子进程，与父进程共享资源；子进程完全负责持久化工作，它遍历数据；此时当父进程的数据被修改的时候，由COW机制来进行数据段页面的分离：数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。 缺点：RDB由于保存一次是要保存整个数据库，那么很可能就会出现保存这段时间出现数据丢失；而且当修改量大的时候，RDB相对比较占内存资源。 AOFAOF 日志是连续的增量备份。AOF 日志记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令（相当于减少冗余操作指令），序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。fsync：AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。Linux 的glibc提供了fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失（即操作了立即写到日志）。但是 fsync 是一个磁盘 IO 操作，非常慢，所以需要综合考量fsynv频率。 缺点：占用磁盘空间大；根据fsync策略，速度可能会慢于RDB 混合持久化在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"拟牛顿法","slug":"人工智能/拟牛顿法","date":"2019-09-26T08:04:01.000Z","updated":"2019-10-31T04:51:16.000Z","comments":true,"path":"人工智能/拟牛顿法/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95/","excerpt":"","text":"思想牛顿法中最困难的部分在于计算$H$和$H^{-1}$ 拟牛顿法的思想就是不用二阶偏导数而构造出可以近似$H$和$H^{-1}$的正定对称矩阵，在拟牛顿的条件下优化目标函数。但是不可能随便一个矩阵都能近似$H$，所以我们要给近似矩阵开一个条件，也就是下面的拟牛顿条件 拟牛顿条件由上一篇我写的文章可知（依然省略掉高阶导数无穷项，实际上应该用$≈$，为了方便这里都用$=$了 \\nabla f(x)=g_{k+1}+H_{k+1}(x-x_{k+1})设$x=x_k$ 记$s_k=x_{k+1}-x_k,y_k=g_{k+1}-g_k$ $\\therefore y_k=H_{k+1}\\cdot s_k$ 或$s_k=H^{-1}_{k+1}\\cdot y_k$ 此即为拟牛顿条件 选择合适的$B_{k+1}$做$H_{k+1}$的近似，合适的$D_{K+1}$做$H^{-1}_{k+1}$的近似，使他们满足拟牛顿条件即可 相当于给拟合$H，H^{-1}$做了一个约束，使得在$f(x_k)与f(x_{k+1})$拟合矩阵与真实矩阵的一阶导相等 以下不同的算法实际上就是设计拟合矩阵的算法 DFP算法DFP算法通过迭代的方法对$D_{K+1}$做$H^{-1}_{k+1}$的近似 主要设置$D_k$待定形式为 \\Delta D_k=\\alpha uu^T+\\beta vv^T推导过程类似BFGS算法，略，见下 D_{k+1}=D_{k}+\\frac{s_ks_k^T}{s_k^Ty_k}-\\frac{D_ky_ky_k^TD_k}{y_k^TD_ky_k},k=0,1,2,\\cdots一般$D_0=I$ BFGS算法BFGS算法通过迭代的方法对$B_{K+1}$做$H_{k+1}$的近似，直接逼近Hessian矩阵 采用迭代法 B_{k+1}=B_k+\\Delta B_k,k=0,1,2,\\cdots一般$B_0=I$ 设置$B_k$的待定形式 \\Delta B_k=\\alpha uu^T+\\beta vv^T$uu^T$和$vv^T$正好构成对称矩阵 代入$y_k=H_{k+1}\\cdot s_k$中（$B_{k+1}$逼近$H_{k+1}$）得 y_k=(B_k+\\alpha uu^T+\\beta vv^T)\\cdot s_k =B_ks_k+\\alpha u^Ts_k\\cdot u+\\beta v^ts_k\\cdot v$u^Ts_k$和$v^Ts_k$都是常数，不妨令$\\alpha u^Ts_k=1,\\beta v^ts_k=-1,u=y_k,v=B_ks_k$, \\therefore \\alpha=\\frac{1}{y_k^Ts_k},\\beta=-\\frac{1}{s_k^TB_ks_k} \\therefore \\Delta B_k=\\frac{y_ky_k^T}{y_k^Ts_k}-\\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}但由于必须储存$D$，使得储存开销很大，不适用大数据大型模型 LBFGS算法通过避免储存完整的Hessian逆运算近似$D$,降低BFGS的储存代价","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"牛顿法求解非线性优化","slug":"人工智能/牛顿法求解非线性优化","date":"2019-09-26T02:02:25.000Z","updated":"2019-10-31T04:51:13.000Z","comments":true,"path":"人工智能/牛顿法求解非线性优化/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%89%9B%E9%A1%BF%E6%B3%95%E6%B1%82%E8%A7%A3%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/","excerpt":"","text":"前面在风格迁移的时候用到了LBFGS，很好奇只需要设置一个闭包迭代即可，不需要像动量算法等一阶优化算法一样设置步长学习率等，于是系统地去了解了一下牛顿法与拟牛顿法 牛顿法首先回想起泰勒展开，此式子即为$f(x)$在$x_k$附近的二阶泰勒展开式 \\phi(x) =f(x_k)+f'(x_k)(x-x_k)+\\frac{1}{2}f''(x_k)(x-x_k)^2+O令导数为0即可求得最值 \\phi'(x)=0省略掉高阶项，则 f'(x_k)+f''(x_k)(x-x_k)=0$\\therefore$ x = x_k-\\frac{f'(x_k)}{f''(x_k)},k=0,1,2,···于是我们就可以从初始$x_0$值开始用此式进行迭代来逼近极小值点，其逼近就是在每次迭代的时候直接跳到近似函数的最小点 那么对于高维度的情形，原泰勒公式就可以表示为 \\phi(X) = \\nabla f(X_k)·(X-X_k)+\\frac{1}{2}(X-X_k)^T·\\nabla^2f(X_k)·(X-X_k)这里的$\\nabla^2 f(X_k)$即为Hessian矩阵，其实就是二阶梯度 \\nabla^2 f(X_k)= \\begin{bmatrix} {\\frac{\\partial^2 f}{\\partial x_1^2}}&{\\frac{\\partial^2 f}{\\partial x_1\\partial x_2}}&{\\cdots}&{\\frac{\\partial^2 f}{\\partial x_1\\partial x_n}}\\\\ {\\frac{\\partial^2 f}{\\partial x_2\\partial x_1}}&{\\frac{\\partial^2 f}{\\partial x_2^2}}&{\\cdots}&{\\frac{\\partial^2 f}{\\partial x_2\\partial x_n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {\\frac{\\partial^2 f}{\\partial x_n\\partial x_1}}&{\\frac{\\partial^2 f}{\\partial x_2^2}}&{\\cdots}&{\\frac{\\partial^2 f}{\\partial x_n\\partial x_n}}\\\\ \\end{bmatrix}$\\nabla f(X_k)$就是一阶梯度，不展开了 因为Hessian矩阵是实对称矩阵，我们可以将其分解为一组实特征值和一组特征向量的正交基。在特定方向$d$的二阶导数可以写成$d^THd$。 当$d$是$H$的一个特征向量的时候，这个方向的二阶导数就是对应的特征值。对于其他方向$d$，方向二阶导数是所有特征值的加权平均，权重在0和1之间，且与$d$夹角越小的特征值权重越大。最大特征值确定最大二阶导数，最小特征值确定最小二阶导数。 记$g_k=\\nabla f(X_k)$,$H_k=\\nabla^2 f(X_k)$， \\nabla \\phi(X)=0则 g_k+H_k(X-X_k)=0$H_k$必为非奇异矩阵（满秩矩阵） $\\therefore$ X = X_k-H_k^{-1}·g_k ,k=0,1,2,\\cdots此即为牛顿法的迭代式，$d_k=-H_k^{-1}·g_k$称为牛顿方向 牛顿法求出的方向是一个逼近，因为其省略了泰勒的高阶展开项（但如果是二次函数，那就不是逼近了，这时候Hessian矩阵退化为常数矩阵，只需要一次运算即可到达最优点） 缺陷 使用牛顿法可以比一阶优化算法更快的收敛，因为每次它都是直接跳到近似函数的最小点（对于二次函数，直接一步收敛），但是这种特性在鞍点附近会造成病态。 会造成局部收敛 Hessian矩阵的计算量是其它一阶优化方法的平方倍，所以对硬件计算负担要求极高 由于步长是定的，所以牛顿方向$-H_k^{-1}·g_k$并不能保证稳定下降，其并不是梯度下降算法 函数必须二阶可导，Hessian矩阵必须为正定矩阵 深度学习通常都有很多局部极值，鞍点，且计算量巨大，所以很少在深度学习中使用牛顿法 改进 针对第四个缺陷，可以对其进行改进，加入线搜索，称作阻尼牛顿法，这个思想和动量算法思想一样 仍然用$d_k$在方向上进行迭代，但是每次迭代的时候需要进行一次线搜索，寻求最优步长因子$\\lambda_k $ $d_k\\to\\lambda_k d_k$ $\\lambda_k=arg\\min f(x_k+\\lambda_k d_k)$ 可以通过多种手段避免直接对Hessian矩阵求逆 比如共轭梯度法（PCG），代数多重网格法（AMG）等 补充PCG思想：结合梯度下降与牛顿法，在一个方向上用牛顿法，一次性迭代完，理论上N个方向N次即可收敛 拟牛顿法","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"非线性优化","slug":"非线性优化","permalink":"https://aisaka.cloud/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/"}]},{"title":"骚动时节的少女们啊","slug":"Anime/骚动时节的少女们啊","date":"2019-09-25T10:30:48.000Z","updated":"2019-09-25T10:48:50.000Z","comments":true,"path":"Anime/骚动时节的少女们啊/","link":"","permalink":"https://aisaka.cloud/Anime/%E9%AA%9A%E5%8A%A8%E6%97%B6%E8%8A%82%E7%9A%84%E5%B0%91%E5%A5%B3%E4%BB%AC%E5%95%8A/","excerpt":"","text":"应该是老马失蹄的最惨的一次 没想到后半段开始一路血崩… 这就是部青春期性教育重要性的宣传片.. 前八集非常不错，冈妈将细腻与敏感的初春体现的淋漓尽致 但是第八集之后，至少我是理解不能…… 冈妈把关于性和爱的模糊不清的这种情感无限夸大 ，然后非常魔幻地表达出来，造成一种非常尴尬的效果，把非常抽象的东西用现实的手段生硬地表现出来造成了极强的违和感 还有白毛和矮子这俩能不能删了orz 前8集9分 ，后几集2分 ，加权一下，6.7分","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"新番","slug":"新番","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E7%95%AA/"}]},{"title":"IOS开发小记","slug":"开发/XCODE开发小记","date":"2019-09-25T09:23:04.000Z","updated":"2019-10-23T04:08:18.000Z","comments":true,"path":"开发/XCODE开发小记/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/XCODE%E5%BC%80%E5%8F%91%E5%B0%8F%E8%AE%B0/","excerpt":"","text":"最近老师想要给一个去中心链的IM开发几个功能，安卓端有人做，但我们实验室没人开发过IOS，老师想起我面试的时候提到过我大二做过IOS开发，就让我这个月搞出来，然后… 不愧是世界上最难用的IDE，回想起了大二被XCODE支配的恐惧 因为当时没用pods管理第三方库…以下踩坑记录 使用CocoaPod管理依赖的项目，XCode只能使用workspace编译项目，如果还只打开以前的xcodeproj文件进行开发，编译会失败。新增的workspace文件会引用原有的应用主工程，还会引用新增的Pods工程 如果 PODS生成的静态链接库没有被主工程target链接，要自己手动建立链接 在头文件搜索路径里 xxx/xxx/ re… 别忘了加\\并设置迭代搜索 build后修改代码，需要build clean再重新build，不然会报上次一样的错 要检查头文件路径是否正确，或者直接写”.h”，则xcode会直接在头文件搜索路径里搜索 mac自带的ruby权限较小，开发不要用这个。我们要自己安装rvm并创建ruby环境，随后我们的cocoapods是在这个环境使用的 respondsToSelector 用来判断某一个方法时候实现 #如果destroy这个方法实现了，就执行之 if ([subViewController respondsToSelector:@selector(destroy)]) &#123; [subViewController destroy]; &#125; UINavigationController 导航控制器 开发的时候一般都是多控制器，由一个父控制器管理多个子控制器 一般都是在Appdelegate中生成（可以将Nav写在一个VC中，然后在Appdelegate中实例化这个VC） 使用方法： 初始化UINavigationController实例 在AppDelegate中设置一个根控制器，即设置self.window.rootViewController=UINavigationController（在AppDelegate中设置,self指的appdelegate） 通过push方法添加需要的子控制器 在初始化UINavagationController的时候调用构造方法initWithRootViewController:就会自动push自己设定的根控制器，但其它view就要创建后手动push 当前view所属控制器self.navigationController 控制器跳转：[self.navigationController pushViewController:xxxViewController animated:YES] 压入(push)控制器：-(void)pushViewController:(UIViewController *)viewController animated:(BOOL)animated; 移除(pop)栈顶控制器:-(UIViewController *)popViewControllerAnimated:(BOOL)animated;即可返回上一层控制器 回到(popTo)指定子控制器:-(NSArray *)popToViewController:(UIViewController *)viewController animated:(BOOL)animated; 回到根(popToRoot)控制器（栈底）:-(NSArray *)popToRootViewControllerAnimated:(BOOL)Animated; 一次压入多个控制器setViewController 栈顶控制器nav.topViewController 当前可见视图控制器nav.visibleViewController ViewController相关 根据名字获取VC：_homeViewController = self.viewControllers[TABBAR_HOME_INDEX]; 账户登入状态等信息可以用单例模式来管理 AppDelegate负责管理程序周期，是程序入口 如-(BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions 这里就是程序launch完后做的事情，这时候就可以初始化Root VC了 协议 接口 委托 委托：A委托B去做某事，B如果没有这个方法，B从C继承，C有这个方法，就会执行C中的该方法（与java一样的向上转型） A是B的委托对象 B引用一个A A将实现B的委托方法 B通过委托方法通知 接口：接口就相当于一个头文件，告诉外部可以用，联想生物细胞的构造 在h文件里写@interfacae，在m文件里实现该interface，就相当于建立了一个类，只有interface暴露的东西才能被外部使用，这种设计是为了更好的安全性 java类和oc类的核心区别在于，java类的共有私用是由类里面自己实现的，可以设置共私有变量和方法，而OC中每个类都是由一个接口interface和实现该interface的类来完成，只有interface中的东西暴露给了外部 协议：协议可以类比java中的interface Universal Link, 中文是通用链接. 可以通过http(s)来唤醒App prepareForSegue:sender: 为了区分视图的跳转，可以用上一个、下一个来表示，也可以用源视图、目标视图来表示。 即： sourceViewController 和destinationViewController。 目标视图控制器是指：即将显示（加载）的视图， 而源视图控制器是指：即将被取代的视图控制器。 跳转总结 https://www.jianshu.com/p/ceaf978f9dfe","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"},{"name":"IOS开发","slug":"开发/IOS开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/IOS%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"https://aisaka.cloud/tags/IOS/"},{"name":"XCODE","slug":"XCODE","permalink":"https://aisaka.cloud/tags/XCODE/"}]},{"title":"Redis集群","slug":"数据库与中间件/Redis集群简介","date":"2019-09-22T16:21:59.000Z","updated":"2020-05-01T16:03:51.000Z","comments":true,"path":"数据库与中间件/Redis集群简介/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E9%9B%86%E7%BE%A4%E7%AE%80%E4%BB%8B/","excerpt":"集群，虽然没用过，但了解一下…","text":"集群，虽然没用过，但了解一下… 主从同步 主从同步是分布式的基础 分布式基础理论：CAP原理 C - Consistent ，一致性 A - Availability ，可用性 P - Partition tolerance ，分区容忍性 网络分区：分布式系统的结点断开网络 一句话概括 CAP 原理就是——网络分区发生P时，一致性C和可用性A两难全。 Redis保证最终一致性 Redis主从同步： ①增量复制（增量同步）：增量追赶，写指令流同步（从库执行指令流） 维持一个指令buffer（是个环形数组） ②全量复制（快照同步）：增量太慢了，指令buffer塞满旧指令还没同步就被覆盖，所以要全量追赶，即快照同步；指令bgsave ③无盘复制（快照同步）：进行快照同步的时候，跨越对磁盘的IO操作（快照化，负荷很高），而是直接通过socket传给从结点，然后结点将接收到的内容存入磁盘再加载快照 前面三个都是异步复制，下面的wait是同步复制 ④wait指令：主从同步wait之前的指令，是阻塞的，这时候不可用 生产快照是一个遍历的过程 主从主要是为了保障Redis的高可用性，同时也能兼顾提升性能 增量同步的buffer要合适，否则一直赶不上指令增加的速度，那就得经常全量复制，影响效率 如果redis只是做缓存，则无需做主从同步 集群方案：Sentinel哨兵——自动主从切换可以将Redis Sentinel 集群看成是一个 ZooKeeper 集群 sentinel的作用： 监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。 提供集群内节点的IP地址给客户端访问（客户端该访问集群中哪台服务器由sentinel决定） 客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。 可以控制何时停止对外服务（可用性丧失） 比如可以规定当还有多少从结点可用的时候才对外提供服务，以及延迟为多少判断从节点可用 集群方案：CodisCodis是中心化的，Codis作为代理。 为什么要聚集多个Redis实例？因为单个Redis实例都是单核心单线程的。 Codis将众多小内存的 Redis 实例综合起来，将分布在多台机器上的众多 CPU 核心的计算能力聚集到一起，完成海量数据存储和高并发读写操作。 Codis 上挂接的所有 Redis 实例构成一个 Redis 集群，当集群空间不足时，可以通过动态增加 Redis 实例来实现扩容需求。同一片Redis集群也可以有多个Codis（容灾、增加QPS）。 在Codis集群中，所有的redis表（key-value）相当于连在了一起成为了一张大表，一个redis储存部分的key-value，那么Codis 要负责将特定的 key 转发到特定的 Redis 实例：Codis通过hash计算再取模得到一个余数来确定该key对应储存到哪个槽位，而一个槽位映射到一个redis实例 （举例：假如有4个redis，那么1024个槽位，每个redis就映射到256个槽位） Codis 还需要一个分布式配置存储数据库（zooKeeper/etcd）专门用来持久化槽位关系，以供多个Codis共享一个槽位映射 于是Codis管理的redis集群扩容的时候，槽位就要被重新划分，一部分槽位对应的key会迁移到另一个/些redis集群中。Codis提供槽位-redis实例映射自动均衡（由于key需要迁移，所以单个 key 对应的 value 不宜过大） 事务只能在单个redis中完成，由于一个事务的多个key可能储存在多个redis中，所以codis不支持事务（只要涉及多个key操作的指令都不支持） Codis由于将分布式配置问题交给第三方zooKeeper/etcd去解决，所以比redis亲儿子集群方案redis clusters简单很多 集群方案：Redis ClusterRedis Clusters是去中心化集群，没有Codis或Sentinel那样的代理作为客户访问的中心 它也和Codis一样，相当于将所有的Redis key-value形成一张大表，将所有数据划分为 16384 个 槽，它比 Codis 的 1024 个槽划分的更为精细，每个节点负责其中一部分槽位。 然而由于没有代理，客户端每一次访问集群（访问集群中任意一个结点）都会获得槽位配置信息表，由要查找某key的客户端自己去定位到目标结点。 那么我们就要用纠正机制来确保客户端与服务器的槽位信息一致，且每个结点会将槽位配置信息持久化 redis cluster提供了迁移工具redis-trib来手动调整槽位分配（codis可以自动调整以让集群负载均衡，且有UI界面），需要手动调整；迁移过程是阻塞的；结点迁移经过了从原结点复制数据，储存到目标结点，删除原结点数据的过程 当①槽位发生过迁移（已经完成迁移），客户端联系目标结点，此时目标槽位已经不归它管，它就会返回一个moved指令和目标结点地址，客户端就去找新的目标结点；但是②在迁移过程中，原结点无法判断新结点是否已经完成迁移（这时候原结点有还没来得及删那就直接返回，没有就要给目标新结点地址），未完成迁移那么新结点就暂时还不认识该槽位，客户端就需要去新结点执行asking指令，告诉新结点，那么新结点就会临时纠正槽位；moved和asking都有最大重试次数，避免死循环 当集群发生结点变更（比如目标结点挂掉）的时候，客户端会连接异常/错误并重连，这就相当于客户端得到了通知 redis cluster提供主从切换，自动切换主从结点，且提供了一种防止网络抖动的机制，即当timeout超过一定时间才进行主从切换 如果某个结点A下线了，被集群中的其中一个结点B发现，那么它就会像整个集群广播，那么整个集群都会知道结点B认为结点A下线了，当集群中大部分结点都认为A下线了，那么整个集群所有结点就认定该结点A下线了 不支持事务（多机请求无法实现原子性，理由同codis） key和服务器映射关系算法在redis集群（作为数据缓存）中使用【hash对服务器数量取模算法】定位服务器，若【服务器数量发生改变（或部分结点失效）】，所有【缓存在一定时间内失效】（比如4台服务器，那么计算目标结点序号就是hash(data)%4=2，那么就去2机器上找，当服务器数量变了，hash公式计算出来的目标服务器就变了，但是数据还是没有变动），当应用无法从缓存中获取数据的时候（认为缓存中没有），它就会去向后端数据库请求，造成数据库压力过大崩溃，此即【缓存雪崩】。所以我们不能用最朴素的hash方法。 hash slotredis cluster和codis都是采用hash slot方法来做key和服务器的映射关系（而不是一致性hash），是固定分配数据与服务器对应的槽位的（所以服务器变更也要迁移数据），所以也不会有缓存雪崩问题 一致性hash我们让数据和服务器都对2^32取模，将数据和服务器映射到同一个hash环中，每个数据储存在于沿逆时针走的第一个服务器结点中。这样一来，一旦有结点挂了，那么只会影响hash环中的部分段数据，而不会影响整个集群！我们只需要重定位部分数据即可。 （服务器映射到hash环可以采用将服务器的IP或主机名来进行hash） 当遇到数据倾斜，即服务器在环上分布不均匀使得某台服务器分配过多数据，这样就起不到我们的挂服务器只影响部分数据的效果了，那我们就可以增加一些虚拟服务器结点，虚拟服务器结点映射到实际服务器结点即可。数据定位的时候也是先映射到虚拟结点再映射到实际结点。","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"神经风格迁移","slug":"人工智能/神经风格迁移","date":"2019-09-21T09:55:30.000Z","updated":"2019-10-23T01:44:27.000Z","comments":true,"path":"人工智能/神经风格迁移/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/","excerpt":"","text":"风格迁移 L_{total}(S,C,G) = \\alpha L_{content}(C,G)+\\beta L_{style} (S,G)内容图像（C）,生成的图像（G ）,样式图像（S） 合成图像为唯一需要学习（更新）的参数（视为模型参数），也是生成的结果，而不是VGG 输入：C 初始化：可以选择让G=C，也可以随机初始化一个G 这个算法里面的参数(也就是是合成图片里面的每个像素点，我们可以将内容图片直接 copy 成合成图片，然后训练使得他的风格和我们的风格图片相似，同时也可以随机化一张图片作为合成图片（两种初始化），然后训练他使得他与内容图片以及风格图片具有相似性。特征的提取 model这里不训练模型，直接使用预训练的vgg来提取特征 def get_model(): vgg = models.vgg19(pretrained=True).features for param in vgg.parameters(): param.requires_grad = False return vgg extract loss这里使用以前用过的register_forward_hook()函数来hook class LayerActivations(): features = [] def __init__(self,model,layer_nums): #这里要hook多层，要保存多层钩子 self.hooks = [] for layer_num in layer_nums: self.hooks.append(model[layer_num].register_forward_hook(self.hook_fn)) def hook_fn(self,module,input,output): self.features.append(output) #捕捉完输出后不能忘掉remove方法，否则所有输入都累加在一起会内存溢出 def remove(self): for hook in self.hooks: hook.remove() #该函数用于将图片输入进模型，经过钩子获取指定多层的特征输出 def extract_layers(layers,img,model): la = LayerActivations(model=model,layer_nums=layers) #清空缓存 la.features=[] #运行模型，开钩 out = model(img) #已经获取到特征，这是我们关注的东西，然后注销钩子 la.remove() #注意这里返回的是列表，一次性钩了多层 return la.features 定义损失# content loss class ContentLoss(nn.Module): def __init__(self,weight): super().__init__() self.weight = weight self.mseloss = nn.MSELoss() def forward(self,inputs,targets): out = self.mseloss(inputs,targets) return out * self.weight 衡量风格损失使用的是Gram Matrix，对于$k$个向量$\\alpha_1,\\alpha_2,\\cdots,\\alpha_k$ G= \\begin{bmatrix} {(\\alpha_1,\\alpha_1)}&{(\\alpha_1,\\alpha_2)}&{\\cdots}&{(\\alpha_1,\\alpha_k)}\\\\ {(\\alpha_2,\\alpha_1)}&{(\\alpha_2,\\alpha_2)}&{\\cdots}&{(\\alpha_2,\\alpha_k)}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {(\\alpha_k,\\alpha_1)}&{(\\alpha_k,\\alpha_2)}&{\\cdots}&{(\\alpha_k,\\alpha_k)}\\\\ \\end{bmatrix}把特征提取输出变换为$k$行$h*w$列的矩阵$X$，那么$X=&lt;\\alpha_1,\\alpha_2,\\cdots,\\alpha_k&gt;$，其中向量$x_i$代表了通道$i$上的样式特征，于是Gram矩阵实际上计算出了各个通道的两两相关性 # style loss class GramMatrix(nn.Module): def forward(self,inputs): b,c,h,w = inputs.size() #hw维度扁平化 features = inputs.view(b,c,h*w) #bmm(A) = AxA^T gram_matrix = torch.bmm(features,features.transpose(1,2)) #为防止值过大，做归一化 gram_matrix.div_(h*w) return gram_matrix class StyleLoss(nn.Module): def __init__(self,weight): super().__init__() self.gramfunc = GramMatrix() self.mseloss = nn.MSELoss() self.weight = weight def forward(self,inputs,targets): gram_inputs = self.gramfunc(inputs) gram_targets = self.gramfunc(targets) out = self.mseloss(gram_inputs,gram_targets) return out * self.weight # loss function def loss_fn(content_layers,style_layers,content_weight,style_weight,content_img,style_img,model,input_param,times): loss = 0 #提取风格图片的特征并计算,注意这里是提取input（合成）和风格/内容的，都要提取 style_features = extract_layers(style_layers,style_img,model) input_features = extract_layers(style_layers,input_param,model) for style_layer_index in range(len(style_layers)): style_loss = StyleLoss(style_weight) style_loss_this = style_loss(input_features[style_layer_index],style_features[style_layer_index]) #提取内容图片的特征并计算 content_features = extract_layers(content_layers,content_img,model) input_features = extract_layers(content_layers,input_param,model) for content_layer_index in range(len(content_layers)): content_loss = ContentLoss(content_weight) content_loss_this = content_loss(input_features[content_layer_index],content_features[content_layer_index]) loss = style_loss_this+content_loss_this if times % 5 == 0: print('style loss:&#123;:.4f&#125; , content loss:&#123;:.4f&#125;'.format(style_loss_this,content_loss_this)) return loss TRAIN使用LBGFS作为优化函数，LBFGS使用的时候就需要用到闭包 def train(Epoch,input_img, content_weight,style_weight,content_img,style_img, content_layers=[21],style_layers=[1,6,11,20,25]): #默认vgg模型 model = get_model().cuda() #初始化合成图片，将input_img作为初始的合成图片并参数化 input_param = nn.Parameter(input_img.data) #初始化优化器 optimizer = torch.optim.LBFGS([input_param]) for epoch in range(Epoch): print('epoch:&#123;&#125;'.format(epoch)) #开始训练 global times times=0 def closure(): optimizer.zero_grad() #勿忘 global times times+=1 loss = loss_fn(content_layers,style_layers,content_weight,style_weight,content_img,style_img,model,input_param,times) loss.backward() return loss optimizer.step(closure) return input_param.data def showImg(res): img = res[0] img = img.cpu() img = transforms.ToPILImage()(img) plt.imshow(img)","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"风格迁移","slug":"风格迁移","permalink":"https://aisaka.cloud/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://aisaka.cloud/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"Adversary Resistant Deep Neural Networks with an Application to Malware Detection","slug":"论文阅读笔记/toMalwareDetection","date":"2019-09-19T10:41:46.000Z","updated":"2019-12-23T10:57:46.000Z","comments":true,"path":"论文阅读笔记/toMalwareDetection/","link":"","permalink":"https://aisaka.cloud/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/toMalwareDetection/","excerpt":"","text":"《Adversary Resistant Deep Neural Networks with an Application to Malware Detection》 Qinglong Wang ,Wenbo Guo,Kaixuan Zhang,AlexanderG.OrorbiaII, Xinyu Xing,Xue Liu,C.LeeGiles KDD 2017（CCF-A） Introduce deep neural networks(DNNs) could help turn the tide in the war against malware infection However, DNNs are vulnerable to adversarial samples Past research in developing defense mechanisms relies on strong assumptions,which typically do not hold in many real-world scenarios. Also,these proposed techniques can only be empirically validated and do not provide any theoretical guarantees. This is particularly disconcerting when they are applied to security-critical applications such as malware detection. Why It Works？ 随机性的引入使得attackers不容易发现DNN的”blind spots”（也就是AEs） 这个adversary-resistant DNNs 只需要一点微小的工作，且可以维持分类的表现 从理论上来说，本文的方法可以保证对AE的抵抗性 该方法也可以应用在图像等其他DNN模型适用效果较好的领域 Related Works Data Augmentation Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014). Towards deep neural network architectures robust to adversarial examples. arXiv:1412.5068 [cs] (2014). Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization. arXiv:1601.07213 [cs] (2016). 增强数据，主要是通过将潜在AEs与普通样本进行训练（对抗训练）以增加对AEs的鲁棒性，对抗训练已被证明很有用 作者指出的问题：blind spots空间太大，不可能去覆盖一个infinite space，且attackers也可以对对抗训练模型本身进行攻击（how），考虑到无限空间，每一次遇到AEs就必须再次训练对抗训练模型，如此反复迭代 Enhancing Model Complexity 增加模型复杂度 Towards deep neural network architectures robust to adversarial examples. arXiv:1412.5068 [cs] (2014). Distillation as a defense to adversarial perturbations against deep neural networks. arXiv preprint arXiv:1511.04508 (2015). （防御蒸馏机制，将第一个深度神经网络输出的软标签输入到第二个网络中进行训练，降低模型对微小扰动的敏感度。第一个模型的软标签熵编码了类之间的相对差异） 作者指出的问题：攻击者可以使用两个近似性能的DNN来拟合整个机制（该论文作者承认了此机制很容易被拟合） 同时该机制实际上是一个梯度掩码模型，并无法抵抗JSMA的攻击 Random Feature Nullification we introduce random feature nullification to both the training and testing phases of DNN models, making the architectures non-deterministic. 引入随机性，对行为特征进行随机失活，看起来像是一种特殊的dropout正则 但区别在于dropout仅仅在训练的时候对神经元随即失活，而本文的方法是在train和test的时候都执行 作者在input与hidden之间加了一层Nullification层 超参数：$μ_p,\\sigma^2_p $ Model Description$X\\in R^{N*M}$ ($N$ 个样本，$M$维特征) $\\hat{I}_p\\in R^{N*M}$ (mask matrix) Nullification来源于$X$与$\\hat{I}_p$按位乘 经验证在Random Nullification中会损失有用的分类特征信息，于是为了解决这个问题，本文为每个样本引入了Nullification Rate：$p^i$，且不仅哪个神经元失活是随机的，失活神经元的数量也是随机的 单个输入$x_i$对应一个$I_{p^i}$，后者是一个二进制向量，0的数量取决于$p^i$，且随机分布。作者使用了高斯分布和均匀分布。 $⌈M·p^i⌉$ :$I_{p^i}$中随机分布的0的个数，$p^i$是从高斯分布$N(μ_p,\\sigma^2_p)$中的一次采样样本 于是DNN的目标函数定义为 \\min_\\theta \\Sigma^N_{i=1} L(f(x_i,I_{p^i};\\theta),y_i)随机特征失活过程（random feature nullification process）表示为$q(x_i,I_{p^i})=x^i⊙I_{p^i}$ (⊙为Hadamard product，一种特殊的矩阵乘法，同阶矩阵，$c_{ij}=a_{ij}*b_{ij}$) 于是$f(x_i,I_{p^i};\\theta)=f(q(x_i,I_{p^i});\\theta)$ 在训练中使用SGD求解目标函数，但这里不同之处在于$I_{p^i}$在一个样本的前向传播和反向传播过程中是固定的，这使得容易计算$L(f(x_i,I_{p^i};\\theta),y_i)$的导数 在测试中由于参数固定，使用高斯分布$N(μ_p,\\sigma^2_p)$的期望作为辅助的随机变量$p^i$ Analysis: Model Resistance to Adversaries攻击防御： 对抗攻击需要求解如下导数($\\hat{x}$是任一测试样本) J_L(\\hat{x})=\\frac{\\partial L(f(x_i,I_{p^i};\\theta),\\hat{y})}{\\partial \\hat{x}} =J_L(q)·\\frac{\\partial q(\\hat{x},I_p)}{\\partial \\hat{x}}where $J_L(q)=\\partial L(f(x_i,I_{p^i};\\theta),\\hat{y})/\\partial q(\\hat{x},I_p)$，$I_p$是在测试中使用的mask matrix 只要此式子求解，攻击者便可以生成AE发动攻击$\\hat{x} \\to\\hat{x}+ \\phi sign(J_L(\\hat{x}))$ 但此时由于乘随机变量$I_p$的存在，使得攻击者无法轻易算出$J_L(q)$ 这里作者说明了如果$I_p$是加随机变量的话$J_L(q)$将可以被轻易求解 模拟攻击： 因此，攻击者要想攻击此模型的最佳办法就算去拟合$I_p$. 作者假设 $I^*_p$ 为 $I_p$ 的最佳拟合，DNNs为黑盒，最佳的扰动为 $\\delta\\hat{x}$ 则最佳合成攻击样本为 $\\hat{x}+\\delta\\hat{x}⊙I^*_p$ 假设攻击者用此来攻击下面图2中的系统 如图可以看到，攻击必须经过feature nullification layer才能抵达实际的DNN，由如下式子表示 (\\hat{x}+\\delta\\hat{x}⊙I^*_p)⊙I_p=(\\hat{x}⊙I_p)+\\delta\\hat{x}⊙I^*_p⊙I_p式子中 $\\hat{x}⊙I_p$ 即为一个真实的nullified样本，$\\delta\\hat{x}⊙I^*_p⊙I_p$ 就是发动攻击的添加的扰动 这里可以看到，尽管 $\\delta\\hat{x}$ 是非常有效的扰动，但 $I^*_p⊙I_p$ 的存在使得该扰动大幅减弱","categories":[{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"https://aisaka.cloud/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"},{"name":"智能对抗","slug":"智能对抗","permalink":"https://aisaka.cloud/tags/%E6%99%BA%E8%83%BD%E5%AF%B9%E6%8A%97/"},{"name":"GAN","slug":"GAN","permalink":"https://aisaka.cloud/tags/GAN/"}]},{"title":"云雀","slug":"日记/云雀","date":"2019-09-18T04:33:18.000Z","updated":"2019-10-29T00:19:08.000Z","comments":true,"path":"日记/云雀/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%BA%91%E9%9B%80/","excerpt":"","text":"懐かしくあどけない 悲しみを捨ててゆこう ひとすじ空へ舞い上がる 翼に心をのせて ねえ 本当はいつだって 一人は寂しいからね 大事なものは ひとつじゃないの 呼び合っているような 雲雀の声だけ遠く 雲の向こうへ 草原に優しい影を残して 将让人留恋的天真与悲伤都舍弃掉吧 任凭羽翼在碧空中划出舞蹈般的痕迹 其实无论何时 孤独一人终会感到寂寞 珍贵的宝物并非是唯一的 如同呼唤彼此的云雀般 只有遥远的啼鸣 在云之彼方的草原上 留下优雅的掠影","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"some papers about GAN and AEs in model security","slug":"论文阅读笔记/security","date":"2019-09-18T03:06:19.000Z","updated":"2019-12-23T10:57:39.000Z","comments":true,"path":"论文阅读笔记/security/","link":"","permalink":"https://aisaka.cloud/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/security/","excerpt":"mainly collected from security conferences and journals，aiming at machine learning model security","text":"mainly collected from security conferences and journals，aiming at machine learning model security year conf/jour zone title topic 2017 ESORICS CCF-B Adversarial examples for malware detection AE 2017 Evading machine learning malware detection 2017 Generating adversarial malware examples for black-box attacks based on GAN GAN 2017 KDD CCF-A Adversary resistant deep neural networks with an application to malware detection AE 2018 Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables 2018 CoRR Deceiving end-to-end deep learning malware detectors using adversarial examples AE 2017 RAID CCF-B Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers 2018 CCF-B Zero-day malware detection using transferred generative adversarial networks based on deep autoencoders 2019 USENIX Securit CCF-A CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning GAN 2019 USENIX Securit CCF-A Misleading Authorship Attribution of Source Code using Adversarial Learning AE 2019 USENIX Securit CCF-A Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks 2018 USENIX Securit CCF-A AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning 2018 USENIX Securit CCF-A A4NT: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation 2018 USENIX Securit CCF-A Formal Security Analysis of Neural Networks using Symbolic Intervals AE 2016 USENIX Securit CCF-A Stealing Machine Learning Models via Prediction APIs 2019 USENIX Securit CCF-A Seeing is Not Believing: Camouflage Attacks on Image Scaling Algorithms AE,IMAGE 2019 TIFS CCF-A GANobfuscator: Mitigating Information Leakage Under GAN via Differential Privacy. GAN,PI 2019 TIFS CCF-A FV-GAN: Finger Vein Representation Using Generative Adversarial Networks GAN,IMAGE 2018 TIFS CCF-A CNN-Based Adversarial Embedding for Image Steganography AE,IMAGE 2017 TIFS CCF-A No Bot Expects the DeepCAPTCHA! Introducing Immutable Adversarial Examples, With Applications to CAPTCHA Generation 2017 TIFS CCF-A A Game-Theoretic Analysis of Adversarial Classification AE 2018 CCS CCF-A Yet Another Text Captcha Solver: A Generative Adversarial Network Based Approach 2018 CCS CCF-A Machine Learning with Membership Privacy using Adversarial Regularization AE,PI 2018 CCS CCF-A Tutorials:Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning AE 2018 CCS CCF-A Towards Understanding the Dynamics of Adversarial Attacks AE 2018 CCS CCF-A Adversarial Product Review Generation with Word Replacements AE,NLP 2018 CCS CCF-A Spartan Networks: Self-Feature-Squeezing Networks for Increased Robustness in Adversarial Settings 2017 CCS CCF-A DolphinAttack: Inaudible Voice Commands AE 2017 CCS CCF-A Evading Classifiers by Morphing in the Dark AE 2017 CCS CCF-A MagNet: A Two-Pronged Defense against Adversarial Examples AE 2017 CCS CCF-A Practical Attacks Against Graph-based Clustering AE,IMAGE 2017 CCS CCF-A Automated Crowdturfing Attacks and Defenses in Online Review Systems AE,NLP 2017 CCS CCF-A POISED: Spotting Twitter Spam Off the Beaten Paths AE,NLP 2017 CCS CCF-A Poster: Adversarial Examples for Classifiers in High-Dimensional Network Data. AE 2017 CCS CCF-A Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning 2016 CCS CCF-A Tutorials:Adversarial Data Mining: Big Data Meets Cyber Security. AE 2016 S&amp;P CCF-A Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks AE 2019 AAAI CCF-A MIGAN: Malware Image Synthesis Using GANs. GAN","categories":[{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://aisaka.cloud/tags/GAN/"},{"name":"AE","slug":"AE","permalink":"https://aisaka.cloud/tags/AE/"},{"name":"model-security","slug":"model-security","permalink":"https://aisaka.cloud/tags/model-security/"}]},{"title":"个人NAS计划","slug":"硬件/个人NAS计划","date":"2019-08-28T02:48:00.000Z","updated":"2019-08-29T08:08:48.000Z","comments":true,"path":"硬件/个人NAS计划/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/%E4%B8%AA%E4%BA%BANAS%E8%AE%A1%E5%88%92/","excerpt":"眼看着google drive容量即将撑爆..而且9月13号到期然后一看续费扩容计划…","text":"眼看着google drive容量即将撑爆..而且9月13号到期然后一看续费扩容计划… 99.99$/1T emmm，家境贫寒，告辞 于是目光投向微软 。。。。。。。。。。。。。 谷歌我不做人辣！！！ 那。。那就组个NAS吧！ 学校里有千兆网，还可以秒掉gdrive和onedrive的龟速正好用上以前大二买的台式机淘汰下来的硬件，先记录一下各个组件 组件 具体型号 价格(元) CPU 9100f 503 GPU 亮机卡 18 主板 影驰b360m.2 280 固态 - - 内存 8g+8g(ddr4 2400) 现成 散热器 ID-COOLING 现成 硬盘支架 要买 机箱 Q300L 现成 电源 VS450 现成 初始硬盘 WD1T 现成 数据硬盘 东芝 P300 448 网线 千兆 现成 合计 1249 然后就可以享受千兆上传下载，无缝同步，超大容量的个人云端硬盘了，爽到","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[{"name":"NAS","slug":"NAS","permalink":"https://aisaka.cloud/tags/NAS/"}]},{"title":"Redis分布式锁&消息队列","slug":"数据库与中间件/Redis异步消息队列和延时队列","date":"2019-08-28T02:26:56.000Z","updated":"2020-05-02T09:15:12.000Z","comments":true,"path":"数据库与中间件/Redis异步消息队列和延时队列/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%92%8C%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/","excerpt":"分布式锁&amp;异步消息队列","text":"分布式锁&amp;异步消息队列 分布式锁setnx(set if not exists)，setnx name name1是获取锁，如果获取失败返回0，同时为了防止程序异常导致无法释放锁（del name不执行），那么我们要【设置一个锁持有期限】expire name 5，这里就有一个问题了（一般这个key是一个专门的锁变量，获取了才可访问接下来的内容）：如果设置期限语句无法执行怎么办？（比如expire的时候宕机） 无法用事务解决获取、设置期限的原子性问题，因为事务无法做到if-else判断（if拿到锁，然后设置期限；这里没有拿到锁的话，setnx还是相当于执行了，那就不能设置期限！），要么都执行，要么都不执行 后来redis提供了扩展setnx方法，在参数中可以设置，【使得 setnx 和 expire 指令可以一起执行，变成了一个原子指令】，彻底解决了分布式锁的问题 分布式锁是一种悲观锁，还可以使用watch这种乐观锁，watch必须在mutl之前设置，它观察设置的变量是否改变，若改变了就返回null表示执行失败 异步消息队列Redis 的 list(列表) 数据结构常用来作为异步消息队列使用（避免使用比如Kafka这种复杂的专业消息队列中间件） 传统生产者消费者问题+sleep避免空轮询（延时队列） 使用lpop,rpop,lpush,rpush进行操作。 但是问题在于这样会造成空轮询（比如队列空，pop没有，返回null，那就一直pop一直pop，CPU耗费高） 于是我们使用延时队列，即一次查不到就sleep一段时间（sleep即延时），但这样一来如果消息多了就会延时很长 延时队列可以通过 Redis 的 zset(有序列表) 来实现，value记录消息，score记录延时 多线程环境下，当线程抢到消息之后，使用zset的zerm移除队列中的其它成员 像前面如果分布式锁获取失败，就可以将请求扔进异步消息队列（延时队列）中 阻塞读/写 可以使用blpop、brpop来阻塞读，blpop、brpop阻塞读在队列没有数据的时候会进入休眠状态，一旦数据到来，则立刻醒过来。这样就避免在队列为空的时候消费者的空轮询（阻塞太久会断开连接）做到了零延时。但这样就只能让一个消费者消费了，要多个消费者消费得用pub/sub模式 pub/sub：主题订阅模式Redis消息队列不支持消息的多播机制：消息多播允许生产者生产一次消息，中间件负责将消息复制到【多个消息队列】，每个消息队列由相应的消费者组进行消费。 订阅发布模式定义了一种一对多的依赖关系，让多个订阅者对象同时监听某一个主题对象。这个主题对象在自身状态变化时，会通知所有订阅者对象，使它们能够自动更新自己的状态。 消费者可订阅多个主题（消费队列），生产者向主题发布 缺点：此模式下发布的消息无法保证可达性，即如果某消费者客户端宕机了，生产者服务端会继续发消息，然后这个消费者客户端就收不到该消息了（没有消费者，该消息被直接丢弃） Stream （redis5.0新发布）支持消息多播，支持持久化消息队列 持久化机制和普通数据结构一样：RDB+AOF Stream采用一个消息链表，所有消息都串在链表上，且都有一个唯一的ID；在这个Stream消息链表上可以挂多个消费组，在链表上往前移动，表示该消费组已经消费到哪条消息了。每个消费者组都是独立的，也就是说Stream上的消息会被所有消费者组消费到，但是消费者组内部的消费者是竞争关系。 消费者会记录已经被读取了的信息 创建Stream的时候可以定义Stream链表最大长度以删除老消息 注意别把Redis的非阻塞单线程IO和异步消息队列搞混了。 单线程指的是网络请求模块使用了一个线程，即一个线程处理所有网络请求，借由此点，依然可以做到请求处理的高并发，只是其IO处理底层是单线程程序 而消息队列是Redis里队列数据结构的一种应用，是可以支持多个线程（消费者，生产者）访问的。","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"Redis非阻塞单线程IO","slug":"数据库与中间件/Redis非阻塞单线程IO","date":"2019-08-21T09:23:04.000Z","updated":"2020-05-30T01:16:57.000Z","comments":true,"path":"数据库与中间件/Redis非阻塞单线程IO/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%8D%95%E7%BA%BF%E7%A8%8BIO/","excerpt":"Redis的网络事件处理器，叫做【文件事件处理器】。它是【非阻塞】、【单线程】的，采用【IO多路复用机制】来同时监听多个Socket，根据Socket上的事件类型来选择对应的【事件处理器】来处理这个事件。所以说【Redis是单线程的模型】。 （单线程指的是【网络请求模】块使用了一个线程，即一个线程处理所有网络请求，借由此点，依然可以做到请求处理的高并发，只是其IO处理底层是单线程程序）","text":"Redis的网络事件处理器，叫做【文件事件处理器】。它是【非阻塞】、【单线程】的，采用【IO多路复用机制】来同时监听多个Socket，根据Socket上的事件类型来选择对应的【事件处理器】来处理这个事件。所以说【Redis是单线程的模型】。 （单线程指的是【网络请求模】块使用了一个线程，即一个线程处理所有网络请求，借由此点，依然可以做到请求处理的高并发，只是其IO处理底层是单线程程序） 原理 文件事件处理器组成结构包括①多个Socket、②IO多路复用程序、③文件事件分派器、④事件处理器（命令请求处理器（read）、命令回复处理器（write）、连接应答处理器（accept）等） IO多路复用程序会监听多个 Socket 当Socket产生AE_READABLE事件时，它就会将该Socket事件放入一个队列中排队 每次从队列中取出一个 Socket 给事件分派器 事件分派器根据当前Socket产生的事件（见下），把 Socket 关联不同的事件处理器。 【一个 Socket 的事件处理完之后】，IO多路复用程序才会将队列中的下一个 Socket 给事件分派器。（所以是单线程） （一个Socket事件处理完的结果会存放在一个回复队列中，待命令回复事件处理器来取出返回） Socket产生的事件： 一个Socket对应一个客户端，可以产生多个事件 ①当Socket可读时，客户端对redis执行read、write、close、connect操作，会产生AE_READABLE事件，可以理解为服务器可以读指令了； ②当Socket可写时，客户端对redis执行read操作，会产生AE_WRITABLE事件，可以理解为服务器可以返回数据了。 为什么是非阻塞的呢？：多路复用：那么一个IO程序可以同时处理多个Socket请求（以上机制实现） 非阻塞：read/write失败就立即返回，执行下一条语句 ATT：一切对Redis的IO都是采用Redis的线程IO模型，即使客户端与服务端都是本机也是这样访问，实际上本地的网络数据流也是靠网卡和端口驱动 一次流程举例 在 Redis 启动初始化的时候，Redis 会将连接应答处理器跟 AE_READABLE 事件关联起来，接着如果一个客户端跟Redis发起连接，此时会产生一个 AE_READABLE 事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的 Socket，同时将这个 Socket 的 AE_READABLE 事件跟命令请求处理器关联起来。 当客户端向Redis发起请求的时候（不管是读请求还是写请求，都一样），首先就会在 Socket 产生一个AE_READABLE 事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从Socket中读取请求相关数据，然后进行执行和处理。 接着Redis这边准备好了给客户端的响应数据之后，就会将Socket的AE_WRITABLE事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据时，就会在 Socket 上产生一个 AE_WRITABLE 事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入 Socket，供客户端来读取。命令回复处理器写完之后，就会删除这个 Socket 的 AE_WRITABLE 事件和命令回复处理器的关联关系。（仅命令回复处理器会有这个操作） 总结Redis即使是单线程也高效率（高QPS）的原因 Redis的数据是存放在RAM中的，IO速度比磁盘IO不知道高得多 非阻塞的IO复用机制（本文） 多路复用，那么一个IO程序可以同时处理多个Socket请求 单线程，避免了多线程频繁上下文切换的开销（本文）","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"高达升级","slug":"硬件/高达升级","date":"2019-08-16T02:40:51.000Z","updated":"2019-10-16T01:22:05.000Z","comments":true,"path":"硬件/高达升级/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/%E9%AB%98%E8%BE%BE%E5%8D%87%E7%BA%A7/","excerpt":"","text":"这个月又对我的台式机PC电脑的几个零件进行了升级，主要是更换了CPU，添加了固态硬盘，而且把原来CPU的单风扇120水冷换成了双风扇夹汉堡。 9900k这货实在是个大火炉，发热量太大了。后来我才发现我忘了设置SYS_FAN的温度检测区域，导致CPU或GPU都热爆了风扇却不全速转起来。 以下为升级后现在的配置： 硬件 参数 CPU Inter i9 9900K 主频3.6GHz，睿频5GHz CPU散热 恩杰 海妖 X62 280冷排，双AER2 风扇 内存 海盗船LPX 32G 16G*2 3000GHz 主板 华擎 Z390 Gaming Phantom ITX主板 显卡 Inno RTX 2080Ti - 显卡散热 Alphacool 北极狼水冷 240冷排，四be quiet风扇 硬盘 NVME 固态硬盘：三星970evo Plus 1T NVME 固态硬盘：海康威视C2000Pro 2T SATAIII 固态硬盘：西部数码 蓝盘 2T SATAIII 固态硬盘：英睿达 BX300 0.5T (MLC颗粒) 机械硬盘：希捷酷鱼 1T 机械硬盘：西部数码 1T 电源 振华 冰山金蝶GX650 650W 机箱 NZXT MANTA 白色 - 其他风扇 乔思伯 日食 Plus 后置位一个 显示器 DELL U2718QM 4K 27英寸 鼠标 罗技 G903 - 键盘 IKBC W200 红轴，霜冻之蓝键帽 机箱手办 美柑 老婆 耳机 1000XM2 - 以后考虑上sunmilo T03那款机箱，那个就得改用itx板子（必须双m2位），电源改sfx（+1000），CPU风扇用风冷。现在暂时先不折腾了","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[]},{"title":"再见，夏天","slug":"日记/summer","date":"2019-08-11T07:21:41.000Z","updated":"2019-08-11T16:47:17.000Z","comments":true,"path":"日记/summer/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/summer/","excerpt":"","text":"朝着大海的列车，在书香，旋律与橘子芬香中，驶向夏天的终点","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"夏天","slug":"夏天","permalink":"https://aisaka.cloud/tags/%E5%A4%8F%E5%A4%A9/"}]},{"title":"DAO中发生了哪些事情（连接池、mybatis、事务管理）？","slug":"开发/DAO中发生了哪些事情？","date":"2019-08-10T03:56:50.000Z","updated":"2021-01-17T11:09:26.000Z","comments":true,"path":"开发/DAO中发生了哪些事情？/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/DAO%E4%B8%AD%E5%8F%91%E7%94%9F%E4%BA%86%E5%93%AA%E4%BA%9B%E4%BA%8B%E6%83%85%EF%BC%9F/","excerpt":"连接池、mybatis、事务管理等","text":"连接池、mybatis、事务管理等 数据库连接池数据库连接池（Connection pooling）是程序启动时建立足够的数据库连接，并将这些连接组成一个连接池，由程序动态地对池中的连接进行申请，使用，释放。为什么要使用带连接池的数据源呢，最根本的原因还是因为每次创建连接开销比较大，频繁的创建和关闭数据库连接将会严重的影响性能。因此，常用的做法是维护一个数据库连接池，每次使用完之后并不是直接关闭数据库连接，再后面如果需要创建数据库连接的时候直接拿之前释放的数据库连接使用，避免频繁创建和关闭数据库连接造成的开销。 连接池配置在数据源DataSource属性中 在实验室项目中使用dbcp（commons-dbcp包）作为数据库连接池，只需要将dbcp配置写在Spring配置中的数据源bean中（DataSource）即可，class位dhcp，见前面spring-mybatis的例子（然后mybatis配置mysql数据源） 当然如果DataSource内容是单独写在db.properties里的话也可以直接写进去 那么Mybatis是如何使用连接池的呢？见此文：https://blog.csdn.net/majinggogogo/article/details/71715846 当我们需要创建SqlSession对象并需要执行SQL语句时（表现在用户调用mybatis生成的代理对象的DAO方法时），这时候MyBatis才会去调用dataSource对象来创建java.sql.Connection对象，这就建立了数据库连接了。也就是说，java.sql.Connection对象的创建一直延迟到执行SQL语句的时候。也就是在这个时候，数据库连接池起作用了。【】 （补充）几种数据源配置： https://blog.csdn.net/u013490585/article/details/61201840 Spring事务管理事务：事务就是并发控制的单位，是用户定义的一个操作序列。它满足ACID属性 事务管理，实质上就是按照给定的事务规则（事务传播行为，事务超时时间等）来执行提交或者回滚操作 Spring事务管理由PlatformTransactionManager 事务管理器（比如提交，回滚，获取状态等方法都在这里定义），TransactionStatus事务状态（设置回滚，是否回滚，是否完成，是否是新事务等），TransactionDefinition基本事务属性的定义（事务属性包括以下） 三个核心接口构成 Spring的事务主要是ThreadLocal和AOP去做实现的 事务属性包括事务隔离级别、事务传播行为、事务超时、事务的只读属性、事务的回滚规则 事务属性：事务隔离级别事务隔离级别（4种）：若干个并发的事务之间的隔离程度 TransactionDefinition.ISOLATION_DEFAULT：使用底层数据库的默认隔离级别 数据库有以下四种隔离级别： 【读未提交】：TransactionDefinition.ISOLATION_READ_UNCOMMITTED：可读取另一个事务未提交的数据（啥都防不了） 注意RU读未提交：指的是线程A修改后还没有提交！万一线程A没修改完，还在继续修改，或者线程A回滚了，那这个时候线程B读取的就是脏数据，此即脏读。这个时候脏是指的读取了线程A没有完成修改的数据，只修改了一半 读未提交指的是线程A修改后还没有提交！万一线程A没修改完，还在继续修改，或者线程A回滚了，那这个时候线程B读取的就是脏数据，此即脏读 【读已提交】：TransactionDefinition.ISOLATION_READ_COMMITTED：只能读另一个事务已提交的数据，保证了读者在一次读中看不到另一个事务未提交的数据（防脏读） 【可重复读】：TransactionDefinition.ISOLATION_REPEATABLE_READ：可以保证只要事务A开始后之后，反复怎么读都能看到一样的东西（防脏读，不可重复读）无法防幻读，因为不能防止insert数据【这是mysql的默认隔离级别】 【串行化】：TransactionDefinition.ISOLATION_SERIALIZABLE：事务依次执行（防脏读，不可重复读，幻读）。但性能差 mysql默认使用可重复读，是因为历史原因，实际上我们最好使用读已提交【不提】 事务属性：事务传播行为事务传播行为（7种）：当一个事务方法被另一个事务方法调用时，这个事务方法应该如何进行。 例如：methodA事务方法调用methodB事务方法时，methodB是继续在调用者methodA的事务中运行呢，还是为自己开启一个新事务运行，这就是由methodB的事务传播行为决定的。 ①、PROPAGATION_REQUIRED ：required , 必须。默认值，A如果有事务，B将使用该事务；如果A没有事务，B将创建一个新的事务。 ②、PROPAGATION_SUPPORTS：supports ，支持。A如果有事务，B将使用该事务；如果A没有事务，B将以非事务执行。 ③、PROPAGATION_MANDATORY：mandatory ，强制。A如果有事务，B将使用该事务；如果A没有事务，B将抛异常。 ④、PROPAGATION_REQUIRES_NEW ：requires_new，必须新的。如果A有事务，将A的事务挂起，B创建一个新的事务；如果A没有事务，B创建一个新的事务。 ⑤、PROPAGATION_NOT_SUPPORTED ：not_supported ,不支持。如果A有事务，将A的事务挂起，B将以非事务执行；如果A没有事务，B将以非事务执行。 ⑥、PROPAGATION_NEVER ：never，从不。如果A有事务，B将抛异常；如果A没有事务，B将以非事务执行。 ⑦、PROPAGATION_NESTED ：nested ，嵌套。A和B底层采用保存点机制，形成嵌套事务。 事务属性：Other事务超时（超时自动回滚） 事务的只读属性 事务的回滚规则（抛出异常则默认回滚，若没有抛出异常则提交） Spring事务管理如何配置使用Spring事务管理：编程式，声明式（最好） （使用tx.spring包） 且使用了事务管理器之后，我们也不必手动配置AOP，Spring自动为我们进行事务AOP设置 以下使用注解方式进行声明式事务管理 将@Transactional注释在接口，接口方法，类，类方法上，这样就不需要在xml配置 举例，为方法加上事务属性： @Transactional(propagation = Propagation.REQUIRED) public boolean transfer(Long fromId， Long toId， double amount) &#123; return bankDao.transfer(fromId， toId， amount); &#125; 注解方式只需要配置事务管理器和AOP： &lt;!-- 1 事务管理器 --> &lt;bean id=\"txManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;property name=\"dataSource\" ref=\"dataSource\">&lt;/property> &lt;/bean> &lt;!-- 2 声明使用注解配置事务管理器，并声明AOP配置方案 \\* transaction-manager 事务管理器 \\* proxy-target-class true ： 底层强制使用cglib 代理 --> &lt;tx:annotation-driven transaction-manager=\"txManager\" proxy-target-class=\"true\"/> 使用了这个tx:annotation-driven声明后，指定了aop实现方案，那么我们就不必再用&lt; aop:advisor&gt;来配置事务管理AOP来 （不这样写的话得【】：https://www.jianshu.com/p/40f79da0cdef） 参考：https://zhuanlan.zhihu.com/p/37108469 具体使用在哪？数据库-DAO-DAO业务层接口-业务层 我们一般将事务设置在【DAO业务接口层的方法】上，举个例子： @Transactional(propagation = Propagation.REQUIRED) public boolean transfer(Long fromId， Long toId， double amount) &#123; //bankDao即为DAO对象，在mybatis配置中是SqlSession根据我写的&lt;DAO方法，SQL语句>为我们生成的代理对象 bankDao.transfer(fromId， toId， amount); bankDao.deletcount(Id); &#125; 这个方法需要满足事务的ACID特性，那我们就在这个方法上用@Transactional配置方法的事务属性（注解式） 总结：DAO中发生了哪些事情？【Spring事务管理器处理DAO-业务接口层事务】 【mybatis处理DAO访问数据库具体操作】 【Mybatis使用Datasource连接池处理DAO的JDBC请求】 【mybatis部分】我们需要写DAO接口，接口中存在DAO方法来访问数据库，每个DAO方法中对应一个SQL语句（mapper映射文件）。mybatis框架通过datasource等配置生成sqlsession工厂，再由这个工厂生产sqlseesion，通过sqlsession获取代理mapper对象。 就相当于这些DAO方法虽然我们没有具体实现，但sqlsession根据我们写的&lt;方法-SQL&gt;帮我们处理了细节，封装在一个代理对象中，就是mapper对象，在这个对象中就封装有具体的JDBC访问。 【连接池部分】在配置datasource的时候就指定了连接池，就可以在mybatis为我们JDBC创建连接（底层隐式自动）的时候，自动管理并发的数据库连接请求了 【Spring提供的事务管理tx-spring】然而多线程每个连接数据库的线程都是一个需要满足ACID的事务，这时候就需要进行事务管理（隔离级别，传播级别等，是否已建立连接等等），而tx-spring已经为我们提供了事务管理工具类，我们在Spring中配置好事务管理器，然后为不同的方法（我们想为DAO方法提供事务管理，那么就要为DAO方法配置）进行事务管理配置（可以在代码中用注解@Transactional直接在方法上配置，由于我们使用基于注解的mybatis，那么实际上我们就将@Transactional配置在DAO接口（也是基于注解的mapper）的方法上！） 【将事务管理以AOP织入DAO方法】使用tx:annotation-driven在里面设置好proxy就不需要我们配置AOP了。","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"夏休","slug":"日记/JSY","date":"2019-08-05T03:58:05.000Z","updated":"2019-08-05T04:34:40.000Z","comments":true,"path":"日记/JSY/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/JSY/","excerpt":"","text":"这个暑假应该是人生最短的一次暑假了 傍晚回到了中学时期住过的小区去看看，保卫大叔竟然一眼认出了我，还和我聊了些以前的事情 我很惊讶那些小事他都记得， 而且明明5年都没有回去过了。 走出大门，蝉鸣声依然密密麻麻。渐行渐远，不一会儿变得窸窸窣窣。 大叔叫我多回来玩，可我回来能去哪呢？ 蝉鸣声声响，可夏日并不长。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"MySQL管理小TIPS","slug":"数据库与中间件/MySQL管理小TIPS","date":"2019-08-01T14:46:48.000Z","updated":"2020-07-15T14:48:40.000Z","comments":true,"path":"数据库与中间件/MySQL管理小TIPS/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/MySQL%E7%AE%A1%E7%90%86%E5%B0%8FTIPS/","excerpt":"一些管理上的tips","text":"一些管理上的tips MySQL小TIP语句后面跟\\G可以让返回结果表示成列表 delete删数据，drop删结构 没有delete * from的用法，只有delete from #登陆mysql mysql -u username -p #然后才会提示你输入密码，密码不能直接输在-p后面 mysql如何查看用户及其权限：https://blog.csdn.net/GX_1_11_real/article/details/95052475 &#39;username&#39;@&#39;ip&#39;，表示用户名，和登陆ip。ip为’%’则表示一切ip，localhost表示本机 host、user字段标识了可以访问数据库的主机和用户组合 查询表的所有列名：SHOW COLUMNS FROM 表名; root@localhost没有密码可能是因为只能从localhost登，不能远程登陆 mysql5.7版本的password字段改为authentication_string了（依然在mysql.user表里），所以修改密码要：https://www.cnblogs.com/benjamin77/p/8681763.html mysql远程登陆：mysql -u 用户名 -p -h 主机地址 要想要远程访问mysql，不但要创建一个host为远程ip或&#39;%&#39;的远程访问账号，还要在设置里允许远程登陆！https://developer.aliyun.com/article/519454 root默认可能没有密码，因为root的host是localhost的，要设置密码可以上面的方法去改（改表） mysql数据库中存放了很多数据库信息，user表中有host user 密码等数据！","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"Explaining and Harnessing Adversarial Examples","slug":"论文阅读笔记/Examples","date":"2019-07-30T04:20:14.000Z","updated":"2019-12-23T10:57:31.000Z","comments":true,"path":"论文阅读笔记/Examples/","link":"","permalink":"https://aisaka.cloud/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Examples/","excerpt":"","text":"《Explaining and Harnessing Adversarial Examples》 Ian J. Goodfellow, Jonathon Shlens &amp; Christian Szegedy ICLR 2015 为什么会产生对抗样本？以前的观点： extreme nonlinearity of DNN and insufﬁcient model averaging and insufﬁcient regularization of the purely supervised learning problem 本文的观点：Linear behavior in high-dimensional spaces is sufﬁcient to cause adversarial examples RELATED WORK Box-constrained L-BFGS can reliably ﬁnd adversarial examples. On some datasets, such as ImageNet (Deng et al., 2009), the adversarial examples were so close to the original examples that the differences were indistinguishable to the human eye. The same adversarial example is often misclassiﬁed by avariety of classiﬁers with different architectures or trained on different subsets of the training data. Shallow softmax regression models are also vulnerable to adversarial examples. Training on adversarial examples can regularize the model —however , this was not practical at the time due to the need for expensive constrained optimization in the inner loop 这就引起我们怀疑即便当前最好的模型是否只是虚有其表，并没有真正学习到内在的语义信息。仅仅能够fit现有样本，无法泛化。 对抗样本的线性解释本文提出了对对抗样本产生原因的线性解释.设置扰动$\\eta,\\epsilon$为一个小到可以被分类器忽略的值 $\\hat{x} = x+\\eta$ ，若$||\\eta||_\\infty&lt;\\epsilon$，分类器将无法将$x$与$\\hat{x}$分开 则$w^T\\hat{x}=w^T(x+\\eta)=w^Tx+w^T\\eta$ 若维度很高，则即使$\\eta$很小，也会使得$w^T\\eta$非常大，影响分类器的判断 令$\\eta=sign(w)$即可使得$w^T\\eta$最大 非线性模型的线性扰动对于现在的神经网络都有很强的线性性质以至于无法抵抗对抗攻击，如 LSTMs (Hochreiter &amp; Schmidhuber, 1997), ReLUs (Jarrett et al., 2009; Glorot et al., 2011), maxout networks (Goodfellow et al., 2013c) 都设计得具有很强的线性性质，所以也方便优化。FGSM将损失函数近似线性化，从而获取$||\\eta||_\\infty&lt;\\epsilon$的最优扰动。 Fast Gradient Sign Method(FGSM) \\eta = \\epsilon sign(\\nabla_xJ(\\theta,x,y))​ \\hat{x} = x+\\epsilon sign(\\nabla_xJ(\\theta,x,y))注意这里$y=y_{true}$ 通过实验证明，作者的假设产生对抗样本的原因是由于模型的线性特性是正确的。这种方法也可以作为一种快速生成对抗样本的方法（即FGSM） 线性模型的对抗训练在Logistics Regression上应用FGSM方法 ，$label\\in\\lbrace1,-1\\rbrace$ $P(y=1|x)=\\sigma(w^Tx+b),\\sigma(z)=softmax(z)$ $\\therefore J = E{x,y \\tilde{} p_{data}}[(-\\frac{1+y}{2})\\ln P(y=1|x)-\\frac{1-y}{2}\\ln P(y=-1|x)]$ 设$p=P(y=1|x),f=w^Tx+b$ $\\therefore J=-\\frac{1}{2}\\ln p-\\frac{y}{2}\\ln p-\\frac{1}{2}\\ln (1-p)+\\frac{y}{2}\\ln (1-p)$ $=-\\frac{1}{2}\\ln p（1-p)-\\frac{y}{2}\\ln \\frac{p}{1-p} $ $= \\frac{1}{2}(f-yf) + \\ln(1+e^{-f})$ $=\\begin{cases} \\ln(1+e^{-f}),y=1\\\\ f+\\ln(1+e^{-f})=\\ln e^f+\\ln(1+e^{-f})=\\ln(1+e^f),y=-1\\end{cases}$ $= \\ln(1+e^{-yf})$ $=\\zeta(-yf)=E{x,y \\tilde{} p_{data}}\\zeta(-y(w^Tx+b)),\\zeta(z) = \\ln(1+e^z)$ $\\therefore \\eta=\\epsilon sign(\\nabla_xJ(\\theta,x,y))$ $=\\epsilon sign(\\nabla_x\\zeta(-y(w^Tx+b)))$ $= \\epsilon sign(\\frac{\\partial \\ln(1+e^{-y(w^Tx+b)})}{\\partial x})$ $=\\epsilon sign(\\frac{1}{1+e^{-y(w^Tx+b)}} ×(-e^{-y(w^Tx+b)})×(yw^T))$ $=\\epsilon sign(\\frac{e^{-yf}}{1+e^{-yf}}×(-y)w)$ $=\\epsilon sign(-w)=-\\epsilon sign(w)$ $\\because w^Tsign(w)=||w||_1，\\hat{x}=x+\\eta,\\eta=\\epsilon-sign(w)$ $\\therefore \\hat{J}=E{x,y \\tilde{} p_{data}}\\zeta(y(\\epsilon||w||_1 -w^Tx-b))$ 可以看到类似于$L^1$正则，不过是减去$L^1$惩罚项。当置信度很高，$w^Tx+b$足够大的时候，$\\epsilon||w||_1$几乎不起作用，但是当模型欠拟合的时候，则会更加欠拟合 深度网络的对抗训练相比于纯线性模型，深度网络可以在训练网络过程中来抵御对抗攻击。 \\hat{J}= \\alpha J(\\theta,x,y)+(1-\\alpha)J(\\theta,x+\\epsilon sign(\\nabla_xJ(\\theta,x,y)))这种方法在训练中不断更新对抗样本，同时训练。 对抗样本的泛化原因根据线性解释，FGSM可以在连续空间上生成对抗样本，而不是特定的点。作者通过取不同的$\\epsilon$值证实了这一点。 为什么不同的分类器会将对抗样本误分到同一类？因为作者假设的模型都在训练集的不同子集上训练，模型泛化后学得的参数差不多，具有一定的稳定性，导致对抗样本也具有稳定性。","categories":[{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"https://aisaka.cloud/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"},{"name":"智能对抗","slug":"智能对抗","permalink":"https://aisaka.cloud/tags/%E6%99%BA%E8%83%BD%E5%AF%B9%E6%8A%97/"}]},{"title":"Pray for Kyoto Animation","slug":"日记/Animation","date":"2019-07-27T02:29:48.000Z","updated":"2019-07-27T03:17:40.000Z","comments":true,"path":"日记/Animation/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/Animation/","excerpt":"","text":"你们一直伴随着我的青春时光，生命却止步于此。 R.I.P. 为动画世界奉献了青春的你们。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[{"name":"京阿尼","slug":"京阿尼","permalink":"https://aisaka.cloud/tags/%E4%BA%AC%E9%98%BF%E5%B0%BC/"}]},{"title":"mini-batch 在网络里的并行计算","slug":"人工智能/mini-batch","date":"2019-07-26T13:11:32.000Z","updated":"2019-10-23T01:45:13.000Z","comments":true,"path":"人工智能/mini-batch/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/mini-batch/","excerpt":"","text":"使用小批量可以 ①提高模型的训练速度，不用过于频繁地计算参数。通过经验风险最小化由一组样本并行计算并共同决定这批数据的梯度方向 ②引入随机性以避免陷入局部极值 具体到设计网络，以RNN为例（RNN与CNN相比的输入是反常的） 输入节点为$x$,隐藏层节点为$h$，输出节点为$o$。设vec_size = v, hidden_size = h, batch_size = 2,则设定参数矩阵(省略偏移) W_{xh}=W_{v*h} , W_{hh}=W_{h*h}, W_{ho}=W_{h*o} ， seq_a = [a_0,a_1,a_2],seq_b = [b_0,b_1,b_2]于是一个mini-batch为[[a_0,b_0],[a_1,b_1],[a_2,b_2]]_{3*2*v} 对其进行迭代，则$t_0$时刻输入矩阵X^{t_0}=[a_0,b_0]=[a^{t_0}_{1*v},b^{t_0}_{1*v}] 注意这里在python中的表示用数学表示形式是一个二维矩阵， Input= X^{t_0} = X_{2*v} = \\begin{bmatrix} {a_{1*v}}\\\\{b_{1*v}} \\end{bmatrix}于是一次循环： Hidden= \\sigma (X^{t_0}×W_{xh} + H^{(t_0-1)}×W_{hh})=\\sigma(X_{2*v}×W_{v*h}+ H^{(t_0-1)}_{2*h}×W_{h*h}) = \\sigma( \\begin{bmatrix} a^{t_0}_{1*v}×W_{v*h}\\\\ b^{t_0}_{1*v}×W_{v*h} \\end{bmatrix} + \\begin{bmatrix}H^{(t_0-1)}_{1*h}×W_{h*h}\\\\ H^{(t_0-1)}_{1*h}×W_{h*h} \\end{bmatrix} ) = \\begin{bmatrix} {h^{a_0}_{1*h}}\\\\{h^{b_0}_{1*h}} \\end{bmatrix} =H^{(t_0)}_{2*h} Output= H^{(t_0)}_{2*h}×W_{h*o} = \\begin{bmatrix} {h^{a_0}_{1*h}×W_{h*o}}\\\\ {h^{b_0}_{1*h}×W_{h*o}} \\end{bmatrix} = \\begin{bmatrix} {o^{a_0}_{1*o}}\\\\{o^{b_0}_{1*o}} \\end{bmatrix} =O^{t_0}_{2*o}由此可看出，在矩阵相乘的规则下，相当于将不同的$seq$样本同时加载进网络中同时并行计算。 通过一段时间将mini-batch全部加载进循环神经网络，通过loss function再平均作为mini-batch的loss，再作BPTT，就可以求出此mini-batch的梯度。 对于CNN，也是一样的原理同时处理一个mini-batch的所有图片，只不过其输入方式与处理方式有所不同。","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"mini-batch","slug":"mini-batch","permalink":"https://aisaka.cloud/tags/mini-batch/"}]},{"title":"RNN做批","slug":"人工智能/RNN做批","date":"2019-07-25T03:20:09.000Z","updated":"2019-10-23T01:45:20.000Z","comments":true,"path":"人工智能/RNN做批/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/RNN%E5%81%9A%E6%89%B9/","excerpt":"","text":"输入RNN的是时间序列，与CNN是反过来的。CNN的输入是输入(batch_size,$C_{in},H_{in},W_{in}$)，而RNN的输入是(seq_len, batch_size, input_size)，batch_size位于第二维度。 在CNN中我们是要在同一时间里输入batch里每张图，而在RNN里我们是要在同一时刻输入一个batch里每个序列的同一个位置。 训练每个batch后，使用ERM进行BP计算，与CNN一样 以下画图理解，注意紫色是实体结构 于是对于一个可迭代的dataloader 对语料矩阵进行转置后可以更快捷方便生批","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"RNN","slug":"RNN","permalink":"https://aisaka.cloud/tags/RNN/"}]},{"title":"我永远喜欢间桐樱","slug":"Anime/我永远喜欢间桐樱-jpg","date":"2019-07-15T01:39:14.000Z","updated":"2019-07-16T04:45:05.000Z","comments":true,"path":"Anime/我永远喜欢间桐樱-jpg/","link":"","permalink":"https://aisaka.cloud/Anime/%E6%88%91%E6%B0%B8%E8%BF%9C%E5%96%9C%E6%AC%A2%E9%97%B4%E6%A1%90%E6%A8%B1-jpg/","excerpt":"","text":"","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[{"name":"老婆","slug":"老婆","permalink":"https://aisaka.cloud/tags/%E8%80%81%E5%A9%86/"}]},{"title":"pytorch获取中间层参数、输出与可视化","slug":"人工智能/pytorch获取中间层参数、输出与可视化","date":"2019-07-10T10:25:34.000Z","updated":"2019-10-23T01:44:20.000Z","comments":true,"path":"人工智能/pytorch获取中间层参数、输出与可视化/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/pytorch%E8%8E%B7%E5%8F%96%E4%B8%AD%E9%97%B4%E5%B1%82%E5%8F%82%E6%95%B0%E3%80%81%E8%BE%93%E5%87%BA%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/","excerpt":"获取模型中间层的权重和其他参数#先设定如下网络 #定义网络结构 class net(nn.Module): def __init__(self): super().__init__() self.c1 &#x3D; nn.Sequential( nn.Conv2d(3,16,5,1,2), nn.ReLU() ) self.c2 &#x3D; nn.Sequential( nn.Conv2d(16,32,5,1,2), nn.ReLU(), ) self.fc &#x3D; nn.Linear(2097152,2) def forward(self,x): x &#x3D; self.c1(x) x &#x3D; self.c2(x) x &#x3D; x.view(x.size(0), -1) x &#x3D; self.fc(x) return x model &#x3D; net() model &#x3D; model.cuda() #载入先前训练好并保存的模型权重 model.load_state_dict(torch.load(&#39;model_wts.pkl&#39;)) #此时网络的结构为 model &gt;&gt; net( (c1): Sequential( (0): Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) (c2): Sequential( (0): Conv2d(16, 32, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) (fc): Linear(in_features&#x3D;2097152, out_features&#x3D;2, bias&#x3D;True) ) #获取某一层 model.c1 &gt;&gt; Sequential( (0): Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) model.fc &gt;&gt; Linear(in_features&#x3D;1048576, out_features&#x3D;2, bias&#x3D;True) #获取Sequential里的子层 model.c1[0] &gt;&gt; Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) #获得某层的权重 model.c1[0].weight &gt;&gt; Parameter containing: tensor([[[[ 2.7182e-03, -8.7767e-03, 3.2988e-02, -1.0006e-01, -1.1177e-01], [-2.9155e-02, -6.2152e-02, 4.1465e-02, -4.5812e-02, 6.7885e-02], [-1.0680e-01, -1.0023e-01, -1.7158e-02, -1.3828e-02, 5.7319e-02], [ 5.1668e-02, -4.2982e-02, 2.7770e-02, -1.1801e-01, 7.9863e-02], [ 1.1050e-01, 2.4979e-02, 5.1047e-03, -4.6120e-02, -9.9121e-02]], ··························#省略 #参数 model.c1[0].parameters()为该层的参数，包含梯度等等 parameters()输出的参数在训练的时候需要传入优化器，比如在训练网络的时候，model的所有参数 都要传入优化器，则是 optimizer &#x3D; torch.optim.Adam(model.parameters(),lr&#x3D;LR) 又如下面一条迁移学习，只要训练最后一层，就只将最后一层的参数传入了优化器 #层的迭代器 for layer in model.SequentialName.children(): pass #应用方法可以见下面迁移学习部分","text":"获取模型中间层的权重和其他参数#先设定如下网络 #定义网络结构 class net(nn.Module): def __init__(self): super().__init__() self.c1 &#x3D; nn.Sequential( nn.Conv2d(3,16,5,1,2), nn.ReLU() ) self.c2 &#x3D; nn.Sequential( nn.Conv2d(16,32,5,1,2), nn.ReLU(), ) self.fc &#x3D; nn.Linear(2097152,2) def forward(self,x): x &#x3D; self.c1(x) x &#x3D; self.c2(x) x &#x3D; x.view(x.size(0), -1) x &#x3D; self.fc(x) return x model &#x3D; net() model &#x3D; model.cuda() #载入先前训练好并保存的模型权重 model.load_state_dict(torch.load(&#39;model_wts.pkl&#39;)) #此时网络的结构为 model &gt;&gt; net( (c1): Sequential( (0): Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) (c2): Sequential( (0): Conv2d(16, 32, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) (fc): Linear(in_features&#x3D;2097152, out_features&#x3D;2, bias&#x3D;True) ) #获取某一层 model.c1 &gt;&gt; Sequential( (0): Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) (1): ReLU() ) model.fc &gt;&gt; Linear(in_features&#x3D;1048576, out_features&#x3D;2, bias&#x3D;True) #获取Sequential里的子层 model.c1[0] &gt;&gt; Conv2d(3, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2)) #获得某层的权重 model.c1[0].weight &gt;&gt; Parameter containing: tensor([[[[ 2.7182e-03, -8.7767e-03, 3.2988e-02, -1.0006e-01, -1.1177e-01], [-2.9155e-02, -6.2152e-02, 4.1465e-02, -4.5812e-02, 6.7885e-02], [-1.0680e-01, -1.0023e-01, -1.7158e-02, -1.3828e-02, 5.7319e-02], [ 5.1668e-02, -4.2982e-02, 2.7770e-02, -1.1801e-01, 7.9863e-02], [ 1.1050e-01, 2.4979e-02, 5.1047e-03, -4.6120e-02, -9.9121e-02]], ··························#省略 #参数 model.c1[0].parameters()为该层的参数，包含梯度等等 parameters()输出的参数在训练的时候需要传入优化器，比如在训练网络的时候，model的所有参数 都要传入优化器，则是 optimizer &#x3D; torch.optim.Adam(model.parameters(),lr&#x3D;LR) 又如下面一条迁移学习，只要训练最后一层，就只将最后一层的参数传入了优化器 #层的迭代器 for layer in model.SequentialName.children(): pass #应用方法可以见下面迁移学习部分 所以如果要进行迁移学习#以VGG举例 VGG的结构为 VGG&#123; (features):Sequential(....略....) (classifier):Sequntial(....略.........(6)Linear(4096-&gt;1000)) &#125; #这里采用预训练的，[创建vgg网络实例] vgg &#x3D; models.vgg16(pretrained&#x3D;True) #[设置冻结层](只改变classifier里的最后一个线性层，特征提取层不变） #冻结住特征提取层(vgg取名叫features)的参数 for param in vgg.features.parameters(): param.requires_grad&#x3D;False #[微调模型]（只改变最后一层fc层，将1000类分类变为我想要的2类分类） #注意如果用vgg.classifier[6].out_features &#x3D; 2的话以后会遇到问题，输出还是1000种类 vgg.classifier[6] &#x3D; nn.Linear(4096,2) #优化器设置 （由于我们直接用预训练的权重，所以只需要训练分类器的参数，所以只将最后一个分类器层的classifier.parameters传入优化器） optimizer &#x3D; optim.SGD(vgg.classifier.parameters(),lr&#x3D;0.0001,momentum&#x3D;0.5) #还可以继续对模型进行一些修改，比如修改最后一层中的dropout #这里使用了迭代器 for layer in vgg.classifier.children(): if (type(layer) &#x3D;&#x3D; nn.Dropout): layer.p&#x3D;0.2 使用pytorch hook进行中间层输出与可视化（这里hook上面第一节中创建的网络） #定义用于hook的类 class LayerActivations(): #定义这个变量用于储存结果 features &#x3D; None #类初始化。当前向传播的时候（即图像数据通过层传输的时候），调用register_forward_hook方法。 #register_forward_hook方法即为[钩子]，此方法返回一个句柄保存到self.hook def __init__(self,model,layer_num): self.hook &#x3D; model[layer_num].register_forward_hook(self.hook_fn) #hook函数具体执行的方法，即hook方法 #register_forward_hook将三个参数传入hook_fn方法内 #module:允许访问层本身 input:流进层的数据 output:层变换后的流出的数据或激活 def hook_fn(self,module,input,output): #将输出保存到[自己设置的features变量中] self.features &#x3D; output.cpu() #注销句柄self.hook def remove(self): self.hook.remove() #定义hook类实例 conv_out &#x3D; LayerActivations(model.c1,0) #运行模型 output &#x3D; model(img) #注销函数 conv_out.remove() # 在hook class中被保存到了features变量的即为输出，自己定义的 activations &#x3D; conv_out.features #activations 即为层输出 #对其进行可视化 fig &#x3D; plt.figure(figsize&#x3D;(20,50)) fig.subplots_adjust(left&#x3D;0,right&#x3D;1,bottom&#x3D;0,top&#x3D;0.8,hspace&#x3D;0,wspace&#x3D;0.2) for i in range(30): ax &#x3D; fig.add_subplot(12,5,i+1,xticks&#x3D;[],yticks&#x3D;[]) ax.imshow(activations[0][i].detach().numpy()) 中间层参数可视化有两种方法 #方法一 for param in nn.parameters(): xxx #方法二 weight = model.state_dict()['features.0.weight']","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"},{"name":"神经网络","slug":"神经网络","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]},{"title":"Future、FutureTask、Callable、Runnable、Thread","slug":"程序语言/Future","date":"2019-06-20T13:00:55.000Z","updated":"2020-06-03T02:11:52.000Z","comments":true,"path":"程序语言/Future/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/Future/","excerpt":"Future、FutureTask、Callable在JUC包中，Runnable和Thread在java.lang中","text":"Future、FutureTask、Callable在JUC包中，Runnable和Thread在java.lang中 Runnable接口顶级接口，线程执行体 必须实现run()方法，即为任务 Callable接口顶级接口，线程执行体 必须实现call()方法，即为任务，且在该方法中return返回值 任务的执行Runnable、Callable、FutureTask是定义任务，并不会新建线程！执行任务需要新建线程 线程管理需要： ①Thread：可以a.由Thread实现run b. 或传入Runnable，由Thread负责创建线程(Thread.start())，然后内部会调用run()。eg:new Thread(new myRun)、或继承Thread重写run() ②线程池：也可以使用线程池的submit()，其中直接传入Runnable、Callable或FutureTask，由线程池负责线程的管理（创建、销毁等）。eg：ExecutorService = Executors.newCachedThreadPool(); 线程池取代Thread进行线程的管理 P.S. 注意Thread执行完任务后，线程就自动销毁了；而线程池不一定，不同的线程池管理线程的方式不一样，线程池一般会线程复用，执行完任务线程会继续运行（程序未终止） Thread实现Runnable并继承Object Thread是抽象类 必须实现其中的run()方法，也可以直接new Thread(Runnable r)来构造Thread对象 我们在想要新建线程执行run()方法的时候，就要myThread.start() start()是准备就绪，当线程可以执行的时候才会调用run方法。 【重要】当程序调用start()方法时，会创建一个新线程，然后执行run()方法。 但是如果我们直接调用run()方法，则不会创建新的线程，run()方法将作为当前调用线程本身的常规方法调用执行，并且不会发生多线程。 Runnable任务可以共享数据，多个Thread可以同时加载一个Runnable实现类实例，当各自Thread获得CPU时间片的时候开始运行runnable实现类实例，runnable实现类实例里面的资源是被共享的 Runnable和Callable只提供了run()/call()方法，无法任务控制，也无法异步获取Callable的返回结果，所以引出牛逼哄哄的FutureTask Future接口Future接口定义了一系列任务控制的方法，并且定义了获取异步线程的返回值的方法 //Future接口 public interface Future&lt;V> &#123; //mayInterruptRunning参数表示是否中断执行中的线程 //①若中断（mayInterruptRunning=true） //如果任务还没开始，返回false； //如果任务已经启动，将以中断执行此任务线程的方式来试图停止任务，如果停止成功，返回true； //②若不中断（mayInterruptRunning=false） //当任务已经启动，将不会对正在执行的任务线程产生影响(让线程正常执行到完成)，此时返回false； //当任务已经完成，返回false。 boolean cancel(boolean mayInterruptIfRunning); //如果任务完成前被取消，则返回true boolean isCancelled(); //如果任务执行结束，无论是正常结束或是中途取消还是发生异常，都返回true boolean isDone(); //获取异步执行的结果，如果没有结果可用，此方法会阻塞直到异步计算完成 //对于使用Runnable构造器，调用该方法会返回null V get() throws InterruptedException, ExecutionException; //获取异步执行结果，如果没有结果可用，此方法会阻塞，但是会有时间限制，如果阻塞时间超过设定的timeout时间，该方法将抛出异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; &#125; FutureTaskFutureTask实现了RunnableFuture接口，RunnableFuture接口继承了Runnable接口和Future接口（即可以通过Runnable接口实现线程（实际上是一律将Runnable转化为Callable来处理），也可以通过Future取得线程执行完后的结果以及使用一系列的线程控制方法），因此FutureTask也可以直接提交给Executor执行。 【FutureTask是为了弥补Runnable和Callable的不足而设计的】： ①可以获得异步返回结果（如果需要） ②提供了一系列方法方便线程控制以及状态查看（Runable方法只有一个run()，只能调用Object的wait等方法进行线程控制，不好） FutureTask有两个构造器，对应上面两点 ①FutureTask(Runnable runnable, V result)：无返回值异步运行，它在Runable的接口之上，封装了很多方法（对于Runable来说，FutureTask就像一个装饰器，实现Future接口来装饰Runable） ②FutureTask(Callable&lt;V&gt; callable)：在①的基础上，变为有返回值异步运行结果 【ATT】FutureTask.run()的run()方法（就是Runnable的run方法）并没有创建线程，所以得交由线程池来执行 Runnable、Callable、FutureTask、Future使用例class myRun implements Runnable &#123; public void run() //runnable实现run方法 &#123; System.out.println(\"123\"); &#125; &#125; class myCall implements Callable &#123; public String call() //Callable里实现call方法 &#123; return \"123\"; &#125; &#125; public class main &#123; public static void main(String[] args) throws Exception &#123; /*新建线程池，负责线程的管理（创建、销毁等）*/ ExecutorService pool = Executors.newCachedThreadPool(); /*调用FutureTask(Runnable runnable, V result)构造器，作为封装的Runnable使用*/ //第二个参数是为了兼容Excutors.callable方法（见PS），直接设置为null即可 FutureTask ft = new FutureTask(new myRun(),null); pool.submit(ft); /*调用FutureTask(Callable&lt;V> callable)构造器，使用Future功能*/ FutureTask&lt;T> ft = new FutureTask(new myCall()); //使用线程池的submit方法提交该FutureTask之后，异步运算结果保存在FutureTask自己中 pool.submit(ft); /*线程池的submit方法返回的就是个FutureTask实例，我们只是一般用Future接口来声明其引用*/ Future&lt;String> ft = pool.submit(new myCall()); /*然后可以调用FutureTask的各种方法了*/ //比如&lt;T> temp = ft.get(); isDone()等 &#125; &#125; P.S. Executors.callable 用来把Runnable包装成Callable&lt;T&gt;。包装出来的Callable&lt;T&gt;只能返回传入的result Callable&lt;T> Executors.callable(Runnable task, T result) 使用场景：当将需要Callable的方法应用于其他无结果的操作时 What’s next【】state属性是贯穿整个FutureTask的最核心的属性，该属性的值代表了任务在运行过程中的状态，随着任务的执行，状态将不断地进行转变。一共有7个state状态，都是volatile的，保证所有线程可见性。FutureTask五大核心属性： 任务本尊：Callable //如果构造器传入的是Runnable，也会被转化为Callable 任务的执行者：runner 任务的结果：outcome 获取任务的结果：state + outcome + waiters 中断或者取消任务：state + runner + waiters待进一步深层源码解读 参考：FutureTask原理解析","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"Mybatis","slug":"开发/Mybatis","date":"2019-06-19T03:26:59.000Z","updated":"2021-01-17T11:09:59.000Z","comments":true,"path":"开发/Mybatis/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/Mybatis/","excerpt":"项目中，DAO是用mybatis来处理mysql数据库访问的，总结一下","text":"项目中，DAO是用mybatis来处理mysql数据库访问的，总结一下 思想mybatis是一个优秀的基于 java 的持久层框架，它内部封装了 jdbc，使开发者只需要关注 sql语句本身， 而不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。 mybatis通过xml 或注解的方式将要执行的各种statement配置起来，并通过java对象和statement 中 sql 的动态参数进行映射生成最终执行的 sql 语句，最后由 mybatis 框架执行 sql 并将结果映射为 java 对象并返回。 采用 ORM 思想解决了实体和数据库映射的问题，对 jdbc进行了封装，屏蔽了 jdbc api 底层访问细节，使我 们不用与 jdbc api 打交道，就可以完成对数据库的持久化操作。 ORM（Object Relation Mapping）对象关系映射：把数据库表和实体类的属性一一对应起来，使我们操作实体类即可操作数据库表 mybatis是mysql的ORM Mybatis原理参考链接： 【】mybatis工作原理：https://blog.csdn.net/u014745069/article/details/80788127 【】Mybatis的sqlsession是如何做到线程隔离的：https://www.cnblogs.com/yougewe/p/10072740.html Mybatis的SQLSession工具类使用ThreadLocal来对线程中的Session来进行管理 环境搭建（映射关系的XML配置） 导入 创建DAO接口和实体类（访问数据库的类） 创建Mybatis的主配置xml文件 在&lt;configuration&gt;里写上数据库环境、数据源、数据库配置信息、事务类型等 主配置文件中要写上mapper映射配置xml文件 &lt;mappers> &lt;mapper resource=\"com.aisaka.myDaoMapper.xml\">&lt;/mapper> &lt;/mappers> 创建映射配置xml文件 注意：①mybatis的映射配置文件必须为之和dao接口的包结构相同 ②映射配置文件的mapper标签namespace属性的取值必须是dao接口的全限定类名 ③映射配置文件的操作配置（select），id属性的取值必须是dao接口的方法名 遵循了这三点，以后开发中就无须在写dao的实现类（mybatis实现） 环境搭建（映射关系的注解配置） 导入 创建DAO接口和实体类（访问数据库的类） 创建Mybatis的主配置xml文件 在&lt;configuration&gt;里写上数据库环境、数据源、数据库配置信息、事务类型等 主配置文件中使用class属性指定被注解的DAO接口全限定类名 &lt;mappers> &lt;mapper class=\"com.aisaka.myDao\">&lt;/mapper> &lt;/mappers> 直接在DAO接口的方法中进行注解配置 public interface myDao&#123; //为DAO接口方法直接写Select注解，内容为sql语句 @Select(\"select * from user\") List&lt;myObj> findAll(); &#125; 不需要指定封装对象等东西了，很方便 环境搭建（Gradel导入Mybatis）用mybatis-generator https://blog.csdn.net/qq_36666651/article/details/79560228 然后就直接在gradel.build里的task里加载mybatis的配置文件（InputStream） 使用（No Spring） 读取配置文件到InputStream中 InputStream in = Resources.getResourceAsStream(&quot;Mybatis主配置文件.xml&quot;); 根据配置文件和SqlSessionFactoryBuilder ，创建SqlSessionFactory工厂 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); SqlSessionFactory factory = builder.build(in); 使用工厂生产SqlSession对象 SqlSession session = factory.openSession(); 使用SqlSession创建Dao接口的代理对象 MyDaoInterface MyDao = session.getMapper(MyDaoInterface.class); MyDaoInterface是我定义的DAO的接口，MyDao即为Mybatis帮我们创建的DAO代理对象 执行Dao代理对象的方法 List&lt;resObj&gt; = myDao.findAll()返回查询结果 findAll()是在mapper中定义的数据库操作方法，其中定义了具体的查询语句和返回对象类型的全限定包名 resObj即为数据库操作的返回值封装到的对象 释放资源 session.close(); in.close(); （注意，也可以自己写DAO实现类，这样就不用mybatis为我们创建代理对象，而是我们自己搞，但这样就比较复杂了。因为mybatis是自动用我们写的DAO接口和mapper中的方法对应的sql语句，给我们创建了DAO代理对象） Spring整合Mybatis：mybatis-springmybatis-spring包：在 mybatis-spring 中 SqlSessionFactory 的创建交给了 SqlSessionFactoryBean 由 Spring 最终创建的 bean 不是 SqlSessionFactoryBean 本身，而是工厂类的 getObject()返回的方法的结果。也就是说，我们可以直接将与数据库操作的mapper类注入DAO 在Spring主配置文件中配置SqlSessionFactoryBean和MapperScannerConfigurer： &lt;!-- 这和mybatis无关，只是mybatis为我们生成的mapper实体类要注入这些提供给service业务层的实体类中--> &lt;context:component-scan base-package=\"com.appsec.system.persistence.mybatis.xdao\"> &lt;!-- 这和mybatis无关，配置数据源，数据源的内容可以单独写在db.propertipes里 --> &lt;bean name=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" init-method=\"init\" destroy-method=\"close\"> &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/xx\">&lt;/property> &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\">&lt;/property> &lt;property name=\"username\" value=\"root\">&lt;/property> &lt;property name=\"password\" value=\"1234\">&lt;/property> &lt;!--由于使用第三方的dbcp连接池获得DataSource，要写下这些连接池配置--> &lt;property name=\"maxIdle\" value=\"30\">&lt;/property> &lt;property name=\"maxWait\" value=\"10\">&lt;/property> &lt;property name=\"defaultAutoCommit\" value=\"false\">&lt;/property> &lt;/bean> &lt;!-- 配置 SqlSessionFactoryBean ，Spring为我们自动获取SqlSessionFactory对象 --> &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;property name=\"dataSource\" ref=\"dataSource\" /> &lt;!-- mybatis 配置文件位置（默认配置的话，可以不用）--> &lt;property name=\"configLocation\" value=\"classpath:conf/mybatis/mybatis-config.xml\">&lt;/bean> &lt;!-- DAO接口所在包名（映射接口扫描包），Spring会自动查找其下的DAO接口并创建mapper对象 --> &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"> &lt;property name=\"basePackage\" value=\"com.appsec.system.persistence.mybatis.mapper\" /> &lt;!-- 这里的需要配置sqlSessionFactoryBean属性，就是前面配置的那个，Spring为我们用它来自动获取sqlSession对象 --> &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\">&lt;/property> &lt;/bean> 然后就可以把mapper（DAO的数据库直接操作接口）写在com.appsec.system.persistence.mybatis.mapper目录下，然后在com.appsec.system.persistence.mybatis.xdao目录下，直接用@Autowired将mapper目录下的mapper注入进xdao的实体类里啦！这些实体类就提供给service层直接访问（在这些实体类中，可以加各种控制，比如数据校验等等，数据再处理等等） mybatis工作流程通过Reader对象读取Mybatis映射文件通过SqlSessionFactoryBuilder对象创建SqlSessionFactory对象获取当前线程的SQLSession事务默认开启通过SQLSession读取映射文件中的操作编号，从而读取SQL语句提交事务关闭资源 sqlsession用mapper接口生成mapper动态代理对象，再调用该对象对应的方法完成sql语句执行 Mybatis事务管理mybatis可以不进行事务管理，直接用spring事务管理 也可以用mabatis的事务管理：https://blog.csdn.net/andamajing/article/details/72026693 几个注解@result：在使用mybatis注解开发的时候，数据库返回的结果集和实体类字段不对应，我们就需要手动指定映射关系 @SelectProvider：可以不直接@Select(SQL语句)，而是右Provider来提供SQL语句，做到SQL语句与DAO的分离 https://blog.csdn.net/qq_38353578/article/details/72621783 如果方法有@Param参数，那Provider指定的类的方法就要用Map来接受Param @Param 用来在DAO层中声明方法参数 即select等语句注释某方法，该方法传入一个参数如@Param(“thisA”) int a，那么就可以在注释的sql语句中用${thisA}来将这个参数放入SQL语句里 3306是mysql的默认端口","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"生产者消费者问题","slug":"程序语言/生产者消费者问题","date":"2019-06-16T14:44:45.000Z","updated":"2020-06-16T14:47:57.000Z","comments":true,"path":"程序语言/生产者消费者问题/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98/","excerpt":"经典问题","text":"经典问题 生产者消费者问题关键点①三类实体：生产者（多个线程）、消费者（多个线程）、仓库（也叫做资源，在生消问题中是一个封装的list） 生产者需要考虑仓库满问题（阻塞等待），消费者需要考虑仓库空问题（阻塞等待），仓库需要考虑互斥访问问题（阻塞等待） 【以及三者访问架构（线程通信问题访问架构）：由仓库（资源）对象管理实际被访问的资源list，提供produce和consume方法给消费者线程和生产者线程使用，这两个方法互斥地访问list对象】 ②仓库是互斥访问的，同时只能有一个线程（生产者或消费者）访问 ③如何做到线程间的通信 生产者消费者问题实现方法wait() / notify()方法被锁住的对象是list（消费者线程和生产者线程互斥访问list）那么就要调用list.wait()和list.notify()进行线程间通信 import java.util.LinkedList; //仓库（即资源） class Storage &#123; //仓库容量 private final int MAX_SIZE = 10; //仓库内容 private LinkedList&lt;Object> list = new LinkedList&lt;>(); //生产一个产品添加进仓库 public void produce() &#123; synchronized(list) &#123; //如果仓库已满，就wait等待，放弃锁，等待notify唤醒重新获取锁（ //因为仓库是互斥访问的，这时候仓库是满的，生产者得等消费者先消费了再生产，所以生产者如果获取了锁就要主动放弃锁，等消费者notify() while(list.size()+1>MAX_SIZE) &#123; System.out.println(\"【生产者\"+Thread.currentThread().getName()+\"】仓库已满\"); try &#123; list.wait(); //必须由notify()唤醒 &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; //仓库未满，可以生产加入仓库了 list.add(new Object()); System.out.println(\"【生产者\"+Thread.currentThread().getName()+\"】生产一个产品，现库存\"+list.size()); //放弃锁，并通知wait队列可以获取锁了（唤醒生产者） list.notify(); &#125; &#125; //从仓库中消费一个产品 public void consume() &#123; synchronized (list) &#123; while (list.size()==0) &#123; System.out.println(\"【消费者\"+Thread.currentThread().getName()+\"】仓库为空\"); try &#123; list.wait(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; list.remove(); System.out.println(\"【消费者\"+Thread.currentThread().getName()+\"】消费一个产品，现库存\"+list.size()); list.notify(); &#125; &#125; &#125; //定义生产者任务 class Producer implements Runnable &#123; //用于记录仓库的引用，来让生产者访问仓库 Storage storage; public Producer(Storage storage) &#123; this.storage = storage; &#125; public void run() &#123; storage.produce(); &#125; &#125; //定义消费者任务 class Consumer implements Runnable &#123; Storage storage; public Consumer(Storage storage) &#123; this.storage = storage; &#125; public void run() &#123; storage.consume(); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; //建立仓库实体 Storage storage = new Storage(); //创建生产者消费者线程 Thread p1 = new Thread(new Producer(storage)); Thread p2 = new Thread(new Producer(storage)); Thread p3 = new Thread(new Producer(storage)); Thread c1 = new Thread(new Consumer(storage)); Thread c2 = new Thread(new Consumer(storage)); Thread c3 = new Thread(new Consumer(storage)); p1.start(); p2.start(); p3.start(); c1.start(); c2.start(); c3.start(); &#125; &#125; await() / signal()方法（ReentrantLock的应用）await() / signal()是属于ReentrantLock机制的Condition组件的方法，而不是Object的 一个ReentrantLock锁可以创建多个Condition，每个Condition都维护一个等待队列 修改仓库类，不使用重量级锁synchronized，改用ReentrantLock轻量级锁 仓库使用一把ReentrantLock锁，并同时维护两个Condition队列：full Condition队列 和 empty Condition队列，将生产者和消费者分开到两个Condition监视器中：full Condition为仓库满的监视器，维护了一个队列，该队列上的线程都是因为list已满而阻塞的生产者；empty Condition为仓库空的监视器，维护了一个队列，该队列上的线程都是因为list为空而阻塞的消费者（当然也可以只用1个Conditon） 多个Condition维持多个等待队列可以使得通知更准确，只通知指定队列的线程开始获取锁，并发效率高 class Storage &#123; //仓库容量 private final int MAX_SIZE = 10; //仓库内容 private LinkedList&lt;Object> list = new LinkedList&lt;>(); //创建ReentrantLock锁 private final ReentrantLock lock = new ReentrantLock(); //将生产者和消费者分开到两个Condition监视器中 //仓库满的监视器，维护了一个队列，该队列上的线程都是因为list已满而阻塞的生产者 private final Condition full = lock.newCondition(); //仓库空的监视器，维护了一个队列，该队列上的线程都是因为list为空而阻塞的消费者 private final Condition empty = lock.newCondition(); //生产一个产品添加进仓库 public void produce() &#123; //不使用重量级锁synchronized，改用轻量级锁 lock.lock(); while(list.size()+1>MAX_SIZE) &#123; System.out.println(\"【生产者\"+Thread.currentThread().getName()+\"】仓库已满\"); try &#123; full.await(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; list.add(new Object()); System.out.println(\"【生产者\"+Thread.currentThread().getName()+\"】生产一个产品，现库存\"+list.size()); //通知empty condition队列上的所有线程 empty.signalAll(); lock.unlock(); &#125; //从仓库中消费一个产品 public void consume() &#123; lock.lock(); while (list.size()==0) &#123; System.out.println(\"【消费者\"+Thread.currentThread().getName()+\"】仓库为空\"); try &#123; empty.await(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; list.remove(); System.out.println(\"【消费者\"+Thread.currentThread().getName()+\"】消费一个产品，现库存\"+list.size()); full.signalAll(); lock.unlock(); &#125; &#125; BlockingQueue阻塞队列方法class Storage &#123; private LinkedBlockingDeque&lt;Object> list = new LinkedBlockingDeque&lt;>(10); public void produce() &#123; try&#123; list.put(new Object()); //阻塞队列如果队满会阻塞住，并自动释放锁，通知其它等待线程，相当于帮我们自动完成了并发管理 System.out.println(\"【生产者\" + Thread.currentThread().getName() + \"】生产一个产品，现库存\" + list.size()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; public void consume() &#123; try&#123; list.take(); System.out.println(\"【消费者\" + Thread.currentThread().getName() + \"】消费了一个产品，现库存\" + list.size()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; 信号量设计三个信号量 ①互斥访问信号量：保证访问仓库的互斥性 ②仓库空位信号量（空的格子即仓库还能放入的资源数量）：维持生产者等待队列 ③仓库满格信号量（满的格子即仓库已放入的资源数量）：维持消费者等待队列（若无，则队空） 这里实际上可以结合前面的方法，三类实体各自采用不同的并发控制实现手段 注意这里的先后顺序，是先申请生产产品，再申请仓库访问互斥量（因为先判断能否生产仓库是否已满，没满才去申请访问仓库开始操作 class Storage &#123; //仓库 LinkedList&lt;Object> list = new LinkedList&lt;Object>(); //访问仓库互斥信号量 Semaphore mutex = new Semaphore(1); //空格信号量 Semaphore EmptyPositions = new Semaphore(10); //满格信号量 Semaphore FullPositions = new Semaphore(0); public void produce() &#123; try&#123; //请求生产一个商品，那么空格-1（释放一个空格—） EmptyPositions.acquire(); //注意这里的先后顺序，是先申请生产产品，再申请仓库访问互斥量（因为先判断能否生产仓库是否已满，没满才去申请访问仓库开始操作） //申请仓库访问互斥量 mutex.acquire(); //生产操作 list.add(new Object()); System.out.println(\"【生产者\" + Thread.currentThread().getName() + \"】生产一个产品，现库存\" + list.size()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;finally &#123; //生产操作完成，释放仓库访问互斥量 mutex.release(); //生产操作完成，满格+1（增加一个满格） FullPositions.release(); &#125; &#125; public void consume() &#123; try&#123; FullPositions.acquire(); mutex.acquire(); list.remove(); System.out.println(\"【消费者\" + Thread.currentThread().getName() + \"】消费一个产品，现库存\" + list.size()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;finally &#123; mutex.release(); EmptyPositions.release(); &#125; &#125; &#125; 管道不同线程间直接传送数据，一个线程发送数据到输出管道，另一个线程从输入管道中读数据。 只适合两个线程间通信 暂略 参考：Java多种方式解决生产者消费者问题","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"Redis服务&基本数据结构","slug":"数据库与中间件/Redis基本数据结构","date":"2019-06-01T09:22:53.000Z","updated":"2020-05-02T10:02:01.000Z","comments":true,"path":"数据库与中间件/Redis基本数据结构/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"Redis（Remote Dictionary Server )，即远程字典服务 数据库是它的一个功能应用，它还可以作为其它中间件使用 redis-cli在命令行进入Redis服务客户端，可以用Jedis在JAVA中操作Redis客户端 Jedis常用API：https://www.cnblogs.com/yepei/p/5662734.html (注意，当我们在本机运行redis服务端之后，我们无论是其它机器在远程访问redis，还是本地用jedis或redis-cli访问redis，都是客户端)","text":"Redis（Remote Dictionary Server )，即远程字典服务 数据库是它的一个功能应用，它还可以作为其它中间件使用 redis-cli在命令行进入Redis服务客户端，可以用Jedis在JAVA中操作Redis客户端 Jedis常用API：https://www.cnblogs.com/yepei/p/5662734.html (注意，当我们在本机运行redis服务端之后，我们无论是其它机器在远程访问redis，还是本地用jedis或redis-cli访问redis，都是客户端) 基本数据结构以下数据结构大都可以通过储存指向对象的void*指针来储存各种类型的值 Redis 的value有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。 基本数据结构（五大value） 简单动态字符串（SDS） 字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。 Redis字符串封装了C字符串，加入了字符串长度字段和未使用空间字段，优势：常数复杂度获取字符串长度、杜绝缓冲区溢出、二进制安全 Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间和惰性空间释放的方式来减少内存的频繁分配。（成倍分配空间） set、get、del、mset、mget、setnx 、expire、incr set name1 thisname1 双端链表（list） Redis 的列表相当于 Java 语言里面的 LinkedList，叫做quicklist，注意它是链表而不是数组。 当列表元素较少的时候的是ziplist（减小空间冗余），它在空间上连续，当数据量较多的时候，它将多个ziplist用双向指针串起来组成quickList。 这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n) Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理 l/rpush、l/rpop、l/rlen（求长度） lindex 、ltrim（遍历链表，所以是慢操作） 字典（hash） Redis 的字典使用hash实现，相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的 redis字典的rehash和java 的hashmap的rehash方式不一样：Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。（保留新旧两个hash结构，查询时同时查询两个，然后将旧hash内容一点一点迁移） hset、hget、hmset、hmget 注意，那么加入进redis里的就是&lt;key,&lt;key1_of_hash,value1，key2_of_hash,value2...&gt;&gt; 集合（set） 相当于java里的hashset，它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值NULL。 sadd、smembers、sismember 、scard、spop 有序集合（zset） 一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一个【hash表】【和】一个叫做【跳跃表】（用于指定score的范围来获取value）的数据结构。（因为链表二分查找效率极低，所以不能二分查找，当然直接遍历就更慢了）。hash表能快速查找成员、跳跃表能实现排序，zset中的元素同时被保存在这两种数据结构中。 跳跃表提供了一种比红黑树更简单但效率差不多的排序数据结构：https://www.zhihu.com/search?type=content&amp;q=%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8，注意为了每次插入后不用全部重新建表，每一个节点的层数是随机出来的，大大降低了插入的复杂度。跳跃列表使得我们可以像二分查找一样可以快速锁定目标所在的段 &lt;key,&lt;value1_of_set,score1，value2_of_hash,score2...&gt;&gt; 可以用zset的score来做时间戳，设置一个时间窗口来限流，将同用户的同行为设置为一个key的zset，&lt;value_of_set,score&gt;设置为&lt;时间戳，时间戳&gt;（value_of_set无实际意义），然后就可以通过窗口来限流了 还有些特殊数据结构如①位图、②HyperLogLog 提供不精确的去重计数方案（替代set方案，速度快耗资源小，可以做网站的UV）：pfadd指令增加计数、 pfcount获取计数③BloomFilter提供不精确的去重方案（替代set方案，某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。它省去90%空间，解决了HyperLogLog只能计数不能去重的问题）原理：每个布隆过滤器由一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。每add一个数就是将该数用不同的hash函数计算出一个位，然后把这几个位都置为1；查该数的时候，计算hash，只要有一个hash算出来的位置不为1，那么就代表该结构中一定没有这个数（而都为1不一定有，因为冲突可能）；数组越大越准确。 对象 每个对象都对应内存中的一个redisObject结构，其中有个指针指向实际数据结构 Redis基于五大数据结构创建了一个对象系统，将这五大数据结构封装成各自对象，我们实际上是与各类对象打交道。（这样可以做到同一类型对象根据不同情形灵活选择不同编码实现；可以手动指定通过encoding属性设置不同编码实现）满足一定条件或操作会自动进行编码的转换 Redis除了会根据值对象的类型来判断键是否能够执行指令命令之外（类型检查），还会根据值对象的编码方式，选择正确的命令实现代码来执行命令（根据不同编码，调用不同的函数实现）。 Redis的对象引用计数机制实现了内存回收机制、对象共享机制（共享一个对象，节约内存） Redis的对象共享机制和JAVA原理差不多，但是不同的是Redis只对整数值的字符串对象进行共享。Redis是在初始化服务器的时候创建一万个字符串对象，这些对象包含了从0到9999的所有整数值，当服务器用到就直接使用这些共享对象。（非整数值会有大量检查开销） Redis对象还有个对象空转时长的字段（记录了对象最后一次被命令程序访问的时间），如果服务器设置了maxmemory选项，那么当内存超过maxmemory后，Redis会优先释放对象空转时长高的对象。 编码： ①字符串对象就有三种编码（int编码整数、raw编码长字符串，以SDS保存、embstr编码短字符串） 在embstr中，redisObject数据和SDS数据是相邻的，那么新建一个对象只需要一次malloc；而raw中两者是不相邻的，新建一次对象需要两次malloc ②list对象就可以是ziplist或linkedlist ③字典对象可以是ziplist（短且值长度小）或hashtable ④集合对象可以是intset或hashtable ⑤有序集合zset可以是ziplist（很短时）或skiplist（跳表） Long double类型表示的浮点数在Redis中也是作为字符串值来保存的，不过操作的时候会转换为浮点 （ziplist见小对象压缩部分） 单机数据库的实现 数据库 ①结构 Redis服务器将所有的数据库都保存在服务器状态redis.h/redisServer结构的db数组中 db数组每一项都是个redis.h/redisDb结构，每个redisDb结构代表一个数据库 redisDb结构体中的a.键空间即数据库的数据，b.expires字典保存了数据库中所有键的过期时间 在初始化Redis服务器时，程序会根据服务器状态的dbnum属性来决定应该创建多少个数据库，默认为16 Redis客户端状态redis.h/redisClient结构的db属性是一个指向redisDb结构的指针，表明目前client的目标数据库。客户端可以执行SELECT指令切换目标数据库。 键空间本身就是个字典hash。加入其中的所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。都是key-value键值对储存，这个value就可以是Redis任意数据结构类型。举例：即使是字典，也是key-&gt;[dict_key,dict_value]，[dict_key,dict_value]即为字典类型的value ②过期 redisDb中的expires字典保存了数据库中所有键的过期时间，常用指令EXPIRE、PERSIST、TTL等 过期字典存的是时间戳+过期期限，然后检查当前时间戳是否大于记录值即可 过期键删除策略：定期删除（确定删除操作执行的时长和频率）、惰性删除（用再检查）、定期删除（计时器） Redis通信协议RESP（更新）RESP(Redis Serialization Protocol)： Redis 序列化协议 RESP非常浪费流量，但Redis 的作者认为数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。 Redis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符号\\r\\n。 单行字符串 以 + 符号开头。 多行字符串 以 $ 符号开头，后跟字符串长度。 整数值 以 : 符号开头，后跟整数的字符串形式。 错误消息 以 - 符号开头。 数组 以 * 号开头，后跟数组的长度。 客户端向服务器发送的指令只有一种格式：多行字符串数组 比如set aaa bbbb-&gt; *3 $3 set $3 aaa $4 bbbb 服务器向客户端回复的响应要支持多种数据结构。 小对象压缩redis可以使用32bit编译 同时redis有个ziplist，当hashtable、linkedlist需要储存的内容很少的时候，redis就会自动有ziplist来实现hash字典和list列表。ziplist在空间上是连续的。对于hash，key-value在ziplist是相邻储存的，linkedkist就不比多说。 当元素个数超过一定数量，那就会自动变换成标准储存结构来储存了 管道客户端通过对管道中的指令列表改变读写顺序就可以大幅节省 IO 时间。管道中指令越多，效果越好。 因为实际上我们在socket请求中，客户端与服务端都存在各自的recv buffer和send buffer；write实际上是用户进程将数据写到send buffer中，再由操作系统内核将缓冲区内容发送到网卡，再层层包装转送出去；read实际上是客户端进程从本地的recv buffer中读取数据，而数据是由操作系统内核负责接收数据到缓冲区。 也就是说，我们实际上的网络开销是read等待缓冲区非空，而write等待缓冲非满。而如果缓冲区是空，我们read要等，而write不用等的情况下，诸如write-read-write-read，我们改成write-write-read-read，显然更好更快，两次write根本不需要等待，不被阻塞。 事务multi指示事务的开始，exec指示事务的执行，discard指示事务的丢弃（丢弃未执行的指令，不是回滚！）。 multi~exec之间收到的指令都不执行，只有在收到exec的时候执行，如果一旦捕获到异常，那么就执行回滚 Redis事务仅满足隔离性，不满足原子性，因为Redis事务不支持回滚（因为回滚复杂，为了保持Redis的简单和高效） 通常 Redis 的客户端在执行事务时都会结合 pipeline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。比如我们在使用 Python 的 Redis 客户端时执行事务时是要强制使用 pipeline 的： pipe = redis.pipeline(transaction=true) #管道 pipe.multi() #事务开始 pipe.incr(\"books\") pipe.incr(\"books\") values = pipe.execute() #事务执行 Jedis如果是多线程redis请求，那么就要使用jedis的连接池：JedisPool来 管理多线程Jedis连接对象 需要使用try catch语句来保证如果jedis对象抛出异常，要归还jedis给连接池 在jedis连接失败不会提供重试机制，所以要人为写重试代码：try捕获连接异常，捕获到就重连 安全使用rename-command把危险指令flushdb、flushall等重命名 要有密码，不然小心被lua脚本注入 redis不支持ssl，所以可以使用ssl代理：spiped 其它 info指令可以获取redis的运行状态信息 scan指令 可以从海量的 key 中找出满足特定前缀的 key 列表来， scan 参数提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是遍历的 limit hint。 （具体原理略） redis服务器默认监听端口 6379 命令行中可以使用重定向&lt;,&gt;等语句，很方便","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"Generative Adversarial Nets","slug":"论文阅读笔记/GenerativeAdversarialNets","date":"2019-06-01T00:44:58.000Z","updated":"2019-12-23T10:58:00.000Z","comments":true,"path":"论文阅读笔记/GenerativeAdversarialNets/","link":"","permalink":"https://aisaka.cloud/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/GenerativeAdversarialNets/","excerpt":"","text":"《Generative Adversarial Nets》 Ian J.Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair†, Aaron Courville, Yoshua Bengio ICLR 2014 GAN开山之作 RELATED WORK","categories":[{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://aisaka.cloud/tags/GAN/"}]},{"title":"n-gram实践","slug":"人工智能/n-gram实践","date":"2019-05-29T11:57:40.000Z","updated":"2019-10-23T01:50:19.000Z","comments":true,"path":"人工智能/n-gram实践/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/n-gram%E5%AE%9E%E8%B7%B5/","excerpt":"对于加固的应用，可以用通过在沙箱穷举各种可能操作返回的API操作序列来建立模型，处理API序列可以用N-gram来分析语义。 发现网上好像很少有用中文说明具体使用，所以记录一下。 n-gram处理之后，实际上是把句子划分为不同的gram！ 以2元词 2-gram（bigram为例）","text":"对于加固的应用，可以用通过在沙箱穷举各种可能操作返回的API操作序列来建立模型，处理API序列可以用N-gram来分析语义。 发现网上好像很少有用中文说明具体使用，所以记录一下。 n-gram处理之后，实际上是把句子划分为不同的gram！ 以2元词 2-gram（bigram为例） ''' class Phrases(sentences=None, min_count=5, threshold=10.0, max_vocab_size=40000000, delimiter=None, progress_per=10000, scoring=\"default\", common_terms=frozenset) ''' corpusList = ['我','爱','你','爱','你','我','爱'],['我','也','爱','你'] bigram = Phrases(corpusList, min_count=1, threshold=0.01, delimiter=b'~') texts = [bigram[line] for line in corpusList] dictionary = corpora.Dictionary(texts) corpus = [dictionary.doc2bow(text) for text in texts] # 列出划分结果 corpus >>[[(0, 1), (1, 2), (2, 1)], [(2, 1), (3, 1), (4, 1)]] # 列出标签 dictionary.token2id >>&#123;'也': 3, '你': 0, '我': 4, '我~爱': 1, '爱~你': 2&#125; 处理过程①对语料库corpusList（document）内每个句子（text）以大小为2的窗口进行滑动， 句子1：我爱 爱你 你爱 爱你 你我 我爱 句子2：我也 也爱 爱你 统计两两出现次数（整个语料库），得到我爱：2 爱你：3 你爱：1 你我：1 我也：1 也爱：1 （delimiter=b’~’参数规定了2-gram的命名方式，两个词以~为连接符号。这里后面就省略连接符号方便看） ②min_count:Ignore all words and bigrams with total collected count lower than this value. 表示一个2-gram最少必须大于的频数，频数小于等于2 的2-gram就不以此为划分，于是变成我爱：2 爱你：3 threshold: Represent a score threshold for forming the phrases (higher means fewer phrases) score评分方法见 附录[1]，这里设置threshold为0.01非常小的目的就是不考虑阈值参数 于是“我~爱”将被ignore，“爱~我”能够保留 ③开始划分句子1：我爱 你 爱你 我爱句子2：我 也 爱你 未被划分到2-gram的，就是单字频数 于是用doc2bow转换为词袋后，词频列表为 句子1： 我爱：2，爱你：1，你：1 句子2： 爱你：1，我：1，也：1 附录 这个score有两种计算公式，默认使用Efficient Estimaton of Word Representations in Vector Space算法 \\frac{(count(worda\\quad followed\\quad by\\quad wordb) - mincount) * N }{(count(worda) * count(wordb))} > threshold, where\\quad N\\quad is\\quad the\\quad total\\quad vocabulary\\quad size.，另一种是npmi(ormalized pointwise mutual information, from “Normalized (Pointwise) Mutual) 可以通过设置score参数选择评价方式","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"n-gram","slug":"n-gram","permalink":"https://aisaka.cloud/tags/n-gram/"},{"name":"NLP","slug":"NLP","permalink":"https://aisaka.cloud/tags/NLP/"}]},{"title":"Spring","slug":"开发/Spring","date":"2019-05-27T16:36:40.000Z","updated":"2021-04-13T16:45:28.790Z","comments":true,"path":"开发/Spring/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/Spring/","excerpt":"Spring思想Spring框架中，core组件是其它组件的基础（其它组件继承core组件） ①控制反转IoC：控制权的反转，把创建对象的权利交给框架（或工厂），包括依赖注入和依赖查找，目标是降低耦合，依赖关系（当前类中需要用到的其它类对象）的管理全部交给Spring维护（只需要配置中写上） 反射可以做到解耦：编译期不依赖、运行时依赖 bean：可重用组件（拥有get、set等方法，且其它成员和方法全为private的JAVA类） 利用反射机制，加载bean配置文件来加载类[类加载解耦]+（单例）bean工厂[类依赖解耦] =&gt; IoC模式=====&gt;再发展一下，专门用框架来做这个bean工厂做的事情=&gt;Spring框架（一部分） ②面向切片AOP：由Spring框架提供动态代理技术具体实现","text":"Spring思想Spring框架中，core组件是其它组件的基础（其它组件继承core组件） ①控制反转IoC：控制权的反转，把创建对象的权利交给框架（或工厂），包括依赖注入和依赖查找，目标是降低耦合，依赖关系（当前类中需要用到的其它类对象）的管理全部交给Spring维护（只需要配置中写上） 反射可以做到解耦：编译期不依赖、运行时依赖 bean：可重用组件（拥有get、set等方法，且其它成员和方法全为private的JAVA类） 利用反射机制，加载bean配置文件来加载类[类加载解耦]+（单例）bean工厂[类依赖解耦] =&gt; IoC模式=====&gt;再发展一下，专门用框架来做这个bean工厂做的事情=&gt;Spring框架（一部分） ②面向切片AOP：由Spring框架提供动态代理技术具体实现 Spring IoC核心容器-ApplicationContextSpring IoC核心容器替代那个工厂，可以用xml形式、注解形式描述bean Spring容器的配置文件是一个map结构（注意配置properties是内存中的数据结构，和bean描述文件xml不一样） instance1=\"com.aisaka.instance1\" instance2=\"com.aisaka.instance2\" 然后在我们的程序中就可以获取Spring IoC核心容器对象 两个接口-BeanFactory和ApplicationContext ApplicationContext：立即创建对象或延迟创建对象（读取完配置文件立即加载）——单例对象适用；更多采用此接口，因为ApplicationContext可以根据对象是单例还是多例智能选择立即创建还是延迟创建（也可以自己设置） BeanFactory：延迟创建对象（什么时候根据id获取对象，什么时候加载；也有XMLBeanFactory()等，使用方法一样）——多例对象适用 ApplicationContext加载bean配置 ApplicationContext是抽象的，主要有三种具体实现（对应三种 bean配置加载方法） ClassPathXmlApplicationContext()加载类路径下的XML Bean配置描述文件 FileSystemApplicationContext()加载磁盘任意路径下的XML Bean配置描述文件 AnnotationConfigApplicationContext()读取注解创建容器（实验室项目都是这个），括号里需要写清basepackage 注意：Spring核心容器只是加载配置，它是原先工厂的角色，实际类是实际类，只是工厂来负责和它交流 Bean创建的三种方式 ①默认构造器：如果没有其它属性，会使用默认构造器创建，没有则报错 &lt;bean id=\"instance\",class=\"com.aisaka.Instance\">&lt;/bean> 显然，创建对象的时候，Spring都是通过反射找到类进行创建对象的（与前面Spring思想将的那个工厂一样） ②使用普通工厂中的方法创建对象，并将该工厂存入Spring容器 &lt;!--工厂--> &lt;bean id=\"instanceFactory\",class=\"com.aisaka.Factory.instanceFactory\"> &lt;/bean> &lt;!--工厂负责创建的对象，factory-bean为工厂类id，factory-method为工厂类的获取对象方法--> &lt;bean id=\"instance\",factory-bean=\"instanceFactory\",factory-method=\"getInstance\"> &lt;/bean> ③使用工厂中的静态方法创建对象，并将工厂存入Spring容器 &lt;!--\"com.aisaka.StaticFactory.instanceFactory\"为静态工厂，getInstance为静态工厂的创建对象方法，\"instance\"为负责创建对象的id--> &lt;bean id=\"instance\",class=\"com.aisaka.StaticFactory.instanceFactory\",factory-method=\"getInstance\">&lt;/bean> 注意，bean对象其实就是一般的对象实例化（用反射的方式），只是让Spring来做了而已，类加载和类实例化两个阶段依然和以前一样 bean对象的作用范围 scope属性指定bean的作用范围： &quot;singleton&quot; ：单例的（默认值） &quot;prototype&quot;：多例的 &quot;request&quot;：作用于web应用的请求范围 &quot;session&quot;：作用于web应用的会话范围 &quot;global-session&quot;：作用于集群环境的会话范围（全局会话范围），当不是集群的时候就是session bean对象的生命周期 单例对象：和IoC容器生命周期一样（容器创建时创建，容器销毁时销毁） 多例对象：使用对象时Spring框架为我们创建，且不随容器的销毁而销毁，可由JAVA GC销毁 使用getbean()方法从容器获取对象 ApplicationContext接口类型不包含close销毁方法，其子类才包含销毁方法 Spring 依赖注入依赖注入：Spring对依赖关系的维护，即将当前类中需要用到的其它类对象交给当前类，这原来是在程序中写，而现在我们直接在xml bean配置文件中搞定 同时，bean对象的初始化的时候需要传入的初始化参数（见注入方式）也全部写在bean配置中。注意这个初始化参数是在程序跑起来之前需要传递的，可以理解为配置数据，比如数据库连接对象参数什么的，都用注入来传递，动态接受的数据就程序里赋值就行了。 比如DAO层、server层，我们通过容器初始化DAO单例对象和server单例对象，然后将DAO层的单例bean对象以参数形式注入进server层的单例bean对象中（也可以在server中获取IoC核心容器来获取DAO对象，但这样不是非侵入式的，改动参数得改动代码），这样程序就大大解耦了 三类能注入的数据 ①基本类型和String ②其他bean类型（在配置文件中或注解配置过的bean） ③复杂类型、集合类型 注入方式 ①使用构造函数注入（除了必须采用这种方式，一般不用） 默认使用默认构造器 或者添加&lt;bean&gt;的下级标签constructor-arg： &lt;bean id=\"instance\",class=\"com.aisaka.Instance\"> &lt;constructor-arg type=\"\",index=\"\",name=\"\",value=\"\",ref=\"\">&lt;/constructor-arg> &lt;constructor-arg type=\"\",index=\"\",name=\"\",value=\"\",ref=\"\">&lt;/constructor-arg> &lt;/bean> type,index,name来指定构造器哪个参数，常用name value用于给指定好的构造器参数赋值； ref用于给指定好的构造器参数赋值，但是赋的值是一个对象的id，这个对象必须是在配置文件中或注解配置过的bean 每一个标签指定一个参数并给其赋值 这种方式的优势：在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功 弊端：改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据也必须提供 ②使用set方法注入（常用） 添加&lt;bean&gt;的下级标签property： &lt;bean id=\"instance\",class=\"com.aisaka.Instance\"> &lt;property name=\"\",value=\"\",ref=\"\">&lt;/property> &lt;property name=\"\",value=\"\",ref=\"\">&lt;/property> &lt;/bean> 属性有name,value,ref name寻找注入对象中的set方法名称。假如是setName()，那么name=&quot;name&quot;，小写且只看后面的 其它同理 set方法创建对象的时候没有明确限制，可以使用默认构造函数，但获取对象时set方法有可能没有执行（毕竟自己手写的，可能漏了） 对于集合，需要使用集合标签注入，比如： &lt;bean id=\"instance\",class=\"com.aisaka.Instance\"> &lt;property name=\"myStrs\"> &lt;array> &lt;value>abc&lt;/value> &lt;value>bfg&lt;/value> &lt;/array> &lt;/property> &lt;property> &lt;map> &lt;entry key=\"1\",value=\"abc\">&lt;/entry> &lt;entry key=\"2\"> &lt;value>efg&lt;/value> &lt;/entry> &lt;/map> &lt;/property> &lt;/bean> 使用注解替代XML描述JAVA BEAN对象 使用注解需要在XML标签的头部换成另一个！！！加入content注解 &lt;context:component-scan base-package=”com.aisaka”&gt;，引入注解扫描区域com.aisaka 可以创建对象、注入数据、改变作用范围、生命周期相关 创建bean对象 ①@Component：把当前类对象存入Spring容器中 属性，@Component(value)，value指定bean的id，如果不写属性则默认为类名首字母小写 与在xml中写&lt;bean&gt;对象是一样的 Controller注解表现层，Service注解业务层，Repository注解持久层（这四个功能都一样） 这个只是为了让代码清晰 ②@Bean：把当前方法的返回值（对象）作为bean对象存入spring的IoC容器中 属性name用于指定bean的id，默认值（不写）是当前方法的名称 与@Component一样可以创建bean对象并存入spring容器中，两者区别：https://blog.csdn.net/w605283073/article/details/89221522 注意默认都是创建单例bean对象，需要用scope改变 通常使用@Bean的方式创建，都是把所有@Bean创建方法写在一个beanConfig类里面 ③@Component和@Bean的区别： @Component用于自动检测和使用类路径扫描自动配置bean，其写在一个完整的类定义的上面，bean类的声明和定义在一起 而@Bean是作用于一个返回对象的方法（create方法），bean类的声明和定义是分开的，且不会自动扫描，所以通常搭配@Configuration来让Spring扫描配置类，然后配置类里面配置一堆Bean，这是和xml中声明bean最相似的方法 注入其它bean类型 @Autowired：自动按照类型（可以是高层接口类型）注入数据，Spring会自动搜索满足该类型的bean对象类完成注入。此时类中的set方法就不用写了 @Qualifier：按照类型+名称注入，属性value指定注入bean的id @Resource：属性name指定bean的id 集合只能用XML注入 @Value：注入基本数据和String，属性value即注入值 【SpEL写法？】 改变bean对象作用范围 @Scope：作用同xml中的scope 默认单例，如果是多例就要写@Scope(&quot;prototype&quot;) @Configuration：配置类注解 使用了这个注解就相当于在XML中配置了&lt;context:component-scan base-package=”com.aisaka”&gt; 它指示一个类声明一个或多个@Bean方法，并且可以由Spring容器处理，以便在运行时为这些bean生成BeanDefinition和服务请求，举例： @Configuration public class AppConfig &#123; @Bean public MyBean myBean() &#123; // instantiate, configure and return bean ... &#125; &#125; @ComponentScan：指定注解创建容器的时候扫描的包 比如上面新建一个配置类Appconfig，然后给它标上@Configuration，那么然后注解IoC核心容器的参数写Appconfig.class，即写成AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(Appconfig.class);就可以解析bean配置获取IoC容器了 加载class，即加载的是字节码 可以通过@Import，参数填其他配置配的字节码XXX.class，来加载其他配置类，且有import的类即为主配置类，会被IoC核心容器加载（IoC核心容器参数就填主配置类） IoC核心容器的参数其实也可以直接填多个配置类（这样就不用@Configuration声明了），但这样不好 @Configuration、+注解创建bean，就可以完全替代XML配置Bean办法了（但这并不一定是最好的） @PropertySource：指定properties文件（Key=Map格式）的位置（略） https://www.cnblogs.com/cxuanBlog/p/10927823.html 关于测试junit测试方法中（@Test标签）没有IoC容器，如果Spring要整合junit配置：①导入spring整合junit的jar包②使用junit提供的一个注解把原有的main方法替换成spring提供的：@Runwith(SpringJUnit4ClassRunner.class)③告知spring运行器，spring和ioc创建是基于xml还是注解的，并说明位置，用@ContextConfiguration 【略】 事务控制与动态代理 什么是事务： 就是一组操作数据库的动作集合。 一组处理步骤或者全部发生或者一步也不执行，我们称该组处理步骤为一个事务。当所有的步骤像一个操作一样被完整地执行，我们称该事务被提交。由于其中的一部分或多步执行失败，导致没有步骤被提交，则事务必须回滚到最初的系统状态。 事务必须满足ACID原则。ACID是原子性（atomicity）、一致性（consistency）、隔离性（isolation）和持久性（durability）的缩写。 事务的原子性表示事务执行过程中的任何失败都将导致事务所做的任何修改失效。一致性表示当事务执行失败时，所有被该事务影响的数据都应该恢复到事务执行前的状态。隔离性表示在事务执行过程中对数据的修改，在事务提交之前对其他事务不可见。持久性表示当系统或介质发生故障时，确保已提交事务的更新不能丢失。持久性通过数据库备份和恢复来保证。 最原始的事物处理：（中间产生的类建议写在一个专门的工具包里） 通过ThreadLocal对象把Connection（业务从DAO获取一个连接，即指向DAO数据源对象的一个引用）和当前线程绑定，从而使得一个线程中只有一个能控制事务的对象 为什么？假如一个事务由ABCDE5个步骤组成，其中一步翻车，那这个事务就应该全部失败，如果不使用将事务与线程绑定就会这样，所以需要将这5个步骤即一个事务绑定到一个线程 于是我们要建立一个用于连接（Connection）的工具类，它专门用于从DAO中获取一个DAO引用（保证多个操作获得的是同一个连接），使用ThreadLocal类实现和线程的绑定 然后再建立一个专门处理该连接的事务处理工具类，用于处理事务：开启事务、提交事务、回滚事务、释放连接（ThreadLocal类对象的方法，不过这个类里先注入连接工具类对象） 注意这些操作，连接不会和线程解绑，所以我们处理完该事务，要把连接和线程解绑 于是我们在业务层就需要有一个连接DAO的工具类对象，和一个DAO事务处理类对象（这个DAO事务管理类是能够获取到当前线程和与当前线程绑定的连接的） 在每一个业务层的操作都会调用：try：开启事务、执行操作（非事务处理工具类，即业务代码）、提交事务、回滚事务（catch）、释放连接（finally） 然后我们就发现，各种依赖关系，太复杂了，于是引入后面的Spring事务控制 通过动态代理实现事务控制与目标业务的分离 静态代理可以做到非侵入式的修改，方法增强 但是我们给每个类都写一个静态代理可太麻烦了，而且如果我们想对这些类统一做一个修改，比如在生成实际类对象之前有统一的操作，那么还是得一一修改代理类 于是我们用动态代理，可以做到动态指定代理对象和代理方法（就是AOP面向切面编程的基本思想）具体回顾前面：JAVA类型信息-动态代理 动态代理特点：class字节码随用随修改，可以在不修改原码的基础上对方法加强 分为：①基于接口的动态代理（前面所讲，需要被代理类实现一个接口） ②基于子类（非接口）的动态代理 需要第三包jar包支持：cglib（略，得学） 然后我们就可以用动态代理来实现事务控制：被代理对象即业务层对象，业务层对象中的任何方法调用都会先经过动态代理对象，在动态代理对象中，就会在原先的事物处理中加上事物控制代码。此时，事物控制代码（增强代码）和业务代码（原先目标代码）就做到了解耦 基于动态代理技术，自然引出Spring的第二大核心思想——AOP P.S. 一般J2EE服务器支持三种类型的事务管理。即：JDBC事务，JTA事务，容器（如Spring）管理事务，三者只存在一个 Spring AOPAOP是Spring的第二个核心，即面向切片编程 AOP使用的就是动态代理技术 Spring AOP为我们提供配置的方式来实现动态代理 一些术语 joinpoint-连接点：被拦截到的点 pointout-切入点：需要增强的连接点才是切入点（被动态代理的方法不一定要增强，在代理对象中如果判断不增强那就不是切入点） advice-通知：拦截到之后要干的事情，根据增强的语句与切入点的位置关系分为前置、后置、异常（catch）、最终（finally块中的）、环绕（包含以上四种）通知 Introduction-引介（略） Target-目标：被代理对象（目标对象） Weaving-织入：增强应用到目标对象的过程 Proxy：代理对象 Aspect-切面：切入点与通知的结合（即整个增强后的代码块） 一个团队里有业务编程人员（目标功能实现），AOP编程人员（抽取公共代码，配置AOP，织入写切面） 配置Spring AOP 需要导入org.aspectj包来解析切入点表达式 通知类就是储存增强方法的类，切入点就是被切入类的待增强方法 ①基于XML配置AOP Spring Framework中AOP的内容也要导入XML开头声明 先配置Spring的IoC，把service的bean对象配置进xml S1：把通知bean也交给Spring来管理 S2：使用aop:config标签表明开始AOP的配置 S3：使用aop:aspect标签表明开始配置切面 其中id属性：给切片提供一个唯一标识符，ref属性：指定通知类的bean的id S4：在aop:aspect标签的内部使用对应标签来配置通知的类型 aop:before标签配置前置通知（后置aop:after-returning、异常(aop:after-throwing)、最终aop:after标签一样） 对于以上通知配置标签中： 属性method是通知类中的哪个方法属于前置通知 属性pointcut是用于切入点表达式，该表达式含义指的是对业务层中哪个类的哪个方法进行增强 切入点表达式的写法：关键字：execution(表达式)，表达式的写法：访问修饰符 返回值 包名.类名.方法名(参数列表) （访问修饰符可以省略；解析切入点表达式就是aspectj提供的功能） 切入点表达式的全通配符写法：* *..*.*(..) （自己根据实际定义哪些需要通配） &lt;!--配置业务类--> &lt;bean id=\"serviceImp\" class=\"com.aisaka.serviceImp\">&lt;/bean> &lt;!--配置通知类--> &lt;bean id=\"advice\" class=\"com.aisaka.service.adivce\">&lt;/bean> &lt;!--配置AOP--> &lt;aop:config> &lt;!--配置切面--> &lt;aop:aspect id=\"advice\" ref=\"advice\"> &lt;!--配置通知的类型，并且建立通知方法和切入点方法的关联--> &lt;aop:before method=\"adviceMethod\" pointcut=\"execution(* com.aisaka.service.adivce.*(*))\">&lt;/aop:before> &lt;/aop:aspect> &lt;/aop:config> 还有个特殊的配置切入点表达式标签：&lt;aop:pointcut&gt;，改为下面这样可以方便表达式重用（可以写在切面层级够整个切面用，或里面的层级用） &lt;aop:before method=\"adviceMethod\" pointcut=\"ex1\">&lt;/aop:before> &lt;aop:pointcut id=\"ex1\" expression=\"execution(* com.aisaka.service.adivce.*(*))\">&lt;/aop:pointcut> 环绕通知：&lt;aop:around &gt;比较特殊，通知方法必须传入一个已经由Spring实现的ProceedingJoinPoint实现类，然后在通知方法中具体实现ProceedingJoinPoint类对象.proceed()来明确调用的业务层方法在什么位置（且该方法必须抛出Throwable错误，而不是Exception），写在其前面就是前置，写在其后面就是后置，写在异常就是balbala。实际上环绕通知就是Spring提供给我们可以在通知类的通知方法代码中手动控制增强方法合适执行的方式。 示例： @Around(\"pt1()\") public Object aroundPringLog(ProceedingJoinPoint pjp)&#123; Object obj = null; try &#123; Object[] args = pjp.getArgs();// 得到方法所需的参数 System.out.println(\"环绕通知:前置...\"); //明确调用业务层方法 obj = pjp.proceed(args); System.out.println(\"环绕通知:后置...\"); return obj; &#125; catch (Throwable throwable) &#123; System.out.println(\"环绕通知:异常...\"); throw new RuntimeException(throwable); &#125;finally &#123; System.out.println(\"环绕通知:最终...\"); &#125; &#125; //示例参考链接：https://blog.csdn.net/weixin_43464964/java/article/details/86504129 ②基于注解配置AOP 在通知类前声明@Aspect 在通知方法前声明不同通知类型：前置@Before、后置@AfterReturning、异常@AfterThrowing、最终@After 环绕通知：@Around 切入点表达式，直接作为上述通知类型的属性 也可以在通知类里定义一个切入点表达式方法： @Pointcut(切入点表达式) private void pt1()&#123;&#125; 然后这个pt1()名字传入上述通知类型的属性中，如@Before(\"pt1()\") 然后再xml中写上&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;，表示开启注解AOP支持 或者写：@EnableAspectJAutoProxy，这样XML就可以删了 注解AOP方式非常简单好写，建议注解 AOP实现事务控制 显然我们就可以把前面提到的事务处理工具类作为通知类了，然后将其中的开启事务、提交事务、回滚事务、释放连接方法分别以前置、后置、异常、最终通，为服务层类配置AOP P.S.但注意，在AOP中这样会有通知调用顺序问题，这时候需要用环绕通知来配置（原因： 在使用除环绕通知的其他通知时，他们的顺序并不是一定的，最终通知会执行优先于后置通知与环绕通知（这是java异常处理里的内容，有时候finally块会先执行【】）,因此当我们使用最终通知来释放一些资源的时候，可能会出现资源已经释放，但是后置通知仍在使用的情况，这时就会出现错误，因此我们遇到这种情况时要特别注意，为了保证通知的顺序，我们必要的使用环绕通知，环绕通知的执行顺序是一致的。） Spring 事务控制【略】事务是在业务层的 Spring提供的事务管理模块：spring-tx 提供了一堆接口，其中实现类之一为org.springframework.jdbc.datasource.DataSourceTransactionManager，使用Spring JDBC或iBatis进行持久化数据时使用 事务控制有基于XML的，基于注解的，也可以基于纯编程的，参考5种Spring配置事务的方式 Spring JdbcTemplate【略】JDBC:JAVA DataBase Connectivity ，JAVA数据库访问技术，是JAVA数据库访问的标准规范，一切JAVA数据库访问都可以通过JDBC来完成 JdbcTemplate是Spring框架提供的一个对象，是对原始JDBC API的简单封装 相关依赖：spring-jdbc,spring-tx,mysql-connector-java 通过IoC容器JdbcTemplate实例（并将数据源Datasource注入其中），然后就可以进行 CRUD操作：增加(Create)、读取(Read)、更新(Update)和删除(Delete) 几个Tips: query结果封装 query中封装用Spring提供的new BeanPropertyRowMapper&lt;目标类&gt;(目标类.class) https://blog.csdn.net/qq_22339269/article/details/82978717 JdbcDaoSupport 简化Jdbc Template类的注入相关工作，不用我们手写Jdbc Template工具类（包含两组get set方法）了，只需要DAO层类继承该类，然后在XML里将DataSource或Jdbc Template 对象注入DAO层对象即可 https://blog.csdn.net/mChenys/article/details/89855169 （不过就只能采用XML配置了，因为我们无法用注解修改Spring提供的JdbcDaoSupport） 表现层、业务层、持久层表现层[Controller]：表示层(UI)业务层[Service]：业务逻辑层(BLL)：负责关键业务的处理和数据的传递。复杂的逻辑判断和涉及到数据库的数据验证都需要在此做出处理。根据传入的值返回用户想得到的值，或者处理相关的逻辑。持久层[Repository]：数据访问层(DAO)：负责数据库数据的访问。主要为业务逻辑层提供数据，根据传入的值来操作数据库，增、删、改、查；不过注意DAO是负责获取数据库访问对象，并借助该对象直接操作数据库 @controller 控制器（注入服务） 用于标注控制层，相当于struts中的action层 @service 服务（注入dao） 用于标注服务层，主要用来进行业务的逻辑处理 @repository（实现dao访问） 用于标注数据访问层，也可以说用于标注数据访问组件，即DAO组件","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"MySQL索引","slug":"数据库与中间件/MySQL索引","date":"2019-05-23T13:35:33.000Z","updated":"2020-09-02T11:39:17.000Z","comments":true,"path":"数据库与中间件/MySQL索引/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/MySQL%E7%B4%A2%E5%BC%95/","excerpt":"索引类型、实现、以及索引优化","text":"索引类型、实现、以及索引优化 索引Innodb中索引由B+树实现，①B+树相比AVL更低，查询耗时更少②B+树叶子结点有序，指针串起来成一串，可以做到顺序查找、范围查找 可以将B+树的中间结点调入内存，数据结点依然存放在磁盘中，这样就很好。 索引的优点：①查找快，减少需要扫描的数据量②由于B+树的有序性，索引的优势就是可以让随机IO变成顺序IO 以什么字段属性建立索引，那中间的结点存的就是该字段的值 索引是有序的（对应到B+树的叶子节点），建立索引的时候就会进行排序 B+ Tree索引没有主键会创建默认主键 主键索引：主键就是一种索引，此即主键索引，也叫聚簇索引。使用：设置primary key 主键索引的叶子结点的data域有完整的数据记录。其叶子结点称为数据页。聚类结点的这个特性决定了索引组织表中的数据也是索引的一部分 辅助索引的叶子 结点的data域记录着主键的值，不包含数据。查询到叶子结点，获取到主键索引值之后需要再次查主键索引树来获取数据（回表查询，相当于进行了两次IO） 理解：所以我们一般用个id（默认的）做主键，然后再用辅助索引索引name之类的字段，然后我们通过辅助索引查得name所对应的主键id，再回标去主键索引中查就能很快查出主键索引树对应叶子节点上的数据。（当然这里可以用覆盖索引改善，不用回表查询）。想想如果没有辅助索引只有主键索引，那我们就得去所有数据行中找对应的name，就相当于没有索引了。 非主键索引：也叫辅助索引。非主键索引是要先链接到主键索引上的，只要建立的不是主键就是非主键索引。使用：create index on（由于默认建立主键，所以非主键索引可以不用担心没有链接到主键索引） 非主键索引可以是不唯一的，但主键索引一定是唯一的 B+Tree和B Tree的区别B+树的叶子节点只存储数据（还有索引值、链表指针），在B+树查找命中的时候，会将叶子结点的data域（一页）读进内存 B+树的一个节点（所有结点）大小=innodb的一页=4个操作系统页(一页4kb)=16kb(系统规定，不用纠结)然后把非叶子结点读入内存，叶子结点只在读取到的时候读入内存 叶子节点只存储数据(索引值和链表指针占不考虑) 非叶子节点存储(索引值+指针（指向下子结点））&lt;=这就是B+树相比B树优秀的地方之一，①非叶子结点只存索引，那当然使得非叶子结点储存的索引量增大，使得中间索引更快，层数更低，查询更有效率！ 并且利用外存的“预读取”原则，每次读取的时候，把整个节点的数据读取到内存中，下次读取很有可能还读取结点附近的数据（局部性原理） ②查询速度更稳定：由于B+Tree非叶子节点不存储数据（data），因此所有的数据都要查询至叶子节点，而叶子节点的高度都是相同的，因此所有数据的查询速度都是一样的。 ③添加了指向相邻叶节点的指针，形成了带有顺序访问指针的B+Tree，这样做是为了提高区间查找的效率 非主键索引，主键索引都是用B+树结构（但非主键索引的叶子结点存放的是主键值） 补充阅读，可以更详细地了解具体结构：https://blog.csdn.net/qq_24384579/article/details/90902132 联合索引当建立联合索引(a,b,c)的时候，那么就会先排序a，再在a定的基础上排序b，再c。这样一来我们在select查询的时候就必须遵循最左匹配原则，要使用后面的索引，必须得先使用前面的索引，即只能select a或a b或abc，才会使用能进行快速索引查找，否则就只是全表扫描很慢 联合索引是一棵树 更多见索引优化-2 哈希索引当某个索引值被使用频繁的时候，InnoDB会在B+ Tree索引之上再创建一个哈希索引，方便快速查找（用短hash在b树中找，这样可以用短键索引长键 其它还有全文索引、空间数据索引 索引优化 索引选择性：不重复的索引值和记录总数的比值（值越高，区分能力就越高，即选择性越强） 使用联合索引，且使用的时候将选择性较强的索引列放在前面（这样我们就可以最快检索出想要的行） 联合索引是将多个索引字段构成了一棵树而不是多颗树！该树的结点上的选择支选择遵循最左匹配原则。 在构造联合索引的B+树时，每个结点先判断左边的索引再判断右边的索引（也就是左边索引字段排好序的情况下，右边索引字段再排序。显而易见为什么必须遵循最左匹配原则） 在联合索引中，中间的结点就是索引字段的值了 #建立联合索引 alter table tb1 add index score_index(NAME,SCORE); #建立此联合索引之后，查询的时候查询NAME或NAME,SCORE就会使用联合索引查询Type=ref，即where NAME=或NAME= AND WHERE =查询的时候，其它顺序就无法使用联合索引（全表/全索引扫描 Type=ALL/index） #（但实际上mysql的查询优化器会优化SCORE,NAME的情况，使得它也会是通过联合索引查询，但是如果顺序不一致，就不会覆盖索引了） #注意：如果不符合最左匹配原则查询name和score，比如直接查询score，依然会使用联合索引，但是type=index，不会采用高效的查询算法了（此时score非有序，得全索引遍历查询） #查询，这里查询就查询了联合索引了 select * from tb1 where NAME='a2dasdasd' and SCORE=102; 对于长字符串，使用前缀索引 （先计算索引选择性，得出最有选择度的长度比如为4，add key name(4)） 覆盖索引：查询在索引树中就可查找所需数据，无需回表，速度更快。 常见实现方法：将被查询的字段，建立到联合索引里去 #基于上面的联合索引 #用到了覆盖索引，因为name，score联合索引的 select NAME,SCORE from tb1 where NAME='a2dasdasd' and SCORE=102; #没有用到覆盖索引，因为查找的字段不止name和score还有其它字段没被联合索引覆盖 select * from tb1 where NAME='a2dasdasd' and SCORE=102; 联合索引就将多个索引字段的值放在了一个结点，这样比如我们只查联合索引索引的字段(id,name)的时候，一次性就把id和name查出来了，不用回表查询！ （explain的extra=using index则表示使用了覆盖索引） SQL慢的可能一个 SQL 执行的很慢，我们要分两种情况讨论： 1、大多数情况下很正常，偶尔很慢，则有如下原因 (1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。 (2)、执行的时候，遇到锁，如表锁、行锁。 2、这条 SQL 语句一直执行的很慢，则有如下原因。 (1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引；没有遵循最左原则选择列。 (2)、数据库选错了索引。 3、我们的SQL请求太多/太长了 尽量上select *，最好用limit，尽量将大SQL语句拆成小的，以便使用缓存 索引不使用于小表上（索引开销大还不如全表扫描，索引的B+树的新增、更新、删除操作需要分裂旋转等操作） 索引设计原则MySQL 索引设计原则： （1）对于经常查询的字段，建议创建索引。 （2）索引不是越多越好，一个表如果有大量索引，不仅占用磁盘空间，而且会影响INSERT，DELETE，UPDATE等语句的性能。 （3）避免对经常更新的表进行过多的索引，因为当表中数据更改的同时，索引也会进行调整和更新，十分消耗系统资源。 （4）数据量小的表建议不要创建索引，数据量小时索引不仅起不到明显的优化效果，对于索引结构的维护反而消耗系统资源。 （5）不要在区分度低的字段建立索引。比如性别字段，只有 “男” 和 “女” ，建a索引完全起不到优化效果。 （6）当唯一性是某字段本身的特征时，指定唯一索引能提高查询速度。 （7）在频繁进行跑排列分组（即进行 group by 或 order by操作）的列上建立索引，如果待排序有多个，可以在这些列上建立组合索引。 参考链接：https://blog.csdn.net/qq_30745307/article/details/81230109 备注explain sqlsentences #分析 ---explain结果--- id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: 索引类型；常用的有index：全索引扫描；all：全表扫描；ref：联合索引 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息；using index表示使用了覆盖检索 参考：https:&#x2F;&#x2F;segmentfault.com&#x2F;a&#x2F;1190000008131735 show index from tb1 #查看索引 更多阅读：MySQL优化策略大全：https://www.jianshu.com/p/d7665192aaaf","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"训练集增补后两个非常诡异的错误","slug":"人工智能/Pytorch-cuda-runtime-error-59-device-side-assert-triggered-at-pytorch-aten-src-THC-generic-THCT-错误","date":"2019-05-08T07:30:44.000Z","updated":"2019-10-23T01:45:38.000Z","comments":true,"path":"人工智能/Pytorch-cuda-runtime-error-59-device-side-assert-triggered-at-pytorch-aten-src-THC-generic-THCT-错误/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch-cuda-runtime-error-59-device-side-assert-triggered-at-pytorch-aten-src-THC-generic-THCT-%E9%94%99%E8%AF%AF/","excerpt":"","text":"这错误原因说了等于没说，完全不知道问题出在哪，只能靠 想 象 力 Pytorch: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCT........错误 在新增了一个类别进入训练集之后（5+1）出现了非常奇怪的CUDA报错 这个错误原因一般是①网络输出的label和标签（训练集种类）数量应该相同 ②是否存在-1标签 我的最后一层应该nn.Linear(32768, 5)改为nn.Linear(32768, 6) 很容易忽略很隐蔽的错误！而且这个错误定位并不准。找了我半天时间， DataLoader worker (pid 20991) is killed by signal: Killed. 检查内存，CPU %MEM一直在增加，跑了很多次都同样出错 Out of memory了 查阅了很多资料，github上有些人也遇到这个问题，有说是因为后台线程设置太多，也以后说enumerate写法问题，还有个说是pytorch的问题 a lot of those issues are because of third party libraries not being fork safe. One alternative resolution might be to use the spawn start method. 最后将子线程设置为1解决 N M B","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"https://aisaka.cloud/tags/CNN/"},{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"}]},{"title":"fixed不生效","slug":"程序语言/fixed不生效","date":"2019-04-19T11:56:29.000Z","updated":"2019-04-19T12:00:09.000Z","comments":true,"path":"程序语言/fixed不生效/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/fixed%E4%B8%8D%E7%94%9F%E6%95%88/","excerpt":"","text":"&#160; &#160; &#160; &#160;在ios上，background-attachment: fixed;标签失效，导致背景图无法自适应屏幕。 &#160; &#160; &#160; &#160;解决办法： body:before &#123; content: ' '; position: fixed; z-index: -1; top: 0; right: 0; bottom: 0; left: 0; background: url(/images/4.jpg) center 0 no-repeat; background-size: cover; &#125;","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[{"name":"Apple","slug":"Apple","permalink":"https://aisaka.cloud/tags/Apple/"}]},{"title":"塞尔达传说：荒野之息","slug":"Game/塞尔达传说：荒野之息","date":"2019-04-15T02:46:30.000Z","updated":"2019-08-28T03:21:43.000Z","comments":true,"path":"Game/塞尔达传说：荒野之息/","link":"","permalink":"https://aisaka.cloud/Game/%E5%A1%9E%E5%B0%94%E8%BE%BE%E4%BC%A0%E8%AF%B4%EF%BC%9A%E8%8D%92%E9%87%8E%E4%B9%8B%E6%81%AF/","excerpt":"传奇的诞生&#160; &#160; &#160; &#160;这款游戏一出生，就轰动了整个游戏界。 &#160; &#160; &#160; &#160;几乎所有重要游戏媒体都给出满分评价，在mc（metacritic，综合所有游戏媒体给出综合平均分）上获取高达98分的平均分。在人类游戏史上排名第二（并列），毫无悬念地摘获了2017年由TGA（The Game Awards，游戏界的奥斯卡）颁发的GOTY（Game Of The Year，年度最佳游戏），同时斩获TGA最佳游戏设计、TGA最佳动作冒险游戏，GS年度最佳游戏，EDGE年度最佳游戏，GDC最佳游戏音效奖、最佳游戏设计奖和年度游戏奖，SXSW最佳游戏性奖、最佳游戏设计奖和年度最佳游戏。","text":"传奇的诞生&#160; &#160; &#160; &#160;这款游戏一出生，就轰动了整个游戏界。 &#160; &#160; &#160; &#160;几乎所有重要游戏媒体都给出满分评价，在mc（metacritic，综合所有游戏媒体给出综合平均分）上获取高达98分的平均分。在人类游戏史上排名第二（并列），毫无悬念地摘获了2017年由TGA（The Game Awards，游戏界的奥斯卡）颁发的GOTY（Game Of The Year，年度最佳游戏），同时斩获TGA最佳游戏设计、TGA最佳动作冒险游戏，GS年度最佳游戏，EDGE年度最佳游戏，GDC最佳游戏音效奖、最佳游戏设计奖和年度游戏奖，SXSW最佳游戏性奖、最佳游戏设计奖和年度最佳游戏。 &#160; &#160; &#160; &#160;媒体，玩家，游戏界一致好评的背后，是游戏设计理念的极致，是任天堂的无数心血—— 重新定义开放世界&#160; &#160; &#160; &#160;公式化开放世界大行其道，玩家已经开始产生厌倦。公式化开放世界的意思就是流水化式地生产出一个开放世界，整个游戏的设计就有寥寥几种模式，而且这几种模式的变化很小，内容填充少。比如说任务类型就是跟踪、刺杀、跑路这几种，演出就几段毫无营养的对话和随便的故事背景。游戏内容看似很多，但其实大多都是重复（说你呢某球），玩家就在不断重复地玩游戏，像做作业一样慢慢清点清任务。&#160; &#160; &#160; &#160;然而荒野之息打破了这种模式。那么任天堂是如何让玩家在开放世界中不感到乏味呢？ 互动与自由&#160; &#160; &#160; &#160;无数的互动，你想得到的想不到的，让塞尔达这个世界仿佛和真实世界一般自然。&#160; &#160; &#160; &#160;塞尔达中的互动实在过多，这里以火举例子。&#160; &#160; &#160; &#160;在塞尔达中，你可以用木棒去引火而得到火，也可以靠铁质的武器打打火石来生火。火可以用来作为照明，也可以用来点燃一切草木以及木材做的东西（也很容易不小心就点燃到易燃物）。在寒冷之地，火可以暖身子，融化冰块，可以生火来烤熟食物。&#160; &#160; &#160; &#160;你以为这样就足够了吗？&#160; &#160; &#160; &#160;在荒野之息中，火还具有传递性。如果你在森林里放一把火，那可能你扭头一会儿，会发现一片森林被你烧了。如果此时有大风吹过的话，火势会蔓延地更快（放火烧山牢底坐穿（））&#160; &#160; &#160; &#160;不仅如此，如果你点燃了大片的草地，可以制造出上升气流，这时候你打开降落伞，就可以随着上升气流飞到空中（然后就可以空中偷袭敌人，或者说到高处去（当然塞尔达的任何悬崖峭壁都可以直接攀爬））&#160; &#160; &#160; &#160;不仅如此，你甚至可以通过火苗的摆动来判别风向和风力，借此来判断如何射弓箭能够射的更准（塞尔达的弓箭会根据被风向和风力干扰，会受重力干扰）。如果你的弓箭上带火焰，那被弓箭射杀的动物将会直接被烤熟（然后就可以直接吃，塞尔达的很多肉类不能生吃需要料理加工）&#160; &#160; &#160; &#160;不仅如此，如果敌人举着木盾，你拿个火把（火在武器上燃火或火剑）甚至能够将敌人的木盾给烧起来，当然如果你自己的武器烧起来也会被烧成灰烬。&#160; &#160; &#160; &#160;以上仅仅为举了一个小小的火为例，荒野之息的世界中还有无数多的细节和互动，比如天气系统，冷热饥饿，敌人的AI，料理系统等等…&#160; &#160; &#160; &#160;仿佛这个世界中的所有的东西之间都能互相影响，各种物理化学原理，在荒野之息显得格外真实。 探索&#160; &#160; &#160; &#160;对于开放世界游戏来说，如何让玩家获得探索的乐趣极为重要。荒野之息在这点上可谓做到了精妙的地步。&#160; &#160; &#160; &#160;对于荒野之息探索与内容设计这块，可以从非常专业的角度来分析，比如参考这篇文章https://www.iyingdi.com/web/article/search/62084?remark=user 这里我仅仅以玩家的角度来举例说明————&#160; &#160; &#160; &#160;荒野之息给人的感觉就是一个时时刻刻都充满未知的游戏。&#160; &#160; &#160; &#160;你可能在路上看到个蔬菜，然后自己放点配菜瞎炒一下，竟然做出了一道新菜。&#160; &#160; &#160; &#160;你可能走着走着天空中突然出现了一条雷龙，俯冲过你头上，你甚至还能攻击它。&#160; &#160; &#160; &#160;你可能发现一座无名小山，你好奇的上去看，竟然在上面发现了一个花园。&#160; &#160; &#160; &#160;你可能不小心把农民的地烧了，回头发现农民伤心的哭了..&#160; &#160; &#160; &#160;你可能发现你把骷髅兵的头打掉了之后，骷髅兵到处乱跑 找到了自己的头又装上了&#160; &#160; &#160; &#160;……&#160; &#160; &#160; &#160;如此种种，实在是太多了无法列举。而这些，没有人强迫你去看，他们都等着你自己主动（一不小心）就发现。所以在塞尔达的世界里，想做什么就去做吧，不要被传统游戏的经验所束缚，你会收获很多惊喜。&#160; &#160; &#160; &#160;在旅途中，你将会一直接触新鲜事物，即使你游山玩水慢慢打，100多个小时你也会全程保持新鲜和探索欲望。 关卡设计任天堂的脑洞无可质疑，过于牛逼，无法表达。 美术风格&#160; &#160; &#160; &#160;看图，过于美丽，无法表达。 解密&#160; &#160; &#160; &#160;如果你是塞尔达系列的老玩家，你期盼一个比前作更强的解密的话，你可能会略微失望，荒野之息的大迷宫只有4个，小迷宫倒是有120个遍布世界各地，谜题的难度和设计上确实是没有前作塞尔达厉害，毕竟荒野之息相比前作塞尔达是完全的革新。但是与解密游戏来说，已经属于极为优秀了。 音乐&#160; &#160; &#160; &#160;大部分曲目采用了钢琴为主，但所有曲目的共同点就是，如同荒野之息这个游戏一样，给人以如同看到辽阔无人的荒野一般的感受。与环境配合恰到好处。对于音乐部分也可以开一个专栏赏析，这里就不作过多分析。 总结&#160; &#160; &#160; &#160;8说了，说就是天下第一。 此文同步发布在社团公众号","categories":[{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"}],"tags":[{"name":"天下第一","slug":"天下第一","permalink":"https://aisaka.cloud/tags/%E5%A4%A9%E4%B8%8B%E7%AC%AC%E4%B8%80/"}]},{"title":"古都","slug":"阅读/古都","date":"2019-04-12T02:40:59.000Z","updated":"2021-01-17T13:09:29.000Z","comments":true,"path":"阅读/古都/","link":"","permalink":"https://aisaka.cloud/%E9%98%85%E8%AF%BB/%E5%8F%A4%E9%83%BD/","excerpt":"","text":"“对美的幻影，总没有厌倦的时候吧。幻影是不能践踏的，践踏了只能自食其果。” ——《古都》 川端康成 &#160; &#160; &#160; &#160;川端先生不愧是日本传统美学的集大成者。 &#160; &#160; &#160; &#160;18~20岁是第一次真正的感受到半遮面的现实的年纪。这些脆弱而细腻，复杂但单纯的情感，在川端先生的笔下如泉水一般汨汨而出，交织出一首含蓄的诗。好像每一句话都氤氲着回音。 &#160; &#160; &#160; &#160;自在飞花轻似梦，无边细雨思如愁。 &#160; &#160; &#160; &#160;在最美好的年纪，一切都终将会消散。纵使韶华易逝，但美犹存。是幻影，是执念。 &#160; &#160; &#160; &#160;无论是千重子，还是雪，亦或是古都——","categories":[{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/categories/%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"川端康成","slug":"川端康成","permalink":"https://aisaka.cloud/tags/%E5%B7%9D%E7%AB%AF%E5%BA%B7%E6%88%90/"}]},{"title":"Word2Vec","slug":"人工智能/词向量","date":"2019-04-10T02:42:09.000Z","updated":"2020-05-29T14:59:42.000Z","comments":true,"path":"人工智能/词向量/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%AF%8D%E5%90%91%E9%87%8F/","excerpt":"","text":"什么是词向量一种词的表示方法。通常NLP中使用one-hot或词向量表示 one-hot即为一维一词，占用空间大，且无法体现词之间的关联性 于是使用词向量可以包含更多信息，且使得向量在空间的表示更稠密。 如何生成词向量基于统计略。 语言模型生成词向量 NNLM（neural network language model） 目标函数 $L=\\frac{1}{T}\\Sigma^T_{t=1}f(w_t,w_{t-1},…,w{t-n+1})$ 这个函数即目标将每一步的文档集的平均输出概率最大化。 但是这个模型在softmax层占用过多资源（与词表长度成正比）。 这个模型虽然现在不使用了，但是却提出了一个很有意义的思路，embedding层，中间层，softmax层（除外）。后面word2vec会详细展开。 C&amp;W 基于NNLM改变了目标函数，$L=max(0,1-(g_{\\theta,E}(s)-g_{\\theta,E}(z)))$ 原NNLM 模型的目标是构建一个语言概率模型 ，而 C&amp;W 则是以生成词向量为目标的模型。 在 NNLM 模型的求解中，最费时的部分当属隐藏层到输出层的权重计算(softmax层)。由于C&amp;W 模型没有采用语言模型的方式去求解词语上下文的条件概率，而是直接对 n 元短语打分，这是一种更为快速获取词向量的方式。C&amp;W 模型的核心机理是 : 如果 n 元短语在语料库中出现过，那么模型会给该短语打高分;如果是未出现在语料库中的短语则会得到较低的评分，将这两者的输出值差异最大化。 Word2Vec 其中包含①CBoW ②skip gram CBoW 输入为上下文（窗口）的one-hot比如我们要预测 i love eating coffee里的eating则one hot编码： i :0001 love:0010 eating:0100 coffee:1000我们要输入eating的前后文（选择窗口），那么输入网络的就是 0001,0010,1000（对应三个块） 模型结构： 假设一共有$V$个单词，在one-hot表示下每个单词$V$维 $W_{V×N}：$输入权值矩阵（所有输入共享一个矩阵，即词嵌入矩阵，查词表），$W_{N×V}’：$输出权值矩阵，最后一层为softmax激活函数 前向计算过程：上下文单词乘以词嵌入矩阵得到各自的词向量，然后再隐层求和平均即为待预测单词的词向量。公式表达：中间的向量为$v$，表记当前词嵌入矩阵为$W$，输入表记为$i_1,i_2,i_3$，则： v=\\frac{W×i_1+W×i_2+W×i_3}{3} 中间那块儿隐藏层得到的向量$v$就是预测词的词向量，为$N$维向量，通常$N&lt;&lt;V$(Word2vec模型中的隐藏层没有激活函数，只是对各输入向量乘以输入权值矩阵$W$之后进行线性求和)。 由输入层到映射层，降低维度的过程($k \\to N$)，就是将one-hot转变为词向量的过程，也就是 word embedding（词嵌入）。之所以词向量能够保留上下文信息，就是因为在训练输入的时候，输入了其上下文信息。 输入权值矩阵$W$是所有单词的word embedding，也叫做查找表（look up table），其将one-hot转化为对应的词向量，实际上该矩阵每一列就是对应one-hot序号的词向量。 如何使用：我们保存了训练结束的$W$矩阵之后，在使用训练好的模型的时候，输入上下文one-hot就能得到对应的词向量了。 如何训练/训练目标：让输入词映射到隐藏层（词向量）后乘以输出权值矩阵$W’$，能够以最大概率准确输出输入词（也就是说输入经过这个word2vec模型并反向输出之后能还原回来，也就相当于信息无损压缩/嵌入后又能正确还原） 具体地，就是要最大化在给定输入词和前后文本情况下输出正确关键词的概率，比如i love eating coffee中，要最大化输出eating的概率，就是要最大化$P(eating|i,love,coffee)$ 具体如何训练：对乘以$W’$获取的输出，概率最大的index所指示的单词为预测出的中间词，与原输入词的one-hot做比较，根据误差反向传播更新权重矩阵。 举例：比如输入为的关键词one-hot为[0,0,0,1]（略去上下文），经过$W’$并映射到隐藏层（词向量）又经过$W’$后，输出为[0.2,0.3,0.1,0.4]，那么损失函数就是计算[0.2,0.3,0.1,0.4]到[0,0,0,1]的损失，尽量减小这个损失。 skip gram 输入为一个词的one-hot，输出为多个词的one-hot（上下文），然后BP训练即可，相当于CBoW结构反过来，学的依然是$W$权重 训练目标：比如输入eating，求上下文，那么就是最大化$P(i|eating),P(i|love)，P(i|coffee)$ 补充：torch.nn.Embedding 与 词嵌入的实际使用词嵌入层 word2vec就是一种词嵌入算法 为什么我们在RNN模型外面对语料做了一次word2vec词嵌入，但再输入进RNN模型之前有还有一个词嵌入层呢？且这个词嵌入层的参数是需要训练学习的。 因为通常word2vec一般只做nn.embedding的初始化。在输入进RNN之前再加一层词嵌入层即nn.Embedding，其目的是让词嵌入向量继续随着模型训练而变化 为什么呢？我们word2vec可能是用了别人的词向量表（如我在项目中用的腾讯词向量表），但我们还需要根据我们的特定任务进行特化，所以我们在RNN网络之前再加一层词嵌入层，让模型根据实际任务去学习词嵌入（学习到的就是这层的参数：词嵌入矩阵） 我们也可以不用两个词嵌入层，其中一个也行，但实验效果会比较差，我在项目中第一次用腾讯w2v+LSTM效果很差应该就是这个原因。 具体参数： torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False) 这是一个矩阵类，里面初始化了一个随机矩阵，矩阵的长是字典的大小（词表长度），宽是目标的词嵌入向量长度，向量的维度根据你想要表示的元素的复杂度而定。类实例化之后可以根据字典中元素的下标来查找元素对应的向量。(长宽位置是否调换取决于输入向量格式，总之得到词向量是一个一维向量)","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"词向量","slug":"词向量","permalink":"https://aisaka.cloud/tags/%E8%AF%8D%E5%90%91%E9%87%8F/"},{"name":"word2vec","slug":"word2vec","permalink":"https://aisaka.cloud/tags/word2vec/"}]},{"title":"百年孤独","slug":"阅读/百年孤独","date":"2019-04-09T07:40:21.000Z","updated":"2021-01-17T13:09:23.000Z","comments":true,"path":"阅读/百年孤独/","link":"","permalink":"https://aisaka.cloud/%E9%98%85%E8%AF%BB/%E7%99%BE%E5%B9%B4%E5%AD%A4%E7%8B%AC/","excerpt":"","text":"“多年以后，面对行刑队，奥雷里亚诺·布恩迪亚上校将会回想起父亲带他去见识冰块的那个遥远的下午。” “同一血脉的两个孤独者之间的接近与友谊无涉，却有助于他们承受将两人分离又联合的神秘孤独。” “奥雷里亚诺平生从未像此刻一般清醒，他忘却了家中的死者，忘却了死者的痛苦，用费尔南达留下的十字木条再次钉死门窗，远离世间一切干扰，因为他知道梅尔基亚德斯的羊皮卷上记载着自己的命运。他发现史前的植物、湿气蒸腾的水洼、发光的昆虫已将房间内一切人类踪迹消除净尽，但羊皮卷仍安然无恙。他顾不得拿到光亮处，就站在原地，仿佛那是用卡斯蒂利亚语写就，仿佛他正站在正午明亮的光线下阅读，开始毫不费力地大声破译。那是他家族的历史，连最琐碎的细节也无一遗漏，百年前由梅尔基亚德斯预先写出。他以自己的母语梵文书写，偶数行套用奥古斯都大帝的私人密码，奇数行择取斯巴达的军用密码。而最后一道防线，奥雷里亚诺在迷上阿玛兰妲·乌尔苏拉时就已隐隐猜到，那便是梅尔基亚德斯并未按照世人的惯常时间来叙述，而是将一个世纪的日常琐碎集中在一起，令所有事件在同一瞬间发生。奥雷里亚诺为这一发现激动不已，逐字逐句高声朗读教皇谕令般的诗行，当年阿尔卡蒂奥曾从梅尔基亚德斯口中听闻，却不知道那是关于自己死亡的预告。他读到羊皮卷中预言世上最美的女人的诞生，她的灵魂与肉身正一起向天飞升；他读到那对遗腹孪生子的来历，他们放弃破译羊皮卷不仅因为缺乏才能和毅力，更是因为时机尚未成熟。读到这里，奥雷里亚诺急于知道自己的身世，跳过几页。此时微风初起，风中充盈着过往的群声嘁喳，旧日天竺葵的昵喃窸窣，无法排遣的怀念来临之前的失望叹息。他对此毫无察觉，因为他发现了关于自己身世的初步线索。他读到一位好色的祖父一时迷了心窍穿越幻象丛生的荒野，寻找一个不会令他幸福的美女。奥雷里亚诺认出了他，沿着亲缘的隐秘小径追寻下去，找到了自己被赋予生命的一刻，那是在一间昏暗的浴室里，蝎子和黄蝴蝶的环绕间，一个工匠在一个因反叛家庭而委身于他的少女身上满足了欲望。他读得如此入神，仍未发觉风势又起，飓风刮落了门窗，掀掉了东面长廊的屋顶，拔出了房屋的地基。到这时，他才发现阿玛兰妲·乌尔苏拉不是他的姐妹，而是他的姨妈，而当年弗朗西斯·德雷克袭击里奥阿查不过是为了促成他们俩在繁复错综的血脉迷宫中彼此寻找，直到孕育出那个注定要终结整个家族的神话般的生物。当马孔多在《圣经》所载那种龙卷风的怒号中化作可怕的瓦砾与尘埃旋涡时，奥雷里亚诺为避免在熟知的事情上浪费时间又跳过十一页，开始破译他正度过的这一刻，译出的内容恰是他当下的经历，预言他正在破解羊皮卷的最后一页，宛如他正在会言语的镜中照影。他再次跳读去寻索自己死亡的日期和情形，但没等看到最后一行便已明白自己不会再走出这房间，因为可以预料这座镜子之城——或蜃景之城——将在奥雷里亚诺·巴比伦全部译出羊皮卷之时被飓风抹去，从世人记忆中根除，羊皮卷上所载一切自永远至永远不会再重复，因为注定经受百年孤独的家族不会有第二次机会在大地上出现。” ​ “生命从来不曾离开过孤独而独立存在。无论是我们出生、我们成长、我们相爱、还是我们成功失败，直到最后的最后，孤独犹如影子一样存在于生命一隅。”​ 百年孤独。","categories":[{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/categories/%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/tags/%E9%98%85%E8%AF%BB/"}]},{"title":"Pytorch中自定义Dataset和Dataloader总结","slug":"人工智能/Pytorch中自定义Dataset和Dataloader","date":"2019-04-05T12:32:04.000Z","updated":"2019-10-23T01:43:14.000Z","comments":true,"path":"人工智能/Pytorch中自定义Dataset和Dataloader/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89Dataset%E5%92%8CDataloader/","excerpt":"","text":"Dataset自定义数据集与DataLoader 数据集加载器Dataset定义了数据集的存在，其中包含了每个数据的路径和标签,dataset类型不是拿来保存的！它只是相当于一个数据集索引器！并没有加载数据或封装数据！ Dataloader则定义了指定数据集的加载方法 在对Dataloader进行迭代的时候，Dataset指向的数据集才正式被加载 DatasetDataset 定义并加载自己的数据集继承自Dataset并必须重写三个函数：__init__(self, )：将任何需要的初始化,比如读取全部数据路径等，不限制参数个数__getitem__(self,index)：根据每次调用时的index返回对应元素和标签__len__(self)：负责返回数据集中的元素个数 以加载图片数据集为例from torch.utils.data import Dataset #结构 class myDataset(Dataset): #self, 代表可以补充其他自定参数 def __init__(self, ): pass def __len__(self): #返回最大长度 return len def __getitem__(self,index): #返回每次应读取的单个数据 return data,label #例子 class myDataset(Dataset): def __init__(self,root,transform&#x3D;None): # 所有图片的绝对路径 imgs&#x3D;os.listdir(root) #这句话可以使用glob快速加载 见66. self.imgs&#x3D;[os.path.join(root,k) for k in imgs] self.transforms&#x3D;transform def __getitem__(self, index): img_path &#x3D; self.imgs[index] pil_img &#x3D; Image.open(img_path) pil_img &#x3D; pil_img.convert(&quot;RGB&quot;) if self.transforms: data &#x3D; self.transforms(pil_img) else: pil_img &#x3D; np.asarray(pil_img) data &#x3D; torch.from_numpy(pil_img) label &#x3D; xxxxx(这里省略，总之是得到这个图的标签） return data,label def __len__(self): return len(self.imgs) #创建数据集实例并初始化 dataSet&#x3D;FlameSet(&#39;.&#x2F;test&#39;,transform &#x3D; transform) #依然用Dataloader加载数据集 data &#x3D; torch.utils.data.DataLoader(myDataset,batch_size&#x3D;BATCH_SIZE,shuffle&#x3D;True,num_workers&#x3D;0) DataLoaderDataLoader将数据集对象和不同的取样器联合，如SequentitalSampler和RandomSampler，并使用单进程或多线程的迭代器，为我们提供批量数据。取样器是为算法提供数据的不同策略。dataloader = torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,shuffle=True，num_workers=0,collate_fn=fn)Dataloader的储存数据形式是一个batch一个batch存，取也是一个batch一个batch取，每组数据的内容分别为一组batch的input和该组batch每个数据对应的label组 for data in phase: inputs,label &#x3D; data 注意: datalodaer.__len__()得到的是batch（分组）总数而不是数据总数dataset.__len__得到的是数据总数 自定义DataLoader： collate_fn是非常重要的，如nlp中经常在里面做paddingcollate_fn是自定义函数来设计数据收集的方式，意思是已经通过上面的Dataset类中的getitem函数采样了batch_size数据，以一个包的形式传递给collate_fn所指定的函数collate_fn的输入是一个list，list的长度是一个batch_size，list中的每个u岸数都是getitem得到的结果 以我一次项目中加载NLP数据集写的代码为例： # 生成datasets # 不进行转置，直接在网络中输入的时候调用RNN的函数进行转置 class textDataset(dataset.Dataset): def __init__(self,data,label): self.data = data self.label = label def __len__(self): return len(self.data) #在取数据的时候调用 def __getitem__(self,index): data = torch.Tensor(self.data[index]) # 这里是在getitem的时候才会转化为long #注意这里在转tensor的时候必须得是list格式，然后转成了之后再取出第0项即为单tensor元素 label = torch.LongTensor([self.label[index]])[0] return data,label def preprocess(batch_data): max_seq_size = 30 #最大句长 （看清楚这里处理的句子是，分割or。分割） vec_size = 200 #经过dataloader调用__getitem__方法从dataset取得的数据是这样的形式(dataset[0],dataset[1],xxxx)一个batch长度， #也就是相当于((data0,label0),(data1,label1),xxx)，所以用zip分别提取出来形成(data,label) #zip(*zipped) 是逆zip datas,labels = zip(*batch_data) corpus_vec_resize = list() #遍历每一行（每一个seq） for corpus_vec in datas: #这里对每个data中的句子做padding #【也可以使用掩码的方式做padding，生成掩码矩阵 应该有更简单的方法或工具】 #将处理后的全部转为Tensor，如果转成narray再弄会出错 #若长度过小,则从句尾开始填充 if len(corpus_vec) &lt; max_seq_size: pad_num = max_seq_size-len(corpus_vec) padding = list([[0]*vec_size]*pad_num) seq_padded = np.append(corpus_vec,padding,axis=0) seq_padded = torch.Tensor(seq_padded) corpus_vec_resize.append(seq_padded) #若长度过长,则依次从句头和句末开始修剪 if len(corpus_vec) > max_seq_size: cut_num = len(corpus_vec)-max_seq_size #句头剪cut_num//2 句尾剪cut-num-cut_num//2 seq_cut = corpus_vec[cut_num//2:len(corpus_vec)-(cut_num-cut_num//2)] seq_cut = torch.Tensor(seq_cut) corpus_vec_resize.append(seq_cut) if len(corpus_vec) == max_seq_size: corpus_vec = torch.Tensor(corpus_vec) corpus_vec_resize.append(corpus_vec) #将datas转变为tensor datas = torch.stack(corpus_vec_resize) #合并处理labels label_res = list() for i in labels: #处理打错的标签(非0和1) if i.item()!=0 and i.item()!=1: label_res.append(1) else: label_res.append(i.item()) labels = torch.LongTensor(label_res) # print(labels) return datas,labels #封装与加载 corpus_dataset = textDataset(data=corpus_vec,label=labels) #这里定义了加载的具体方法：preprocess textDataloader = dataloader.DataLoader(corpus_dataset,batch_size=batch_size,shuffle=False,num_workers=1,collate_fn=preprocess) dataloader参数的更多详细资料还可以参考下面资料： https://www.jianshu.com/p/8ea7fba72673https://www.jianshu.com/p/bb90bff9f6e5 https://blog.csdn.net/weixin_30241919/article/details/95184794 dataloader的num_work子线程尽量数量开多点！不要让大量时间用去读数据.一般子线程设和核的个数相同 getitem()如果类中定义了getitem()方法,那么它的实例对象（假设为P）就可以P[Key]这样取值。当实例对象做P[Key]运算的时候就会调用getitem()方法，返回的就是这个方法的return dataset里有这个方法，当dataloader加载dataset的时候就会自动调用","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"数据","slug":"数据","permalink":"https://aisaka.cloud/tags/%E6%95%B0%E6%8D%AE/"}]},{"title":"重新打理BLOG","slug":"博客/重新打理BLOG","date":"2019-03-27T05:48:48.000Z","updated":"2021-01-18T02:56:55.000Z","comments":true,"path":"博客/重新打理BLOG/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/%E9%87%8D%E6%96%B0%E6%89%93%E7%90%86BLOG/","excerpt":"","text":"前段时间因为繁忙，没时间打理个人网站 现在打算开始整理一下，逐步也把评论系统，目录之类的插件给搞定 把绝大部分日记都迁出去了，以后这里主要是..啥都有","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"HEXO遇到的坑","slug":"博客/HEXO遇到的坑","date":"2019-03-27T04:30:42.000Z","updated":"2019-04-01T15:07:42.000Z","comments":true,"path":"博客/HEXO遇到的坑/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/HEXO%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/","excerpt":"","text":"source文件夹下面新建一个叫CNAME的文件填上网址 才能由自定义域名访问自己的github.io 安装了图片插件但是图片依然无法显示问题 ①可能是图片路径出错导致 要在_config.yml中修改url为自己的域名！ ②后缀名要注意大小写！ 路径和名称大小写要统一！ hexo改标题出现乱码 language: zh-Hans 配置文件要保存为UTF-8格式，不然会乱码 语法上的坑 HEXO 表格与正文之间需要两个空行","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"https://aisaka.cloud/tags/HEXO/"}]},{"title":"python相关笔记","slug":"程序语言/python相关笔记","date":"2019-03-27T03:00:58.000Z","updated":"2019-10-23T02:10:41.000Z","comments":true,"path":"程序语言/python相关笔记/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/python%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/","excerpt":"迄今为止在python上遇到的坑，超长预警","text":"迄今为止在python上遇到的坑，超长预警 with open的使用with open('/path/to/file', 'r') as f: print(f.read()) 等效于try: f = open('/path/to/file', 'r') print(f.read()) finally: if f: f.close() os.listdir(path) 返回path路径下的所有文件和文件夹列表 os.path.join(path1,str) 将两个字符串合并生成一个新路径 列表解析功能 比如b =[i+2 for i in a] apk_dirs = [os.path.join(BASE_PATH, name) for name in names] list用于将元组转换为列表 元祖不可更改，列表可以更改。列表对应一大批操作函数。 通过这种方式可以遍历打开Path路径下的所有文件 注意冒号 for file in os.listdir(Path): with open(os.path.join(Path, file), 'r') as f '''熟悉用python操作文件路径 熟悉使用2 3 for in等''' Python JSONhttp://www.runoob.com/python/python-json.htmljson.dumps 将 Python 对象编码成 JSON 字符串json.loads 将已编码的 JSON 字符串解码为 Python 对象 字典&#123;元组(列表[ 经常用a.append(1)来代表一位记录特征 shutil.copy(source, destination)将source路径的文件复制为destination路径的文件（相当于cp） matplotlib.pyplot 用于画画的库 dict.value() 方法返回所有的字典值组成的列表 index() 函数用于从列表中找出某个值第一个匹配项的索引位置。 jupyter可以方便选择哪几个指定模块来执行 而不用执行整个文件 python目录与文件操作（部分） os.path.exists(path) 判断一个目录是否存在 os.makedirs(path) 多层创建目录 os.mkdir(path) 创建目录 shutil.copy(fileA, fileB) 将路径文件A复制到路径文件B。注意如果fileB路径的中间路径并不存在，需要建立中间的目录！（手动or用os.makedirs） 混淆矩阵sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)y_true: 是样本真实分类结果，y_pred: 是样本预测分类结果labels：是所给出的类别，通过这个可对类别进行选择sample_weight:样本权重后两者可以没有详细用法见 https://blog.csdn.net/m0_38061927/article/details/77198990 https://blog.csdn.net/m0_37518259/article/details/80658131 读取文件的编码问题，字符串编码问题 超级大坑超级大坑！！！！！https://stackoverflow.com/questions/956867/how-to-get-string-objects-instead-of-unicode-from-json python格式化输出print (&quot;Name:%10s Age:%8d Height:%8.2f&quot;%(&quot;Aviad&quot;,25,1.83)) ```python in not in正确写法key = “aaa”lt = [“aaa”,”bbb”,”vvv”]if key in lt: print(&quot;list is true&quot;) else: print(&quot;list is false&quot;) list is true 错误写法1：key写成一个列表。 in语法是要一个元素in一个列表key = [“aaa”]lt = [“aaa”,”bbb”,”vvv”]if key in lt: print(&quot;list is true&quot;) else: print(&quot;list is false&quot;) list is false 错误写法2：if a in b is True。 不能用is True。原因不明（？）key = “aaa”lt = [“aaa”,”bbb”,”vvv”]if key in lt is True: print(&quot;list is true&quot;) else: print(&quot;list is false&quot;) list is false 21. 有时候python无法判断该数据为数值or字符串。 所以在输出的时候，有些无法分清的情况需要&#96;print(str(key))&#96; 22. python的函数参数传递（实参和形参） 在函数体内修改参数内容会影响到函数外的对象吗？ （1）如果数字、字符串或元组，本身就是不可变的，自然也不会影响到函数体外的对象 （2）如果是列表或字典，那么函数内修改参数内容，就会影响到函数体外的对象。 备注：这里的修改参数是修改参数对象内部的值，不是赋值哦。即var[1]&#x3D;&#39;hello&#39;和var&#x3D;[&#39;hello&#39;,&#39;world&#39;]区别。即使是列表，在函数体内对参数重新赋值了，不会影响到函数体外的对象哦。注意和c++的比较。 相当于python函数参数传递是一个指针 23. 字典添加新pair &#96;&#96;&#96;python dict &#x3D;&#123;&#125; dict[&#39;aaa&#39;]&#x3D; 0 python中没有do while循环。可以由如下代码代替 while True: xxxx if condtion满足: break 求列表元素个数len(list) for i in range(a,b) 包含a不包含b ```for line in file: line = line.spilt(&#39;,‘) 这样读出来的列表元素全是字符串形式！而且 末尾的/n也会包含在最后一个字符里 28. &#96;str.strip（）&#96;去掉字符串末尾字符（常用来去掉&#39;&#x2F;n&#39;等 29. &#96;list&#96;有序而&#96;dict&#96;无序 30. &#96;&#96;&#96;python total_list &#x3D; sorted(total_dict.items(), key&#x3D;lambda x: x[1]) for (key, value) in total_list: python中字典是无序的，list是有序的想要对字典或列表等排序需要借助sort函数。然而由于字典是无序的，经sort函数操作之后会变成一个列表。如果直接使用sort(dict.values)的话，将生成一个只由字典的value构成的排序后的列表，如果sort(dict.keys)的话同理为只由键组成的排序后的列表。如果要输出键值对的话，就按照上面的代码，转化为了有序元组列表的形式。lambda表示语法形式lambda x: x[1]中x[0]表示对键进行排序，x[1]表示对值进行排序sort函数默认是从小到大排序，如果要从大到小则添加参数reverse=True【以上内容可继续探索】 python3 中 \\即为直接除法 判断类型是 type(a) is dict不是 a is dict！ 字典无法在遍历中动态改变，而类别可以 Debug:Error loading notebook An unknown error occurred while loading this notebook.这个错误的弥补方法是修改~/.local/share/jupyter文件夹的权限：sudo chmod -R 777 ~/.local/share/jupyter if os.path.splitext(resPath + file)[1] == ‘.jpg’ ls -l filename|grep total统计文件夹下文件个数 递归删除文件夹shutil.rmtree(path=folderPath)在shutil库下 python多进程默认不能共享全局变量https://blog.csdn.net/houyanhua1/article/details/78236514python多进程相当于将环境所有变量什么的给每一个进程复制一份，所以你在子进程修改了变量自然不会修改到全局 python子进程不报错 需要用 try: except Exception as ex: print(ex) 来捕获 重置索引用reset_index然后drop掉index列即可reindex就是一坨屎 截取字符串操作 str &#x3D; ‘0123456789’ print str[0:3] #截取第一位到第三位的字符 print str[:] #截取字符串的全部字符 print str[6:] #截取第七个字符到结尾 print str[:-3] #截取从头开始到倒数第三个字符之前 print str[2] #截取第三个字符 print str[-1] #截取倒数第一个字符 print str[::-1] #创造一个与原字符串顺序相反的字符串 print str[-3:-1] #截取倒数第三位与倒数第一位之前的字符 print str[-3:] #截取倒数第三位到结尾 print str[:-5:-3] #逆序截取，具体啥意思没搞明白？ 位运算 np.bitwise_and([7],[3])=3 np.bitwise_or([7],[3])=7 路径字符串分割 path.split(&#39;&#x2F;&#39;)[-1] 以&#x2F;为分隔符，保留倒数第一段 dataFrame.to_csv(savePath,mode=&#39;a&#39;,header=0,index=False) python list/字符串替换 # Python replace() 方法把字符串中的 old（旧字符串/list） 替换成 new(新字符串/list)，如果指定第三个参数max，则替换不超过 max 次。 str = str.replace(old, new[, max]) # 注意不会改变原始内容，要赋值回去！ python多线程 # 由于每个python模块（python文件）都包含内置的变量__name__，当运行模块被执行的时候，__name__等于文件名（包含了后缀.py）。如果import到其他模块中，则__name__等于模块名称（不包含后缀.py）。而“__main__”等于当前执行文件的名称（包含了后缀.py）。所以当模块被直接执行时，__name__ == '__main__'结果为真；而当模块被import到其他模块中时，__name__ == '__main__'结果为假，就是不调用对应的方法。 # __name__ 是当前模块名，当模块被直接运行时模块名为 __main__ 。当模块被直接运行时，代码将被运行，当模块是被导入时，代码不被运行 from multiprocessing import Pool #创建线程对象 pool = Pool(processes=k) #开始执行线程内容 func即为我们每个线程要执行的东西，args为传入func函数参数 pool.apply_async(func,args=(agr1,arg2,arg3)) #等待所有进程结束 pool.close() pool.join() 常见迭代方法： for index, item in enumerate(list) os.path.getsize函数的单位为字节B 正则表达式https://blog.csdn.net/u014535666/article/details/82972089#注意python3中 .? .+等要用括号包起来！ (.?) (.+)且注意 findall返回的list元组！python正则表达式常用函数的理解:https://www.cnblogs.com/papapython/p/7482349.html df.drop(x) 如果df.drop([等式]) 会出事！直接全没了！ 验证一下 linux语句返回输出os.system()可以执行linux语句但无法获取输出os.popen()就可以获取命令行输出 ，返回的是一个文件还要 r = os.popen(commend) result = r.read() python赋值、copy与deepcopylist中套list得用deepcopyhttps://blog.csdn.net/u010712012/article/details/79754132赋值与深浅拷贝https://www.cnblogs.com/Eva-J/p/5534037.htmlpython一切都是对象，赋值是传递引用 eval函数在python中做数据类型的转换还是很有用的。它的作用就是把数据还原成它本身或者是能够转化成的数据类型.注意 为了安全性 还有个ast.literal_evalhttp://www.php.cn/python-tutorials-376459.html xgboost版本为0.6a1的时候 对应scikit-learn的版本为0.19.0版本要匹配！ 弱智错误：os.system(str)里面只能是一个字符串，如果是要多段拼接是用加号不是逗号！os.system(&quot;ps&quot;,&quot;-ef&quot;) 错误！os.system(&quot;ps&quot;+&quot;-ef&quot;)正确！ python继承 #定义类A class A: #B继承A class B(A): if __name__ == &#39;__main__&#39;: os.path.join用这个组合路径更好！ format函数 (python格式化输出）https://www.runoob.com/python/att-string-format.htmlformat函数输出可以不限制括号内的参数类型，转化为字符串输出format 函数可以接受不限个参数，位置可以不按顺序。 &quot;&#123;&#125; &#123;&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 不设置指定位置，按默认顺序 &gt;&gt;&#39;hello world&#39; &quot;&#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 设置指定位置 &gt;&gt;&#39;hello world&#39; &quot;&#123;1&#125; &#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 设置指定位置 &gt;&gt;&#39;world hello world&#39; 也可以设置参数 print(&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(name&#x3D;&quot;菜鸟教程&quot;, url&#x3D;&quot;www.runoob.com&quot;)) # 通过字典设置参数 site &#x3D; &#123;&quot;name&quot;: &quot;菜鸟教程&quot;, &quot;url&quot;: &quot;www.runoob.com&quot;&#125; print(&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(**site)) # 通过列表索引设置参数 my_list &#x3D; [&#39;菜鸟教程&#39;, &#39;www.runoob.com&#39;] print(&quot;网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;&quot;.format(my_list)) # &quot;0&quot; 是必须的 &gt;&gt;网站名：菜鸟教程, 地址 www.runoob.com 网站名：菜鸟教程, 地址 www.runoob.com 网站名：菜鸟教程, 地址 www.runoob.com 也可以向 str.format() 传入对象： class AssignValue(object): def __init__(self, value): self.value &#x3D; value my_value &#x3D; AssignValue(6) print(&#39;value 为: &#123;0.value&#125;&#39;.format(my_value)) # &quot;0&quot; 是可选的 &gt;&gt;value 为: 6 数字格式化： print(&quot;&#123;:.2f&#125;&quot;.format(3.1415926)); &gt;&gt;3.14 更多用法列表见网页 可以这样用 print(&#39;-&#39;*10) 除法/ 一般除法//整除%求余 plt画图导库import matplotlib.pyplot as plthttps://blog.csdn.net/majinlei121/article/details/83994935常用函数(用法参数见help）plt.plot()画图plt.show()显示图像plt.legend()显示图像和图例 plt.xticks()``plt.yticks()x,y坐标轴的值设置(可以设置旋转坐标值等）plt.xlabel()``plt.ylabel()x,y轴标签设置plt.title()设置图像标题 w1 = plt.figure() 新建一个画图窗口 w1指向ax1 = fig.add_subplot(2,1,1) 向窗口中加入子图，参数为排列位置， ax1指向， 画2行1列个图形的第1个ax1.plot() 向ax1中画图 注意：无论是在子图中画图还是直接画图，都要用plt.show()来显示图像在子图中画图，要用 子图窗口.plot()来画图，不用子图则plt.plot()来画图 plt.scatter()画散点图plt.bar()画柱状图 返回对象的属性值vars()用法vars(object)可用于很多封装对象 zip函数 打包网上摘抄理解https://www.cnblogs.com/waltsmith/p/8029539.html zip函数非常好用！常用 class()(x) 这种用法class()即为生成class对象，后面跟个(x)就是调用该生成对象的方法！ getitem()如果类中定义了getitem()方法,那么它的实例对象（假设为P）就可以P[Key]这样取值。当实例对象做P[Key]运算的时候就会调用getitem()方法，返回的就是这个方法的return pip install xxx -i https://pypi.tuna.tsinghua.edu.cn/simple中科大源","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"PYTHON","slug":"程序语言/PYTHON","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/PYTHON/"}],"tags":[]},{"title":"python数据分析相关笔记","slug":"程序语言/python数据分析相关笔记","date":"2019-03-27T02:49:56.000Z","updated":"2019-12-26T08:19:21.000Z","comments":true,"path":"程序语言/python数据分析相关笔记/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/","excerpt":"迄今为止在python数据分析相关库上遇到的坑，超长预警","text":"迄今为止在python数据分析相关库上遇到的坑，超长预警 source .bashrc source activate base先激活base环境再jupyter notebook启动jupyter notebook！先前anaconda安装的包都是在base环境下的！在jupyter中sys.path就可以看出环境对没对！如果不是指定anaconda3中（我安装的）环境，那就没对！查看anconda3有哪些环境conda info --envs .ipynb文件转.py文件jupyter nbconvert --to script demo.ipynb for i in (a,b) for i in range(a,b) 别搞混了！且range左闭右开 black10w.drop(black10w[black10w[&#39;Filename&#39;]==filename].index,axis=0,inplace=True)去掉dataframe中文件名为filename的那一行 virtualenv --python=/usr/bin/python3.5 --no-site-packages envNAME用此命令建立新的python环境，并使用系统的python3.5http://www.cnblogs.com/freely/p/8022923.html +见20181123的周记 drop函数是个返回值！ pandas里好多函数都是返回值形式！一定勿忘赋值回去！不然不会改变df = df.drop(list) drop掉list中索引的内容，默认drop行（axis=0）如df=df.drop([0])就是把第0行去掉如果设置axis=1就是去掉列 索引可以不一定是序号 列用str索引那么列表里的元素就是list即可！drop掉指定行之后，不会自己重新索引！ 要手动重新索引!df = df.reset_index(drop = True)也可以直接修改列索引df = pd.DataFrame(df,columns = [&#39;One&#39;,&#39;Two&#39;,&#39;Three&#39;])（如果不需要用索引刻意不重建） pandas中的append()函数也是个返回值！df=df.append(x)在append两个dataframe之后，索引可能就乱了！要在append里加参数ignore_index=True即可自动重建索引df=df.append(x,ignore_index=True) 但是，非pandas库中的不一定是！比如对于list，不在pandas中，则必须直接list.append() iloc函数是按行数（编号）的！而不是index索引，即使drop后 index没有被重新排列，iloc也是从1开始数来定位 drop函数是drop的对应index，而不是编号！ 比如 a b c 0 1 6 4 1 2 7 4 2 3 8 5 drop掉1后就变成 a b c 0 1 6 4 2 3 8 5 而这时候iloc[2]就out of bonud了，因为编号2已经不在了，在的是index2 但是 loc是按索引取号！ 即使这行删了，他也不会out of bonud 因为想要的索引那行并没有被删！ 所以在循环删除满足条件的行的时候，要用loc来删除！因为删除行后每行的索引是不变的！但行号是会变的！iloc是按行号来算的，所以就会出错！ drop(x) 这里x是索引而不是行号 item = ‘t2_asd’item[0:3]输出：t2_截取和range一样，也是左闭右开 feaMatrix[:,&#39;a&#39;]等效于feaMatrix.a DataFrame.values values是DataFrame的一个特殊属性，得到一个array包含每一行的值(一个list) columns和rows也是DF的特殊属性，分布得到Index类型的列索引和行索引 如果feaMatrix.columns.values则得到array类型的列索引列表和行索引列表 >>feaMatrix.columns.values array(['a', 'b'], dtype=object) 切片和range都是左闭右开！！！！！ 切片的时候 行用：而列不能用： 矩阵合并可以用merge和append，都属于pandas库 pd.merge(left, right, how&#x3D;&#39;inner&#39;, on&#x3D;None, left_on&#x3D;None, right_on&#x3D;None, left_index&#x3D;False, right_index&#x3D;False, sort&#x3D;True, suffixes&#x3D;(&#39;_x&#39;, &#39;_y&#39;), copy&#x3D;True, indicator&#x3D;False) left︰ 对象right︰ 另一个对象on︰ 要加入的列 （名称）。必须在左、 右综合对象中找到。如果不能通过 left_index 和 right_index 是假，将推断 DataFrames 中的列的交叉点为连接键left_on︰ 从左边的综合使用作为键列。可以是列名或数组的长度等于长度综合right_on︰ 从正确的综合，以用作键列。可以是列名或数组的长度等于长度综合left_index︰ 如果为 True，则使用索引 （行标签） 从左综合作为其联接键。在与多重 （层次） 的综合，级别数必须匹配联接键从右综合的数目right_index︰ 相同用法作为正确综合 left_indexhow︰ 之一 ‘左’，’右’，’外在’、 ‘内部’。默认为内部。每个方法的更详细说明请参阅︰sort︰ 综合通过联接键按字典顺序对结果进行排序。默认值为 True，设置为 False将提高性能极大地在许多情况下suffixes︰ 字符串后缀并不适用于重叠列的元组。默认值为 (‘_x’，’_y’)。copy︰ 即使重新索引是不必要总是从传递的综合对象，复制的数据 （默认值True）。在许多情况下不能避免，但可能会提高性能 / 内存使用情况。可以避免复制上述案件有些病理但尽管如此提供此选项。indicator︰ 将列添加到输出综合呼吁 _merge 与信息源的每一行。_merge 是绝对类型，并对观测其合并键只出现在 ‘左’ 的综合，观测其合并键只会出现在 ‘正确’ 的综合，和两个如果观察合并关键发现在两个 right_only left_only 的值。eg：result = pd.merge(left, right, how=&#39;outer&#39;, on=[&#39;key1&#39;, &#39;key2&#39;]) 遇见大坑:合并中发生排列组合问题！当两个要合并的dataframe里合并关键字有重名项的时候，将会发生排列组合！ a b 1 0 1 2 a c d 1 1 5 1 2 6 按a合并，结果是 a b c d 1 0 1 5 1 0 2 6 1 2 1 5 1 2 2 6 矩阵检索 #对于两个矩阵，找同一项的另一项，直接找速度非常慢。可以采用矩阵合并之后，再搜索 df.loc[df.Filename==filename, 'label'] = 1 tencent[tencent.Filename == '5F94E5453CF23ACBF0256575D629A442'] #以上两种都可以找 dataframe删除行或列用法：DataFrame.drop(labels=None,axis=0, index=None, columns=None, inplace=False) 在这里默认：axis=0，指删除index，因此删除columns时要指定axis=1； inplace=False，默认该删除操作不改变原数据，而是返回一个执行删除操作后的新dataframe； inplace=True，则会直接在原数据上进行删除操作，删除后就回不来了。 eg: tencent = tencent.drop([tencent[tencent.Filename == '6A6709AA7F9DF362CF90D2DE063D1FFF'].index.values[0]],inplace=True) #这里tencent[tencent.Filename == '6A6709AA7F9DF362CF90D2DE063D1FFF'] 找到了该行，.index.values[0]]取出了索引号，然后由drop函数去drop，inplace=True重建索引，然后赋值回给tencent ################################## >>>df = pd.DataFrame(np.arange(12).reshape(3,4), columns=['A', 'B', 'C', 'D']) >>>df A B C D 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 #Drop columns,下面两种方法等价 >>>df = df.drop(['B', 'C'], axis=1) A D 0 0 3 1 4 7 2 8 11 >>>df = df.drop(columns=['B', 'C']) A D 0 0 3 1 4 7 2 8 11 #Drop rows by index >>>df = df.drop([0, 1]) A B C D 2 8 9 10 11 对于index类型，可以用index.values转化为array类型 .values是什么属性 JSON和字典[JSON]和[字典]的标准格式是用&#123;&#125;包起来的内容！必须要有外面的{}dict = eval(str)可以将字符串转化为字典 inplace inplace参数的理解： 修改一个对象时： inplace=True：不创建新的对象，直接对原始对象进行修改； inplace=False：对数据进行修改，创建并返回新的对象承载其修改结果。 python中list转字符串命令：’’.join(list)其中，引号中是字符之间的分割符，如“,”，“;”，“\\t”等等如：list = [1, 2, 3, 4, 5]‘’.join(list) 结果即为：12345‘,’.join(list) 结果即为：1,2,3,4,5 json函数库 import json dict = json.loads(string) #即可将string转换为json，其中里面的一切格式问题都不用管，json.loads全部解决 python分割除了用split方法以外，还可以用正则表达式实现多规则分割import re a = \"Hello world!How are you?My friend.Tom\" re.split(\" !|\\?|\\.\", a) ['Hello', 'world', 'How', 'are', 'you', 'My', 'friend', 'Tom'] ''' 但要注意，对? ( ) . 等字符分割的时候要转义，即要写 \\. \\( \\) \\? ''' append的时候勿忘ignore_index = True 否则索引就凉了！ python广播numpy广播使得不同数组间可以进行运算如一个向量+一个常数的时候，常数会被自动扩展成一个向量见松鼠书P435 numpy向量化计算尽量少使用显式循环用向量化（并行运算） 即将元素作为向量进行计算numpy.dot(x,y)numpy.exp(v)等等 numpy有很多向量化函数即为点乘平时计算的时候也可以直接用向量化计算，速度快很多 numpy中常用reshape来确保数组的形式 a.T转置 numpy.random.randn(5)随机生成矩阵 15 注意生成的只有一个[]numpy.random.randn(1,5)随机生成矩阵 注意生成的是[[]] ==用这个（numpy array格式）*不要用上面那种写法，容易出错！不直观，它既不是行向量也不是列向量 不要吝惜使用reshape assert(表达式)语句用于检查表达式是否正确，如果不正确程序在这里引发错误方便检查 list.append()不需要a = a.append() 改变DATAFRAME的顺序 order = ['date', 'time', 'open', 'high', 'low', 'close', 'volumefrom', 'volumeto'] df = df[order] Dataframe遍历不能用for Line in DataFrame来遍历！要么用iloc index方法 for i in range(0, len(df)): print df.iloc[i]['c1'], df.iloc[i]['c2'] 要么用iterrows（https://blog.csdn.net/ls13552912394/article/details/79349809） 排序不成功问题问题：遇到排序问题，使用下面的语句对pandas的某列进行排序时,发现根本没排序成功。bada_air.sort_value(by=’time’,ascending=False)解决方案：这里牵扯到很重要的参数inplace,默认的inplace设置是False,并没有对本体进行覆盖，所以解决方法有两个：1.设置本体覆盖，令inplace=Truebada_air.sort_value(by=’time’,ascending=False,inplace=True)2.设置传值覆盖bada_air=bada_air.sort_value(by=’time’,ascending=False) pd.read_csv出现Unnamed:0这一列解决办法：pd.read_csv(path,index_col=0) 记清楚loc[行限制，列限制]比如行限制就可以A=A.loc[A.Filename = ‘aaa’,:]或者其他选法等等 合并 merge join 等的用法https://www.jianshu.com/p/5ecea164cec6 错点！ series别忘了转成list 再用in！ a in list O a in Series X df1=df2 传递的不是指针，而是内容复制了一份 关于drop drop是drop的索引 注意drop属于panda 要用df = df.drop(x) inplace=True参数设置重建索引，df = df.drop(x,inplace=True) 重建索引df = df.reset_index(drop = True) 修改DF某元素（最终选择方法二）一。一个大坑在修改df元素的时候，iloc和loc有重大区别！loc和iloc都可以进行切片，但是用iloc不可以修改切片中的元素！loc可以修改切片中的元素！ test = pd.DataFrame(&#123;'a':[3,4,5,6],'b':[6,7,8,9]&#125;) test['c']=0 test.iloc[2].c+=2 #用iloc test >> a b c 0 3 6 0 1 4 7 0 2 5 8 0 3 6 9 0 test = pd.DataFrame(&#123;'a':[3,4,5,6],'b':[6,7,8,9]&#125;) test['c']=0 test.loc[2].c+=2 #用loc test >> a b c 0 3 6 0 1 4 7 0 2 5 8 2 3 6 9 0 二。但是！！ 在很多情况下 这样还是无法修改！！！！所以用这个方法！！不用loc iloc 先选列索引 再选行索引！test[&#39;c&#39;][2]+=2 统一使用此方法！ test = pd.DataFrame(&#123;'a':[3,4,5,6],'b':[6,7,8,9]&#125;) test['c']=0 test['c'][2]+=2 #看这里！！！！！！！！！！！！！！！！ test >> a b c 0 3 6 0 1 4 7 0 2 5 8 2 3 6 9 0 在处理大批量数据时,如果需要先向df对象插入空列,在后期再填充空列中对应位置的元素,应优先考虑使用loc而不是iloc,因为前者的访问速度比后者快几十倍 dict排序https://www.cnblogs.com/dylan-wu/p/6041465.html dict = sorted(dict.items(),key=lambda item:item[1],reverse=True) # items()将dict转化为迭代器，lambda正咋表达式，item[1]即为迭代器的第二项 判断nan math.isnan(x) #x得是float类型 type(x) != float #用类型判断，因为nan属于float类型 python取数据！ python搜索数据 重要总结！https://www.jianshu.com/p/805f20ac6e06 python搜索数据的时候 这种情况要用isin allDatasetApiCorpus[allDatasetApiCorpus['Filename'].isin(list)] Series可以直接与int比大小，等于对每一项比大小！eg: lis = [1,2,3,-1,-2,-3] lis = pd.Series(lis) lis[lis>0] >> 0 1 1 2 2 3 dtype: int64 lis>0 >> 0 True 1 True 2 True 3 False 4 False 5 False dtype: bool 枚举 enumerate的用法lis = [1,2,3,-1,-2,-3] for index, var in enumerate(lis): print(index,' ',var) >> 0 1 1 2 2 3 3 -1 4 -2 5 -3 元组可以这样用s = (2,1) s[0] >>2 转置narray.T, dataframe.T 去重 drop_duplicates()drop_duplicates()是去除重复行，要想去除重复列要先转置 DataFrame = DataFrame.drop_duplicates(subset=None, keep='first', inplace=False) ''' subset : column label or sequence of labels, optional 用来指定特定的列，默认所有列（指的是以哪些列为参考删除行，删的还是行） keep : &#123;‘first’, ‘last’, False&#125;, default ‘first’ 删除重复项并保留第一次出现的项 inplace : boolean, default False 是直接在原来数据上修改还是保留一个副本 ''' 初始化列表 list# 一维列表 # 初始化递增的list，与L = [i for i in range(10)] 效果相同 L = range(10) # print(L) # [0,1,2,3,4,5,6,7,8,9] #初始化每项为0的一维列表 L = [0] * 5 # print(L) #[0,0,0,0,0] # 二维列表 L = [[0] * 5 for i in range(5)] #print(L) #[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] #这里需要注意，虽然L = [[0] * 5] * 5，也输出同样的效果，但是万万不能这样做！ #因为[0] * 5是一个一维列表的对象，再* 5的话只是把对象的引用复制了3次。什么意思呢，就是如果我们将L[0][0] = 1，#再输出L如下： L = [[0] * 5] * 5 L[0][0] = 1 #print(L) #[[1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]] #我们只是想改变L[0][0]，结果L[[n][0]全部改变了！这回知道为啥不能这么做了吧！ #所以对于一位列表初始化，也建议大家用L = [[0] for i in range(5)]来代替L = [[0] * 5] Numpy扁平化函数 ravel和flatten from numpy import * a = arange(12).reshape(3,4) print(a) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] print(a.ravel()) # [ 0 1 2 3 4 5 6 7 8 9 10 11] print(a.flatten()) # [ 0 1 2 3 4 5 6 7 8 9 10 11] 可以看到这两个函数实现的功能一样,但我们在平时使用的时候flatten()更为合适.在使用过程中flatten()分配了新的内存,但ravel()返回的是一个数组的视图.视图是数组的引用(说引用不太恰当,因为原数组和ravel()返回后的数组的地址并不一样),在使用过程中应该注意避免在修改视图时影响原本的数组. [confusion_matrix - too many values to unpack]you can only assign multiple variables dynamically if the number of outputs is certain. If you assign the result of `confusion_matrix` to a single variable, you can then check its contents in a loop and assign the contents conditionally: returned = confusion_matrix(y_true, y_predict).ravel() for var in returned: #... do stuff with each item in the returned collection You could also just check its length and if it is 4, you can proceed as usual: if len(returned) == 4: tn, fp, fn, tp = returned 遍历dataframefor col in df遍历的是列标签要遍历行有几种方案https://blog.csdn.net/ls13552912394/article/details/79349809遍历这种东西在df选取等操作中不是一个好的解决方案，可以通过df的搜索loc iloc等很多方式来实现，比遍历好得多方便的多 python list去重运用set的特性opList = list(set(opList)) 切片的时候若不存在msgTrojanDynamicDF.loc[:,[‘android.content.Intent_setAction’,’sss’] ]其中如果sss不存在，则sss列全为NaN但如果两列都不存在，就会报错 Series.sum(axis-1)可以统计竖向的和 拼接dataframe df = pd.concat([A,B,C])numpy.transpose 用于翻转https://blog.csdn.net/u012762410/article/details/78912667 torch.cat 拼接Tensortorch.cat((a,b),1)` 转置np.transpose()torch.transpose() 左闭右开注意python各个库的左闭右开原则 [:]切片的时候注意！ range,list,numpy,pandas,torch都这样 将数据结构转化为集合可以自动去重！（#去重）a = set(a)set(1,2,3) = set(1,1,1,1,1,1,2,3) tensor,numpy array的创建与扩展 #创建 np.zeros([3,10]) #创建一个3x10的array torch.zeros(3,10) #创建一个3x10的tensor list([0])*10 #[10,10,10,10,10,10,10,10,10,10] list([[0]*10]*3) #创建一个3x10的list np.random.rand(3,10) #随机创建一个3x10的array torch.rand(3,10) #随机创建一个3x10的tensor #合并/拓展 a.extend([4,5]) #[1,2,3,4,5] #注意用法 extend后保存的值就为a，和append用法类似 removes = np.append(array1,array2,axis=0) #axis为合并的维度 tensor 使用torch.stack进行合并 list 删除元素 list.remove(x) print(list) 该方法没有返回值只会删掉匹配到的第一个还有2个方法懒得记了 python remove里有个巨坑！如果用for循环来remove的话，for循环的时候，每删除一个元素，长度就会改变，索引就会变化！所以remove就会出问题！比如 要依次删除1，2位置的元素。第一次删除了1位置，那么列表索引就变了，2元素成为了1元素，3元素成为了2元素！2元素就这样被跳过了！解决办法见下 for循环 动态修改列表的时候的注意事项如何解决：deepcopy一份，一个列表用于循环，一个列表用于移除值（from copy import deepcopy) 调换维度。 使用numpyarrray.swapaxes(ax0,ax1) numpy.size()函数 a = np.array(…) np.size(a) 计算数组和矩阵所有数据的个数 np.size(a,1)计算该array第1维（第一个维度为0）的元素个数 tensor/array值归一化 tensor.div_() narray.div_() windows路径\\\\变成/即可 改变numpy array中的数据类型 array = array.astype(obj_type) obj_type就可以为比如float","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"PYTHON","slug":"程序语言/PYTHON","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/PYTHON/"}],"tags":[]},{"title":"JDBC Template和JDBC Statement","slug":"开发/JDBC","date":"2019-03-20T03:57:11.000Z","updated":"2021-01-17T11:09:51.000Z","comments":true,"path":"开发/JDBC/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/JDBC/","excerpt":"JDBC Template和Mybatis都是对JDBC的封装，底层最终还是使用JDBC连接数据库。","text":"JDBC Template和Mybatis都是对JDBC的封装，底层最终还是使用JDBC连接数据库。 JdbcTemplate是Spring的一部分,是对数据库的操作在jdbc的封装,处理了资源的建立和释放(不需要我们管理连接了),我们只需要提供SQL语句(不需要我们设置参数了)和提取结果(查询时候可以直接返回对应的实体类),使JDBC更加易于使用。 通过Spring IoC把DataSource注册到JdbcTemplate之中（mybatis也是将datasource等环境信息来配置mybatis的sqlsession工厂，再来根据我们写在接口mapper方法中写的sql语句来自动构建具体代理的mapper对象）。 然而，我们使用更优秀的基于ORM设计的mybatis代替使用JDBC Template，进一步降低DAO层的耦合 （以后做一个JDBC Template方式和Mybatis的对比【】） 有关jdbc statement（转载）： 链接：https://www.nowcoder.com/questionTerminal/d29b742b521743118a741d01fcdc0b96?pos=396&amp;mutiTagIds=570&amp;orderByHotValue=0&amp;done=0 来源：牛客网 1.Statement、PreparedStatement和CallableStatement都是接口(interface)。 2.Statement继承自Wrapper、PreparedStatement继承自Statement、CallableStatement继承自PreparedStatement。 \\3. Statement接口提供了执行语句和获取结果的基本方法； PreparedStatement接口添加了处理 IN 参数的方法； CallableStatement接口添加了处理 OUT 参数的方法。 \\4. a.Statement: 普通的不带参的查询SQL；支持批量更新,批量删除; b.PreparedStatement: 可变参数的SQL,编译一次,执行多次,效率高; 安全性好，有效防止Sql注入等问题; 支持批量更新,批量删除; c.CallableStatement: 继承自PreparedStatement,支持带参数的SQL操作; 支持调用存储过程,提供了对输出和输入/输出参数(INOUT)的支持; Statement每次执行sql语句，数据库都要执行sql语句的编译 ， 最好用于仅执行一次查询并返回结果的情形，效率高于PreparedStatement。 PreparedStatement是预编译的，使用PreparedStatement有几个好处 \\1. 在执行可变参数的一条SQL时，PreparedStatement比Statement的效率高，因为DBMS预编译一条SQL当然会比多次编译一条SQL的效率要高。 \\2. 安全性好，有效防止Sql注入等问题。 \\3. 对于多次重复执行的语句，使用PreparedStament效率会更高一点，并且在这种情况下也比较适合使用batch； \\4. 代码的可读性和可维护性。","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"WE NEED R!G!B!","slug":"硬件/R-G-B","date":"2019-02-27T05:08:14.000Z","updated":"2019-03-27T05:35:28.000Z","comments":true,"path":"硬件/R-G-B/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/R-G-B/","excerpt":"北极狼和北极熊水冷性能虽然很强，但是他们有个缺点就是没有RGB———— 这怎么行呢。 RGB化改造迫在眉睫 于是我买了HALOS圣环，自己定做了显卡侧灯板","text":"北极狼和北极熊水冷性能虽然很强，但是他们有个缺点就是没有RGB———— 这怎么行呢。 RGB化改造迫在眉睫 于是我买了HALOS圣环，自己定做了显卡侧灯板 改装之前—————— 改装之后—————— 动图： 愉快打电动~ 这中间遇到个小插曲 那块显卡侧灯右边漏光的一条是因为… 我定做的时候 尺寸量错了，多度了半厘米。 于是只能用刀片来削…. 然后就成这样了","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[{"name":"神说，要有光","slug":"神说，要有光","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E8%AF%B4%EF%BC%8C%E8%A6%81%E6%9C%89%E5%85%89/"}]},{"title":"背包问题","slug":"算法与数据结构/背包问题","date":"2019-02-20T04:09:48.000Z","updated":"2021-01-26T09:08:00.000Z","comments":true,"path":"算法与数据结构/背包问题/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","excerpt":"题目：有$n$个物品，背包体积为$m$，$v[i]$代表第$i$个物品体积，$w[i]$代表第$i$个物品的价值","text":"题目：有$n$个物品，背包体积为$m$，$v[i]$代表第$i$个物品体积，$w[i]$代表第$i$个物品的价值 注意这里只写出状态定义和状态转移公式，有些判断就没写了 注意dp数组元素的生成顺序，要先生成小问题再生成大问题，这就决定了循环顺序，特殊的像区间DP的外层循环就必须是长度len 对于滚动数组优化，如果用到了$i-1$层的更小状态，那么就必须倒序循环枚举状态；如果只用到了$i$层的更小状态，那么就只能顺序循环枚举状态 所有背包问题都是①先循环物品，②再循环体积（多一个其它条件就多一维，多循环一层）③再枚举决策（可能无需循环） 背包枚举的都是$dp$数组的状态空间，搞清定义 01背包题目：每个物品只有选与不选 $f(i,j)$表示前$i$个物品装进体积为$j$的背包的最大价值 最后一个不同点：第$i$个物品选还是不选 f(i,j)=\\max\\{f(i-1,j),f(i-1,j-v[i])+w[i]\\}注意，左边都是$i-1$子问题，想清楚式子的含义！ 空间优化（滚动数组）：$f(j)=max(f(j),f(j-v[i])+w[i])$，由于用到上层dp值（在滚动数组中即为编号较小的未更新元素），所以$j$必须倒序循环枚举 完全背包题目：每件物品可以选无限次 $f(i,j)$表示前$i$个物品装进体积为$j$的背包的最大价值 最后一个不同点：第$i$个物品不选，第$i$个物品选1个，第$i$个物品选2个，….. $f(i,j)=\\max\\{f(i-1,j),f(i-1,j-v[i])+w[i],f(i-1,j-2v[i])+2w[i]+\\cdots\\}$ 等价变形：$f(i,j-v[i])=\\max\\{f(i-1,j-v[i]),f(i-1,j-2v[i])+w[i],f(i-1,j-3v[i])+2w[i]+\\cdots\\}$ 回代原式（时间优化）： f(i,j)=\\max\\{f(i-1,j),f(i,j-v[i])+w[i]\\}注意：这里就背包体积$j$只能从小到大循环了，因为用到了当层$i$下、$j$更小的子问题解，而以前用到的都是$i-1$层的子问题解 空间优化（滚动数组）：$f(j)=max(f(j),f(j-v[i])+w[i])$，用到了本层编号较小的dp值，所以$j$必须正序循环枚举 多重背包题目：每个物品最多有$s[i]$件 $f(i,j)$表示前$i$个物品装进体积为$j$的背包的最大价值 最后一个不同点：第$i$个物品不选，第$i$个物品选1个，第$i$个物品选2个，…..，第$i$个物品选$s[i]$个 $f(i,j)=\\max\\{f(i-1,j),f(i-1,j-v[i])+w[i],f(i-1,j-2v[i])+2w[i]+\\cdots+f(i-1,j-s[i]×v[i])+s[i]×w[i]\\}$ 由于每个物品的选择上限不同，所以不能等价变形，需要多写一层循环遍历第$i$个物品可能的选择个数$0$到$s[i]$来求，也就是多了个决策循环；（但转化为01背包就可以不循环决策了，见下面优化方法） 时间优化：可以将同一个物品的$s[i]$份拆开变成$s[i]$个1个物品，这就转化为01背包问题了。但直接拆复杂度是不变的，可以通过二进制的方法来拆，将$s$个物品打包成$\\log s$个物品组，用它们可以凑出$0$到$s$的任意一个数，减少01背包子问题数量，这样时间复杂度由$O(nsv)$优化到$O(n\\log s v)$。举个例子，我们原来想要用01背包表示“第$i$个物品最多可选7个”，就需要用$[1,1,1,1,1,1,1,1]$来表示，然后用01背包dp来解；而现在我们知道7的二进制编码为$0111$，那么第$i$个数就只需要$[4,2,1]$来表示，那么我们dp的时候会自动组合这三个堆，比如算得$dp(i,j)$下$i$选3个是最优解，那么dp实际上就是选择了$2$和$1$，没选$4$。这里的核心就在于：二进制的组合可以以较低的位数表达（编码）任意一位十进制 混合背包题目：有三类物品，第一类：只能用1次（01背包）；第二类：可以用无限次（完全背包）；第三类：物品最多只能用$s[i]$次（多重背包） 只需要判断当前物品是什么类，然后转移的时候按照对应类的物品去转移即可 可以将多重背包转化为01背包，那就只需要判断两种情况了（01、完全） 二维费用背包题目：除了体积限制以外还有其它限制，背包重量不能超过$M$，每个物品的重量为$m[i]$（基于01背包） $f(i,j,k)$：第$i$个物品装进体积是$j$，重量是$k$的背包的最大价值 $f(i,j,k)=\\max \\{f(i-1,j,k),f(i-1,j-v[i],k-m[i])+w[i]\\}$ 需要进行三重循环：前$i$个物品、背包最大体积$j$、背包最大重量$k$ 空间优化（滚动数组）：$f(j,k)=\\max\\{f(j-v[i],k-m[i]),f(j,k)\\}$，用到上一层$i$，需要从大到小枚举体积和重量 二维背包也可以基于完全背包等，基本都是一样改，多一个条件，状态方程就多一维，就多一层枚举循环 ATT：我们枚举的是状态空间，多的一层枚举循环是背包重量不同造成状态维度多了一维，也就是说子问题更多了 分组背包题目：物品分为$N$组，同一组内物品只能选一件 先遍历组，再遍历决策，求最值 $f(i,j)$：从前$i$组物品里选，且体积不超过$j$的背包最大价值 $v[i][k]$即为第$i$组第$k$个物品，要先构造好；第$i$组一共用$s$个物品 $f(i,j)=\\max\\{f(i-1,j),f(i-1,j-v[i][0])+w[i][0],f(i-1,j-v[i][1])+w[i][1],\\cdots,f(i-1,j-v[i][s])+w[i][s]\\}$ 需要进行三次循环：遍历组$i$，背包体积$j$，遍历组内物品编号$k$ 很像多重背包问题，公式也像，其实多重背包问题就是分组背包问题的一种特殊情况，但分组背包无法进行优化 背包问题求方案数题目：一般背包问题是求最大最小价值，这里还需要求最优价值下的方案数 在01背包的基础上，①需要新开一个数组，两个dp同时进行（最优解dp、方案数dp）且需要利用最优解的dp状态去推方案数dp状态②决策的时候需要判断选$i$和不选$i$两种选择的总价值的大小关系，如果选$i$与不选$i$的价值一样大则最大价值的方案数多了$g(i-1,j−v[i])+g(i-1,j)$种；若不选第$i$个物品更大，则多了$g(i-1,j)$种；若选第$i$个物品更大，则多了$g(i-1,j−v[i])$种③方案数dp的状态方程如何理解？因为$g(i,j)$是$i$个物品在背包体积$j$下的最佳方案数，可由②中所述的三种选法组成，这里对$g$的集合划分、最后一个不同点 是不同的！ $f(i,j)$：前$i$个物品，背包体积是$j$的情况下的背包最大价值（以前是体积最多是$j$的背包方案数，这样的话可能体积用不完，但是也能转移） f(i,j)=\\max\\{f(i-1,j),f(i-1,j-v[i])+w[i]\\}​（同01背包）$g(i,j)$：前$i$个物品，背包体积是$j$的情况下的背包方案数（注意转移条件，最后一个子问题划分为三类） g(i,j)= \\begin{cases} g(i-1,j), f(i-1,j)>f(i-1,j-v[i])+w[i]\\\\ g(i-1,j−v[i]),f(i-1,j)","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"图像预处理：transforms和PIL小结","slug":"人工智能/图像预处理：transforms和PIL小结","date":"2019-01-28T03:14:11.000Z","updated":"2019-10-23T01:50:38.000Z","comments":true,"path":"人工智能/图像预处理：transforms和PIL小结/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E5%83%8F%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9Atransforms%E5%92%8CPIL%E5%B0%8F%E7%BB%93/","excerpt":"","text":"色图真好玩.jpg transformsⅠ. transforms.ToTensor() ①将(H,W,C)输入的numpy array或img转换成(C,H,W)格式 通道的具体顺序与cv2读的还是PIL.Image读的图片有关系cv2:(B,G,R)PIL.Image:(R, G, B) ②归一化，归一到$(0,1)$区间 Ⅱ. transforms.Normalize() 标准化。 即使输入的每个值分布到$(-1，1)$中 公式为$Normalize = \\frac{(x-mean)}{std}$(std为标准差，mean为均值) 标准差公式$std = \\sigma = \\sqrt{\\frac{1}{N} \\Sigma^N_{i=1}(x_i-μ)^2 }$ 注意实际是img里的每个像素（每个值）都要经过此公式运算 通过标准化后可以让数据服从标准正态分布 一般来说参数为 transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)) 这里的三个维度是因为输入的$x$为三维的，如果$x$是灰度图，那就是一维 $(0.5,0.5,0.5)$即为三个维度（分别对应RGB三个通道）的均值和标准差。这里默认为该值，如果你能够计算出你的数据集的均值和标准差，那么用计算出来的值更好。（如imagenet数据集提供方就给出了该数据集的均值和标准差） 以上两个函数通常是连着用的 Ⅲ.transforms.Lambda 用法:transforms.Lambda(lambda img:func(img,)) 这里的func可以是自己定义的函数，也可以直接调用表达式比如transforms.Lambda(lambda img:img)(什么都没处理，返回了自己本身) 在transforms库中存在很多官方给的预处理工具，但是如果需要自己定义，比如截取图像指定区域，则需要自己用Lambda函数封装一个处理函数 eg:自己定义一个截取图片的crop函数 from torchvision import transforms def __crop(img, pos, size): \"\"\" :param img: 输入的图像 :param pos: 图像截取的位置,类型为元组，包含(x, y) :param size: 图像截取的大小 :return: 返回截取后的图像 \"\"\" ow, oh = img.size x1, y1 = pos tw = th = size # 有足够的大小截取 # img.crop坐标表示 (left, upper, right, lower) if (ow > tw or oh > th): return img.crop((x1, y1, x1+tw, y1+th)) return img # 然后使用transforms.Lambda封装其为transforms策略 # 然后定义新的transforms为 normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) data_transforms = transforms.Compose([ #注意这里的用法 transforms.Lambda(lambda img: __crop(img, (5,5), 224)), transforms.RandomHorizontalFlip(), # 随机水平翻转给定的PIL.Image,翻转概率为0.5 transforms.ToTensor(), # 转成Tensor格式，大小范围为[0,1] normalize ]) Ⅳ. 逆过程 transforms.Normalize()的逆过程即原公式求反函数 原公式$Normalize = \\frac{(x-(-mean))}{std}$的反函数即为 $x = Normalize*std+mean$ 注意是$x$中的每个元素都要经过此逆运算，可以使用numpy array的矩阵批量乘法 如果$std$和$mean$三个维度（RGB情况）是不一样的，那就要分别在三个维度上单独做逆运算 transforms.ToTensor()的逆过程为transforms.ToPILImage()(这个类里面就包含各种处理了包括逆归一化) 这里也可以直接用plt.imshow(tensor)来显示图像 这里tensor要*255，因为.ToTensor也有归一化的功能 注：另外transforms组件可以单独拿出来用，不一定要compose组合 但有个问题需要注意！用法是 transforms.ToPILImage()(tensor) 因为transforms里的组件都是对象！不是方法，得建立对象之后再调用对象的方法! PILⅠ. 打开图片 使用PIL.Image.open只会调用本地图片浏览器打开图片所以要用matplotlib.pyplot.imshow()来打开PIL导入的图片 (一般import matplotlib.pyplot as plt) 注意先要将PIL.Image导入的图片转化为narray格式 (np.array)（导入进来的时候是PIL.Image.Image对象） 注意open: 打开并识别所提供的图像文件。不过，使用这函数的时候，真正的图像数据在你进行数据处理之前并没有被读取出来。可使用 load函数进行强制加载。 mode 参数可以省略，但它只能是 “r” 值。 如果想要迭代打开多张图片每张都显示，则必须 plt.imshow(img) #多一句show plt.show() 也可以使用PIL.Image.open加载图片 from PIL import Image img = Image.open(iMagePath) 注意读取单个图片进入神经网络训练的时候 imga = torch.unsqueeze(imga, 0) imga = imga.cuda() Ⅱ. plt.imshow()不能同时显示多张图片如果想要显示多张，可以在每个plt.imshow()后面加一个plt.show() Ⅲ. 图片处理部分 transform=transforms.Compose( [transforms.Resize(256), #resize并不会改变长宽比例！ 重要问题1 transforms.CenterCrop(256), #resize后要crop！ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ]) #然后可以用这个来处理单个PIL图片 img = transform(img) #这样即应用了变换 #也可以用以下这个来处理数据集 trainset = torchvision.datasets.ImageFolder(train_dir, transform=transform) Ⅳ. 应用图片数据预处理 transforms模块 生成的transforms直接作用在PIL上 # 比如这段定义了变换之后 transform=transforms.Compose( [transforms.Resize(256), transforms.CenterCrop(256), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ]) #如果是用loader来加载的话就是 trainset = torchvision.datasets.ImageFolder(train_dir, transform=transform) #如果是直接应用到一个图片上的话就是 img = Image.open(picPath) imga = transform(img) Ⅴ. resize与toTensor的先后顺序 transform=transforms.Compose( [transforms.Resize(256), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ]) # 这里面的变换是有顺序的！ # transforms.Resize()是图片变换，是作用在PIL.Images上的！所以一定要在ToTensor之前！ 图片变换》ToTensor》归一化 transforms.Resize() works on PIL.Images, so just swap the order of your transformations and your code should run. 否则会报错TypeError: img should be PIL Image. Got Ⅵ. resize和crop的区别resize并不会改变长宽比例！是等比缩放的crop是在图中挖出一部分（裁剪） 这个才会改变比例！resize后要crop！ transforms.Resize(256) transforms.CenterCrop(256) crop 有很多种方式 待学习crop和resize的作用范围都是PIL而不是tensor ImageFolder图片数据集定义 trainset = torchvision.datasets.ImageFolder(root=train_dir) train_dir中要有子文件夹！ 按照子文件夹读取标签！ imageFolder打标签的问题：和文件夹的顺序有关 【按照各子文件夹的顺序打上0.1.2…. 且是刷新后的顺序！ 所以最好是直接0,1,2,3给子文件夹命名，自己清楚里面代表的是啥就是了！】 所以如果说两个文件夹内的子文件夹都是一样的话，相同分类打的标签就是一样的 ImageFolder两个重要属性： ①class_to_idx ②classes 关于输入网络的图片尺寸输入图片尺寸必须一样是因为在出特征提取层，进入全连接层的时候，全连接层是固定的，所以如果只是要提取出特征的话，并不要求输入图片尺寸一样！ 有个很好玩的FCN（全卷积网络）就是这样","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"https://aisaka.cloud/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Redis做缓存的一些问题","slug":"数据库与中间件/Redis做缓存的一些问题","date":"2019-01-22T16:14:39.000Z","updated":"2020-05-17T04:45:36.000Z","comments":true,"path":"数据库与中间件/Redis做缓存的一些问题/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis%E5%81%9A%E7%BC%93%E5%AD%98%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","excerpt":"缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级 Redis做缓存是因为Redis访问快，如果客户端在Redis中找得到目标数据，那就不去mysql找了，分担了mysql压力，实现高并发要求 一般缓存都是用户发起一次请求之后，再将该数据加载到缓存（并为该缓存expire一个有效期） 但是缓存实现高并发会出现一堆问题","text":"缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级 Redis做缓存是因为Redis访问快，如果客户端在Redis中找得到目标数据，那就不去mysql找了，分担了mysql压力，实现高并发要求 一般缓存都是用户发起一次请求之后，再将该数据加载到缓存（并为该缓存expire一个有效期） 但是缓存实现高并发会出现一堆问题 缓存过期策略缓存过期可以采用 ①主动检查（默认每秒扫描10遍，且使用贪心策略一轮随机检查20个key，超过1/5过期就继续检查，直到轮数上线） ②惰性检测（用到再判断是否过期） （从服务器是根据主服务器的指令进行操作，不会自己判断过期） 缓存淘汰策略当redis缓存空间不够用（超maxmemory设置），这时候ram放不下的数据就会放到磁盘，发生RAM和磁盘数据的频繁交换，这样极大影响效率，所以要淘汰 一些即使没有过期的key 以下为淘汰方法： noeviction：停止写请求 FIFO：最先缓存的最先过期： LFU：最少频率使用 LRU：最近最少使用 ttl：key的剩余寿命ttl越小越先被淘汰 random：随机淘汰 缓存更新策略①Cache aside：由客户端自己负责写redis缓存还是写mysql数据库（先访问redis，找不到，再去mysql取数据，然后放到缓存中） ②Read Through：用户请求的时候，若redis服务器没有缓存，则由redis缓存服务器负责去mysql数据库服务器拿数据来更新缓存 ③Write Through：和Read Through一样是由redis缓存服务器负责与mysql交道，只不过发生在用户更新数据时候 ④Write Behind Caching Pattern：Write Through，且redis是异步更新mysql的 第②③④策略下，对于客户端而言，redis和mysql是一个整体，不用管谁是谁，缓存细节被隐藏了 缓存雪崩【缓存失效】，导致所有本来应该查询redis缓存的请求全部取查后端mysql数据库了，造成mysql数据库压力过大崩盘 造成缓存失效的可能性很多，比较多的一种是原有缓存失效，而新缓存还没有储存到redis缓存中（比如大量缓存同时过期），如果是使用普通的hash定位服务器方法也会造成缓存失效。这样会瞬间给mysql造成巨大压力而崩盘。 解决： ①避免缓存大量同时过期解决：比如缓存过期时间随机 ②在新缓存就位之前，临时储存失效缓存：这样请求来了，新缓存还没到，就先直接返回临时缓存，而不是直接过期丢弃之 ③防止过多请求同时访问数据库：加锁队列，但这样就没法高并发了，并没有解决实际问题，所以不会用在高并发环境中 缓存穿透对于数据库没有的数据，每次用户请求的就要先查redis缓存，返回空，然后去mysql查，又返回空，如果大量这样的请求存在，那就造成了缓存穿透，增加系统负荷 解决： ①布隆过滤器：将所有可能的数据存在一个布隆过滤器中（一个很大的bitmap），布隆过滤器可以快速判断出一定不存在的数据，进而直接拦截，不进行在系统中查询 ②缓存不存在的key：那么第二次相同key来查，redis就返回一个默认值告诉他没有，那也就不会继续访问数据库了 缓存预热开机的时候，不必等用户第一次访问数据库再将数据加载到缓存，而是预热一部分数据直接加载到缓存 缓存降级弃车保帅，降级非核心业务缓存，保证核心业务缓存","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"炼丹小结","slug":"人工智能/炼丹小结","date":"2019-01-20T10:22:59.000Z","updated":"2019-10-23T01:42:20.000Z","comments":true,"path":"人工智能/炼丹小结/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%82%BC%E4%B8%B9%E5%B0%8F%E7%BB%93/","excerpt":"","text":"40层网络的参数比4层网络多10倍 因为每层都有参数所以batch size也要相应的减小！不然太大了 train loss 一直处于一个摇摆（震荡）状态可能是学习率设置过大导致的 如何选择神经网络的自适应优化算法： SGD：随机梯度下降 SGD+Momentum: 基于动量的SGD（在SGD基础上做过优化） SGD+Nesterov+Momentum：基于动量，两步更新的SGD（在SGD+Momentum基础上做过优化） Adagrad：自适应地为各个参数分配不同学习速率 Adadelta： 针对Adagrad问题，优化过的算法（在Adagrad基础上做过优化） RMSprop：对于循环神经网络（RNNs）是最好的优化器（在Adadelta基础上做过优化） Adam：对每个权值都计算自适应的学习速率（在RMSprop基础上做过优化） 如果数据输入量很小，那就选一种自适应学习速率的方法（如Adam）。这样你就不用对学习速率进行调优，因为你的数据本来就小，NN学习耗时也小。这种情况你更应该关心网络分类的准确率； 对于稀疏数据集，应该使用某种自适应学习率的方法（如Adam），且另一好处为不需要人为调整学习率，使用默认参数就可能获得最优值； 如果想使训练深层网络模型快速收敛或所构建的神经网络较为复杂，则应该使用自适应学习速率的方法（如Adam），通常它们收敛起来比较快，实际效果更优； Adam在不同超参数下的鲁棒性较好，不过有时可能需要调整下η值。Adam算法中的超参数β1和β2以及learning-rate也会显著影响模型，有时需要调试； RMSprop, Adadelta, 和 Adam 非常相似，在相同的情况下表现都很好，但偏置校验让Adam的效果稍微比RMSprop好一点； 如果不知道为你的神经网络选择哪种优化算法，就直接选Adam [Insofar, Adam might be the best overall choice.] 上面的结论都未必正确，重在自己的实践 （本段总结自 神经网络优化算法的选择） 超参数搜索 python有超参数自动搜索模块 sklearn.model_selection Python超参数自动搜索模块GridSearchCV上手ML模型超参数调节：网格搜索、随机搜索与贝叶斯优化 基于要解决的问题类别,神经网络的最后一层通常是确定的. 回归问题: 最后使用一个有输出的线性层,输出的值是连续的. 二分类问题:最后使用sigmoid激活函数, 因为它的输出值不是接近1就是接近0 对于多分类问题,网络最后使用softmax层. 它从前一先行层获取输入,并输出给定数量样例上的概率. (所有概率相加的总和必然为1)(当然如果二分类问题想要输出概率也可以用softmax) BN（Batch Normalization）是个好文明 损失函数选择对于回归问题,通常使用MSE(均方误差)对于分类问题,通常使用交叉熵(MSE对于每一个输出的结果都非常看重，而交叉熵只对正确分类的结果看重。)其他的 | 损失函数 | 通常用法 || —- | —- || L1 loss | 通常作为正则化器使用 || MSE loss | 均方误差损失,用于回归问题的损失函数 || Cross-entropy loss | 交叉熵损失,用于二分类和多分类问题 || NLL Loss | 用于分类问题,允许用户使用特定的权重处理不平衡数据集 || NLL Loss2d | 用于像素级分类,通常和图像分割问题有关|注意：①若使用了nn.CrossEntropyLoss() 函数，则最后一层就不应该使用softmax函数！这个函数包含了log_softmax，其操作为“使用对数似然损失函数和log_softmax激活函数进行DNN分类输出” CrossEntropyLoss()=log_softmax() + NLLLoss()但是，使用log_softmax运算是在output输出进入损失函数的时候。如果要获取输出概率，那就得在得到outputs后，在网络外面单独求一个F.softmax(outputs.data,dim=1)(但若使用log_softmax() + NLLLoss()， log_softmax函数是在网络里的（获得网络输出之前），所以不需要在网络外面单独求softmax)②损失函数 CrossEntropyLoss() 与 NLLLoss() 类似③损失函数NLLLoss() 的 输入 是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率，适合最后一层是log_softmax()的网络. log_softmax和softmax的选择损失函数NLLLoss() 的 输入 是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率，适合最后一层是log_softmax()的网络.用了log_softmax得到的结果是对softmax求次对数（并非采用直接求 ，而是一种较快的方式） 一般用loader加载的时候，num_workers使用少于机器内核数量的woker是一个通用的实践 权值增速比 0.01比较好 网络结构中的参数计算 O=输出图像的尺寸 output I=输入图像的尺寸 input K=卷积层的核尺寸 kernal N=核数量 number of kernal S=移动步长 strike P =填充数 padding ①想要con2d卷积出来的图片尺寸没有变化, P=\\frac{K-1}{2} 每层连接的参数计算：详细解释CNN卷积神经网络各层的参数和链接个数的计算 ②输出图像的大小计算 输出图像尺寸的计算公式如下： O=\\frac{I-K+2P}{S}+1 Softmax 是神经网络中另一种输出层函数，计算输出层的值。主要用于神经网络最后一层，作为输出层进行多分类，是Logistic二分类的推广。也可以单独使用。 batch size的选择 训练神经网络时如何确定batch size 学习率变更策略 如何选择最适合你的学习率变更策略 神经网络权值初始化 神经网络初始权值不能全部设置一样，否则学不到 深度学习中神经网络的几种权重初始化方法 常见学习率选择策略 | 策略 | 解释 || —- | —-|| StepLR | 步长规则，学习率倍数变化(步长内变gamma倍) || MultiStepLR | 步长不规则，学习率倍数变化 || ExponentialLR | 步长为1，学习率乘数变化 || ReduceLROnPlateau | 常用。当特定的度量指标，如训练损失、验证损失或准确率不再变化时，学习率就会改变。通用实践是降为原来的1/2~1/10 | 池化/卷积 与 ReLU的顺序 在最大池化之后或者在应用卷积之后使用非线性层是通用的最佳实践 FC, dropput都是可以有多层，不是只能用一层 深度学习的11个常见陷阱应对方法总结 神经网络 11 大常见陷阱及应对方法","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"炼丹","slug":"炼丹","permalink":"https://aisaka.cloud/tags/%E7%82%BC%E4%B8%B9/"}]},{"title":"imageTest","slug":"博客/imageTest","date":"2019-01-16T01:55:42.000Z","updated":"2019-03-27T04:50:22.000Z","comments":true,"path":"博客/imageTest/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/imageTest/","excerpt":"图片测试","text":"图片测试","categories":[],"tags":[]},{"title":"2080Ti上一体式水冷","slug":"硬件/2080Ti上一体式水冷","date":"2019-01-16T01:32:57.000Z","updated":"2019-04-03T05:13:55.000Z","comments":true,"path":"硬件/2080Ti上一体式水冷/","link":"","permalink":"https://aisaka.cloud/%E7%A1%AC%E4%BB%B6/2080Ti%E4%B8%8A%E4%B8%80%E4%BD%93%E5%BC%8F%E6%B0%B4%E5%86%B7/","excerpt":"前段时间买了非公的2080Ti，感觉自带的散热不太行，玩游戏温度飙升到84度直接撞温度墙。于是我搞了个 ocool的北极狼一体式水冷（花了我1300大洋，这水冷都够我买一张1060了orz） 自己动手，丰衣足食~","text":"前段时间买了非公的2080Ti，感觉自带的散热不太行，玩游戏温度飙升到84度直接撞温度墙。于是我搞了个 ocool的北极狼一体式水冷（花了我1300大洋，这水冷都够我买一张1060了orz） 自己动手，丰衣足食~ 这是原装风冷的样子 首先拆去原装散热器，脱去外套 可以看到一件暴露的核心和硅脂 然后卸下底板 这就是PCB背部了 然后就可以把PCB上的均热板给去掉，完整的PCB板子 就暴露在眼前 可以看到11个gddr6显存，11G，下面那个地方缺了一块强迫症就很难受 16相供电，嗯果然是公版PCB 拆解结束~ 擦掉硅脂，裁剪了一堆导热胶，将显存和供电给覆盖住。可以看到核心上的标签写着TU102核心 涂上祖传的德国暴力熊硅脂 然后安装好水冷的冷头和底板，这里要注意安装对齐！第一次就没安装好导致水冷头没和核心密切接触使得温度超高。 然后就结束啦！2080Ti水冷显卡诞生！","categories":[{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"}],"tags":[{"name":"显卡","slug":"显卡","permalink":"https://aisaka.cloud/tags/%E6%98%BE%E5%8D%A1/"}]},{"title":"深度学习实践结构性经验总结","slug":"人工智能/深度学习实践结构性经验总结","date":"2019-01-14T08:34:33.000Z","updated":"2019-10-23T01:43:20.000Z","comments":true,"path":"人工智能/深度学习实践结构性经验总结/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E7%BB%93%E6%9E%84%E6%80%A7%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/","excerpt":"","text":"总体流程 定义网络结构 定义数据变换 定义超参数，损失函数，优化方法，自适应学习率等… 读取训练集与测试集（自定义数据集，多种读入方式等..）开始训练： 训练一个Epoch自适应学习率更新循环：训练一个batch——从dataloader读取一个mini batch 转换为cuda变量 梯度清0FORWARD 将数据输入模型得到结果 根据结果得到预测标签 计算train lossBACKWARD 反向计算梯度 优化器更新统计本batch 统计本epoch 【注】①如果是测试，则取消[自适应学习率更新]和[BACKWARD]的步骤即可训练和测试可以结合起来 train=datalodaer(trainset…),test=dataloader(testset…)则在开始训练一个epoch的时候，加一个循环 for phase in [train,test]即可，后面的在测试不需要的步骤作判断if phase is train: do就行②可以设置一个全局的最优准确率，然后记录下来最佳准确率，并储存当时的最优模型权重③注意设置模型模式，model.train(True)设置为训练模式model.eval(True)设置为测试模式 定义网络结构在定义网络结构的时候,如下形式# 定义的网络结构类必须继承自nn.Module class myNet(nn.Module): # 注意传入参数self到结构函数 # init中的参数为初始化网络的参数 def __init__(self): super().__init__ # 定义网络 # 单个定义 self.s1 &#x3D; nn.Conv2d(......) # 或集合定义 self.s1 &#x3D; nn.Sequential( nn.Conv2d(......), nn.ReLU() ) # 全连接层(对于卷积神经网络用于分类） self.fc &#x3D; nn.Linear() # 注意传入参数self和x（输入矩阵）！ # forward中的参数为训练的时候要传入的参数 比如求output &#x3D; model(x)时 def forward(self,x): x &#x3D; self.conv1(x) x &#x3D; self.fc(x) # 经过特征提取层后，要扁平化才能进入fc层！ x &#x3D; x.view(x.size(0), -1) return F.softmax(x) 注意，一个误区：定义网络是定义网络的结构！输入一般输入一个batch，对该batch的处理为网络的内容 nn包含了所有的层结构定义组件, F包含了所有的函数, nn中的每个组件都需要添加到nn.Module容器中才能使用. def参数中的self即指向nn.Module(指向本类,而本类继承自nn.Module), 通过定义self.diyiceng = nn.Conv2d(xxx) 即将组件添加到了nn.Module容器中 nn.Sequential 组合一系列组件定义#eg self.conv2 &#x3D; nn.Sequential( nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2) ) #这里就将三个组件组合成一个组件了 #注意里面直接写组件组成即可 不是变量定义 建立深度学习模型一般实践数据预处理与特征工程 向量化 值归一化 处理缺省值 特征工程过拟合 获取更多数据、数据增强等 缩小网络规模 应用权重正则化 应用dropout欠拟合 获取更多数据 增加权重 一般流程 问题定义与数据集创建 选择模型评估标准 评估协议（测试集 验证集） 准备数据 模型基线（创建一个非常简单的模型来打破基线分数 如二分类为0.5) 训练大达到过拟合 应用正则化 学习率选择策略","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}]},{"title":"Redis","slug":"数据库与中间件/Redis","date":"2019-01-02T09:12:14.000Z","updated":"2020-04-28T09:24:28.000Z","comments":true,"path":"数据库与中间件/Redis/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/","excerpt":"非关系型数据库，有字符串独立字典（有序无序）六种储存关系","text":"非关系型数据库，有字符串独立字典（有序无序）六种储存关系 redis中的数据都是以key-value键值对的形式储存的，但这个value也可以是很复杂的形式，比如json等等，可以自己定义；而mysql就是多张表。（所以redis的操作也比sql少很多） 与mysql的区别，redis数据库是储存在内存中的，而mysql数据库是储存在硬盘中的，故redis每次查询更快，直接从内存中取，而mysql是要从硬盘中IO （所以显然redis更适合做缓存，密码等轻量数据的运行数据库，mysql适合做视频，文本等大量数据的存储数据库） redis的持久化就是将内存中的数据库储存到硬盘中（以rdb格式储存），所以每次运行redis都要将硬盘中的持久化数据加载到内存 redis可以不注册账户，为什么呢？因为只有有权限访问这个持久化数据库文件（rdb文件）的linux用户才有权限将之加载进内存（载入redis运行），所以权限问题很容易解决 安装：apt install redis-server 后台运行：redis-server &amp; 启动redis终端：redis-cli key * 查看所有的key redis可以开多个数据库，并在不同数据库切换 redis每次重启会自动载入该linux用户上次载入的rdb文件，可以直接删掉该rdb","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"向目标函数加入正则的具体实现","slug":"人工智能/向目标函数加入正则的具体实现","date":"2018-12-01T03:04:42.000Z","updated":"2019-10-23T01:44:08.000Z","comments":true,"path":"人工智能/向目标函数加入正则的具体实现/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%90%91%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E5%8A%A0%E5%85%A5%E6%AD%A3%E5%88%99%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"在数据经过模型之后 l1, l2 = torch.tensor(0), torch.tensor(0) optimizer.zero_grad() output = model(input) for params in model.parameters(): l1 += torch.norm(param,1) #torch.norm(param,1)为求param的l1范数 l2 += torch.norm(param,2) #torch.norm(param,2)为求param的l2范数 loss_origin = loss(output,label) loss = loss_origin + l1 + l2 loss.backward() optimizer.step() ATT：不能使用在模型中输出！ 使用以下这种方法是输出的中间层的输出，而不是参数！ #错误示范 class model(nn.Module): def __init__(self): super().__init__() self.linear1 = nn.Linear(64,32) self.linear2 = nn.Linear(32,16) def forward(self,input): linear1_out = self.linear1(input) linear2_out = self.linear2(linear1_out) return linear1_out,linear2_out 使用pytorch自带的权重衰减 torch.optim自带的参数weight_decay可以设置权值衰减率，即可以实现L2正则化","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"}]},{"title":"维度及Pytorch中常用的维度变换与torch.max()","slug":"人工智能/Pytorch中常用的维度变换与torch-max","date":"2018-11-12T11:25:24.000Z","updated":"2019-10-23T01:42:54.000Z","comments":true,"path":"人工智能/Pytorch中常用的维度变换与torch-max/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2%E4%B8%8Etorch-max/","excerpt":"","text":"Tensor.view() 扁平化简单说就是一个把tensor 进行reshape的操作。常常配合 a.size(0)来取得某一位的维度数 a&#x3D;torch.randn(3,4,5,7) b &#x3D; a.view(1,-1) print(b.size()) &gt;&gt;torch.Size([1, 420]) 其中参数-1表示剩下的值的个数一起构成一个维度。如上例中，第一个参数1将第一个维度的大小设定成1，后一个-1就是说第二个维度的大小=元素总数目/第一个维度的大小，此例中为3*4*5*7/1=420. （由于第一个维度被展为1了，那后面所有元素全部摊开展平了） #第1,2个维度不变（保持原来的维度），第三个位置写-1表示剩下的维度全部扁平化为一个维度 d &#x3D; a.view(a.size(0),a.size(1),-1) print(d.size()) &gt;&gt;torch.Size([3, 4, 35]) e&#x3D;a.view(4,-1,5) print(e.size()) &gt;&gt;torch.Size([4, 21, 5]) 在扁平化批处理的图片的时候（CNN中会出现） 为了扁平化每一张图片的数据，又不想把不同图片的数据混在一起扁平，那么就应该 x &#x3D; x.view(x.size(0), -1) 注意：遇到错误RuntimeError: invalid argument 2: view size is not compatible with input tensor&#39;s size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view().需要让Tensor连续化，即加一步x = x.contiguous()原因解释:https://blog.csdn.net/appleml/article/details/80143212使用torch.view()的条件是Tensor是连续的,在对Tensor进行了transpose等操作之后就会变得不连续，就需要这个函数来连续化 unsqueeze降维 和squeeze升维对于torch:使用unsqueeze降维 和squeeze升维 #升维 unsqueeze(torch1,0) #在第0个位置增加一个值为1的维度 #(2, 2)->(1,2,2) #降维 squeeze(torch1) #squeeze给torch删去值为1的维度 #(2, 2, 1)->(2, 2) 比如灰度图像只有2维,这个时候就需要升维 对于numpy array,函数不一样:expand_dims 升维 squeeze 降维 #升维 expand_dims(narray1,0) #在第0个位置增加一个值为1的维度 与torch用法一致 torch.max函数①torch.max()简单来说是返回一个tensor中的最大值。例如： si&#x3D;torch.randn(4,5) print(si) &gt;&gt;tensor([[ 1.1659, -1.5195, 0.0455, 1.7610, -0.2064], [-0.3443, 2.0483, 0.6303, 0.9475, 0.4364], [-1.5268, -1.0833, 1.6847, 0.0145, -0.2088], [-0.8681, 0.1516, -0.7764, 0.8244, -1.2194]]) print(torch.max(si)) &gt;&gt;tensor(2.0483) #输出了最大值 ②这个函数的参数中还有一个dim参数，使用方法为re = torch.max(Tensor,dim),返回的res为一个二维向量，其中res[0]为最大值的Tensor，res[1]为Tensor中最大值对应的index**。例如： &gt;&gt;&gt; print(torch.max(si,0)) (tensor([1.1659, 2.0483, 1.6847, 1.7610, 0.4364]), tensor([0, 1, 2, 0, 1])) &gt;&gt;&gt; print(torch.max(si,0)[0]) tensor([1.1659, 2.0483, 1.6847, 1.7610, 0.4364]) 注意，Tensor的维度从0开始算起。在torch.max()中指定了dim之后，比如对于一个3x4x5的 Tensor，指定dim为0后，得到的结果是维度为0的“每一行”对应位置求最大的那个值，此时输出的Tensor的维度是4x5. （在这个二维tensor里，dim=0就是求每行最大值） 对于简单的二维Tensor，如上面例子的这个4x5的Tensor。指定dim为0，则给出的结果是4行做比较之后的最大值；如果指定dim为1，则给出的结果是5列做比较之后的最大值，且此处做比较时是按照位置分别做比较，得到一个新的Tensor。（在这个二维tensor里，dim=1就是求每列最大值） eg_, preds = torch.max(outputs.data, 1) 输出的outputs也是torch.autograd.Variable格式，得到输出后（网络的全连接层的输出）还希望能到到模型预测该样本属于哪个类别的信息，这里采用torch.max。torch.max()的第一个输入是tensor格式，所以用outputs.data而不是outputs作为输入；第二个参数1是代表dim的意思，也就是取每一行的最大值，其实就是我们常见的取概率最大的那个index；第三个参数loss也是 这个函数可以直接处理组 对于python中的维度的理解(tensor array等)[ [ [ ] ] ]最外层是第0维，中间层是第1维，最里层是第二维操作哪一维，就相当于该维以外的维度都固定住，操作只在该维下进行，对于更高维度（外维），都执行相同的操作 对于网络中fc层之后还要返回计算softmax的值的时候，应该选择return F.los_softmax(x,dim=1)因为经过fc层之后的矩阵结构为[[a1,a2],[b1,b2]] (假设二分类，batch=2）则要对[a1,a2]求softmax，再对[b1,b2]求softmax，所以是固定第0维，操作第1维，对第一维的每组求softmax","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"}]},{"title":"对BP算法的理解","slug":"人工智能/对反向传播的理解","date":"2018-11-08T04:55:38.000Z","updated":"2019-10-23T01:43:56.000Z","comments":true,"path":"人工智能/对反向传播的理解/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%AF%B9%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"损失函数$J(W_{11},W_{12},\\cdots,W_{ij},\\cdots,W{mn})$ 要计算梯度$\\nabla J=\\frac{\\partial J}{\\partial W_{11}}e_{11}+\\cdots+\\frac{\\partial J}{\\partial W_{mn}}e_{mn} $，$e_{ij}$为单位正交向量（$J$对每个参数求偏导） 那么使用链式法则，我们可以画出计算图 ①先标记出所有中间结点 ②对每一个结点，写出上一层直连结点（最顶层就是$J$）对该节点求得的偏导式（偏的是本结点中间变量），其他变量都视为常数 ③根据计算图，使用链式法则（两个结点之间，偏导式同路径相乘，所有路径相加） 主要理解清，某一个中间结点对另一个邻层中间结点求导，是对中间变量求导，只看局部，其它的变量都视为常数，都先只计算邻接层求导，再分别计算完每个偏导式之后，再运用链式法则根据全路径计算跨层求导 这样一来会有很多的重复计算（重复路径）。 为了解决这个问题，BP的做法是自顶向下，逐层反向求导，累计计算 也就是说从最高层$J$开始，按层计算出该层的偏导式值，然后再把这个值（是个含变量的表达式，但是对于这个中间层来说是个常数）发给这个结点下属路径下的每个结点（让他们乘上这个上层来的偏导式），然后再计算下一层的偏导式，如此迭代到输入层 注意都是先推导式子，最后再代入值计算，比如输入以及真实label都是最后推导完式子后计算的时候的一个常数值","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"BP","slug":"BP","permalink":"https://aisaka.cloud/tags/BP/"}]},{"title":"notes_1108","slug":"人工智能/notes-1108","date":"2018-11-08T03:35:24.000Z","updated":"2019-10-23T01:43:51.000Z","comments":true,"path":"人工智能/notes-1108/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/notes-1108/","excerpt":"","text":"NN的输出是一个向量，包含对各个种类的输出值，最后一个层有多少个神经元，输出向量就有多少维，所以在求的时候是矩阵求梯度下降，Loss Function作用于一个矩阵 NN为什么用非线性激活函数 线性函数公式写出来之后 会发现 无论多少层，他都只能生成线性分类器（成为了感知机）无法去拟合绝大多数的真实情况而非线性的组合 就可以去逼近任何函数 关于梯度下降的算法一个训练样本的损失函数就是一个向量，有多少特征就有多少维ML算法中的代价函数通常可以分解成每个样本的代价函数的总和具体求和之后如何求导见1 于是不使用batch的整体梯度下降需要计算($m$为训练集样本个数)。所有样本计算出最终结果来计算梯度。这样对显存的要求就极高（在大样本集上是不可能） \\nabla_{\\theta}J(\\theta)=\\frac{1}{m}\\sum_{i=1}^m\\nabla_\\theta L(x^{(i)},y^{(i)},\\theta)如果使用minibatch，则变成（一个batch有$m’$个训练样本） 一个batch计算一个$g$来更新梯度 g=\\frac{1}{m'}\\sum_{i=1}^{m'}\\nabla_\\theta L(x^{(i)},y^{(i)},\\theta)然后使用如下的梯度下降算法估计梯度 \\theta \\leftarrow \\theta - \\epsilon g于是在一轮训练集中，要更新很多次梯度，目标去逼近整体更新梯度的方向在一轮中的几个批次，可能是局部梯度减小，整体损失变大，但是在一轮下来之后，会变成朝着整体减小的方向震荡前进 CNN一个牛逼的地方就在于通过感受野和权值共享减少了神经网络需要训练的参数的个数，所谓权值共享就是同一个Feature Map中神经元权值共享，该Feature Map中的所有神经元使用同一个权值。因此参数个数与神经元的个数无关，只与卷积核的大小及Feature Map的个数相关。但是共有多少个连接个数就与神经元的个数相关了，神经元的个数也就是特征图的大小。 为什么用交叉熵作损失函数？每层怎么做计算https://blog.csdn.net/huwenxing0801/article/details/82791879对于分类问题，用交叉熵损失函数更好，因为交叉熵函数公式可知道，交叉熵只关心对正确类别的预测概率，因为只要其值足够大，就可以保证分类结果正确。对于回归问题，用平方差损失函数更好，它希望预测概率尽量完全等于标签概率。（比交叉熵损失函数严格很多） 前馈神经网络，如BP，RFN 循环神经网络，RNN","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"使用markdown编辑数学公式","slug":"工具/使用markdown编辑数学公式","date":"2018-11-07T09:22:44.000Z","updated":"2019-09-26T05:12:23.000Z","comments":true,"path":"工具/使用markdown编辑数学公式/","link":"","permalink":"https://aisaka.cloud/%E5%B7%A5%E5%85%B7/%E4%BD%BF%E7%94%A8markdown%E7%BC%96%E8%BE%91%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/","excerpt":"Typora是我认为最好用的markdown编辑器，书写直观，数学公式编辑器非常方便，总结一下在上面编辑数学公式的语法。 注意，首先要在文件—偏好设置—Markdown关联语法 里勾选内联公式 创建公式编辑栏的方式 内联公式：两个$之间​ 公式块：两个$$之间 ctrl + shift +m 常用公式的代码 注意，一个块要用{}包裹起来，^_上下标叠着写就行 输入 公式 x^2 $x^2$ x_1 $x_1$ \\frac{x}{y} $\\frac{x}{y}$ \\sqrt[x]{y} $\\sqrt[x]{y}$ \\vec{x} $\\vec{x}$ \\int_{a}^{b}{x}dx $\\int_{a}^{b}{x}dx$ \\cdots $\\cdots$ \\sum_{n=1}^{100}{a_n} $\\sum_{n=1}^{100}{a_n}$ \\lim_{n\\to +\\infty} $\\lim_{n\\to +\\infty}$ \\prod_{n=1}^{99}{x_n} $\\prod_{n=1}^{99}{x_n}$ a \\quad b $a \\quad b$ 特殊字符","text":"Typora是我认为最好用的markdown编辑器，书写直观，数学公式编辑器非常方便，总结一下在上面编辑数学公式的语法。 注意，首先要在文件—偏好设置—Markdown关联语法 里勾选内联公式 创建公式编辑栏的方式 内联公式：两个$之间​ 公式块：两个$$之间 ctrl + shift +m 常用公式的代码 注意，一个块要用{}包裹起来，^_上下标叠着写就行 输入 公式 x^2 $x^2$ x_1 $x_1$ \\frac{x}{y} $\\frac{x}{y}$ \\sqrt[x]{y} $\\sqrt[x]{y}$ \\vec{x} $\\vec{x}$ \\int_{a}^{b}{x}dx $\\int_{a}^{b}{x}dx$ \\cdots $\\cdots$ \\sum_{n=1}^{100}{a_n} $\\sum_{n=1}^{100}{a_n}$ \\lim_{n\\to +\\infty} $\\lim_{n\\to +\\infty}$ \\prod_{n=1}^{99}{x_n} $\\prod_{n=1}^{99}{x_n}$ a \\quad b $a \\quad b$ 特殊字符 希腊字母、三角函数、对数函数直接写转义字符+对应的内容即可，比如 对于如希腊字母，第一个字母大写就对应其大写字母，小写即对应其小写字母 \\sinx = $\\sin x$ \\log_2 = $\\log_2$ \\lambda=$\\lambda$ \\theta=$\\theta$ \\Omega=$\\Omega$ \\Delta=$\\Delta$ 梯度\\nabla=$\\nabla$ 其它特殊符号 前三行关系运算符 输入 公式 输入 公式 \\pm $\\pm$ \\cdot $\\cdot$ \\div $\\div$ \\leq $\\leq$ \\geq $\\geq$ \\partial $\\partial$ \\in $\\in$ \\notin $\\notin$ \\cup $\\cup$ \\cap $\\cap$ \\subset $\\subset$ \\subseteq $\\subseteq$ \\supset $\\supset$ \\supseteq $\\supseteq$ \\forall $\\forall$ \\infty $\\infty$ \\varnothing $\\varnothing$ \\exists $\\exists$ \\because $\\because$ \\therefore $\\therefore$ 大括号 c(u)&#x3D; \\begin&#123;cases&#125; formula1,condition1\\\\ formula2,condition2 \\end&#123;cases&#125; $c(u)=\\begin{cases} formula1,condition1\\\\\\ formula2,condition2 \\end{cases}$ 以\\begin&#123;cases&#125;开始，以\\end&#123;cases&#125;结束，中间行间隔用\\\\，每行的条件和公式之间用逗号相隔 矩阵 \\begin&#123;bmatrix&#125; &#123;a_&#123;11&#125;&#125;&amp;&#123;a_&#123;12&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;1n&#125;&#125;\\\\ &#123;a_&#123;21&#125;&#125;&amp;&#123;a_&#123;22&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;2n&#125;&#125;\\\\ &#123;\\vdots&#125;&amp;&#123;\\vdots&#125;&amp;&#123;\\ddots&#125;&amp;&#123;\\vdots&#125;\\\\ &#123;a_&#123;m1&#125;&#125;&amp;&#123;a_&#123;m2&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;mn&#125;&#125;\\\\ \\end&#123;bmatrix&#125; $\\begin{bmatrix} {a_{11}}&amp;{a_{12}}&amp;{\\cdots}&amp;{a_{1n}}\\\\ {a_{21}}&amp;{a_{22}}&amp;{\\cdots}&amp;{a_{2n}}\\\\ {\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\ {a_{m1}}&amp;{a_{m2}}&amp;{\\cdots}&amp;{a_{mn}}\\\\ \\end{bmatrix}$ 关于HEXO使用mathjax渲染公式的问题见此篇文章https://www.jianshu.com/p/7ab21c7f0674","categories":[{"name":"工具","slug":"工具","permalink":"https://aisaka.cloud/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://aisaka.cloud/tags/markdown/"}]},{"title":"更换HEXO框架","slug":"博客/更换HEXO框架","date":"2018-11-06T03:57:58.000Z","updated":"2019-04-01T15:47:27.000Z","comments":true,"path":"博客/更换HEXO框架/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/%E6%9B%B4%E6%8D%A2HEXO%E6%A1%86%E6%9E%B6/","excerpt":"","text":"这两天将更换了个人网站的框架 更改框架是个蛮麻烦的过程 其中以前的文章很多格式都乱掉了 而且图片全部没有了……. 只能手动修正了","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"https://aisaka.cloud/tags/HEXO/"}]},{"title":"Pytorch常用模块以及nn.Module","slug":"人工智能/Pytorch常用模块以及nn-Module","date":"2018-10-18T04:20:59.000Z","updated":"2019-10-23T01:43:28.000Z","comments":true,"path":"人工智能/Pytorch常用模块以及nn-Module/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E4%BB%A5%E5%8F%8Ann-Module/","excerpt":"","text":"pytroch常用包PyTorch框架中有一个很常用的包：torchvisiontorchvision主要由3个子包构成：torchvision.datasets、torchvision.models、torchvision.transformstorchvision和torchtext基于torch.utils.data.Dataset和torch.utils.data.DataLoder类构建nn来源于torch.nnoptim来源于torch.optim 超参数算法都在里面lr_scheduler来源于torch.optim.lr_scheduler 自适应学习率算法在里面ImageFolder在torchvision.datasets中torchvision.models中提供一些现有的流行算法 torch.nn.functional 各中层函数的实现，与层类型对应，如：卷积函数、池化函数、归一化函数等等 torch.nn与nn.Moduletorch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络。 torch.nn的核心数据结构是Module，它是一个抽象概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。无需纠结variable和tensor了，0.4版本已经将两个类彻底合并了。 在实际使用中，最常见的做法是继承nn.Module，撰写自己的网络/层。 自定义层Linear必须继承nn.Module，并且在其构造函数中需调用nn.Module的构造函数，即super(Linear, self).__init__() 或nn.Module.__init__(self)，推荐使用第一种用法。 在构造函数__init__中必须自己定义可学习的参数，并封装成Parameter，比如 _FasterRcnn类init中定义了 self.RCNN_loss_cls = 0 和 self.RCNN_loss_bbox = 0 还有在本例中我们把w和b封装成parameter。parameter是一种特殊的Variable，但其默认需要求导（requires_grad = True）。 forward函数实现前向传播过程，其输入可以是一个或多个variable，对x的任何操作也必须是variable支持的操作。 无需写反向传播函数，因其前向传播都是对variable进行操作，nn.Module能够利用autograd自动实现反向传播，这点比Function简单许多。 faster rcnn等中反向传播直接写pass的原因。 使用时，直观上可将layer看成数学概念中的函数，调用layer(input)即可得到input对应的结果。它等价于layers.__call__(input)，在__call__函数中，主要调用的是 layer.forward(x)，另外还对钩子做了一些处理。所以在实际使用中应尽量使用layer(x)而不是使用layer.forward(x)。 Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器，前者会给每个parameter都附上名字，使其更具有辨识度。 Module能够自动检测到自己的Parameter，并将其作为学习参数。 nn.ReLU和F.ReLU有什么区别?将ReLU层添加到网络有两种不同的实现，即nn.ReLU和F.ReLU两种实现方法。其中nn.ReLU作为一个层结构，必须添加到nn.Module容器中才能使用，而F.ReLU则作为一个函数调用，看上去作为一个函数调用更方便更简洁。具体使用哪种方式，取决于编程风格。在PyTorch中,nn.X都有对应的函数版本F.X，但是并不是所有的F.X均可以用于forward或其它代码段中，因为当网络模型训练完毕时，在存储model时，在forward中的F.X函数中的参数是无法保存的。也就是说，在forward中，使用的F.X函数一般均没有状态参数，比如F.ReLU，F.avg_pool2d等，均没有参数，它们可以用在任何代码片段中。 nn.Softmax() &#x3D; nn.Linear() + forward最后输出的时候调用F.softmax()","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"}]},{"title":"CNN的卷积过程理解","slug":"人工智能/CNN的卷积过程理解","date":"2018-10-15T12:30:52.000Z","updated":"2019-10-23T01:43:34.000Z","comments":true,"path":"人工智能/CNN的卷积过程理解/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CNN%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B%E7%90%86%E8%A7%A3/","excerpt":"","text":"CNN的卷积层这就涉及到CNNs要做的工作了。每一个卷积核中的数值，都是算法自己学习来的，不需要我们费心去设置。【CNN的特征提取部分和FC部分一样，也是需要训练的。训练学得Fliter的具体值，然后学得图像特征相当于Fliter是W，图片是X，最终提取得到的特征是Y 输入进FC里（全连接层）训练过程中，W不断学习得到最佳Fliter（Filter其实就是权值！每个像素的权值！二维的所以在最开始的FIlter时候其实就是权值初始化的问题,后面算法自己会学到）】我们需要做的是设置超参数（学习超参数） 所谓的卷积层conv就是一堆卷积核，卷积层的参数就是卷积核的参数 CONV-&gt;ACTIVATE-&gt;POOL-&gt; XXXXXXXX -&gt;FC 多通道卷积——理解卷积层的工作原理非常重要输出的层数必为卷积核的层数，以卷积核的视角来做卷积，一个卷积核生成一个卷积层！ ** 同一个卷积核对所有通道做卷积然后进行求和得到该卷积核对应的卷积层","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"https://aisaka.cloud/tags/CNN/"}]},{"title":"SQL语句","slug":"数据库与中间件/SQL语句","date":"2018-10-11T13:56:33.000Z","updated":"2020-09-02T11:43:02.000Z","comments":true,"path":"数据库与中间件/SQL语句/","link":"","permalink":"https://aisaka.cloud/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/SQL%E8%AF%AD%E5%8F%A5/","excerpt":"SQL 分为数据操作语言 (DML) 和 数据定义语言 (DDL)。 DML是用于执行查询的语法：select，update，delete，insert into DDL部分使我们有能力创建或删除表格，定义索引（键），规定表之间的链接，以及施加表间的约束：create database，alter database，create table，alter table，drop table，create index，drop index *是通配符 sql的字符串是varchar(size)，用字符串用单引号表示","text":"SQL 分为数据操作语言 (DML) 和 数据定义语言 (DDL)。 DML是用于执行查询的语法：select，update，delete，insert into DDL部分使我们有能力创建或删除表格，定义索引（键），规定表之间的链接，以及施加表间的约束：create database，alter database，create table，alter table，drop table，create index，drop index *是通配符 sql的字符串是varchar(size)，用字符串用单引号表示 select 列名 from 表名 列出列 列名可为多个列，返回列数据 检索列名，行名无需单引号 select distinct 列名 from 表名：只列出列中不重复元素 select 列名 from 表名 where 列 运算符 值 select 列名 from 表名 where 列 运算符 值 and 列 运算符 值 select 列名 from 表名 where 列 运算符 值 or 列 运算符 值 select 列名 from 表名 order by 列名 排序 逆序：order by 列名 DESC null 值默认为最小值 insert into 表名 values (值1，值2，…) insert into 表名(列1,列2,…) values (值1，值2，…) 不能插null，如果不插就是null update 表名 set 列名=新值 where 列名 运算符 值 修改数据：通过where定位行，再通过set修改行中某列属性 delete from 表名 where 列名 运算符 值 where 列名 运算符 值：定位行 一般select，update，delete都是主定位列，所以需要where辅助 运算符 =，&lt;&gt;/!=，&gt;，&lt;，&gt;=，&lt;=，BETWEEN(在某个范围内)，LIKE(搜索某种模式，即匹配) between 0 and 150 like &#39;%CG&#39;，%是通配符 in：where字句中规定多个值，如where name in (value1,value2) is null，is not null top：规定返回记录的数目 在mysql中等价于select from limit 数目（省略select和from的值） select top 百分比 percent * from 返回一定百分比 通配符 %：替代一个或多个字符 _：替代一个字符 [charlist]：字符列中的任何单一字符 charlist或[!charlist]：不在字符列中的单一字符 select 列名 from 表名 as 别名 指定别名 table.列名：点语法 点语法，可以助力多表查询 于是就可以配合出多表查询比如：select * from table1,table2 where table1.NAME=table2.NAME; 我们也可以用专业的join，见下 join：多表查询 从两个或更多的表中获取结果 select * from table1 join table2 on tb1.name=tb2.name; 同时有inner join，left join，right join，full join join=inner join是返回两张表中完全匹配的结果 left join，right join返回左/右表所有行 full join是返回左表和右表的所有行 join条件语句使用on而不是where！ union：合并查询结果 写在两个select from中间（是一个语句！） eg：select * from tb1 **union** select * from tb2; union选取不同的值，union all可以选取相同的值 insert select into：从一个表中选取数据插入另一个表，复制表，常用来备份 insert into table_backup select * from table1; from后面可以加上①where子句，②还可以配合join连接两个表一起复制 要求目标表存在 create ：创建表/table eg:create database myDB create table table1 { ​ NAME varchar(255),​ MALE varchar(10),​ HEIGHT int(200) } SQL约束（constraints） ①添加约束： 在创建表的时候在变量后面规定约束，比如在17中第一个列定义改为：NAME varchar(255) primary key , 在表定义中加单独行如unique(MALE) 用alter table语句增加约束：alter table table1 add unique(MALE) ②约束类型： not null：非null unique：保证该数据在该列唯一 primary key：【主键】，唯一标识数据库表中的每条记录，一个表只能有一个主键，不能为null 主键最好是完全业务无关的字段，比如NAME等就不太好当主键，一般把主键叫做id foreign key：【外键】一个表中的 foreign key 指向另一个表中的 primary key 外键约束会降低数据库的性能 添加方法：一样的三种方法，不过后面语句特殊要指定references： foreign key (fk) references table2(NAME) 注意：必须保证该表外键和被连接表的主键是完全一样的类型定义！ 当两张表存在关联字段的时候，利用外键可以保证主表和从表的一致性和完整性，我们可以定义主从表on update，on delete关联规则： NULL、RESTRICT、NO ACTION（默认）删除：从表记录不存在时，主表才可以删除。更新：从表记录不存在时，主表才可以更新。 CASCADE删除：删除主表时自动删除从表。更新：更新主表时自动更新从表。 SET NULL删除：删除主表时自动更新从表值为NULL。更新：更新主表时自动更新从表值为NULL。这些规则的使用方法：举例 alter table table1 add foreign key (fk) references table2(NAME) on update cascade 也可以在创建的时候定义，跟在定义句子后面即可 check：限制列中的值的范围 举例：SCORE int check(SCORE&gt;0) default：默认值 ③撤销约束： 都是先通过alter table table1 来指定哪个表，再加上不同的drop操作 删除外键直接删掉外键列 Index—索引 create index 索引名 on 表名（列名） 索引值允许重复，默认升序，如果要建立唯一索引（索引值不可相同）：create unique index 索引名 on 表名（列名） 可以索引多列：create index 索引名 on 表名（列1，列2，…） 可以降序索引：create index 索引名 on 表名（列名 DESC） 关于索引： 在不读取整个表的情况下，索引使数据库应用程序可以更快地查找数据。索引可以高效地查询数据，是一种速度优化！用户无法看到索引，它们只是被用来加速搜索，加速查询。由于更新一个包含索引的表也需要更新索引，所以通常在经常被搜索的列和表上建立索引 drop：删除索引、表、数据库、视图 drop index 索引名 on 表名 drop table 表名 drop database 数据库名 alter：为【表】中【添加，删除】【列、约束】 可以做到很多事情 alter table 表名 add alter table 表名 drop 见前面 auto-increment 属性，和约束一样的添加删除方法。每有新记录插入的时候主动创建字段，如果已创建就自动+1 show 查看数据库相关信息 view 视图 可以从表中选择一些数据建立视图，视图中的数据是虚拟的，还是属于原来的表 创建视图：create view view_tb1 select from where 更新视图（略） mysql数据类型： 常用的 Text类型： char(size)：定长字符串，最长255 varchar(size)：变成字符串，最长255，大于则自动转为TEXT TEXT：最大长度65535 MEDIUMTEXT：最大长度16777215 LONGTEXT：最大长度4,294,967,295 还有诸如Number，Date中的一些类型 SQL Functionselect function(列) from 表 mysql的常用函数：avg(),max(),min(),sum(),lcase(),ucase(),count(),first(),last(),len(),round(),format()等等 mid(列名,int a,int b)，可以从列中提取该列元素中a~b区间的字符 主键与索引浅层区别没有主键会创建默认主键 主键索引：主键就是一种索引，此即主键索引。使用：设置primary key 非主键索引：非主键索引是要先链接到主键索引上的，只要建立的不是主键就是非主键索引。使用：create index on（由于默认建立主键，所以非主键索引可以不用担心没有链接到主键索引） 非主键索引可以是不唯一的，但主键索引一定是唯一的 一些注意点 SQL中where 和 on的区别 在join中，条件必须先用on，但后面的子条件可以接在on后面，也可以用where 对于inner join没有区别 但在left join时，on后面的条件只对右表有效（right join就只对左表有效） 而where是对两个表都有效 //这两个结果是不一样的select * from person p left join account a on p.id=a.id and p.id!=4 and a.id!=4; select * from person p left join account a on p.id=a.id where p.id!=4 and a.id!=4; https://blog.csdn.net/u013468917/article/details/61933994 sql having（前面出现的）和where（可以前面未出现） where筛选的是数据库表里面本来就有的字段，而having筛选的字段是从前筛选的字段筛选的。 https://www.cnblogs.com/ljf-Sky/p/9024683.html group by和order by 的使用","categories":[{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[]},{"title":"中秋","slug":"日记/中秋","date":"2018-09-25T12:11:51.000Z","updated":"2019-11-02T00:34:42.000Z","comments":true,"path":"日记/中秋/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%B8%AD%E7%A7%8B/","excerpt":"中秋到了，月儿圆了。","text":"中秋到了，月儿圆了。 遥想起两年前的中秋节，那时候正还看着动画，正好那天是喜欢的七海死的那集。那段时间开始入了另一个大坑，认识了很多人。 去年的这个时候，因为学业繁忙，甚至都没有时间去赏赏月，吃吃月饼。今年也是把去年的月饼给补上了。 然后这就是两年过去了。跨过了毕业的槛，现在正坐在实验室里，对着面前的数据绞尽脑汁。 经历了动荡的一年，现在，这几天算是终于安稳下来了。有了自由的空间，有了喜欢的研究的东西，电脑也配好了，也能和朋友一起玩了。 即将到来的是9天国庆，又能够好好休息一阵子。 远离了喧嚣（我也不知道是好是坏，对我来说，也是有两面性的。）也终于能够开始做高中毕业就要想做的那些事了。 さ、はじまるよ","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"notes_0915","slug":"人工智能/notes-0915","date":"2018-09-15T02:44:40.000Z","updated":"2019-10-23T02:11:43.000Z","comments":true,"path":"人工智能/notes-0915/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/notes-0915/","excerpt":"尽量少使用显式循环用向量化（并行运算） 即将元素作为向量进行计算numpy.dot(x,y)numpy.exp(v)等等 numpy有很多向量化函数即为点乘平时计算的时候也可以直接用向量化计算，速度快很多 神经网络——堆叠的线性分类器一个网元就是一个线性分类器 激活函数的选择 ReLU&gt;sigmodReLU最常用，sigmod基本不用 tensor = 张量在pytorch中，matrix即为张量 tensor，list，numpy array, tensor list的 转换方法 list = [[1,2,3],[3,4,5]] tensor = torch.Tensor(list) #List->Tensor narray = numpy.array(list) #List->narray tensor = torch.from_numpy(narray) #narray->tensor narray = tensor.numpy() #Tensor->narray 注意list narray tensor之间的转换方法 将tensor list转变为tensor： 用torch.stack而不是torch.Tensor tensor_list &#x3D; [tensor0,tensor1,tensor2..]&#x3D;&gt;tensor tensor &#x3D; torch.stack(tensor_list) 注意tensor中的格式必须相同，如果想要和list一样合并变长tensor必须用cat）","text":"尽量少使用显式循环用向量化（并行运算） 即将元素作为向量进行计算numpy.dot(x,y)numpy.exp(v)等等 numpy有很多向量化函数即为点乘平时计算的时候也可以直接用向量化计算，速度快很多 神经网络——堆叠的线性分类器一个网元就是一个线性分类器 激活函数的选择 ReLU&gt;sigmodReLU最常用，sigmod基本不用 tensor = 张量在pytorch中，matrix即为张量 tensor，list，numpy array, tensor list的 转换方法 list = [[1,2,3],[3,4,5]] tensor = torch.Tensor(list) #List->Tensor narray = numpy.array(list) #List->narray tensor = torch.from_numpy(narray) #narray->tensor narray = tensor.numpy() #Tensor->narray 注意list narray tensor之间的转换方法 将tensor list转变为tensor： 用torch.stack而不是torch.Tensor tensor_list &#x3D; [tensor0,tensor1,tensor2..]&#x3D;&gt;tensor tensor &#x3D; torch.stack(tensor_list) 注意tensor中的格式必须相同，如果想要和list一样合并变长tensor必须用cat） Tensor数学运算 tensor.sub(b) #tensor-b fin = torch.add(tensor1,tensor2) #fin = tensor1+tensor2 (mul div同add) torch.sum() #批矩阵相乘函数 torch.bmm(A,B) 对numpy array求math function，不要用math.function，直接用numpy.function如 np.exp(nparray) 如果对tensor求math函数的报错only one element tensors can be converted to Python scalars的话，就将tensor转化为numpy array再用numpy库的数学函数求 torch.Varibale和torch.Tensor用法基本一致，可以替换使用Variable包装了一个Tensor，并且保存着梯度和创建这个Variablefunction的引用本质上Variable和Tensor没有什么区别，不过Variable会放在一个计算图里面，可以进行前向传播和反向传播以及求导 显卡信息nvidia-smi sum(condition)计算满足condition的总数eg：sum(predict == label)preidict 是一个listlabel是一个list他们形状相同则统计两个列表中对应元素相同的个数 batch每一次从训练集/验证集/预测集 里面取数（从dataloader里取），都是以一个batch为一组来取按batch进行训练的模型，在使用的时候也是按batch进行预测，输出的也是按batch的输出值 释放CUDA显存 torch.cuda.empty_cache() 保存和加载模型 #直接保存模型和参数 torch.save(model_object, 'resnet.pth') #直接加载模型和参数 model = torch.load('resnet.pth') #但要注意！ 加载的时候，得先运行网络的定义！（即要先有网络结构，它才会把加载的参数填入网络） #加载预训练模型 https://blog.csdn.net/lscelory/article/details/81482586 测试的时候爆显存有可能是忘记设置no_grad, 示例代码如下： with torch.no_grad(): for ii,(inputs,filelist) in tqdm(enumerate(test_loader), desc='predict'): if opt.use_gpu: inputs = inputs.cuda() if len(inputs.shape) &lt; 4: inputs = inputs.unsqueeze(1) else: if len(inputs.shape) &lt; 4: inputs = torch.transpose(inputs, 1, 2) inputs = inputs.unsqueeze(1) 先设置不使用梯度，然后将测试时候的batchsize设置成训练时候的二分之一或者三分之一就不会爆了。 可能原因是测试的时候真的需要更大的显存。 指定使用哪块GPU 0123 os.environ[\"CUDA_VISIBLE_DEVICES\"] = 3 保存和加载模型 ,获得模型权重参数 # 保存和加载整个模型 torch.save(model, 'model.pkl') model = torch.load('model.pkl') # 仅保存和加载模型参数(推荐使用) torch.save(model.state_dict(), 'params.pkl') # 注意是先在里面torch.load文件 在加载到model（网络实例）的权重字典里 model.load_state_dict(torch.load('params.pkl')) 得到模型权重： model.state_dict 查看trainset打的标签 trainset.class_to_idx nn.Linear层就相当于一个y = w·x + b 对于带有梯度的tensor（由于variable和tensor合并了， 在cuda且求了grad），要对其操作则要 tensor.cpu().detach() 再进行运算操作 detach可以去掉去梯度部分 Pytorch 训练和测试时记得加 model.train 和 model.eval 设置模型模式 如果用到了BN和dropout，用PyTorch进行训练和测试时一定注意要把实例化的model指定train/eval，eval（）时，框架会自动把BN和DropOut固定住，不会取平均，而是用训练好的值，不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大。 这两个方法是针对在网络train和eval时采用不同方式的情况，比如Batch Normalization和Dropout Class Inpaint_Network() ...... Model &#x3D; Inpaint_Nerwoek() #train: Model.train(mode&#x3D;True) ..... #test: Model.eval() glob模块 (非常有用的文件读取操作模块） glob是python自己带的一个文件操作相关模块，用它可以查找符合自己目的的文件，类似于Windows下的文件搜索，支持通配符操作，_,?,[]这三个通配符，_代表0个或多个字符，?代表一个字符，[]匹配指定范围内的字符，如[0-9]匹配数字。两个主要方法如下。 ①glob方法： glob模块的主要方法就是glob,该方法返回所有匹配的文件路径列表（list）；该方法需要一个参数用来指定匹配的路径字符串（字符串可以为绝对路径也可以为相对路径），其返回的文件名只包括当前目录里的文件名，不包括子文件夹里的文件。 比如： glob.glob(r’c:*.txt’) #我这里就是获得C盘下的所有txt文件 glob.glob(r’E:\\pic**.jpg’) #获得指定目录下的所有jpg文件 #使用相对路径： glob.glob(r’..&#x2F;*.py’) ②iglob方法 获取一个**迭代器**（ iterator ）对象，使用它可以逐个获取匹配的文件路径名。与glob.glob()的区别是：glob.glob同时获取所有的匹配路径，而 glob.iglob一次只获取一个匹配路径。 这样就可以不一次性读完所有文件，节约内存 下面是一个简单的例子： f &#x3D; glob.iglob(r&#39;..&#x2F;*.py&#39;) print f &gt;&gt; &lt;generator object iglob at 0x00B9FF80&gt; for py in f: print py 常用help看用法..torch里的函数用法繁多 向量运算的一个注意点：要先去掉梯度！ 涉及梯度计算的Tensor（以前是被封装成Variable，但后来合并了），需要用.data来取得其tensor eg:loss.data outputs.data 损失函数返回值，模型输出，都是含有梯度的向量，需要用.data再参与运算！ 注意单元素tensor！ Use tensor.item() to convert a 0-dim tensor to a Python number 比如每个batch的loss返回值、sum(tensor1==tensor2)等都是单元素tensor tensor和普通数字不能随意运算，不然会出错 要注意，tensor运算得到的结果也是tensor，就算是sum(tensor1==tensor2)得到相等元素数量，得到的也是tensor(x) （x为相等元素数量，一个常数），依然需要sum(temsor1==temsor2).item()才能参与普通数字运算 否则会出莫名其妙的错误！：比如 t1 &#x3D; torch.Tensor([2,3,4,5]) t2 &#x3D; torch.Tensor([2,3,7,6]) sum(t1&#x3D;&#x3D;t2) &gt;&gt; tensor(2,dtype&#x3D;torch.uint8) sum(t1&#x3D;&#x3D;t2)&#x2F;10 &gt;&gt; tensor(0,dtype&#x3D;torch.uint8) torch.sum(t1&#x3D;&#x3D;t2) &gt;&gt; tensor(2) torch.sum(t1&#x3D;&#x3D;t2)&#x2F;10 &gt;&gt; tensor(0) #这样才正确 sum(t1&#x3D;&#x3D;t2).item()&#x2F;10 &gt;&gt; 0.2 torch.sum(t1&#x3D;&#x3D;t2).item()&#x2F;10 &gt;&gt; 0.2 #tensor除(&#x2F;)一个常数是整除！ 数据集 最好使用三个数据集：训练集、验证集、测试集 sklearn.model_selection.train_test_split 函数可用于方便的划分数据集 dropout 和 dropout2d的区别 torch.nn.Dropout对所有元素中每个元素按照概率0.5更改为零 而torch.nn.Dropout2d是对每个通道按照概率0.5置为0（即一个通道全为0） 对于网络 class model(nn.Module) ... net &#x3D; model() model.features net 注意a = a.cuda() 要赋值回去 torch的交叉熵的输入第一个位置的输入应该是在每个label下的概率, 而不是对应的label否则会报错dimension out of range (expected to be in range of [-1, 0], but got 1) 返回对象的属性值vars()用法vars(object)可用于很多封装对象如dataloader等等 交叉熵损失函数中的weight参数 （权重） weight &#x3D; torch.FloatTensor([0.13859937, 0.5821059, 0.63871904, 2.30220396, 7.1588294, 0]).cuda() 迁移学习修改网络应该直接修改层，修改线性层的out_features会遇到问题 #应该直接修改最后一层网络 vgg.classifier[6] &#x3D; nn.Linear(4096,2) 注意初始化网络结构和传入参数到网络里进行计算的区别 初始化网络实体的时候是传入init()里的参数，相当于初始化网络部件 传入参数是传入forward()里的传输，这个传入的就需要计算了 先初始化网络再传入参数进行计算 输入损失函数的真实标签项，必须为long类型 不能是tensor float！tensor int！ 具体如此生成： list = [1,2,3] tensor = torch.LongTensor(list) cuda runtime error: device-side assert triggered at xxx 这个问题一般来自模型输出的label数量和标签类别种类数量不同。要洗一遍数据集的标签 自定义层 可以自己定义层，只需要继承自nn.Module并实现forward()函数 问题：需要实现backwards函数吗？它会自动求导吗？： pytorch可以自动求导，但如果实现的层不可导，就需要自己实现梯度的反向传递（比如存在if条件，孤立点，拐点，就需要自定义求导式）也就是所谓的 “Extending torch.autograd”. 官网虽然给了例子 以下举例，自己建立了一个计算Gram Matrix 格拉姆矩阵的层（由于是可导的，所以不需要自己实现） 继承的时候别忘了super().__init__()","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"DigitalOcean成功迁移Vultr","slug":"博客/DigitalOcean成功迁移Vultr","date":"2018-09-13T14:39:26.000Z","updated":"2019-04-01T15:36:16.000Z","comments":true,"path":"博客/DigitalOcean成功迁移Vultr/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/DigitalOcean%E6%88%90%E5%8A%9F%E8%BF%81%E7%A7%BBVultr/","excerpt":"","text":"新日本东京服务器，平均延迟122ms，联通延迟更低，甚至可以加速器用233 但是pixiv默认ban Vultr IP，这就很蛋疼了…..","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"优化器optimizer和超参数更新","slug":"人工智能/优化器optimizer和超参数更新","date":"2018-09-10T02:01:03.000Z","updated":"2019-10-23T01:43:00.000Z","comments":true,"path":"人工智能/优化器optimizer和超参数更新/","link":"","permalink":"https://aisaka.cloud/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E4%BC%98%E5%8C%96%E5%99%A8optimizer%E5%92%8C%E8%B6%85%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0/","excerpt":"","text":"optimizeroptimizer.param_group记录了模型迭代的优化器参数信息optimizer.step后可从optimizer.param_groups[0][‘params’]查看参数变化optimizer.param_groups[0]是一个字典包含dict_keys([&#39;params&#39;, &#39;lr&#39;, &#39;betas&#39;, &#39;eps&#39;, &#39;weight_decay&#39;, &#39;amsgrad&#39;])所以可以自己看想要的信息，也可以直接修改！ 模型权重参数是存在于model.parameters()中的，这个也是要传入optimizer的变量 超参数更新（optimizer和scheduler都是自己事先定义的变量，前者为优化器，后者为自适应学习率优化器optimzer = torch.optim.Adam(……)scheduler = torch.optim.lr_scheduler.StrpLR(……)) optimizer.step()：通常用在每个mini-batch之中，用了之后模型才会更新scheduler.step()：通常用在epoch里面，用了之后才会对学习率lr进行调整optimizer.zero_grad() 用在每个mini-batch之中，梯度参数清0，以避免参数把上一次optimizer调用时创建的梯度累加在一起（根据pytorch中的backward()函数的计算，当网络参量进行反馈时，梯度是被积累的而不是被替换掉；但是在每一个batch时毫无疑问并不需要将两个batch的梯度混合起来累积，因此这里就需要每个batch设置一遍zero_grad 了。）","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"永无止境的庙会里","slug":"日记/永无止境的庙会里","date":"2018-09-09T12:51:31.000Z","updated":"2018-11-05T10:43:31.000Z","comments":true,"path":"日记/永无止境的庙会里/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%B0%B8%E6%97%A0%E6%AD%A2%E5%A2%83%E7%9A%84%E5%BA%99%E4%BC%9A%E9%87%8C/","excerpt":"","text":"永无止境的庙会，我能远离它吗？","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"No title","slug":"日记/523","date":"2018-08-25T09:47:13.000Z","updated":"2019-04-03T04:56:58.000Z","comments":true,"path":"日记/523/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/523/","excerpt":"","text":"Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary. By Steve Jobs","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"旅途之后","slug":"日记/旅途之后","date":"2018-08-15T13:45:03.000Z","updated":"2019-04-03T05:12:39.000Z","comments":true,"path":"日记/旅途之后/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%97%85%E9%80%94%E4%B9%8B%E5%90%8E/","excerpt":"从最后一节暑期课，到现在，快一个月了。我的旅途结束了。 走了很多地方，看见了不同的人与景，进入了不同的生活。 旅行也许是改变现在的尝试。回到了家。迷茫与困惑的感觉随之而归。一段旅行的结束，是思考的最好时机。","text":"从最后一节暑期课，到现在，快一个月了。我的旅途结束了。 走了很多地方，看见了不同的人与景，进入了不同的生活。 旅行也许是改变现在的尝试。回到了家。迷茫与困惑的感觉随之而归。一段旅行的结束，是思考的最好时机。 仿佛又如四年前那样。 摆在面前的，是无数的不确定。我不知道，我想要做的，是否正确 ——没有答案，亦或是只有在未来才能知晓那个答案。甚至，我不知道那是不是我内心到底想要做的。 现在想，高考是人生中最轻松的一次考试，它有答案有老师。 可后来生活里的每一道题，都没有答案。 我只能用很长的时间，付出最大的辛苦，来给出一个我的答案。 筚路蓝缕，以启山林。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"致过去与未来交界的现在","slug":"日记/致过去与未来交界的现在","date":"2018-07-01T13:24:50.000Z","updated":"2019-04-03T05:00:57.000Z","comments":true,"path":"日记/致过去与未来交界的现在/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E8%87%B4%E8%BF%87%E5%8E%BB%E4%B8%8E%E6%9C%AA%E6%9D%A5%E4%BA%A4%E7%95%8C%E7%9A%84%E7%8E%B0%E5%9C%A8/","excerpt":"蓝渐白的天幕落下","text":"蓝渐白的天幕落下 闪烁着一颗星星天空纯粹无暇矮矮的楼房立于两边在天幕下，只显得两道黑影 仰望无暇的星空静静伫立沐浴在着清澈湛蓝的夜空下 脑海里闪过了过去与现在的境像那些情感——激动，难过，感动，兴奋，生气，期待…在心中闪烁，点燃了思绪 不一会儿，在夜空的沐浴下，思绪也归于这夜空的宁静。 致过去与未来交界的现在。","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"鱼玄机","slug":"Music/鱼玄机","date":"2018-06-25T01:31:05.000Z","updated":"2019-04-03T04:59:24.000Z","comments":true,"path":"Music/鱼玄机/","link":"","permalink":"https://aisaka.cloud/Music/%E9%B1%BC%E7%8E%84%E6%9C%BA/","excerpt":"","text":"我憨的这首鱼玄机唱的太好听了 av8444592","categories":[{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"}],"tags":[]},{"title":"十字路口","slug":"日记/十字路口","date":"2018-06-22T17:05:11.000Z","updated":"2019-04-03T04:58:52.000Z","comments":true,"path":"日记/十字路口/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%8D%81%E5%AD%97%E8%B7%AF%E5%8F%A3/","excerpt":"","text":"下一站，","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"AS安装实录","slug":"开发/AS安装实录","date":"2018-06-01T02:14:17.000Z","updated":"2019-04-03T05:06:01.000Z","comments":true,"path":"开发/AS安装实录/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/AS%E5%AE%89%E8%A3%85%E5%AE%9E%E5%BD%95/","excerpt":"你墙国还是你墙国 XCode10分钟搞定的事情AS能折腾一年 1/安装SDK问题。离线安装SDK，并修改SDK路径","text":"你墙国还是你墙国 XCode10分钟搞定的事情AS能折腾一年 1/安装SDK问题。离线安装SDK，并修改SDK路径 2/无限卡下载SDK在/home/aisaka/android-studio/bin/idea.properties中加入一行disable.android.first.run=true 3/安装gradel问题手动离线安装gradel，讲gradel压缩包放入wrapper里的乱码文件夹里，放一个压缩包和一个文件夹然后在setting里手动设置gradel路径到4.4-all 4/gradel无法同步问题https://www.e-learn.cn/content/wangluowenzhang/28422 5/同步gradel速度极慢问题改hosts(ipv6 hosts)关掉gradel代理 6/运行模拟器时无法加载驱动问题 failed to load driver: nouveau 下午3:55 Emulator: libGL error: unable to load driver: nouveau_dri.so 下午3:55 Emulator: libGL error: driver pointer missing 下午3:55 Emulator: libGL error: failed to load driver: nouveau 下午3:55 Emulator: libGL error: unable to load driver: swrast_dri.so 下午3:55 Emulator: libGL error: failed to load driver: swrast 下午3:55 Emulator: emulator: ERROR: Missing initial data partition file: &#x2F;home&#x2F;aisaka&#x2F;.android&#x2F;avd&#x2F;Nexus_5X_API_27.avd&#x2F;userdata.img 下午3:55 Emulator: X Error of failed request: BadValue (integer parameter out of range for operation) 下午3:55 Emulator: Major opcode of failed request: 155 (GLX) 下午3:55 Emulator: Minor opcode of failed request: 24 (X_GLXCreateNewContext) 下午3:55 Emulator: Value in failed request: 0x0 下午3:55 Emulator: Serial number of failed request: 58 下午3:55 Emulator: Current serial number in output stream: 59 下午3:55 Emulator: Process finished with exit code 1 下午3:55 Gradle build finished in 1s 316ms问题解决：https://kotlintc.com/articles/4062执行如下命令： $ cd ~&#x2F;Android&#x2F;Sdk&#x2F;emulator&#x2F;lib64&#x2F;libstdc++ $ mv libstdc++.so.6 libstdc++.so.6.bak $ ln -s &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6 libstdc++.so.6","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"},{"name":"andoird开发","slug":"开发/andoird开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/andoird%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"动态规划","slug":"算法与数据结构/动态规划","date":"2018-05-29T13:26:59.000Z","updated":"2021-03-04T17:16:20.000Z","comments":true,"path":"算法与数据结构/动态规划/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","excerpt":"能用DP解决的问题： 如果是【求一个问题的最优解（通常是求最大值或最小值）】，而且该问题能够分解成若干个子问题，并且子问题之间还有重叠的更小的子问题，就可以考虑用动态规划来解决这个问题（也可以用DFS搜索）。 在应用动态规划之前要分析能否把大问题分解成小问题，【分解后的每个小问题也存在最优解，如果把小问题的最优解组合起来能够得到整个问题的最优解（核心）】，那么我们可以应用动态规划解决这个问题。","text":"能用DP解决的问题： 如果是【求一个问题的最优解（通常是求最大值或最小值）】，而且该问题能够分解成若干个子问题，并且子问题之间还有重叠的更小的子问题，就可以考虑用动态规划来解决这个问题（也可以用DFS搜索）。 在应用动态规划之前要分析能否把大问题分解成小问题，【分解后的每个小问题也存在最优解，如果把小问题的最优解组合起来能够得到整个问题的最优解（核心）】，那么我们可以应用动态规划解决这个问题。 核心思想将问题拆分为规模不同的子问题，然后就可以使用递归DFS从上到下计算（难点），但这样会导致大量重复计算 于是我们从最小规模开始，步步为营，记录每一个子问题的最优解，一直递推出最大规模问题的最优解，此即DP的思想 DP解决问题步骤 将问题划分为相似的子问题====&gt;这常常是难点与关键，找到不同规模的相似子问题，划分子问题 每一个子问题要在 【不存在更小子问题的所有可能（不与子问题关联）】和【存在更小子问题的所有可能（建立更小规模子问题的关联）】（不用考虑更小子问题如何求解，因为问题规模是从小到大递推求解的，此时更小规模子问题的最优解已经被记录下来了），在这些所有的可能中【选择出最优解作为当前规模的子问题的最优解】 根据小规模子问题，建立状态转移方程（递推式，有的是从顶部往下推，有的是从底部往上推） （实际上找到了相似子问题建立递推方程之后，我们就可以用暴力DFS来做了，只不过这样效率极低，重复计算了很多子问题，于是我们才想接下来走3 4步骤走DP。） 步步为营，缓存并复用以往结果，记录规模从小到大的子问题的最优解（这里就是DP的优势，这样使得搜索树中重复计算的部分全部不用重算了） 继续按顺序从小往大递推计算，步步求最优并重复③，直到最终规模问题（用for循环，计算递推式） 【1和2是解决这类问题必须的（即使暴力DFS来做），3和4步才是DP的关键】 是不是很熟悉，是不是很耳熟 这不就是数学归纳法、数学归纳法、数学归纳法（重要的事情要强调三遍）吗 不过DP中是先推导出状态转移方程，再利用计算机暴力求解出来 注意，如果不采用步骤②③，而是使用递归来解决步骤①，那就不是DP了，递归来解决此问题效率很低（递归树中存在大量重复计算，且栈开销大） TIPS【思考DP题，先想递归DFS怎么做，再想改成DP来做】先抽象成用DFS来做，即找到子问题就是难点，不同问题要抽象建模。 【DP就是DFS改为从下而上+备忘录】 可以先用DFS暴力搜索做出来，再改成DP 一维DP：剪绳子问题（整数拆分问题）一根长度为 $n $的绳子，请把绳子剪成整数长度的$ m $段（$m、n$都是整数，$n &gt; 1$并且$m &gt; 1$），每段绳子的长度记为$ k[0],k[1], … ,k[m] $。请问$ k[0]×k[1] ×… ×k[m] $可能的最大乘积是多少？例如，当绳子的长度是$8$时，我们把它剪成长度分别为$2、3、3$的三段，此时得到的最大乘积是$18$。 思路： ①先找到子问题：将一个数拆分为两个数的所有可能拆法中，若不继续划分（不考虑更小子问题，即一个绳子拆分为两段的所有可能拆法），以及另一个数将被继续拆分（有更小子问题，在子问题中还将被继续划分，但不用考虑内部，更小规模问题的最优解已经被记录），在这里面中找到最优解 该问题的小规模子问题就是每一次切分将一个数切成两个部分，使其乘积最大 这里可能很难理解，见下面的理解部分 （问题画成一颗树，暴力枚举就要搜索这棵树的每个可能性） ②给出递推式（从顶部开始推）： F(n)=\\max\\{i×F(n-i),i×(n-i)\\},i=1,2,\\cdots,n-1理解：$F(1)=\\max \\{0\\}=0$：若长度为$n=1$，最小切分为$1$，那分完只能是$0×1=0$ $F(2)=\\max\\{1×1,1×F(1)\\}=1$：长度为$n=2$，最优解为不继续划分（具体理解见下面第三个子问题最优解$F(3)$的计算） $F(3)=\\max\\{1×2,1×F(2)\\}$：长度为$n=3$，这时候就有两种选择了，直接划分一刀为$1，2$或者划分为$1,2$后还继续将$2$划分，由$F(2)=1$可知如果继续划分的话，划分后的子问题最优解为$1$，那么$1×F(2)=1×1=1$，显然比不划分（$1×2$）小，那么该子问题我们就选择不划分就是最优解，即$F(3)=2$ $F(4)=\\max\\{1×3,2×2,3×1,4×0,1×F(3),2×F(2),3×F(1),4×F(0)\\}=balabala$ 左边为拆成两半之后不再继续拆分，右边为拆成两半后继续拆分 以此类推，我们不断得到了在绳子长度不断增加（就是问题规模不断扩大）下的最优解序列：$F(0),F(1),F(2),F(3),\\cdots F(n)$，每个前面的问题都是其后面的问题的更小规模的子问题，每一步都获得了子问题的最优解，那么最终得到的就是最终问题的最优解。 ③④缓存并复用结果，我们从底往顶推，依次计算$F(0),F(1),F(2),F(3),\\cdots F(n)$ 每一轮求出一个子问题的最优解，从最小规模问题逐步往上推，每个$F(x)$都是最优解，那么最终就求出问题$F(n)$的最优解 其中根据方程最开始的几个子问题需要手动计算作为启动 解题： 暴力搜索：其实暴力搜索解法就是使用递推式（所以我们还是得先像上面一样写出递归式！无论用暴力解还是DP解，这都是基础），从上往下递归DFS搜索所有可能，这其中就重复计算了很多东西，算法效率极低 先明白暴力搜索怎么做，再看DP就很容易理解，DP就是在暴力DFS之上的改进 class Solution &#123; public int cuttingRope(int n) &#123; return dfs(n); &#125; int dfs(int n) &#123; //最小子问题n=2，无法拆分 if (n==2) return 1; int maxOfSonProblem=0; //遍历该子问题：划分，将数划分成i和n-i两段，目的是找到最佳i //在所有可能划分中×继续划分或不继续划分 for(int i=1;i&lt;n-1;i++) &#123; //n-i不继续划分，直接得到乘积，不需要递归计算 int sonNotDivid = i*(n-i); //n-i继续划分，继续递归 int sonDivid = i*dfs(n-i); maxOfSonProblem = Math.max(maxOfSonProblem,Math.max(sonNotDivid,sonDivid)); &#125; return maxOfSonProblem; &#125; &#125; 动态规划：动态规划就从下到上，记录（备忘录）每个子问题的最优解，步步为营，算法效率极高 int[] produce; int dp(int n) &#123; produce = new int[n+1]; produce[1]=0; produce[2]=1; //子问题计数，步步为营，规模扩大 for(int i=3;i&lt;n+1;i++) &#123; //遍历该子问题：划分，将数i（小规模子问题）划分成j和i-j两段 //在所有可能划分中×继续划分或不继续划分，在这些组合中找出最优解 int maxOfSonProblem=0; for(int j=1;j&lt;i;j++) &#123; int sonNotDivid = j*(i-j); int sonDivid = j*produce[i-j]; maxOfSonProblem = Math.max(maxOfSonProblem,Math.max(sonDivid,sonNotDivid)); &#125; produce[i]=maxOfSonProblem; &#125; return produce[n]; &#125; 一维DP：最大连续子序列递推式：f(n)=f(n-1)+array[n] if f(n-1)>=0 二维DP搜索空间是二维的，需要两个起始边界，计算dp数组 题目： M个朋友一起完成一幅刺绣，这幅刺绣可以被分成N个部分，数组T表示绣完每个部分所需的时间。每个部分只能被一个人完成，并且每个人都只能完成连在一起的部分（即数组T内连续的一段）。所有人并行工作，请问想要完成这幅刺绣所需的最短时间是多少？要求：时间复杂度度为O(nlogt), t=sum(T) 输入： 第一行为N 第二行为M 第三行为T 示例1， 输入： 3 2 3 1 4 输出： 4 说明：第一个人去绣3和1，耗时为4；第二个人绣4，耗时为4。总耗时为4。 示例2， 输入： 5 3 1 1 1 4 3 输出：4 说明：第一个人绣1,1,1，耗时为3；第二个人绣4，耗时为4；第三个人绣3，耗时为3。总耗时为4 解题： 方法一，二维DP算法 递推式：dp(m, n) = min( //所有拆分的最小可能 max(T(0), dp(m-1, n-1)), //max是因为统计的是最长耗时 max(T(0)+T(1), dp(m-1, n-2)), … , max(T(0)+T(1)+…+T(n-m), dp(m-1, m-1)) ) 原问题变成第1个人做第0段，剩下m-1个人做剩下n-1段；第1个人做第0，1段，剩下m-1个人做剩下n-2段；……；第1个人做第0，1，……，n-m段，剩下m-1个人做剩下m-1段。这些里面最小的情况 public class Main &#123; public static void main(String[] args) &#123; //M朋友，N段，T[]绣完每部分的时间 int N=5,M=3; int[] T = new int[]&#123;0,1,1,1,4,3&#125;; //T[0]=0，非用户输入 //dp(m,n)：m个人做右边n段的最优解子问题储存矩阵 //则划分：第一个人做0,1,2,...n-m段 int[][] dp = new int[M+1][N+1]; //启动子问题：dp(i,i),i个人做最后i段,取后i个里面的最大元素 for(int i=1;i&lt;M+1;i++) &#123; int max=0; for(int j=N;j>=i;j--) if (T[j]>max) max = T[j]; dp[i][i]=max; &#125; //启动子问题：dp(1,i),1个人做最后i段，取和 int sum=0; for(int i=1;i&lt;N+1;i++) &#123; sum = T[N-i+1]+sum; dp[1][i] = sum; &#125; //开始m=2的由下向上计算递推过程 for(int m=2;m&lt;M+1;m++) //m个人【至少】做m段 for(int n=m+1;n&lt;N+1;n++) &#123; //求dp(m,n)子问题的最优解，m个人做后n段 int min = 1000000; //这里一会儿改为T数组元素和 int firstPersonSum = 0; //这里在做dp(m,n)子问题，那么第一个人做的就应该从第m+1个数开始算 for(int i=N-n+1;i&lt;N+1;i++) &#123; firstPersonSum += T[i]; //剩下的人做剩下的部分 int otherPeopleSum = dp[m-1][N-i]; //两者取最大，并行算最大耗时 int sonProblemSum = firstPersonSum>otherPeopleSum?firstPersonSum:otherPeopleSum; //刷新min记录 if (sonProblemSum&lt;min) min = sonProblemSum; &#125; //求得dp(m,n)最小值即最优解 dp[m][n] = min; &#125; System.out.println(dp[M][N]); &#125; &#125; 方法二：此题也可以用非DP算法来求解，思路如下： 通过二分方法寻找最大耗时，然后验证这个最大耗时是否可行（段落结合即结合段落分配给一个人做）验证方法为，从段落的第一段开始两两段落结合，①如果结合后的耗时&gt;最大耗时，则方案不可行；②如果&lt;最大耗时，则拆开这两段，继续往后遍历，如果遍历到最后发现剩余的人数不够做剩下的段落了，则方案不可行直到最后就找到了最大耗时这样复杂度就比dp还低，不需要探索状态空间 题型有很多","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"分治策略","slug":"算法与数据结构/分治策略","date":"2018-05-27T02:12:48.000Z","updated":"2018-11-06T05:32:03.000Z","comments":true,"path":"算法与数据结构/分治策略/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%88%86%E6%B2%BB%E7%AD%96%E7%95%A5/","excerpt":"对分治策略的分析见文章[递归分析]http://aisakaki.com/?p=406 1、分解（分） 2、解决（治） 3、合并 一些使用分治策略的算法 ①归并排序 T(n)=2T(n/2)+Θ(n) 2为子问题数目，n/2为子问题规模，Θ(n)为附加计算量（分治法运行时间） 通过主定理case2，可以得到其T(n)=O(nlgn)","text":"对分治策略的分析见文章[递归分析]http://aisakaki.com/?p=406 1、分解（分） 2、解决（治） 3、合并 一些使用分治策略的算法 ①归并排序 T(n)=2T(n/2)+Θ(n) 2为子问题数目，n/2为子问题规模，Θ(n)为附加计算量（分治法运行时间） 通过主定理case2，可以得到其T(n)=O(nlgn) ②二分查找 分：二分 治：比较。只在一个子数组中递归 T(n)=1*T(n/2)+Θ(1) 1个子问题 ③乘方问题 求x^n 如果用朴素方法，那么T(n)=O(n) 如果采用分治策略，那么T(n)=T(n/2)+Θ(1)=O(lgn) (master method) &lt;O(n) *注意奇偶n的处理，但其递归式不变 只有一个子问题，画递归树的话就是一条链 ④非不拉几数列 Fn=Fn-1 + Fn-2 if n&gt;=2 Fn=0 if n=0 Fn=1 if n=1 1*若采用朴素的递归方式，不停计算Fn-1,Fn-2,触底就返回，那么 T(n)=Ω(φ^n) φ=(1+√5)/2 （φ为黄金比例，神奇） 子问题的规模仅仅缩小到了n-1，递归树非常庞大 复杂度为指数级，代价很高，所以此种方法不好。 最理想的算法复杂度为多项式级 2*事实上，在建立非不拉几递归树的时候，会发现很多公共子树，这些子树重复计算，产生了大量冗余。 如果考虑从底向上计算（线性。依次计算F(1),F(2),F(3),….)，那么其复杂度会是O(n) 3*有一个更简单的办法（数学），F(n)=φ^n/√5并取整至最接近的整数，复杂度即为③中的问题，为O(lgn) 由于φ为浮点数，所以这样不精确且对运算要求极高，在现有机器上无法运行 4*第二种数学方法 Fn-1 Fn = 1 1 ^n Fn Fn-2 = 1 0 （左右皆为矩阵，右边是矩阵的n次幂，待安装数学公式插件再修改） 证明：数学归纳法。比较简单，证略。 其复杂度为O(lgn) ⑤矩阵乘法 朴素方法：三层循环，i对应左行，j对应右列，k对应遍历每个元素。T(n)=O(n^3) 分治方法1： 利用分块矩阵，将母矩阵变成2*2的矩阵 A= A11 A12 A21 A22 B=B11 B12 B21 B22 C=C11 C12 C21 C22 由此可以写得四个表达式 c11=A11B11 + A12B21 C12=A11B12+A12B22 C21=A21B11+A22B22 C22=A21B12+A22B22 由此可得每次递归需要将有八个递归子问题（乘），并加上4次矩阵加法时间 （8个规模为n/2的矩阵乘法（递归）和4个规模为n/2（即合并起来为一个规模为n）的矩阵加法（非递归，常数） 所以其递归表达式为 T(n)=8T(n/2)+Θ(n^2) 由主定理得，T(n)=Θ(n^3) 此方法效率依然很低，和朴素方法没什么区别。 思考：为什么效率低？ 因为矩阵乘法是Θ(n^3)级复杂度，而一次递归将产生8个子问题，每个子问题皆矩阵乘法 而矩阵加法是Θ(n^2)级复杂度。所以为了使递归树变小，我们应尽量减少矩阵乘法，多做矩阵加法。 比如，一次递归产生8个子矩阵乘法问题，递归树太“茂盛”了，我们能否减小到7个？ 通过这种思考下去，就想到了第二种方法 分治方法2：Strassen方法 该算法具体内容见https://blog.csdn.net/qwertyuer/article/details/44255087 该算法下，T(n)=7T(n/2)+Θ(n^2)=Θ(n^lg7)&lt;Θ(n^3) 分：将AB 矩阵分为8个子矩阵 治：中间计算过程 合：将子问题的解合并为原问题的解 未完待续","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"C#","slug":"程序语言/c","date":"2018-05-25T13:07:53.000Z","updated":"2019-04-03T05:04:02.000Z","comments":true,"path":"程序语言/c/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/c/","excerpt":"闲暇时间做游戏，在学习Unity 由于U3D需要用C#，所以迅速对比java c了解一下C#的语法特性方便记忆。 —————————————————————————— 1、析构函数 ~object() &#123;&#125; 2、重写方法 override void method() &#123;&#125;","text":"闲暇时间做游戏，在学习Unity 由于U3D需要用C#，所以迅速对比java c了解一下C#的语法特性方便记忆。 —————————————————————————— 1、析构函数 ~object() &#123;&#125; 2、重写方法 override void method() &#123;&#125; 3、继承(类与接口） public class son : father &#123;&#125; 4、无指针，用引用，同java 5、使用ref关键字进行引用传递（必须初始化） ref关键字放在需要传递的变量面前，把一个输出参数的内存地址传递给方法（即传递实参） public void Grow (int _nSpan, **ref** outCurrentAge) &#123; this.nAge+&#x3D;_nSpan; nOutCurrentAge&#x3D;this.nAge; &#125; 主程序中 int nCurrentAge&#x3D;0; s.Grow(3 ,**ref** nCurrentAge) Console.WriteLine(nCurrentAge);6、使用out关键字进行引用传递（无需初始化） 7、使用params关键字传递多个参数 params关键字指明一个输出参数被看作为一个参数数组，这种类型的输出参数只能作为方法的最后一个输入参数 主要用于，在调用一个方法时，预先不能确定参数的数量、数据类型等。 public void setHobby(**params** string[] _setArrHobby) &#123; &#125; 主程序：s.setHobby(“reading”,”singing”,”programing”); 8、比较字符串 int Compare(strA,strB); 输出为0则相等 亦可用lool Equals，int CompareTo 不过，Compare是静态方法，且可重载。 CompareTo不是静态方法，且没有重载形式","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"C#","slug":"程序语言/C","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/C/"}],"tags":[]},{"title":"递归分析","slug":"算法与数据结构/递归分析","date":"2018-05-23T01:17:56.000Z","updated":"2018-11-06T05:32:53.000Z","comments":true,"path":"算法与数据结构/递归分析/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%80%92%E5%BD%92%E5%88%86%E6%9E%90/","excerpt":"1、第一种，代入法（数学归纳） 这里需要用到数学归纳法 对于递归式 T(n) = 4T(n/2) + n 函数增长： 当n乘2的时候，T将乘以4 先考虑求其渐进上界 猜测，为theta(n^3)的时候，满足情况 对k&lt;n T(k)&lt;=ck^3 (T(k) ∈ O(n^3)) 设置一个常量g(n)来替代ck^3 （ g(n) ∈ O(n^3)) ） 用数学归纳法证明：","text":"1、第一种，代入法（数学归纳） 这里需要用到数学归纳法 对于递归式 T(n) = 4T(n/2) + n 函数增长： 当n乘2的时候，T将乘以4 先考虑求其渐进上界 猜测，为theta(n^3)的时候，满足情况 对k&lt;n T(k)&lt;=ck^3 (T(k) ∈ O(n^3)) 设置一个常量g(n)来替代ck^3 （ g(n) ∈ O(n^3)) ） 用数学归纳法证明： 1* T(1)=O(1) T(1)=c =O(1) 2* 假设T(n/2) = O((n/2)^3) +n 3 T(n) = 1/2g(n) +n = g(n) + (n – 1/2g(n)) 后部为余项 n -1/2g(n) = n – cn^3 1) ∴ T(n) &lt;= g(n) = O(n^3) （非对称相等） 猜测，为theta(n^2)的时候，满足情况 同理 设置 g(n) = O(n^2) 用数学归纳法证明： 1* T(1)=O(1) 2* 假设T(n/2) = O((n/2)^2) + n 3 T(n) = 4T(n/2) +n = g(n) +n = g(n) – (-n) (-n)为余项。此时无法证明-n为非负数 所以需要在原来的假设上进行改进 对T(k)进行更低阶的展开 以凑得一个非负的余项（想法：扩展系数到余项） 【注意这里使用了更强的归纳法，所以需要证明的结论更强了。 在归纳的时候需要归纳到的式子的主部已经变了。这里容易忽略】 对k&lt;n 假设 T(k)&lt;=c1*k^2 – c2*k (T(k) ∈ O(n^2)) 即令g(n)=c1n^2 – c2n T(n) = 4*T(n/2)+n =4(c1(n/2)^2 – c2(n/2) +n) =c1n^2 – (2c2 -4)n =c1n^2 – c2n – (c2-1)*n n&gt;0) 余项为(c2-1)*n ∴当c2-1&gt;0即c2&gt;1时 T(n)&lt;=g(n) =O(n^2) 对基本情况 为使T(1) = c1- c2 =O(1)成立 即 对于∀c2&gt;1,Ec1&gt;c2 ∴c1需要足够大 综上所述，当c1足够大,c2&gt;1,T(n)=O(n^2) 证毕 对于渐进下界Omega同理可证 所以有个很关键的地方，就是要进行合理的猜测。 可以通过经验猜测，也可以通过第二种方法递归树法来猜测 2、递归树法 这个方法不太严谨，但很常用（一般要通过代入法来证明） ATT： 注意并理解递归树的画法（和式画法），理解递归式每一项的意义 理解非递归代价，递归代价，总代价。 对于式T(n)=aT(n/b)+f(n)中，f(n)即为非递归代价，n为当层规模，比如第3层所有结点的非递归代价和即为a^2 * f(n/b^3) ，单个结点的非递归代价为 f(n/b^3)。如果算上递归代价，就还需要计算该结点下递归子树的总代价。 f(n)不再递归，反应了该节点的非递归部分的代价。 aT(n/b)反应了函数增长，我们可以在其中看出横向增长(子问题数目）和递归规模（子问题规模）。 注意层数=高度+1 完全N叉树的叶节点=N^高度 网站上不方便画图emmm 所以，图略 分析递归树： 对于T(n)=cn^2+3T(n/4) 纵向分析： 子问题的规模为上一步的1/4 最终问题规模会到达1 （代价:T(1)） 深度为i的结点对应规模为 n/(4^i) 的子问题 所以当触底，子问题规模为1时 ，即 n/(4^i)=1， 递归树有log4(n)+1层（深度为0,1,2…log4(n)） 横向分析： 对于第i层，结点数为3^i 所以对于第i层的代价为 3^i * (n/(4^i))^2 所以对于最后一层，即i=log4(n)，代入即可得 最后一层的代价为 n^log4(3) * T(1) T(1)为常数,n为常数 所以最后一层的代价为theta(n^log4(3)) 经过以上分析，我们可以知道每一层的代价为一个等比级数，用等比级数求和公式即可求出整颗树的总代价。 由于有时候在表示渐进上界的时候并不需要如此严格(精确度不需要这么高），所以可以放缩为比较好处理的级数 3、主方法 主定理(master method)适用于一种形式的递归式 T(n)=aT(n/b)+f(n) （公式比较复杂，等安装了插件之后再写数学表达式，网页不方便表示） 定理的证明：通过三个引理来证明 1*使用递归树求得代价公式（为一个等比级数和与叶结点代价和之和）， 2*考虑f(n)的三种情况，在等比级数上进行变形，推导出简化渐进上界 3*将变形后的等比级数和所求得的简化渐进上界与原来的叶节点代价和相加，得到最终的渐进上界 （具体推导过程略，网站暂时上不方便写太多公式） 主定理对于快速求解非常重要，需要牢记结论","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"图书馆","slug":"日记/图书馆","date":"2018-05-12T06:02:12.000Z","updated":"2019-04-03T04:59:06.000Z","comments":true,"path":"日记/图书馆/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E5%9B%BE%E4%B9%A6%E9%A6%86/","excerpt":"","text":"一个知道自己有多渺小的地方…","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"内部类","slug":"程序语言/内部类","date":"2018-04-17T09:03:00.000Z","updated":"2020-04-25T09:14:09.000Z","comments":true,"path":"程序语言/内部类/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E5%86%85%E9%83%A8%E7%B1%BB/","excerpt":"JAVA内部类","text":"JAVA内部类 内部类对象类型：OuterClassName.InnerClassName 内部类访问外部类 内部类拥有外部类一切元素的访问权。 本质：当某个外部类对象创建了一个内部类对象的时候，此内部类对象必定会秘密地捕获一个指向那个外部类对象的引用，然后在你访问此外部类成员的时候，就是用那个引用来选择外部类成员 对外部类对象的引用可以用OuterClassName.this （在其它地方）告知某外部类去创建其自己的内部类对象：.new语法（易错） 这个方法也适合多重嵌套内部类，.new能限定正确的作用域 //外部类对象outer OuterClassName outer = new OuterClassName(); //【通知外部类对象outer去建立其内部类对象】，注意这里的用法！ OuterClassName.InnerClassName inner = outer.new InnerClassName() 拥有外部类对象之后，才能创建内部类对象 内部类的一大用途：与接口配合使用——工厂方法（内部类Ver.最常用） 阻止任何依赖于类型的代码，并且完全隐藏了实现的细节。我们并不需要知道是什么类实现了接口，我们只要根据接口的描述去使用这个新生成的对象（引用类型为接口类类型）即可，这个对象通过工厂类里的实现了该接口的内部类生成 举例如下：其中有接口Sing和Dance，于是我建立了一个工厂类Factory，在里面通过内部类Singer和Dancer实现了Sing和Dance接口（显然这么设计是因为Singer当然会Sing，只要一个对象满足Sing接口的要求，那它就可以是个Sing接口类型的对象，其子类型为Singer）。然后我在工厂类里提供两个供外部使用的方法createSinger和createDancer，其返回Sing和Dance接口类型的对象，在这里在函数中返回的实际上是接口类型的子类对象Singer和Dancer，于是就经过了自动的向上转型为接口类型。在外部看来，该函数返回的就是符合接口的对象，并不关心也没法知道具体细节，只需要根据接口定义来使用该对象即可。 package aisaka; interface Sing &#123; boolean sound = true; void singing(); &#125; interface Dance &#123; boolean dance = true; void dancing(); &#125; class Factory &#123; //私有内部类，禁止外部访问，实现了Sing接口 private class Singer implements Sing &#123; String name; Singer(String name) &#123; super(); this.name = name; &#125; @Override public void singing() &#123; System.out.println(name + \":A Singer is singing\"); &#125; &#125; //私有内部类，禁止外部访问，实现了Dance接口 private class Dancer implements Dance &#123; String name; Dancer(String name) &#123; super(); this.name = name; &#125; @Override public void dancing() &#123; System.out.println(name + \":A Dancer is dancing\"); &#125; &#125; //提供外部创建符合Sing接口的对象 public Sing createSinger(String name) &#123; return new Singer(name); &#125; //提供外部创建符合Dance接口的对象 public Dance createDancer(String name) &#123; return new Dancer(name); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; Factory factory = new Factory(); Sing singer1 = factory.createSinger(\"世界第一歌手aisaka\"); Dance dancer1 = factory.createDancer(\"世界第一舞者aisaka\"); singer1.singing(); dancer1.dancing(); &#125; &#125; /*OUTPUTS * 世界第一歌手aisaka:A Singer is singing * 世界第一舞者aisaka::A Dancer is dancing */ 不过注意工厂类内的东西不能为static的 更多内部类的使用方法 作用：你要解决一个复杂的问题，想创建一个类来辅助你的解决方案，但是又不希望这个类是公共可用的。 ①局部内部类：定义在 private方法/任意作用域内中 的内部类 注意，公有方法或默认方法中不能定义局部内部类 局部内部类可以访问当前代码块的常量，和外围类的所有成员 ②匿名内部类： 当一个子类继承/实现父类的时候，一种简化不需要给子类命名的一种表达式 注意新建对象的时候就不是写那个继承父类的那个匿名内部类的引用了（因为匿名了，本来也没有），而是写父类对象引用 //将上面的工厂方法中，实现接口的类写作工厂类的匿名内部类 //这里直接在工厂类中的生成对象方法里写内部类，就不需要单独写个内部类实现接口了，而是新建对象的时候直接写在匿名内部类里 public Dance createDancer(String name) &#123; //注意这里是new一个Dance接口类型而不是Dancer实现类型，实际上这里的意思是创建一个继承/实现自Dance的匿名类的对象 return new Dance() &#123; //内部类开始&#123; @Override public void dancing() &#123; System.out.println(\"A Dancer is dancing\"); &#125; &#125;; //内部类结束&#125;; &#125; 匿名内部类不能有构造器； 对于需要构造器的的匿名内部类，a. 对于传参数到构造器：只需要简单地将参数直接传递给基类（父类）构造器即可 b.对于想要在构造器初始化：用初始化块替代 new Dance(x)&#123;内部类&#125;; 但注意，接口没有构造器，所以匿名内部类只有继承的时候才有构造方法，实现接口不能有构造方法！ 显然匿名内部类只能实现一个接口or继承一个类；如果要在同一个类中继承两个类，那就只能通过匿名内部类的方式继承（最多继承一个类，多个接口） 匿名内部类想要使用外部定义对象的时候，需要该参数引用是final的 ③静态内部类（嵌套类）： 如果不需要内部类对象与其外围类对象之间有联系，那么就可以将内部类声明为static，称作嵌套类 要创建静态内部类，不需要先实例化外围类对象！，且静态内部类只能访问外围类对象中的final方法（与静态方法、静态成员一样，都不需要实例化外围类对象） 嵌套类可以放接口中，接口中的任何内部类都是自动public static 内部类是面向对象的闭包 闭包是一个可调用对象，它记录了一些信息，这些信息来源于创建它的作用域。 如上面的工厂方法，工厂类中的新建对象函数返回了一个引用，这就是回调，这个引用就是“钩子”，这个钩子很安全，只能调用其实现的接口给的方法。 根据工厂方法的原理，可以看出回调的价值在于可以在运行时动态地决定调用什么方法 内部类的继承问题 当继承某个外围类的时候，子类中新建一个与父类内部类重名的内部类，这两个内部类是共存的，各自在各自的命名空间互不影响；如果明确直接继承某个内部类，那调用子类的时候就是调用该子类了 内部类的构造器必须连接到指向其外围类对象的引用，所以在继承内部类的时候，导出类不再存在可以连接的默认对象，这时候就需要将外围类对象传入这个子类构造函数中并用outerObject.super()调用其构造器 class WithInner &#123; class Inner &#123;&#125; &#125; public class InheritInner extends WithInner.Inner &#123; //! InheritInner() &#123;&#125; // 这样写就报错了 InheritInner(WithInner wi) &#123; //注意这里，在子类的构造函数中传入了继承内部类的外围类对象 wi.super(); //继承外围类构造器 &#125; public static void main(String[] args) &#123; WithInner wi = new WithInner(); InheritInner ii = new InheritInner(wi); &#125; &#125; 内部类标识符 每个类都会产生.class文件，内部类则WithInner$Inner.class","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"接口","slug":"程序语言/接口","date":"2018-04-17T09:02:51.000Z","updated":"2020-04-25T09:09:15.000Z","comments":true,"path":"程序语言/接口/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E6%8E%A5%E5%8F%A3/","excerpt":"JAVA接口","text":"JAVA接口 接口和内部类为我们提供了一种将接口与现实分离的更加结构化的方法（不像其它语言一样只是概念，而有实际的语法支持结构） 抽象类 关键字：abstract，加在抽象类或抽象方法前：abstract class&#123;&#125;; abstract void(int a)&#123;&#125; 包含抽象方法的类叫抽象类（没有抽象成员变量这种东西），只要包含一个抽象方法，那该类就必须限定为抽象类（写上abstract关键字，否则报错） 抽象方法仅声明方法、没有方法体 抽象类中可以包含非抽象方法 继承抽象类如果不实现所有抽象方法，那么导出类依然是抽象类 抽象类中的成员变量会继承给导出类 不可建立抽象类对象 接口 关键字：interface，与class是不同的东西，替代class关键字：interface ABC&#123;&#125; ①接口导出为具体类叫做“实现”该接口使用implements关键字，一个具体类可以实现多个接口（JAVA中的唯一实现多重继承的方式） ②接口之间（导出为接口）可以继承，使用extends关键字，且接口继承接口可以多重继承 但注意一个类只能继承一个具体类/抽象类 接口中的成员变量会被继承给导出类 接口中所有方法都不能提供方法体（相比抽象类更抽象了，完全抽象），所有方法都是自动abstract的 但有例外：接口中的default方法可以有方法体 default void forEach&#123;xxx&#125; 子类优先继承父类的方法， 如果父类没有相同签名的方法，才继承接口的默认方法 具体类必须实现接口的所有方法；如果不实现所有抽象方法，那么导出类就会是抽象类 接口的设计就可以做到：“你可以用任何你想要的对象来调用我的方法，只要你的对象遵循我的接口”，以Scanner举例，Scanner接受一个Readable接口的实现类对象，只要满足这个接口，那就可以输入进Scanner中，我们在使用键盘输入的时候输入Scanner的就是System.in，它就实现了Readable接口 多重继承 java中一个具体类可以同时继承一个具体类，并实现多个接口 class Hero extends ActionCharacter implements CanFight, CanSwin, CanFly&#123;&#125; （继承需写在前） 使用接口的核心原因：①为了能够向上转型为多个基类类型（以及为此带来的灵活性） 对于接口interface Fruits以及实现该接口的子类Apple,这样引用是OK的：Fruits apple = new Apple();，子类也可以向上转型为接口引用 ②与抽象类一样，防止创建该类的对象，确保仅仅是建立一个接口 如果知道某事物应该成为一个基类，那么第一选择应该是使它成为一个接口 经常某类会继承一个父类（子类is a 父类），并实现若干接口（会打篮球，会跳舞接口，etc，内部有具体的动作方法） 注意权限问题 所有的抽象方法（接口中和抽象类中）的访问权限一定都是public 所以子类在实现该方法的时候，一定要带上public权限关键字！ 因为JAVA中方法和类的默认权限是包访问权限，即本包中的类可以访问，并不是public权限 接口中的成员变量也是自动public的 嵌套接口 接口也可以在一个类中，就像内部类一样，内部类可以实现该内部接口，内部的嵌套接口也必须是public的 工厂方法 在工厂对象上调用创建方法，而该工厂对象将生成接口的某个实现的对象 像一个专门负责生成对象的工厂一样，这个工厂里生成的对象都符合某接口标准 工厂方法可以做到代码与接口的实现分离 工厂类中的方法可以作静态方法，或者使用更加优雅的方式：匿名内部类（只有内部类才可以是静态类） 【接口没有构造器】","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"多态","slug":"程序语言/多态","date":"2018-04-17T09:02:38.000Z","updated":"2020-04-25T09:09:21.000Z","comments":true,"path":"程序语言/多态/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E5%A4%9A%E6%80%81/","excerpt":"JAVA多态","text":"JAVA多态 多态通过分离做什么和怎么做，从另一个角度将接口和实现分离开来，消除类型之间的耦合关系。这改善代码组织结构、可读性、扩展性。 向上转型与向下转型是多态的体现，它允许我们不管子类，编写的代码只与该子类的基类打交道 比如直观地：Fruit apple = new Apple() 绑定 问题：当子类和父类存在同一个方法（接口）时，子类重写父类方法（接口）时候，程序在运行时调用该方法应该调用子类还是父类的该方法？所以我们需要用绑定来确定调用那种方法 定义：将一个方法调用同一个方法主体关联起来称作绑定 前期绑定：在程序执行前进行绑定（若有，由编译器和连接程序进行实现），面向过程语言默认此方式 后期绑定：在运行时根据对象的类型进行绑定，也叫动态绑定或运行时绑定。方法的动态绑定是基于实际的对象类型，而不是它们声明的对象引用类型 Java中所有方法都是通过动态绑定实现多态的，于是我们只需要发送消息给某个对象，让该对象在运行时去判断应该做什么事情，也就是说我们可以通过调用父类引用正确地访问子类方法。然而子类中有而父类中没有的方法无法被调用，因为它标明的是父类引用。 动态绑定具体细节：https://zhuanlan.zhihu.com/p/24317613 可拓展性，减小耦合 即：将改变的事物和未变的事物分离开来，比如乐器都有一个play方法，是不变的；而不同乐器的形状是改变的，这时候就可以设计instrument为piano,violin的基类，只需要将子类引用向上转型为基类引用，统一调用instrument类的play方法即可，以后新添子类也不需要改动基类，只需要创建一个子类新继承自基类即可 只有普通的方法可以动态绑定对象，也就是说只有普通方法调用可以是多态的。成员变量（域）和静态方法都不具备多态性 （TiJ P156） 静态方法是与类，而非与单个对象相关联的，不具备多态性","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"复用类","slug":"程序语言/复用类","date":"2018-04-17T09:02:29.000Z","updated":"2020-06-16T10:12:25.000Z","comments":true,"path":"程序语言/复用类/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E5%A4%8D%E7%94%A8%E7%B1%BB/","excerpt":"JAVA复用类","text":"JAVA复用类 组合、继承、代理 ①组合：在新的类中产生现有类的对象。由于新的类是由现有类的对象所组成。该方法只是复用了现有程序代码的功能，而非它的形式。适合has-a 关系②继承：按照现有的类型来创建新类。无需改变现有类的形式，采用其形式并在其中添加新代码。适合is-a关系 ③代理：为了避免得到新类（继承or组合）的对象中所有的方法都暴露给外界，我们将新类的对象放在一个代理类中定义和初始化，然后设置需要提供给外界的方法和成员。 默认构造器的隐式生成 如果没有自定义构造器，JAVA会生成一个无参数的默认构造器；一旦定义了自定义构造器，JAVA就不会自动生成一个默认构造器 继承：extends 一个子类继承父类，就会继承父类全部protect、public、默认权限的非static方法和成员变量。 （static方法与类绑定，见多态章节） 构造器与继承 构造器实质上是隐式声明的static方法，所以创建子类的时候，构造器不会被继承（否则就乱了，A-B-C，C直接用A的构造器构造出来，不符合设计理念） 但是子类的默认构造器会默认带有一个隐式super()，子类被实例化时会默认调用父类的构造器。 一旦在子类自定义了构造器，JAVA就不会自动生成带有super()默认构造器，所以自定义子类构造器里需要自己手动调用super()方法。此时如果父类构造器带参数，那么就要在子类构造器中使用一样的参数列表（可以添加其他参数），然后调用super(传入父类构造器的参数) 以上的设计解释： 基类的构造器总是在导出类的构造过程中被调用，而且按照继承层次逐渐向上链接，以使每个基类的构造器都能得到调用（执行顺序则为从基类到子类）。这样做是有意义的，因为构造器具有一项特殊任务：检查对象是否被正确地构造。导出类只能访问它自己的成员，不能访问基类的成员（基类成员通常是private类型）。只有基类的构造器才具有恰当的知识和权限来对自己的元素进行初始化。因此，必须令所有构造器都得到调用，否则就不可能正确构造完整对象。这正是编译器要强制每个导出类部分都必须调用构造器的原因。 基类对于一般方法，可以通过super.method()和this.method()分别调用父类/本类中的方法 super代表父类 this代表子类 ①可以通过super.var和this.var分别调用父类/本类中的成员 ②对于一般方法，可以通过super.method()和this.method()分别调用父类/本类中的方法 ③对于构造方法，通过super(参数表)和this(参数表)，分别调用父类/本类的构造方法，且必须写在本构造方法的第一行 写super调用父类构造器的时候只能写该子类的直接父类有的构造器 构造函数调用栈：定义子类的一个对象时，会先调用子类的构造函数，然后在调用父类的构造函数，如果父类函数足够多的话，会一直调用到最终的父类构造函数，函数调用时会使用栈空间，所以按照入栈的顺序，最先进入的是子类的构造函数，然后才是邻近的父类构造函数，最后再栈顶的是最终的父类构造函数，构造函数执行是则按照从栈顶到栈底的顺序依次执行：也就是先执行父类的构造方法，再执行子类的构造方法 而一般方法就不会这样，可以写在方法内任意位置，按照顺序调用即可 一个构造函数只能出现一个this或一个super this和super都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 this是指向本对象的指针, super是一个Java关键字 重载与重写 重载：一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。 重写：重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写！ protected权限修饰符 就类用户而言，这是private的，但对于以下两种情况可以访问 ①保内或包外的继承该类的子类 ②同一包内的类（相当于包含默认权限） 向上转型与向下转型 向上转型 : 将子类引用转换为父类引用的动作 向上转型后,父类只能调用父类方法或者子类重写后的方法,而子类中的单独方法则是无法调用的，父类中被重写的方法也是无法调用的（除非子类用super调用父类方法），因为本质只是引用的转换 其目的只是方便参数统一、有利于程序设计 向下转型 : 通过父类强制转换为子类,从而来调用子类独有的方法 向下转型会自动进行安全性检查，即该类型是否为目标类。向上转型之后再向下转型的对象可以通过安全性检查 体现了多态性，见下一章 final ①修饰类：这个类不能被继承 final类中的成员方法都会被隐式的指定为final方法。（显然地，类都无法被继承了，那方法和成员自然不可能 被子类重写） ②修饰方法：这个方法不能被子类重写 private方法和成员隐式默认为final ③修饰成员变量：必须要赋初始值，且只会被初始化一次，以后不可被修改（即使在同一个类中也不可修改） final成员变量可以①定义处赋初值②定义处不赋初值，在构造器中赋初值 一个static final的成员变量只占据一段不能改变的储存空间，即实质为define一个常量 如果是final引用，代表引用本身（地址值）不可修改，但引用指向的对象是可以修改的 加载子类之前会先加载父类 如果继承关系是A-B-C-D-E，那么就会按照E-D-C-B-A一步一步往回找直到基类，然后再按A-B-C-D-E加载各类 见super的使用那儿，super调用父类构造器必须（默认构造器是隐式的）放在子类构造器第一行，也即是要先执行父类的构造方法，再执行子类的构造方法 重要：构造函数是私有的，构造函数不能被覆盖，不能被继承（重写），但可以被重载（同一个类中同名不同参的构造函数）。只是每一次继承父类的是，子类会默认创建一个无参构造函数，然后可以通过显式调用super(null / parameters)来使用父类构造函数，或者就是调用父类中 已定义的无参构造函数","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"JAVA的两个问题","slug":"程序语言/JAVA的两个问题","date":"2018-04-16T12:53:39.000Z","updated":"2020-06-11T03:41:26.000Z","comments":true,"path":"程序语言/JAVA的两个问题/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98/","excerpt":"今天在写工厂的时候，对于这样一个语句，遇到了两个问题 mom obj = new son(); 以下为源代码 输出的结果为 0 Type son 一、 这就很奇怪了。按照已知知识，mom obj = new son();这句话是在堆上新建一个son类型的对象，然后向上转型为mom类型。此时的obj，既是属于son类型，也属于其基类mom类型。这是java多态性的一个具体体现。对象实体是son类型的，那么我在调用son中的方法test的时候，和输出变量a的时候，理想输出应为","text":"今天在写工厂的时候，对于这样一个语句，遇到了两个问题 mom obj = new son(); 以下为源代码 输出的结果为 0 Type son 一、 这就很奇怪了。按照已知知识，mom obj = new son();这句话是在堆上新建一个son类型的对象，然后向上转型为mom类型。此时的obj，既是属于son类型，也属于其基类mom类型。这是java多态性的一个具体体现。对象实体是son类型的，那么我在调用son中的方法test的时候，和输出变量a的时候，理想输出应为 1 Type son 然而结果却不是。方法调用的是子类的方法，然而成员变量却调用的是基类的变量值。 我又运行了如下代码，更奇怪的事情发生了。 我在son类中加入了一个新方法test2()。在主函数中调用obj中的test2方法。 更奇怪的事情发生了。 为什么编译器不认这个儿子了？ 经过多次测试，和查阅资料，我终于知道了原因。 首先要知道，java中除了static方法和final方法（private方法属于final方法）之外，其他所有的方法否是后期绑定的（动态绑定）。(final可以关闭动态绑定，但实际上，这对性能提升并不大，所以不要试图用final来提升性能，而是根据设计决定是否使用final） 向上转型，在运行时，会遗忘子类对象中与父类对象中不同的方法。也会覆盖与父类中相同的方法–重写。所以obj可以调用的是mom中有的方法，而son中有，mom中却没有的方法，是不能调用的。java 的这种机制遵循一个原则：当超类对象引用变量引用子类对象时,被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法， 但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。 于是我们可以知道，向上转型机制，实际上遗失了子类的成员变量和基类没有的方法。 这就解释了为什么是这样的结果。 二、 在探究这个语句的执行过程的时候，就又引申出了另一个问题。构造器的继承问题。 对于mom obj = new son(); 按照已知知识，mom obj是建立了一个mom类型的引用obj，相当于c中的一个指针。此时由于没有对象实体，其值为null（空指针）。但是当我在执行以下代码的时候，却发生了很奇怪的事情。 对于以下语句 输出结果为 mom son 奇怪了，难道是mom obj这个语句的时候就已经进行了对象的创建和初始化？ 我试了一下，如果只是 那么结果为 说明了mom obj语句并没有创建和初始化对象，只是声明了一个mom类型的引用。 于是我查阅书籍，在《thinking in java》看到了如下几段 “类的代码在初次使用的时候才加载。这通常是指加载发生于创建类的第一个对象之时，但是当访问static域或static方法的时候，也会发生加载（构造器也是static方法，尽管static关键字并没有显示地写出来。因此更准确地讲，类是在其任何static成员被访问的时候加载的。” 所以说实际上， 在加载类的时候，会依次访问加载基类（或叫父类，超类），其中在遇到static对象和代码段的时候，会依程序中的顺序初始化。（而构造器也是static方法，只是没有写出来而已。 所以举例 对继承关系 A-&gt;B-&gt;C-&gt;D 在生成D类对象的时候，会执行构造器且构造器执行顺序为A-&gt;B-&gt;C-&gt;D。 这就解释了为什么是这个结果。","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"初始化与清理","slug":"程序语言/初始化与清理","date":"2018-04-16T09:02:16.000Z","updated":"2020-06-16T10:11:58.000Z","comments":true,"path":"程序语言/初始化与清理/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E6%B8%85%E7%90%86/","excerpt":"JAVA初始化与清理","text":"JAVA初始化与清理 JAVA中的一切事物皆对象 OOP三大特征：封装、继承、多态 程序入口方法也是存在于一个static final类中的 JAVA是静态语言，但也有一些动态特征 初始化顺序：静态块=静态成员&gt;非静态块=非静态成员&gt;构造器调用 （块中的语句在初始化的时候就会被执行，成员在初始化的时候会赋予表达式给的值） Ch.14有更底层解释，JVM有更更底层解 （同级先后由代码先后顺序决定） 于是显然，在基类构造器中调用的方法被导出类重写了的话，那在导出类初始化的时候会以基类的初始化环境来调用该方法，而不是调用导出类重写的方法 数值成员变量赋初值，对象成员变量初始化都是可以写在成员变量定义处的 构造器是一个特殊的静态方法 静态成员变量即类变量，静态方法即类方法，储存在方法区的该类Class对象里","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"多级中文域名解析系统-3","slug":"网络与云/多级中文域名解析系统-3（c语言）","date":"2018-04-05T05:01:20.000Z","updated":"2020-06-28T14:00:45.000Z","comments":true,"path":"网络与云/多级中文域名解析系统-3（c语言）/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E5%A4%9A%E7%BA%A7%E4%B8%AD%E6%96%87%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%B3%BB%E7%BB%9F-3%EF%BC%88c%E8%AF%AD%E8%A8%80%EF%BC%89/","excerpt":"ROOT_DNS根服务器的逻辑代码","text":"ROOT_DNS根服务器的逻辑代码 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #define RRFILE \"RRroot.txt\" int main(int argc, char *argv[]) &#123; char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(ROOT_SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); struct sockaddr_in cli; socklen_t len=sizeof(cli); while(1) &#123; recvfrom(sockfd,recvbuf,sizeof(recvbuf),0,(struct sockaddr*)&amp;cli,&amp;len); printf(\"\\n收到本地服务器请求：\\n\"); //读取，构造包，得到需要找的域名和类型 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); print_header(recv_header); struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(query_section,recvbuf,&amp;recvBufferPointer); print_query_section(query_section); //开始查找与写缓冲 //调用初次搜索函数 int over = firstFindRR(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); //第一次搜索没有查到结果,开始查询下一个该去哪个服务器 if(over==0) &#123; printf(\"\\n本服务器没有找到\\n\"); loopFindNS(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); &#125; //发送 sendto(sockfd,sendbuf,sendBufferPointer,0,(struct sockaddr*)&amp;cli,len); //缓冲区重置 sendBufferPointer=0; recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); &#125; close(sockfd); &#125; DNS1第一级域名解析服务器主逻辑，以下四个中间级服务器逻辑都差不多 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #define SERVER_IP \"127.0.0.4\" #define RRFILE \"RRL1.txt\" int main(int argc, char *argv[]) &#123; char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); struct sockaddr_in cli; socklen_t len=sizeof(cli); while(1) &#123; recvfrom(sockfd,recvbuf,sizeof(recvbuf),0,(struct sockaddr*)&amp;cli,&amp;len); printf(\"\\n收到本地服务器请求：\\n\"); //读取，构造包，得到需要找的域名和类型 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); print_header(recv_header); struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(query_section,recvbuf,&amp;recvBufferPointer); print_query_section(query_section); //开始查找与写缓冲 //调用初次搜索函数 int over = firstFindRR(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); //第一次搜索没有查到结果,开始查询下一个该去哪个服务器 if(over==0) &#123; printf(\"\\n本服务器没有找到\\n\"); loopFindNS(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); &#125; //发送 sendto(sockfd,sendbuf,sendBufferPointer,0,(struct sockaddr*)&amp;cli,len); //缓冲区重置 sendBufferPointer=0; recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); &#125; close(sockfd); &#125; DNS2第二级域名解析服务器主逻辑 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #define SERVER_IP \"127.0.0.5\" #define RRFILE \"RRL2.txt\" int main(int argc, char *argv[]) &#123; char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); struct sockaddr_in cli; socklen_t len=sizeof(cli); while(1) &#123; recvfrom(sockfd,recvbuf,sizeof(recvbuf),0,(struct sockaddr*)&amp;cli,&amp;len); printf(\"\\n收到本地服务器请求：\\n\"); //读取，构造包，得到需要找的域名和类型 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); print_header(recv_header); struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(query_section,recvbuf,&amp;recvBufferPointer); print_query_section(query_section); //开始查找与写缓冲 //调用初次搜索函数 int over = firstFindRR(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); //第一次搜索没有查到结果,开始查询下一个该去哪个服务器 if(over==0) &#123; printf(\"\\n本服务器没有找到\\n\"); loopFindNS(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); &#125; //发送 sendto(sockfd,sendbuf,sendBufferPointer,0,(struct sockaddr*)&amp;cli,len); //缓冲区重置 sendBufferPointer=0; recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); &#125; close(sockfd); &#125; DNS3第三级域名解析服务器主逻辑 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #define SERVER_IP \"127.0.0.6\" #define RRFILE \"RRL3.txt\" int main(int argc, char *argv[]) &#123; char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); struct sockaddr_in cli; socklen_t len=sizeof(cli); while(1) &#123; recvfrom(sockfd,recvbuf,sizeof(recvbuf),0,(struct sockaddr*)&amp;cli,&amp;len); printf(\"\\n收到本地服务器请求：\\n\"); //读取，构造包，得到需要找的域名和类型 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); print_header(recv_header); struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(query_section,recvbuf,&amp;recvBufferPointer); print_query_section(query_section); //开始查找与写缓冲 //调用初次搜索函数 int over = firstFindRR(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); //第一次搜索没有查到结果,开始查询下一个该去哪个服务器 if(over==0) &#123; printf(\"\\n本服务器没有找到\\n\"); loopFindNS(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); &#125; //发送 sendto(sockfd,sendbuf,sendBufferPointer,0,(struct sockaddr*)&amp;cli,len); //缓冲区重置 sendBufferPointer=0; recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); &#125; close(sockfd); &#125; DNS4第四级域名解析服务器主逻辑 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #define SERVER_IP \"127.0.0.7\" #define RRFILE \"RRL4.txt\" int main(int argc, char *argv[]) &#123; char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); struct sockaddr_in cli; socklen_t len=sizeof(cli); while(1) &#123; recvfrom(sockfd,recvbuf,sizeof(recvbuf),0,(struct sockaddr*)&amp;cli,&amp;len); printf(\"\\n收到本地服务器请求：\\n\"); //读取，构造包，得到需要找的域名和类型 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); print_header(recv_header); struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(query_section,recvbuf,&amp;recvBufferPointer); print_query_section(query_section); //开始查找与写缓冲 //调用初次搜索函数 int over = firstFindRR(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); //第一次搜索没有查到结果,开始查询下一个该去哪个服务器 if(over==0) &#123; printf(\"\\n本服务器没有找到\\n\"); loopFindNS(query_section,RRFILE,sendbuf,&amp;sendBufferPointer); &#125; //发送 sendto(sockfd,sendbuf,sendBufferPointer,0,(struct sockaddr*)&amp;cli,len); //缓冲区重置 sendBufferPointer=0; recvBufferPointer=0; memset(sendbuf,0,512); memset(recvbuf,0,512); &#125; close(sockfd); &#125; 参数与设置#define LOCAL_SERVER_IP \"127.0.0.2\"","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[]},{"title":"多级中文域名解析系统-2","slug":"网络与云/多级中文域名解析系统-2（c语言）","date":"2018-04-05T04:53:04.000Z","updated":"2020-06-28T14:00:49.000Z","comments":true,"path":"网络与云/多级中文域名解析系统-2（c语言）/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E5%A4%9A%E7%BA%A7%E4%B8%AD%E6%96%87%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%B3%BB%E7%BB%9F-2%EF%BC%88c%E8%AF%AD%E8%A8%80%EF%BC%89/","excerpt":"LOCAL_DNSlocal DNS作为本地网络中的逻辑核心非常重要","text":"LOCAL_DNSlocal DNS作为本地网络中的逻辑核心非常重要 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include \"defAndTools.h\" #include \"localServer.h\" #define CACHEFILE \"localCache.txt\" int isEnd(struct DNS_Header *header) &#123; if (header->authorNum!=0) return 0; return 1; &#125; int main(int argc, char *argv[]) &#123; //①设置监听 int serverSocket = socket(AF_INET, SOCK_STREAM, 0); //发送缓冲区和接收缓冲区 char sendbuf[512]; char recvbuf[512]; int sendBufferPointer=0; int recvBufferPointer=0; //初始化缓冲区 memset(sendbuf,0,512); memset(recvbuf,0,512); //声明两个套接字sockaddr_in结构体，分别用于客户端和服务器 struct sockaddr_in server_addr; struct sockaddr_in clientAddr; int addr_len = sizeof(clientAddr); int client; //初始化服务器端的套接字 bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_port = htons(SERVER_PORT); server_addr.sin_addr.s_addr = inet_addr(LOCAL_SERVER_IP); //绑定套接字 bind(serverSocket, (struct sockaddr *)&amp;server_addr, sizeof(server_addr)); //设置监听状态 listen(serverSocket, 5); //②循环监听 while(1) &#123; printf(\"监听端口 ： %d\\n\",SERVER_PORT); //调用accept，进入阻塞状态，返回一个client套接字描述符 client = accept(serverSocket, (struct sockaddr*)&amp;clientAddr, (socklen_t*)&amp;addr_len); printf(\"连接成功\\n\"); struct sockaddr_in c; socklen_t cLen = sizeof(c); getpeername(client, (struct sockaddr*) &amp;c, &amp;cLen); printf(\"请求端信息： %s : %d\\n\",inet_ntoa(c.sin_addr),ntohs(c.sin_port)); //对于TCP，先接收一个两字节的包长度 unsigned short recv_length; recv(client,&amp;recv_length,2,0); recv_length = ntohs(recv_length); //接收客户端发来的数据，recv返回值为接收字节数 int dataNum = recv(client,recvbuf,recv_length,0); //③提取recvbuf，构建DNS包 //构造DNS包头部，从缓冲区读取一个DNS头部 struct DNS_Header *client_query_header; client_query_header = malloc(sizeof(DNS_HEAD)); decode_header(client_query_header,recvbuf,&amp;recvBufferPointer); printf(\"\\n请求端信息：\\n\"); print_header(client_query_header); //构造准备发送的DNS头部 struct DNS_Header *query_header; query_header = malloc(sizeof(DNS_HEAD)); memcpy(query_header,client_query_header,sizeof(DNS_HEAD)); query_header->queryNum = 1; //④解析并处理请求 //有多少个请求，就进行几次循环，每个循环完成一次系统运作 for(int i=0;i&lt;client_query_header->queryNum;i++) &#123; //读取解析一个请求部分 struct DNS_Query *client_query_section; client_query_section = malloc(sizeof(DNS_QUERY)); decode_query_section(client_query_section,recvbuf,&amp;recvBufferPointer); printf(\"\\n正在处理第 %d 个请求\\n\",i+1); print_query_section(client_query_section); //判断本地缓存中是否存在 int findInCache = firstFindRR(client_query_section,CACHEFILE,sendbuf,&amp;sendBufferPointer); if (findInCache==1) &#123; printf(\"在本地缓存中找到记录，直接回复请求\\n\"); goto findit; &#125; //本地缓存不存在 char UDPsendbuf[512]; char UDPrecvbuf[512]; int UDPsendBufferPointer=0; int UDPrecvBufferPointer=0; memset(UDPsendbuf,0,512); memset(UDPrecvbuf,0,512); //直接将从客户端接受收的包写入缓冲区 printf(\"\\n发送给根服务器的请求：\\n\"); encode_header(query_header,UDPsendbuf,&amp;UDPsendBufferPointer); print_header(query_header); encode_query_section(client_query_section,UDPsendbuf,&amp;UDPsendBufferPointer); print_query_section(client_query_section); //定义用于接收的结构。由于根服务器必然不可能返回最终结果，所以不需要构造answer struct DNS_Header *recv_header; struct DNS_RR *recv_answer,*recv_authority,*recv_additional; recv_header = malloc(sizeof(DNS_HEAD)); recv_authority = malloc(sizeof(DNS_ResouceRecord)); recv_additional = malloc(sizeof(DNS_ResouceRecord)); //与根服务器建立UDP连接 int sockfd=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(ROOT_SERVER_IP); bind(sockfd,(struct sockaddr*)&amp;addr,sizeof(addr)); //发送 sendto(sockfd,UDPsendbuf,UDPsendBufferPointer,0,(struct sockaddr*)&amp;addr,sizeof(addr)); //接收回复 socklen_t len=sizeof(addr); recvfrom(sockfd,UDPrecvbuf,sizeof(UDPrecvbuf),0,(struct sockaddr*)&amp;addr,&amp;len); //断开 close(sockfd); printf(\"\\n收到根服务器的回复：\\n\"); //从接收缓冲区解析并构造包结构然后打印 decode_header(recv_header,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_header(recv_header); decode_resource_record(recv_authority,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_resource_record(recv_authority); decode_resource_record(recv_additional,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_resource_record(recv_additional); //重置缓冲区 UDPsendBufferPointer=0; UDPrecvBufferPointer=0; memset(UDPsendbuf,0,512); memset(UDPrecvbuf,0,512); //用于计数本次循环是第几级服务器发来的 int count=0; while(isEnd(recv_header)==0) &#123; count++; //向下一个服务器建立UDP连接 int sockfm=socket(AF_INET,SOCK_DGRAM,0); struct sockaddr_in addr; addr.sin_family =AF_INET; addr.sin_port =htons(SERVER_PORT); addr.sin_addr.s_addr=inet_addr(recv_additional->rdata); //recv_additional->rdata即保存着下一个服务器的IP bind(sockfm,(struct sockaddr*)&amp;addr,sizeof(addr)); //重置缓冲区和结构 UDPsendBufferPointer=0; UDPrecvBufferPointer=0; memset(UDPsendbuf,0,512); memset(UDPrecvbuf,0,512); free(recv_header); recv_header = NULL; free(recv_authority); recv_authority = NULL; free(recv_additional); recv_additional = NULL; //直接将从客户端接受收的请求写入发送缓冲区 printf(\"\\n发送给 %d级 服务器的请求：\\n\",count); encode_header(query_header,UDPsendbuf,&amp;UDPsendBufferPointer); print_header(query_header); encode_query_section(client_query_section,UDPsendbuf,&amp;UDPsendBufferPointer); print_query_section(client_query_section); //发送 sendto(sockfm,UDPsendbuf,UDPsendBufferPointer,0,(struct sockaddr*)&amp;addr,sizeof(addr)); //接收回复 len=sizeof(addr); recvfrom(sockfm,UDPrecvbuf,sizeof(UDPrecvbuf),0,(struct sockaddr*)&amp;addr,&amp;len); //断开连接 close(sockfm); //开始处理 printf(\"\\n收到 %d级 服务器发来的回复：\\n\",count); recv_header = malloc(sizeof(DNS_HEAD)); recv_answer = malloc(sizeof(DNS_ResouceRecord)); recv_authority = malloc(sizeof(DNS_ResouceRecord)); recv_additional = malloc(sizeof(DNS_ResouceRecord)); decode_header(recv_header,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_header(recv_header); for(int j=0;j&lt;recv_header->answerNum;j++)&#123; decode_resource_record(recv_answer,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_resource_record(recv_answer); &#125; for(int j=0;j&lt;recv_header->authorNum;j++)&#123; decode_resource_record(recv_authority,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_resource_record(recv_authority); &#125; for(int j=0;j&lt;recv_header->addNum;j++)&#123; decode_resource_record(recv_additional,UDPrecvbuf,&amp;UDPrecvBufferPointer); print_resource_record(recv_additional); &#125; &#125; //UDP请求的循环结束，此时构造得到的结构体已经得到该次请求目标结果，且已经在循环中打印 //将从最终结果服务器返回来的结构写入发送缓冲区，本次循环结束 encode_header(recv_header,sendbuf,&amp;sendBufferPointer); for(int j=0;j&lt;recv_header->answerNum;j++)&#123; encode_resource_record(recv_answer,sendbuf,&amp;sendBufferPointer); //将结果写入cache addRRToCache(recv_answer,\"localCache.txt\"); &#125; for(int j=0;j&lt;recv_header->authorNum;j++)&#123; encode_resource_record(recv_authority,sendbuf,&amp;sendBufferPointer); addRRToCache(recv_authority,\"localCache.txt\"); &#125; for(int j=0;j&lt;recv_header->addNum;j++)&#123; encode_resource_record(recv_additional,sendbuf,&amp;sendBufferPointer); addRRToCache(recv_additional,\"localCache.txt\"); &#125; findit:; //⑤发送缓冲 //发送已准备好的在缓冲区的数据,包总长度即为当下发送缓冲区指针下标 unsigned short send_length = htons(sendBufferPointer); send(client,&amp;send_length,2,0); send(client, sendbuf, sendBufferPointer, 0); //一个请求的解析与回答发送结束,清空发送缓冲区与指针，准备进行下一次发送 sendBufferPointer=0; memset(sendbuf,0,512); &#125; //对一个客户端的所有请求解析结束 close(client); recvBufferPointer=0; memset(recvbuf,0,512); printf(\"连接关闭\\n\"); printf(\"===================================\\n\\n\"); &#125; &#125; ClientClient为本机主逻辑 #include &lt;stdio.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;sys/stat.h> #include &lt;fcntl.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;netinet/in.h> #include &lt;arpa/inet.h> #include &lt;stdint.h> //底层操作 #include \"defAndTools.h\" //本地服务器 #include \"localServer.h\" int main(int argc, char *argv[]) &#123; //容错 for (int i=1;i&lt;=(argc-1)/2;i++) if (strTypeToCode(argv[2*i])==0) &#123; printf(\"类型错误！\\n\"); exit(0); &#125; //①连接本地服务器 初始化TCP连接 int clientSocket = socket(AF_INET, SOCK_STREAM, 0); //发送缓冲和接收缓冲 char sendbuf[512]; char recvbuf[512]; //定义缓冲区指示下标 int sendBufferPointer=0; int recvBufferPointer=0; //清空缓冲区 memset(sendbuf,0,512); memset(recvbuf,0,512); struct sockaddr_in serverAddr; serverAddr.sin_family = AF_INET; serverAddr.sin_port = htons(SERVER_PORT); serverAddr.sin_addr.s_addr = inet_addr(LOCAL_SERVER_IP); //连接服务器 if(connect(clientSocket, (struct sockaddr *)&amp;serverAddr, sizeof(serverAddr))==-1) printf(\"连接失败\\n\"); printf(\"发送信息：\\n\"); //②根据输入内容，准备DNS包，并写入发送缓冲区 //定义DNS头部 struct DNS_Header *query_header; query_header = malloc(sizeof(DNS_HEAD)); //调用函数，填写欲发送的DNS包的头部结构体 unsigned short tag = create_tag(0,0,0,0,0,0,0,0); //argc-1除2即为域名请求的个数，因为每个域名参数后带一个类型 create_query_header(query_header,999,tag,argc/2,0x0000,0x0000,0x0000); //将头部写入缓冲区 encode_header(query_header,sendbuf,&amp;sendBufferPointer); //打印生成的头部 print_header(query_header); //根据运行参数生成一个或多个请求部分并写入缓冲区 for(int i=1;i&lt;=(argc-1)/2;i++) &#123; //填写DNS请求结构，argv[2*i]字符串对应的类型 unsigned short qtype = strTypeToCode(argv[2*i]); unsigned short qclass = 0x0001; struct DNS_Query *query_section; query_section = malloc(sizeof(DNS_QUERY)); create_query_section(query_section,argv[2*i-1],qtype,qclass); encode_query_section(query_section,sendbuf,&amp;sendBufferPointer); print_query_section(query_section); &#125; //③向本地服务器发包 //发送已准备好的在缓冲区的数据,包总长度即为当下发送缓冲区指针下标 unsigned short length = htons(sendBufferPointer); //对于TCP连接，必须先发送一个DNS包总长度，否则wireshark不会识别！ send(clientSocket,&amp;length,2,0); send(clientSocket, sendbuf, sendBufferPointer, 0); //④根据请求数量收包,有多少个请求就会收到多少个DNS包 for(int k=0;k&lt;query_header->queryNum;k++) &#123; unsigned short recv_length; recv(clientSocket,&amp;recv_length,2,0); recv_length = ntohs(recv_length); int dataNum = recv(clientSocket, recvbuf, recv_length, 0); //⑤处理接收到缓冲区的DNS包,从中抽取出需要返还给用户的数据 //构造DNS包头部，从缓冲区读取并填充DNS头部 struct DNS_Header *recv_header; recv_header = malloc(sizeof(DNS_HEAD)); decode_header(recv_header,recvbuf,&amp;recvBufferPointer); printf(\"[回复： %d]\\n\",k+1); print_header(recv_header); struct DNS_RR *recv_answer,*recv_add; //标准回复只可能在answer和addition有值，所以只需要考虑读这两个部分 for(int i=0;i&lt;recv_header->answerNum;i++) &#123; //读取解析打印一个回应部分 recv_answer = NULL; recv_answer = malloc(sizeof(DNS_ResouceRecord)); decode_resource_record(recv_answer,recvbuf,&amp;recvBufferPointer); print_resource_record(recv_answer); &#125; for(int i=0;i&lt;recv_header->addNum;i++) &#123; //读取解析打印一个addition部分 recv_add = NULL; recv_add = malloc(sizeof(DNS_QUERY)); decode_resource_record(recv_add,recvbuf,&amp;recvBufferPointer); print_resource_record(recv_add); &#125; recvBufferPointer=0; memset(recvbuf,0,512); &#125; close(clientSocket); &#125;","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://aisaka.cloud/tags/DNS/"}]},{"title":"多级中文域名解析系统-1（c语言）","slug":"网络与云/中文DNS实现（c语言）","date":"2018-04-05T04:36:41.000Z","updated":"2020-06-28T14:00:24.000Z","comments":true,"path":"网络与云/中文DNS实现（c语言）/","link":"","permalink":"https://aisaka.cloud/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/%E4%B8%AD%E6%96%87DNS%E5%AE%9E%E7%8E%B0%EF%BC%88c%E8%AF%AD%E8%A8%80%EF%BC%89/","excerpt":"Introduce 支持中文域名解析，支持缓存与多请求 遵循RFC1180标准，可被wireshark抓包检测到 本系统包含一个客户端，四个中间多级DNS，一个根DNS，一个本地DNS 难点在于①不用python而使用C语言必须写非常多的底层操作，主要集中在defAndTools库中②DNS请求的逻辑 Project Structure CODES EXPLAINATION defAndTools.h 此包为主要工具包，涉及网络中的核心底层的操作，是主要难点之一 LOCAL_DNS.c 本地DNS服务器核心逻辑，是本网络中的核心部件，是主要难点之一 Client.c 客户端主逻辑 ROOT_DNS.c 根域名解析服务器的逻辑代码 DNS1.c 第一级域名解析服务器主逻辑 DNS2.c 第二级域名解析服务器主逻辑 DNS3.c 第三级域名解析服务器主逻辑 DNS4.c 第四级域名解析服务器主逻辑 localServer.h 本地DNS服务器的参数设置 FILES EXPLAINATION localCache.txt 本地DNS服务器的缓存 RRL1.txt 第一级域名解析服务器的缓存 RRL2.txt 第二级域名解析服务器的缓存 RRL3.txt 第三级域名解析服务器的缓存 RRL4.txt 第四级域名解析服务器的缓存 RRroot.txt 根域名解析服务器的缓存 defAndTools此包为主要工具包，涉及网络中的底层的操作","text":"Introduce 支持中文域名解析，支持缓存与多请求 遵循RFC1180标准，可被wireshark抓包检测到 本系统包含一个客户端，四个中间多级DNS，一个根DNS，一个本地DNS 难点在于①不用python而使用C语言必须写非常多的底层操作，主要集中在defAndTools库中②DNS请求的逻辑 Project Structure CODES EXPLAINATION defAndTools.h 此包为主要工具包，涉及网络中的核心底层的操作，是主要难点之一 LOCAL_DNS.c 本地DNS服务器核心逻辑，是本网络中的核心部件，是主要难点之一 Client.c 客户端主逻辑 ROOT_DNS.c 根域名解析服务器的逻辑代码 DNS1.c 第一级域名解析服务器主逻辑 DNS2.c 第二级域名解析服务器主逻辑 DNS3.c 第三级域名解析服务器主逻辑 DNS4.c 第四级域名解析服务器主逻辑 localServer.h 本地DNS服务器的参数设置 FILES EXPLAINATION localCache.txt 本地DNS服务器的缓存 RRL1.txt 第一级域名解析服务器的缓存 RRL2.txt 第二级域名解析服务器的缓存 RRL3.txt 第三级域名解析服务器的缓存 RRL4.txt 第四级域名解析服务器的缓存 RRroot.txt 根域名解析服务器的缓存 defAndTools此包为主要工具包，涉及网络中的底层的操作 #include &lt;stdio.h> #include &lt;string.h> #include &lt;arpa/inet.h> #include &lt;stdlib.h> #define MAX_SIZE_OF_DOMAIN 100 #define SERVER_PORT 53 #define ROOT_SERVER_IP \"127.0.0.3\" //用于储存域名方便处理的全局变量 char domain_temp[MAX_SIZE_OF_DOMAIN]; typedef struct DNS_Header &#123; unsigned short id; //16位的消息ID标示一次正常的交互，该ID由消息请求者设置，消息响应者回复请求时带上该ID。 unsigned short tag; //tag要拆，并单独写一个生成tag函数 unsigned short queryNum; //标示请求部分的条目数 unsigned short answerNum;//标示响应部分的资源记录数。如果响应消息中没有记录，则设置为0 unsigned short authorNum;//标示权威部分的域名服务器资源记录数。如果响应消息中没有权威记录，则设置为0 unsigned short addNum; //标示额外部分的资源记录数。 &#125;DNS_HEAD; typedef struct DNS_Query &#123; char *name; //请求的域名。 unsigned short qtype; //记录的类型 [A:0x0001] [NS:0x0002] [CNAME:0x0005] [MX:0x000F] unsigned short qclass; //请求的资源记录的类型 一般为[IN:0x0001] &#125;DNS_QUERY; typedef struct DNS_RR &#123; char *name; unsigned short type; //请求的域名 unsigned short _class; //响应的资源记录的类型 一般为[IN:0x0001] unsigned int ttl; //该资源记录被缓存的秒数。 unsigned short data_len; //RDATA部分的长度 unsigned short pre; //MX特有的优先级 Preference char *rdata; //[A:32位的IP地址（4字节）] [CNAME/NS/MX:域名] &#125;DNS_ResouceRecord; typedef struct tag &#123; unsigned short qr; //[1]标示该消息是请求消息（该位为0）还是应答消息（该位为1） unsigned short opcode; //[4]0 QUERY。标准查询 unsigned short aa; //[1]只在响应消息中有效。该位标示响应该消息的域名服务器是该域中的权威域名服务器。因为Answer Section中可能会有很多域名 unsigned short tc; //[1]标示这条消息是否因为长度超过UDP数据包的标准长度512字节，如果超过512字节，该位被设置为1 unsigned short rd; //[1]是否递归查询。1为递归查询 unsigned short ra; //[1]在响应消息中清除并设置。标示该DNS域名服务器是否支持递归查询。 unsigned short z; //[3] 冗余res 0 unsigned short rcode; //[4] 0 成功的响应 &#125;TAG; /***********************缓冲区操作和工具***************************/ /*此函数用于向buffer中写入8bit数据 * *buffer:指向缓冲区 * *bufferPointer:目前已写入的缓冲区最新一位的下一位 * 以下put16bits put32bits同理 */ void put1Byte(char *buffer,int *bufferPointer, char value) &#123; //调整value为网络字节序 value = htons(value); //void *memcpy(void *dest, void *src, unsigned int count); //用于 把资源内存（src所指向的内存区域） 拷贝到目标内存（dest所指向的内存区域）,count为拷贝区域大小. //buffer为缓冲区首地址，bufferPointer为缓冲区已写入下标，此函数参数为指向这两个量的指针，通过传递地址来实现主函数与子函数的实参传递。 //value为欲写入缓冲区的数据(value为8bit) memcpy(buffer + *bufferPointer,&amp;value,1); //缓冲区已写入下标向后移动，使其指向下一次写入时应该写入的位置,*bufferPointer为指针bufferPointer所指地址的内容 *bufferPointer += 1; &#125; void put2Bytes(char *buffer,int *bufferPointer, unsigned short value) &#123; value = htons(value); memcpy(buffer + *bufferPointer,&amp;value,2); *bufferPointer += 2; &#125; void put4Bytes(char *buffer,int *bufferPointer, unsigned int value) &#123; value = htons(value); memcpy(buffer + *bufferPointer,&amp;value,4); *bufferPointer += 4; &#125; //将变长字符串str写入buffer void putDomainName(char *buffer,int *bufferPointer, char *str) &#123; memcpy(buffer + *bufferPointer,str,strlen(str)+1); //末尾0需要一起打印 *bufferPointer += strlen(str)+1; &#125; //从缓冲区取16个位 unsigned short get2Bytes(char *buffer,int *bufferPointer) &#123; unsigned short value; memcpy(&amp;value,buffer + *bufferPointer,2); *bufferPointer += 2; return ntohs(value); &#125; unsigned int get4bits(char *buffer,int *bufferPointer) &#123; unsigned int value; memcpy(&amp;value,buffer + *bufferPointer,4); *bufferPointer += 4; return ntohs(value); &#125; //读取变长字符串str 读取到0即停止 0即为'\\0' //域名不考虑字节序问题 ，也不用考虑编码问题，都是一个字节一个字节读 void getDomainName(char *buffer,int *bufferPointer,int *lengthOfDomain) &#123; int valueWriting=0; while(buffer[*bufferPointer]!=0) &#123; domain_temp[valueWriting] = buffer[*bufferPointer]; valueWriting++; (*bufferPointer)++; &#125; domain_temp[valueWriting] = 0; //末尾为0，写入字符串结束符，方便对字符数组进行字符串操作 (*bufferPointer)++; //缓冲区读写下一位指针指示跳过末尾0 *lengthOfDomain = valueWriting+1; //包含了末尾结束符 &#125; //eg 3www6google3com0 //生成域名编码 //一个UTF8 数字占1个字节。一个UTF8汉字占3个字节 void encode_domain(char* domain) &#123; memset(domain_temp,0,MAX_SIZE_OF_DOMAIN); int valueWriting=0; char *p,*q; q = domain; p = q; char count = 0; while(1) &#123; if((*p=='.')||(*p==0)) &#123; //第一位为count,写入字符串 *(domain_temp+valueWriting)=count; //此处最后一位0的情况写入了 valueWriting += 1; //写入q开始，长度为count的字符串（长度为count) memcpy(domain_temp+valueWriting,q,count); valueWriting += count; //计数清0 count = 0; //如果未读到字符串末尾，将q移动到p+1的位置，重新开始下一轮 if (*p=='.') &#123; q=p+1; p = q; &#125;else break; &#125;else &#123; p++; count++; &#125; &#125; &#125; //解析编码的域名 void decode_domain(char* domain) &#123; memset(domain_temp,0,MAX_SIZE_OF_DOMAIN); int valueWriting = 0; char *p = domain; int count = *p; while(count!=0) &#123; for(int i=0;i&lt;count;i++) &#123; p += 1; domain_temp[valueWriting] = *p; valueWriting++; &#125; if (*(p+1)!=0) &#123; domain_temp[valueWriting] = '.'; valueWriting++; &#125; p += 1; count = *p; &#125; domain_temp[valueWriting]=0; &#125; //OPCODE、Z、RCODE不用管，无论输入什么都为0。其他都是单位的 unsigned short create_tag(unsigned short qr,unsigned short opcode,unsigned short aa,unsigned short tc,unsigned short rd,unsigned short ra,unsigned short z,unsigned short rcode) &#123; unsigned short tag = 0; if (qr==1) tag = tag | 0x8000; if (aa==1) tag = tag | 0x0400; if (tc==1) tag = tag | 0x0200; if (rd==1) tag = tag | 0x0100; if (ra==1) tag = tag | 0x0080; return tag; &#125; //类型的名字与编码的转换 unsigned short strTypeToCode(char* type) &#123; if (strcmp(type,\"A\")==0) return 0x0001; if (strcmp(type,\"NS\")==0) return 0x0002; if (strcmp(type,\"CNAME\")==0) return 0x0005; if (strcmp(type,\"MX\")==0) return 0x000F; return 0; &#125; char* codeTypeToStr(unsigned short num) &#123; if (num==0x0001) return \"A\"; if (num==0x0002) return \"NS\"; if (num==0x0005) return \"CNAME\"; if (num==0x000F) return \"MX\"; return \"ERROR\"; &#125; /***********************DNS头部操作***************************/ /* *此函数用于填充客户端发送请求的dns包的头部 */ void create_query_header(struct DNS_Header *query_header,unsigned short id,unsigned short tag,unsigned short queryNum,unsigned short answerNum,unsigned short authorNum,unsigned short addNum) &#123; query_header->id = id; query_header->tag = tag; query_header->queryNum = queryNum; query_header->answerNum = answerNum; query_header->authorNum = authorNum; query_header->addNum = addNum; &#125; /*此函数用于将已经填充好的dns头部结构体的成员依次写入buffer * *header: 指向已填充好的dns头部结构体的指针 * *buffer: 指向缓冲区 * *bufferPointer: 目前已写入的缓冲区最新一位的下一位 */ void encode_header(struct DNS_Header *header,char *buffer,int *bufferPointer) &#123; put2Bytes(buffer,bufferPointer,header->id); put2Bytes(buffer,bufferPointer,header->tag); put2Bytes(buffer,bufferPointer,header->queryNum); put2Bytes(buffer,bufferPointer,header->answerNum); put2Bytes(buffer,bufferPointer,header->authorNum); put2Bytes(buffer,bufferPointer,header->addNum); &#125; void decode_header(struct DNS_Header *header,char *buffer,int *bufferPointer) &#123; header->id=get2Bytes(buffer,bufferPointer); header->tag=get2Bytes(buffer,bufferPointer); header->queryNum=get2Bytes(buffer,bufferPointer); header->answerNum=get2Bytes(buffer,bufferPointer); header->authorNum=get2Bytes(buffer,bufferPointer); header->addNum=get2Bytes(buffer,bufferPointer); &#125; void print_header(struct DNS_Header *query_header) &#123; printf(\"[DNS HEADER]\\n\"); printf(\"ID : %d\\n\",query_header->id); printf(\"TAG : 0x%x\\n\",query_header->tag); printf(\"QueryNum : %d\\n\",query_header->queryNum); printf(\"AnswerNum : %d\\n\",query_header->answerNum); printf(\"AuthorNum : %d\\n\",query_header->authorNum); printf(\"AddNum : %d\\n\",query_header->addNum); &#125; /***********************DNS请求部分操作***************************/ /* *生成DNS包的请求部分 */ void create_query_section(struct DNS_Query *query_section,char* domain_name, unsigned short qtype, unsigned short qclass) &#123; int domain_length = strlen(domain_name); query_section->name = malloc(domain_length+1); memcpy(query_section->name,domain_name,domain_length+1); query_section->qtype = qtype; query_section->qclass = qclass; &#125; /* *将已经填充好的dns的一个请求结构体的成员依次写入buffer(调用一次该函数只写入一个请求 */ void encode_query_section(struct DNS_Query *query_section,char *buffer,int *bufferPointer) &#123; //先计算用decodeDomain得到字符串 //再用strlen计算字符串长度为点语法name长度+2（头尾多了一个数字） //再发送 char *domain_name; int lengthOfEncodedDomain = strlen(query_section->name)+2; domain_name = malloc(lengthOfEncodedDomain); encode_domain(query_section->name); memcpy(domain_name,domain_temp,lengthOfEncodedDomain); putDomainName(buffer,bufferPointer,domain_name); put2Bytes(buffer,bufferPointer,query_section->qtype); put2Bytes(buffer,bufferPointer,query_section->qclass); &#125; /* *解析请求部分。解析即为将缓冲区的字节流提取，转码，生成对应的结构体 */ void decode_query_section(struct DNS_Query *query_section,char *buffer,int *bufferPointer) &#123; //从缓冲区读出编码过的域名 char* domain_name = malloc(MAX_SIZE_OF_DOMAIN); memset(domain_name,0,MAX_SIZE_OF_DOMAIN); int lengthOfDomain=0; getDomainName(buffer,bufferPointer,&amp;lengthOfDomain); memcpy(domain_name,domain_temp,lengthOfDomain); //解码域名 decode_domain(domain_name); memcpy(domain_name,domain_temp,strlen(domain_name)); query_section->name = domain_name; query_section->qtype = get2Bytes(buffer,bufferPointer); query_section->qclass = get2Bytes(buffer,bufferPointer); &#125; void print_query_section(struct DNS_Query *query_section) &#123; printf(\"[DNS QUERY]\\n\"); printf(\"Name : %s\\n\",query_section->name); printf(\"Type : %s\\n\",codeTypeToStr(query_section->qtype)); printf(\"Class : IN\\n\"); &#125; /***********************DNS RR操作和RR文件解析操作***************************/ //生成resource record记录 void create_resource_record(struct DNS_RR *resource_record,char* name, unsigned short type, unsigned short _class, unsigned int ttl, unsigned short pre,char *rdata) //data_len不用输入 &#123; //unsigned short pre为一个MX类型特有的优先级，定长，只有MX类型发送。 int domain_length = strlen(name); //易错点：strlen只读到0但不包含0，所以为了把结束符也复制进去，长度要+1 resource_record->name = malloc(domain_length+1); memcpy(resource_record->name,name,domain_length+1); resource_record->type = type; resource_record->_class = _class; resource_record->ttl = ttl; //data_len if (type==0x0001) resource_record->data_len=4; //对于IP，长度为4 data_len是编码后的长度，length是非编码长度，注意 else resource_record->data_len = strlen(rdata) + 2; //对于域名，生成data_len包含末尾结束符（域名末尾结束符） //pre if (type==0x000F) &#123; resource_record->pre = pre; resource_record->data_len += 2; //对于邮件类型，由于有pre的存在，多占两个字节 &#125; //char* rdata int rdata_length = strlen(rdata); //要加上末尾结束符 resource_record->rdata = malloc(rdata_length+1); memcpy(resource_record->rdata,rdata,rdata_length+1); &#125; //编码resource record记录，编码即为将结构体的内容编码，处理为字节流，写入缓冲区 void encode_resource_record(struct DNS_RR *resource_record,char *buffer,int *bufferPointer) &#123; char *domain_name; int lengthOfEncodedDomain = strlen(resource_record->name)+2; domain_name = malloc(lengthOfEncodedDomain); encode_domain(resource_record->name); memcpy(domain_name,domain_temp,lengthOfEncodedDomain); putDomainName(buffer,bufferPointer,domain_name); put2Bytes(buffer,bufferPointer,resource_record->type); put2Bytes(buffer,bufferPointer,resource_record->_class); put4Bytes(buffer,bufferPointer,resource_record->ttl); put2Bytes(buffer,bufferPointer,resource_record->data_len); if (resource_record->type==0x000F) put2Bytes(buffer,bufferPointer,resource_record->pre); //如果类型为A，发送的是IP，将IP写入缓冲区 if(resource_record->type == 0x0001) &#123; //不能调用get put函数，因为inet_addr自带字节序变换功能 unsigned int rdata = inet_addr(resource_record->rdata); memcpy(buffer + *bufferPointer,&amp;rdata,4); *bufferPointer += 4; &#125;else&#123; //如果类型为MX、CNAME、NS //则发送的是域名，则调用域名编码 char *rdata; int lengthOfEncodedDomain2 = strlen(resource_record->rdata)+2; rdata = malloc(lengthOfEncodedDomain2); encode_domain(resource_record->rdata); memcpy(rdata,domain_temp,lengthOfEncodedDomain2); putDomainName(buffer,bufferPointer,rdata); &#125; &#125; //解析resource record记录 void decode_resource_record(struct DNS_RR *resource_record,char *buffer,int *bufferPointer) &#123; //从缓冲区读出编码过的域名 char* domain_name = malloc(MAX_SIZE_OF_DOMAIN); memset(domain_name,0,MAX_SIZE_OF_DOMAIN); int lengthOfDomain=0; getDomainName(buffer,bufferPointer,&amp;lengthOfDomain); memcpy(domain_name,domain_temp,lengthOfDomain); //解码域名 decode_domain(domain_name); memcpy(domain_name,domain_temp,strlen(domain_name)); resource_record->name = domain_name; resource_record->type = get2Bytes(buffer,bufferPointer); resource_record->_class = get2Bytes(buffer,bufferPointer); resource_record->ttl = get4bits(buffer,bufferPointer); resource_record->data_len = get2Bytes(buffer,bufferPointer); if (resource_record->type==0x000F) resource_record->pre = get2Bytes(buffer,bufferPointer); //如果发送的是IP（类型为A），则读出IP 。 不能采用get put方法，因为inet_ntoa方法已经更换字节序 if(resource_record->type == 0x0001) &#123; unsigned int rdata; memcpy(&amp;rdata,buffer + *bufferPointer,4); *bufferPointer += 4; struct in_addr in; memcpy(&amp;in, &amp;rdata, 4); resource_record->rdata = malloc(MAX_SIZE_OF_DOMAIN); char *temp = inet_ntoa(in); memcpy(resource_record->rdata,temp,strlen(temp)+1); //+1是为了包含末尾0 &#125;else&#123; //如果发送的是域名，则调用域名解码（类型为CNAME NS MX） //从缓冲区读出编码过的域名 char* rdata = malloc(MAX_SIZE_OF_DOMAIN); int lengthOfDomain2=0; getDomainName(buffer,bufferPointer,&amp;lengthOfDomain2); memcpy(rdata,domain_temp,lengthOfDomain2); //解码域名 decode_domain(rdata); memcpy(rdata,domain_temp,strlen(rdata)); resource_record->rdata = rdata; &#125; &#125; void print_resource_record(struct DNS_RR *resource_record) &#123; printf(\"[RESOURCE RECORD]\\n\"); printf(\"Name : %s\\n\",resource_record->name); printf(\"Type : %s\\n\",codeTypeToStr(resource_record->type)); printf(\"Class : IN\\n\"); printf(\"TTL : %d\\n\",resource_record->ttl); printf(\"Data_Len : %d\\n\",resource_record->data_len); if (resource_record->type==0x000F) printf(\"Preference : %d\\n\",resource_record->pre); printf(\"IP|DOMAIN : %s\\n\",resource_record->rdata); printf(\"===================================\\n\"); &#125; //砍掉一个域名第一个.之前的部分,如果已经是最后一节，指向域名的指针指向NULL void cut(char** domainPointer) //这里传入的是 指向指向域名的指针的指针 &#123; while(1) &#123; (*domainPointer)++; if (**domainPointer=='.') &#123; (*domainPointer)++; break; &#125; if (**domainPointer==0) &#123; *domainPointer = NULL; break; &#125; &#125; &#125; /***********************文件读写***************************/ //将RR写进cache文件里 void addRRToCache(struct DNS_RR *resource_record, char* cacheFile) &#123; FILE *RR = fopen(cacheFile, \"a+\"); fprintf(RR,\"%s \",resource_record->name); fprintf(RR,\"%d \",resource_record->ttl); fprintf(RR,\"IN \"); fprintf(RR,\"%s \",codeTypeToStr(resource_record->type)); fprintf(RR,\"%s\\n\",resource_record->rdata); fclose(RR); &#125; //第一次在RR文件里扫描 （初次搜索函数） //如果找到了，返回1，且encode进buffer int firstFindRR(struct DNS_Query *query_section,char *RRDOCUMENT,char *buffer,int *bufferPointer) &#123; int over = 0; FILE *RR = fopen( RRDOCUMENT, \"r\" ); //定义一个RR结构体用来储存从文件中读入的一条RR struct DNS_RR *fileRR; fileRR = malloc(sizeof(DNS_ResouceRecord)); memset(fileRR,0,sizeof(DNS_ResouceRecord)); fileRR->name=malloc(MAX_SIZE_OF_DOMAIN); fileRR->rdata=malloc(MAX_SIZE_OF_DOMAIN); //第一次搜索 while(fscanf(RR,\"%s \",fileRR->name)!=EOF) &#123; fscanf(RR,\"%d\",&amp;fileRR->ttl); char type[10],_class[10]; fscanf(RR,\"%s \",_class); fscanf(RR,\"%s \",type); fileRR->type = strTypeToCode(type); fscanf(RR,\"%s\\n\",fileRR->rdata); if((strcmp(query_section->name,fileRR->name)==0) &amp;&amp; (query_section->qtype==fileRR->type)) &#123; printf(\"\\n发送回复：\\n\"); //生成answer RR create_resource_record(fileRR,fileRR->name, fileRR->type, 0x0001, fileRR->ttl, 0x0000,fileRR->rdata); //生成头 struct DNS_Header *header; header = malloc(sizeof(DNS_HEAD)); unsigned short tag = create_tag(1,0,1,0,0,0,0,0); if (strcmp(type,\"MX\")==0) create_query_header(header,0x1235,tag,0,1,0,1); else create_query_header(header,999,tag,0,1,0,0); //将头和answer encode进buffer encode_header(header,buffer,bufferPointer); print_header(header); encode_resource_record(fileRR,buffer,bufferPointer); print_resource_record(fileRR); over=1; break; &#125; &#125; //读指针回到开头 fseek(RR,0,0); //对于MX类型，特殊，需要再搜索一遍，搜索到的邮件服务器域名的IP，并写入addition RR中发送 if ((fileRR->type==0x000F)&amp;&amp;(over==1)) &#123; struct DNS_RR *addFileRR; addFileRR = malloc(sizeof(DNS_ResouceRecord)); addFileRR->name=malloc(MAX_SIZE_OF_DOMAIN); addFileRR->rdata=malloc(MAX_SIZE_OF_DOMAIN); while(fscanf(RR,\"%s \",addFileRR->name)!=EOF) &#123; fscanf(RR,\"%d \",&amp;addFileRR->ttl); char type[10],_class[10]; fscanf(RR,\"%s \",_class); fscanf(RR,\"%s \",type); addFileRR->type = strTypeToCode(type); fscanf(RR,\"%s\\n\",addFileRR->rdata); if(strcmp(fileRR->rdata,addFileRR->name)==0) &#123; printf(\"邮件服务器：\\n\"); //生成addition RR create_resource_record(addFileRR,fileRR->rdata, 1, 1, fileRR->ttl, 0, addFileRR->rdata); encode_resource_record(addFileRR,buffer,bufferPointer); print_resource_record(addFileRR); break; &#125; &#125; &#125; fclose(RR); return over; &#125; void loopFindNS(struct DNS_Query *query_section,char *RRDOCUMENT,char *buffer,int *bufferPointer) &#123; FILE *RR = fopen( RRDOCUMENT, \"r\" ); cut(&amp;query_section->name); //剪掉首段地址，进行第二次搜索 while(query_section->name!=NULL) &#123; fseek(RR,0,0); struct DNS_RR *nextRR; nextRR = malloc(sizeof(DNS_ResouceRecord)); nextRR->name=malloc(MAX_SIZE_OF_DOMAIN); nextRR->rdata=malloc(MAX_SIZE_OF_DOMAIN); while(fscanf(RR,\"%s \",nextRR->name)!=EOF) &#123; fscanf(RR,\"%d \",&amp;nextRR->ttl); char type[10],_class[10]; fscanf(RR,\"%s \",_class); fscanf(RR,\"%s \",type); nextRR->type = strTypeToCode(type); fscanf(RR,\"%s\\n\",nextRR->rdata); if(strcmp(query_section->name,nextRR->name)==0) &#123; printf(\"\\n下一级服务器信息：\\n\"); //生成头 struct DNS_Header *header; header = malloc(sizeof(DNS_HEAD)); unsigned short tag = create_tag(1,0,1,0,0,0,0,0); create_query_header(header,999,tag,0,0,1,1); encode_header(header,buffer,bufferPointer); print_header(header); //生成authority RR NS记录type=2 此时query_section->name经过cut后已经变成了下一个要去的DNS服务器域名 struct DNS_RR *authRR; authRR = malloc(sizeof(DNS_ResouceRecord)); create_resource_record(authRR, query_section->name, 2, 1, nextRR->ttl, 0, query_section->name); encode_resource_record(authRR,buffer,bufferPointer); print_resource_record(authRR); //生成additon RR A记录type=1 struct DNS_RR *addRR; addRR = malloc(sizeof(DNS_ResouceRecord)); create_resource_record(addRR, query_section->name, 1, 1, nextRR->ttl, 0, nextRR->rdata); encode_resource_record(addRR,buffer,bufferPointer); print_resource_record(addRR); goto out; &#125; &#125; cut(&amp;query_section->name); &#125; out: fclose(RR); &#125;","categories":[{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://aisaka.cloud/tags/DNS/"}]},{"title":"2018","slug":"日记/2018","date":"2017-12-31T16:22:20.000Z","updated":"2019-04-03T04:57:37.000Z","comments":true,"path":"日记/2018/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/2018/","excerpt":"","text":"呼，又一年过去了。 愿望实现了吗？努力了吗？坚持希望了吗？有未来吗？","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"操作系统与计算机网络","slug":"计算机理论/操作系统与计算机网络","date":"2017-11-05T12:39:44.000Z","updated":"2020-09-10T09:09:23.000Z","comments":true,"path":"计算机理论/操作系统与计算机网络/","link":"","permalink":"https://aisaka.cloud/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"操作系统进程线程调度略 内存管理CPU查找一个数据，先进行逻辑地址翻译成物理地址（先查缓存中的快表TLB有无记录，若无，去主存中的页/段表查） TLB or 主存中最终查得到目标页面的物理地址和该页面是否被调入内存（虚拟内存机制），如果没有调入内存，则产生缺页中断（中断处理将该页面调入内存） 这里获取到物理地址，并确定目标页在内存中之后，就应该通过物理地址去获取数据了。（先查缓存cache中是否存有该物理地址对应的页面，如果没有，再去指定地址的主存查找） 最多要访问两次主存 总体来说就是：逻辑地址-&gt;物理地址，（考虑虚拟内存机制），物理地址-&gt;访问数据 文件系统FCB文件控制块 目录结构 硬链接接指针指向目标文件 软链接记录目标文件的路径 访问控制表 文件物理地址分配： 连续分配 链接分配（隐式链接：一个串一个；显式链接：一个FAT文件分配表记录所有链接，FAT在磁盘中只有一张，可以加载进内存，每个表项存放对应块的下一块连接指针） P.S. FAT32中表示文件大小的那个变量是4个字节，也就是32位表示，所以最大支持4G 索引分配（每个文件都有索引块储存在外存，所以需要IO两次或多次（若为多级索引）） 文件储存空间管理（物理块是否空闲分配）： 空闲表法、空闲链表法、位视图法 磁盘： 一个盘面很多磁道，一个磁道划分成固定大小的几百个扇区（通常512B），一个扇区叫一个盘块 扇区是最小可寻址单元 簇是根据不同的文件系统决定的，可以1KB 2KB 4KB等，是每次读写数据时的最小单位 而文件物理地址分配的时候，分配的是簇（因为是读写最小单位），比如FAT里一个表项是一个簇 磁盘调度算法：FCFS、SSTF（最短寻找时间）、SCAN（电梯）、CSCAN（循环） IO程序直接控制方式：CPU阻塞等待IO数据 中断驱动方式：IO使用中断通知CPU数据好了 DMA：IO与内存直接交换数据，CPU只在开始和结束做点微小的工作 SPOOLing假脱机：提高IO速度，将独占设备改造为共享设备，实现虚拟设备等（实际上就是把需要打印机要打印的东西先拷到磁盘中，然后挂载到打印机等待队列上，等资源有了就打印） 计算机网络从高层向下逐层封装，然后到最底层实际通过物理层发送 物理层①物理层（原生bit流）： 工作设备：中继器，集线器 数据链路层②数据链路层（帧）：差错控制（确认、超时重传）。流量控制、传输管理；提供点到点通信（点：一个硬件或IP地址）分为MAC（介质访问控制子层）和逻辑链路控制子层 PPP HDLC；工作设备： 网桥、交换机（帧转发），网卡 网卡存在一个唯一的代码：MAC（介质访问控制）地址，也叫物理地址 重传：回退N帧重传（只收顺序帧）；回退N帧缓存窗口只重传丢弃；窗口外丢弃；收一个ACK一个 控制介质访问：ALOHA；间隙ALOHA；CSMA/CD；CSMA/CA(无线) 当数据经过网络层分组转发到达LAN之后，LAN中是在数据链路层MAC地址寻址（具体见网络层的ARP） 网络层③网络层（数据报）：流量控制、拥塞控制、差错控制、网际互联、路由选择&lt;-路由器（路由选择、分组转发） IP ICMP ARP RARP OSPF 路由算法：1距离向量（RIP，每个结点仅与它的直接邻居交谈；30秒固定更新；有最高跳数，超出即不可达，以防止环路） 2链路状态（OSPF，每个结点都具有完全的网络拓扑信息，每个结点向所有结点广播，但仅广播与它直接相连的链路的费用，然后问题变成了最短路径问题，使用Dijkstra算法；链路每变化一次就更新，重新计算最小路径） 层次路由：通过层次路由，将互联网划分为很多自治系统，每个自治系统AS（AS内部有很多个路由器，可以由多个局域网组成）自己决定域内的路由选择协议（如RIP、OSPF），对于域外交流，需要用到BGP协议（应用层协议，基于TCP）（一种外部网关协议，用在互联网的网关之间，每个AS选出一个BGP发言人，与其它AS的BGP发言人TCP交换路由信息） 由于链路层数据报有最大传送单元MTU限制，所以IP数据报过大会被分装在多个小的IP数据报中（称为片），然后再在目的地的网络层被重新组装 路由表中的每一行：&lt;目的IP地址，子网掩码，下一跳地址&gt; 分组转发过程：①从数据报首部获取目标主机IP，得到目标网络地址 ②对与路由器直接相连的网络逐个排查，用子网掩码与IP按位与，看结果是否和相应的网络地址相匹配，若匹配则直接交付③若路由表中有目的地址的主机路由，则将数据报传送给该路由④对路由表中每一行的子网掩码和目的IP按位与得到目标网络地址，若与该行的目的IP地址相同，则传送给下一跳路由器⑤若有默认路由，则传给默认路由器⑥出错 注意：得到下一跳路由器的IP地址并不是直接将该地址填入待发送的数据报，而是将IP地址转换成MAC地址（荣国ARP），将其放在MAC帧首部中，然后根据这个MAC地址找到下一跳路由器（链路层）。在不同网络中传送时，MAC帧中的源地址和目的地址要发生变化，但是最终目的IP地址是不会变的。 网络地址转换NAT：通过将专用网络地址（如本地局域网）转换为公用网络地址，从而对外部隐藏内部管理的IP地址 局域网内不需要路由器，因为只有广域网才需要路由转发功能。局域网使用的协议主要工作在数据链路层，广域网使用的协议主要工作在网络层。一个局域网连接进广域网就需要路由器。 IP地址： 分为&lt;网络号，主机号&gt; 网络号首部为标志位（ABCDE类网络） 主机号全为0表示本网络本身，如202.98.174.0 127.0.0.1为回环地址，永远不会出现在网络上（不会被转发出去） 0.0.0.0表示本网络上的本主机 255.255.255.255表示本网络的广播地址 路由器对广播域有隔离作用 子网划分： 不划分子网，即一台机器一个物理地址会使得路由表太大 所以变成：&lt;网络号，子网号，主机号&gt; + 子网掩码 路由交换的时候必须告知子网掩码 网络变成三级结构了 软件实现，将子网掩码与IP地址按位与就可以得到子网地址 CIDR（无分类域间路由选择）：灵活划分子网，可以实现路由聚合，构成超网 表示法：&lt;网络前缀，主机号&gt;/前缀所占比特数，如206.1.0.0/17 仍然有掩码一词，网络前缀-网络号即为人为划分子网数 ARP：每台主机都有一个ARP缓存。主机A欲向本局域网的某主机B发送IP数据报，就先在ARP缓存中查看是否有误主机B的IP地址，若有，则直接查出B的MAC地址。若没有，就通过使用目的MAC地址为FFFFFFFFFFFF的帧来封装并广播ARP请求分组，同一个局域网内的主机B收到ARP请求后，向主机A发送响应ARP分组，包含MAC地址。 主机A收到后写缓存，并向目的MAC地址的硬件发送MAC帧。 ICMP：ICMP是网络层协议！它可以让主机或路由器报告差错和异常情况。分为ICMP差错报告报文、ICMP询问报文； PING工作在应用层，直接使用网络层的ICMP，不使用TCPUDP Traceroute/Tracert（跟踪分组路过的路由）工作在网络层，使用ICMP 组播：只发一份，分叉（路由）复制 局域网内不需要网络层的分组转发，直接用交换机即可（数据链路层）；公网就需要网络层分组转发、路由选择，需要路由器（网络层） 传输层④传输层：屏蔽下层通信子网；为端到端提供可靠的传输服务、流量控制、差错控制、服务质量、数据传输管理等 TCP UDP；提供端到端的逻辑通信（端：运行在主机上的进程，一个进程由一个端口标识，所以叫端） 套接字是一个通信端点： TCP：面向连接，可靠 UDP：无连接，非可靠（UDP也要校验，有差错就丢弃） TCP如何做到可靠传输：校验、序号（保证有序）、确认号（标明希望下一个报文段的序号，累计确认至第一个断序处）、重传（超时重传、冗余ACK确认可以快速重传） TCP流量控制：滑动窗口，每次可以动态要求窗口大小 TCP拥塞控制（防止过多数据注入，以免网络中的路由器或链路过载，一般表现为超时）：[慢开始算法、拥塞避免算法]（慢开始窗口从1开始，倍数增大，到一个门限改用拥塞避免算法，窗口加法增大，第一次超时，窗口变为1，门限减半）、[快重传、快恢复]（快重传指收到3个ACK就认为超时，这时候以门限/2为窗口大小开始发包，直接进入拥塞避免状态）（慢开始和快重传都指的是拥塞/超时从什么时候开始，从1窗口开始是慢开始，从门限开始是快重传，门限都会减半） 一旦发现拥塞，缩小窗口/减少主机发送分组数 关于三次握手四次挥手（非常重要，但这里不解释） 三次挥手的原因： 如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。 应用层⑤应用层（会话层、表示层、应用层） 会话层：不同主机的各个进程之间进行有序的会话，也叫建立同步 表示层：提供数据表示的变换功能 应用层：用户与网络的解谜，如FTP，DNS，SMTP，HTTP，DHCP，BGP DHCP：基于UDP；往返共四次，都是广播，前面先确认，后面再发送。某计算机启动，①向本地网络广播DHCP发现报文，②只有DHCP服务器才能回复该报文，DHCP先在数据库查找该计算机配置信息，找不到就在IP池中取一个地址，然后将信息广播，DHCP回复称为提供报文（也是广播）③计算机如果接受该配置信息，就通过广播发送DHCP请求报文确认④DHCP广播DHCP确认报文，将该IP地址分配给计算机","categories":[{"name":"计算机理论","slug":"计算机理论","permalink":"https://aisaka.cloud/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"递归算法设计","slug":"算法与数据结构/递归算法设计","date":"2017-10-19T11:30:23.000Z","updated":"2018-11-06T05:33:05.000Z","comments":true,"path":"算法与数据结构/递归算法设计/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/","excerpt":"一、递归算法设计 设计一个递归算法，先要搞清楚最基本的模型 先考虑最小模型（最基本模型）应该如何操作 写出基本模型和递推式之后，再确定参数传递 其中注意抓住（单或多）入口与（单或多）出口 进入入口之后就不要管其中间过程，将他们视为整体，转而去出口语句处，思考对最小单元执行什么内容，判断是否出栈。","text":"一、递归算法设计 设计一个递归算法，先要搞清楚最基本的模型 先考虑最小模型（最基本模型）应该如何操作 写出基本模型和递推式之后，再确定参数传递 其中注意抓住（单或多）入口与（单或多）出口 进入入口之后就不要管其中间过程，将他们视为整体，转而去出口语句处，思考对最小单元执行什么内容，判断是否出栈。 （即只管整体（入栈）与最小单元（出栈口判断与操作）） （这时候结合二叉树递归遍历就很好理解。 对于栈底，先遍历左子树，然后第二条语句执行时，第一条语句遍历左子树已经执行结束，也就是说对于栈底层来说，左子树已经完全遍历结束 这对于每一个中间节点都是成立的，我们只需要考虑当层，不用管中间过程，这个中间过程就是递归，我们在设计最小单元、入口出口的时候就已经设计好了） 二、递归大体等效为两种 一种等效于正向循环（直到不满足前一直执行），另一种回溯（直到满足条件再反向执行） 这取决于执行体相对于递归语句的位置 递归思想在树与图中应用广泛，可以说是重要爆了 设计算法要充分发掘隐含实际情况的隐含特性 TBC.","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"JAVA异常处理","slug":"程序语言/JAVA异常处理","date":"2017-07-11T03:40:26.000Z","updated":"2020-06-16T10:51:11.000Z","comments":true,"path":"程序语言/JAVA异常处理/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","excerpt":"JAVA异常处理的设计思路java的设计思想里是尽量在代码运行前就手动检查代码(try、throw等工具)所有可能错误，也就是检查异常 （区分编译错误，那个由程序编译时自动检查，是不一样的东西） 但是有些异常是没法在运行前检查的，如RuntimeException（比如其子类异常：除0错，越界错），所以没办法，才是非检查异常（且这些错误全部都检查的话程序也太臃肿了）（Error也属于非检查异常）非检查异常属于JVM会自动默认直接抛出，不处理的 不过RuntimeException也可以自己手动检查异常，一切语句都可以自己设置检查运行时错误（一切语句运行起来的时候都是运行时），而其它检查异常就不能随便乱抛了，得满足该异常条件","text":"JAVA异常处理的设计思路java的设计思想里是尽量在代码运行前就手动检查代码(try、throw等工具)所有可能错误，也就是检查异常 （区分编译错误，那个由程序编译时自动检查，是不一样的东西） 但是有些异常是没法在运行前检查的，如RuntimeException（比如其子类异常：除0错，越界错），所以没办法，才是非检查异常（且这些错误全部都检查的话程序也太臃肿了）（Error也属于非检查异常）非检查异常属于JVM会自动默认直接抛出，不处理的 不过RuntimeException也可以自己手动检查异常，一切语句都可以自己设置检查运行时错误（一切语句运行起来的时候都是运行时），而其它检查异常就不能随便乱抛了，得满足该异常条件 Error和Exception的区别Error：由 JVM 所侦测到的无法预期的错误，由于这是属于 JVM 层次的严重错误，导致 JVM 无法继续执行，因此，这是不可捕捉到的，无法采取任何恢复的操作，顶多只能显示错误信息（如系统崩溃，内存不足，堆栈溢出等）。 Exception：可以在程序运行中进行捕获并处理，继续执行 JAVA异常操作分两个环节：抛出异常和处理异常 抛出异常抛出异常有两种方式： 代码设计者手动抛出异常使用throw Throwable对象来手动抛出异常 throw new RuntimeException(); JVM自动捕获到异常并抛出将需要JVM自动捕获抛出异常的代码写在try块里 处理（抛出的）异常异常链无论是手动抛出，还是自动抛出，抛出的【异常对象都会自动抛向方法调用者】，当方法调用者即为主程序且不catch处理，那么程序就终止，并打印异常信息；若被处理，则按try catch处理异常 举个例子，方法B抛出异常，如果是主程序直接调用该方法B，则直接抛出，程序终止，打印异常信息（假定未catch处理）；如果是方法A调用抛出异常的方法B，那该异常就抛给A，接着A向上抛，如果有try catch则直接按照对应方式处理，没有就程序终止，打印异常信息 抛出的检查异常要么用throws声明，要么用try catch捕获，非检查异常（Error、RuntimeException）不用（非检查异常本质是所有方法都默认throws RuntimeException了，Error同） （以下代码也包含抛出异常部分） 异常抛出后，可以直接向上抛（如果还能）不处理（但要throws声明）；也可以用catch处理。（如果是JVM自动抛出的异常则不能用throws声明） throws声明：只标识该方法可能抛出的异常列表，不处理throws声明方式 class test &#123; void method() throws Exception &#123; throw new Exception(); //手动抛出异常 &#125; &#125; 异常链（还有上层调用者，则继续向上抛出）： class newTest &#123; void fatherMethod() throws Exception //异常对象通过异常链传递到该方法后，该方法的父类调用者已是主程序，且无catch处理，则程序终止，打印异常信息 &#123; method(); &#125; void method() throws Exception &#123; throw new Exception(); &#125; &#125; 上层调用者也可以是catch方式 class newTest &#123; void fatherMethod() &#123; try&#123; method(); &#125;catch (Exception e)&#123; System.out.println(\"father knows it\"); &#125; &#125; void method() throws Exception &#123; throw new Exception(); &#125; &#125; catch：处理抛出的异常自动捕获的异常只能通过try catch来处理 void testMethod() &#123; try&#123; method(); //try代码块，在该代码块里由JVM自动抛出异常 &#125;catch (Exception e)&#123; //catch捕获try代码块中抛出的异常对象 System.out.println(\"i know it\"); //如果捕获到异常对象，处理代码 &#125; &#125; catch也可以同时捕获多个异常，写多个catch即可 JVM自动捕获异常后再手动抛出封装异常try catch结合手动throw 有时我们会从 catch 中手动抛出一个异常，目的是为了改变异常的类型（比如抛出一个我自己定义的异常MyException）。多用于在多系统集成时，当某个子系统故障，异常类型可能有多种，可以用统一的异常类型向外暴露，不需暴露太多内部异常细节。 class MyException extends Exception //自定义异常 &#123; String name; Exception e; MyException(String name) &#123; this.name = name; &#125; void initCause(Exception e) //传入导致错误的异常对象 &#123; this.e = e; &#125; //other functton &#125; class test &#123; void testMethod() throws MyException &#123; try&#123; //doSth &#125;catch(RuntimeException e) //这里捕获到了RuntimeException后，手动抛出我自己封装好的Exception类 &#123; MyException ex = new MyException(\"xxx is wrong!\"); ex.initCause(e); throw ex; &#125; &#125; &#125; 自定义异常见上面JVM自动捕获异常后再手动抛出封装异常部分的例子 MORE原理1：JVM如何捕获到异常并抛出？①当一个方法中发生异常时，这个方法会创建该异常的一个异常对象（即try块，自动捕获异常） ②也可以手动自己创建一个异常对象（throw） 将异常对象交给JVM的过程就叫抛出异常 原理2：JVM是如何处理异常的？JVM 会顺着调用栈去查找看是否有可以处理异常的代码（catch）（也就构成了前面所说的异常链）。 如果有，JVM将该异常对象传递给它，由处理代码块进行处理； 如果到了栈底还没有（即前面所说的上层调用者已是主程序），JVM 就会将该异常转交给默认的异常处理器，该默认异常处理器打印出异常信息并终止应用程序。 NoClassDefFoundError 和 ClassNotFoundExceptionNoClassDefFoundError 是Error，发生在加载某类时在内存中找不到该类的定义 ClassNotFoundException是检查异常，使用反射的时候，通过传入的类路径参数没有找到该类 异常不要拿来做流程控制finally，总有意想不到的惊喜等着你。。。 异常就是单纯处理异常的 关于return 和 finallyreturn和finally执行顺序问题：Java finally语句到底是在return之前还是之后执行？ 给出结论： 1.finally语句是在try的return语句执行之后，return返回之前执行（return的语句执行后不返回，再继续执行finally中的语句，finally执行完后再返回） 2.finally块中的return语句会覆盖try块中的return返回。 3.inally里的修改语句可能影响也可能不影响try或catch中 return已经确定的返回值 以及一些finally语句执行问题的结论： （1）try语句没有被执行到，如在try语句之前就返回了，这样finally语句就不会执行，这也说明了finally语句被执行的必要而非充分条件是：相应的try语句一定被执行到。 （2）在try块中有System.exit(0);这样的语句，System.exit(0);是终止Java虚拟机JVM的，连JVM都停止了，所有都结束了，当然finally语句也不会被执行到。","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"}],"tags":[]},{"title":"验收","slug":"日记/验收","date":"2017-05-15T10:26:26.000Z","updated":"2019-04-01T15:38:36.000Z","comments":true,"path":"日记/验收/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E9%AA%8C%E6%94%B6/","excerpt":"","text":"问老师验收中","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"Know more ,know less","slug":"日记/know-more-know-less","date":"2017-04-20T01:28:17.000Z","updated":"2019-04-01T15:38:51.000Z","comments":true,"path":"日记/know-more-know-less/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/know-more-know-less/","excerpt":"","text":"知道越多，知道越少","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"がんばれ！","slug":"日记/がんばれ！","date":"2016-11-09T15:22:14.000Z","updated":"2019-04-01T15:37:33.000Z","comments":true,"path":"日记/がんばれ！/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E3%81%8C%E3%82%93%E3%81%B0%E3%82%8C%EF%BC%81/","excerpt":"","text":"","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"CO-原码、反码、补码","slug":"计算机理论/CO-原码、反码、补码","date":"2016-10-18T07:43:56.000Z","updated":"2019-10-23T04:59:21.000Z","comments":true,"path":"计算机理论/CO-原码、反码、补码/","link":"","permalink":"https://aisaka.cloud/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/CO-%E5%8E%9F%E7%A0%81%E3%80%81%E5%8F%8D%E7%A0%81%E3%80%81%E8%A1%A5%E7%A0%81/","excerpt":"转载自http://www.cnblogs.com/zhangziqiu/archive/2011/03/30/ComputerCode.html 原码, 反码, 补码 详解本篇文章讲解了计算机的原码, 反码和补码. 并且进行了深入探求了为何要使用反码和补码, 以及更进一步的论证了为何可以用反码, 补码的加法计算原码的减法. 论证部分如有不对的地方请各位牛人帮忙指正! 希望本文对大家学习计算机基础有所帮助! 一. 机器数和真值在学习原码, 反码和补码之前, 需要先了解机器数和真值的概念.","text":"转载自http://www.cnblogs.com/zhangziqiu/archive/2011/03/30/ComputerCode.html 原码, 反码, 补码 详解本篇文章讲解了计算机的原码, 反码和补码. 并且进行了深入探求了为何要使用反码和补码, 以及更进一步的论证了为何可以用反码, 补码的加法计算原码的减法. 论证部分如有不对的地方请各位牛人帮忙指正! 希望本文对大家学习计算机基础有所帮助! 一. 机器数和真值在学习原码, 反码和补码之前, 需要先了解机器数和真值的概念. 1、机器数一个数在计算机中的二进制表示形式, 叫做这个数的机器数。机器数是带符号的，在计算机用一个数的最高位存放符号, 正数为0, 负数为1. 比如，十进制中的数 +3 ，计算机字长为8位，转换成二进制就是00000011。如果是 -3 ，就是 10000011 。 那么，这里的 00000011 和 10000011 就是机器数。 2、真值 因为第一位是符号位，所以机器数的形式值就不等于真正的数值。例如上面的有符号数 10000011，其最高位1代表负，其真正数值是 -3 而不是形式值131（10000011转换成十进制等于131）。所以，为区别起见，将带符号位的机器数对应的真正数值称为机器数的真值。 例：0000 0001的真值 = +000 0001 = +1，1000 0001的真值 = –000 0001 = –1 二. 原码, 反码, 补码的基础概念和计算方法.在探求为何机器要使用补码之前, 让我们先了解原码, 反码和补码的概念.对于一个数, 计算机要使用一定的编码方式进行存储. 原码, 反码, 补码是机器存储一个具体数字的编码方式. 1. 原码原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制: [+1]原 = 0000 0001 [-1]原 = 1000 0001 第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是: [1111 1111 , 0111 1111] 即 [-127 , 127] 原码是人脑最容易理解和计算的表示方式. 2. 反码反码的表示方法是: 正数的反码是其本身 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反. [+1] = [00000001]原 = [00000001]反 [-1] = [10000001]原 = [11111110]反 可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算. 3. 补码补码的表示方法是: 正数的补码就是其本身 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1) [+1] = [00000001]原 = [00000001]反 = [00000001]补 [-1] = [10000001]原 = [11111110]反 = [11111111]补 对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值. 三. 为何要使用原码, 反码和补码在开始深入学习前, 我的学习建议是先”死记硬背”上面的原码, 反码和补码的表示方式以及计算方法. 现在我们知道了计算机可以有三种编码方式表示一个数. 对于正数因为三种编码方式的结果都相同: [+1] = [00000001]原 = [00000001]反 = [00000001]补 所以不需要过多解释. 但是对于负数: [-1] = [10000001]原 = [11111110]反 = [11111111]补 可见原码, 反码和补码是完全不同的. 既然原码才是被人脑直接识别并用于计算表示方式, 为何还会有反码和补码呢? 首先, 因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减. (真值的概念在本文最开头). 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别”符号位”显然会让计算机的基础电路设计变得十分复杂! 于是人们想出了将符号位也参与运算的方法. 我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了. 于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. 首先来看原码: 计算十进制的表达式: 1-1=0 1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2 如果用原码表示, 让符号位也参与计算, 显然对于减法来说, 结果是不正确的.这也就是为何计算机内部不使用原码表示一个数. 为了解决原码做减法的问题, 出现了反码: 计算十进制的表达式: 1-1=0 1 - 1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原= [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0 发现用反码计算减法, 结果的真值部分是正确的. 而唯一的问题其实就出现在”0”这个特殊的数值上. 虽然人们理解上+0和-0是一样的, 但是0带符号是没有任何意义的. 而且会有[0000 0000]原和[1000 0000]原两个编码表示0. 于是补码的出现, 解决了0的符号以及两个编码的问题: 1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补 + [1111 1111]补 = [0000 0000]补=[0000 0000]原 这样0用[0000 0000]表示, 而以前出现问题的-0则不存在了.而且可以用[1000 0000]表示-128: (-1) + (-127) = [1000 0001]原 + [1111 1111]原 = [1111 1111]补 + [1000 0001]补 = [1000 0000]补 -1-127的结果应该是-128, 在用补码运算的结果中, [1000 0000]补 就是-128. 但是注意因为实际上是使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示.(对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原, 这是不正确的) 使用补码, 不仅仅修复了0的符号以及存在两个编码的问题, 而且还能够多表示一个最低数. 这就是为什么8位二进制, 使用原码或反码表示的范围为[-127, +127], 而使用补码表示的范围为[-128, 127]. 因为机器使用补码, 所以对于编程中常用到的32位int类型, 可以表示范围是: [-231, 231-1] 因为第一位表示的是符号位.而使用补码表示时又可以多保存一个最小值. 四 原码, 反码, 补码 再深入计算机巧妙地把符号位参与运算, 并且将减法变成了加法, 背后蕴含了怎样的数学原理呢? 将钟表想象成是一个1位的12进制数. 如果当前时间是6点, 我希望将时间设置成4点, 需要怎么做呢?我们可以: 1. 往回拨2个小时: 6 - 2 = 4 2. 往前拨10个小时: (6 + 10) mod 12 = 4 3. 往前拨10+12=22个小时: (6+22) mod 12 =4 2,3方法中的mod是指取模操作, 16 mod 12 =4 即用16除以12后的余数是4. 所以钟表往回拨(减法)的结果可以用往前拨(加法)替代! 现在的焦点就落在了如何用一个正数, 来替代一个负数. 上面的例子我们能感觉出来一些端倪, 发现一些规律. 但是数学是严谨的. 不能靠感觉. 首先介绍一个数学中相关的概念: 同余 同余的概念两个整数a，b，若它们除以整数m所得的余数相等，则称a，b对于模m同余 记作 a ≡ b (mod m) 读作 a 与 b 关于模 m 同余。 举例说明: 4 mod 12 = 4 16 mod 12 = 4 28 mod 12 = 4 所以4, 16, 28关于模 12 同余. 负数取模正数进行mod运算是很简单的. 但是负数呢? 下面是关于mod运算的数学定义: 上面是截图, “取下界”符号找不到如何输入(word中粘贴过来后乱码). 下面是使用”L”和”J”替换上图的”取下界”符号: x mod y = x - y L x / y J 上面公式的意思是: x mod y等于 x 减去 y 乘上 x与y的商的下界. 以 -3 mod 2 举例: -3 mod 2 = -3 - 2xL -3/2 J = -3 - 2xL-1.5J = -3 - 2x(-2) = -3 + 4 = 1 所以: (-2) mod 12 = 12-2=10 (-4) mod 12 = 12-4 = 8 (-5) mod 12 = 12 - 5 = 7 开始证明再回到时钟的问题上: 回拨2小时 = 前拨10小时 回拨4小时 = 前拨8小时 回拨5小时= 前拨7小时 注意, 这里发现的规律! 结合上面学到的同余的概念.实际上: (-2) mod 12 = 10 10 mod 12 = 10 -2与10是同余的. (-4) mod 12 = 8 8 mod 12 = 8 -4与8是同余的. 距离成功越来越近了. 要实现用正数替代负数, 只需要运用同余数的两个定理: 反身性: a ≡ a (mod m) 这个定理是很显而易见的. 线性运算定理: 如果a ≡ b (mod m)，c ≡ d (mod m) 那么: (1)a ± c ≡ b ± d (mod m) (2)a c ≡ b d (mod m) 如果想看这个定理的证明, 请看:http://baike.baidu.com/view/79282.htm 所以: 7 ≡ 7 (mod 12) (-2) ≡ 10 (mod 12) 7 -2 ≡ 7 + 10 (mod 12) 现在我们为一个负数, 找到了它的正数同余数. 但是并不是7-2 = 7+10, 而是 7 -2 ≡ 7 + 10 (mod 12) , 即计算结果的余数相等. 接下来回到二进制的问题上, 看一下: 2-1=1的问题. 2-1=2+(-1) = [0000 0010]原 + [1000 0001]原= [0000 0010]反 + [1111 1110]反 先到这一步, -1的反码表示是1111 1110. 如果这里将[1111 1110]认为是原码, 则[1111 1110]原 = -126, 这里将符号位除去, 即认为是126. 发现有如下规律: (-1) mod 127 = 126 126 mod 127 = 126 即: (-1) ≡ 126 (mod 127) 2-1 ≡ 2+126 (mod 127) 2-1 与 2+126的余数结果是相同的! 而这个余数, 正式我们的期望的计算结果: 2-1=1 所以说一个数的反码, 实际上是这个数对于一个膜的同余数. 而这个膜并不是我们的二进制, 而是所能表示的最大值! 这就和钟表一样, 转了一圈后总能找到在可表示范围内的一个正确的数值! 而2+126很显然相当于钟表转过了一轮, 而因为符号位是参与计算的, 正好和溢出的最高位形成正确的运算结果. 既然反码可以将减法变成加法, 那么现在计算机使用的补码呢? 为什么在反码的基础上加1, 还能得到正确的结果? 2-1=2+(-1) = [0000 0010]原 + [1000 0001]原 = [0000 0010]补 + [1111 1111]补 如果把[1111 1111]当成原码, 去除符号位, 则: [0111 1111]原 = 127 其实, 在反码的基础上+1, 只是相当于增加了膜的值: (-1) mod 128 = 127 127 mod 128 = 127 2-1 ≡ 2+127 (mod 128) 此时, 表盘相当于每128个刻度转一轮. 所以用补码表示的运算结果最小值和最大值应该是[-128, 128]. 但是由于0的特殊情况, 没有办法表示128, 所以补码的取值范围是[-128, 127] 本人一直不善于数学, 所以如果文中有不对的地方请大家多多包含, 多多指点!","categories":[{"name":"计算机理论","slug":"计算机理论","permalink":"https://aisaka.cloud/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"javascript扼要","slug":"程序语言/javascript扼要","date":"2016-10-07T06:25:25.000Z","updated":"2019-04-03T05:04:22.000Z","comments":true,"path":"程序语言/javascript扼要/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/javascript%E6%89%BC%E8%A6%81/","excerpt":"~_~ 继续开坑 html负责数据的显示，css负责样式的显示，javascript负责完成页面的交互 javascript有很多框架（类似于OC中的Fundation Cocoa框架集等），最早的是prototype.js现在很少用 现在最流行的几种比如 jQuery 有很多插件，Extjs等，DWR框架（可以达到直接通过js调用java的代码）","text":"~_~ 继续开坑 html负责数据的显示，css负责样式的显示，javascript负责完成页面的交互 javascript有很多框架（类似于OC中的Fundation Cocoa框架集等），最早的是prototype.js现在很少用 现在最流行的几种比如 jQuery 有很多插件，Extjs等，DWR框架（可以达到直接通过js调用java的代码） 一、 ①可直接在html中在script标签中写 &lt;script type&#x3D;”text&#x2F;javascript&gt; (类似于css的&lt;style type&#x3D;”text&#x2F;css”&gt;.. &#x2F;*js代码*&#x2F; &lt;&#x2F;script&gt; ②也可以引入外部文件（常用） css中用link 通过src指定外部文件位置 &lt;script type&#x3D;”text&#x2F;javascript” src&#x3D;”hello.js&gt;&lt;&#x2F;script&gt; 注意：&lt;script&gt;标签**不能自结束！** alert(“”); 二、基本语法相关 很多东西 常用技巧习惯语法和java很像 ①javascript是动态类型语言，而C java等是静态类型语言，动态类型语言是运行到哪读哪 ②变量：js只能通过var来创建变量，eg: var a = 20 注意for(var i;i&lt;=10;i++) 不要习惯性把var写成int等 住手这不是c/java啊喂 xxxx 注意：当在函数内部没有使用var来声明变量的时候，这个变量就会作为全局变量声明！所以在函数中定义变量一定要使用var ③函数: 通过function来创建函数 方法一： function fn1() &#123; &#125; 方法二：var x=function()&#123; return a;&#125;然后x(); 就是这个函数 方法三：function fn2()&#123;&#125; var y=fn2;（仅函数名 不带括号） (理解..其实都一个原理，指针 内存等） 函数名字可以通过改指针改，这是静态语言无法做到的 ④注释：同java （html）通过&lt;input type=”xxx”&gt;&lt;/input&gt;标签 等来插入按钮等 然后可以添加事件 比如xxx可以为button，则为添加一个按钮 ⑤数据类型相关 常用 alert（typeof a); 查看a的类型 注对于数组等对象而言返回object 对于函数返回function 强制类型转换：Number(a)（java中为（Number）a） 如果强制转换一个非数字的值为Number会得到一个NaN的值 parseInt(a)可将字符串开头的几个数字转换为Int ，但如果开头不是数字则NaN a instanceof Array 判断as是不是Array的实例 是则返回true 布尔类型 true false 在js中，除了NaN，undefined，0这三个类型以外，其余皆为true （ 然后就可以通过这个特性搞事情 比如if(a) 等等 三、面向对象、原型（详细原理见二部分引用外部文章） js中没有“类”的概念（ruby python也是） js的对象是基于原型拷贝的 动态语言一般都基于原型拷贝 只有一个根对象 “类”的定义 function Person(name,age)&#123; this.name&#x3D;name; (定义了Person的一个属性为name) this.age&#x3D; age; this.mmm&#x3D;”ssssss”; (定义了Persion的一个属性为mmm） &#125;必须要用this声明，如果没有this声明则仅仅只是函数的一个局部变量而不是类的属性 就算要在类里面创建函数 也需要this！ eg :this.abc= function(){} js中每创建一个对象都存在一个function行为，占有内存，因为这个function行为属于一个属性，而java中不会这样，function不属于类的属性。 var p1&#x3D; new Person(“jack”,10); alert(p1.name); 除了点语法以外，也可以通过对象[“属性字符串”]完成对属性的调用 如alert(p1[“name”]; 在js中对于对象而言 ，可以通过for in来遍历对象的属性 可以获取对象中所有的显示声明的属性 e.g.for (var a in p1)&#123;&#125; 要显示p1的所有属性 遍历输出之 即可for(var i in p1) &#123;alert(p1[i]&#125; 常用对象：查库。 二部分引用外部文章：理解（重要，此文写得非常详细清晰） Javascript中的函数、this以及原型链接：http://www.cnblogs.com/xfrog/archive/2013/06/16/3138293.html 关于函数 在Javascript中函数实际上就是一个对象，具有引用类型的特征，所以你可以将函数直接传递给变量，这个变量将表示指向函数“对象”的指针，例如： function test(message)&#123; alert(message); &#125; var f &#x3D; test; f(&#39;hello world&#39;); 你也可以直接将函数申明赋值给变量： var f &#x3D; function(message)&#123; alert(message); &#125;; f(&#39;hello world&#39;); 在这种情况下，函数申明中可以省略函数名称，因为此时名称已经没有任何意义，我们可直接通过变量f来调用函数。 通过Function类型，我们可以更好地理解函数即对象： var f &#x3D; new Function(&quot;message&quot;,&quot;alert(message);&quot;); f(&#39;hello world&#39;); 关于this this可以看成调用函数的实际作用域上下文。比较以下函数的执行结果： function test()&#123; this.property &#x3D; &#39;hello world&#39;; &#125; test(); alert(window.property); &#x2F;&#x2F;由于在全局范围内调用，test函数中的this实际指向全局对象(window) var obj &#x3D; &#123;&#125;; test.call(obj); &#x2F;&#x2F;通过call第一个参数指定执行上下文范围，所以test函数中this指向obj实例。 alert(obj.property); var obj2 &#x3D; &#123;&#125;; obj2.test2 &#x3D; test; &#x2F;&#x2F;将obj2实例方法test指向 全局test方法 obj2.test2(); &#x2F;&#x2F;由于是在obj2上调用test方法，所以test函数中的this也指向了obj2实例 alert(obj2.property); 定义类型 在Javascript中可以定义构造函数，构造函数与一般函数没有任何区别，在创建实例时，如果我们使用了new关键字，那么这个函数就具有构造函数的特性，否则就是一般函数，如下所示，我们定义了一个Person类型： function Person()&#123; this.name &#x3D; &#39;xfrog&#39;; this.Say &#x3D; function()&#123; alert(this.name); &#125;; &#125; 当使用new关键字时，可以创建一个新的Person对象实例： var p1 &#x3D; new Person(); p1.Say(); 如果不使用new关键字，将直接执行Person函数，由于执行上下文为全局范围，故name属性和Say方法将被添加到window对象： Person(); Say(); window.Say(); 原型 注意上述Person的定义方式，当使用new来创建Person实例时，将会执行Person构造函数，也就是会声明name属性和Say方法，这样可能产生效率问题，注意以下代码： var p1 &#x3D; new Person(); var p2 &#x3D; new Person(); var test &#x3D; p1.Say &#x3D;&#x3D; p2.Say; 比较p1和p2两个Say函数指针，返回false，表示每个Person实例中的Say方法都是独立的，而事实上Say函数的功能是完全一样的，我们完全没有必要为每个对象重新分配Say函数”对象“，如果Person实例很多，将会造成大量的内存耗用。 如果将Say函数提取出来放入全局执行范围，似乎可解决次问题： &gt;&gt; function Person()&#123; this.name &#x3D; &#39;xfrog&#39;; this.Say &#x3D; say; &#125; function say()&#123; alert(this.name); &#125; var p1 &#x3D; new Person(); var p2 &#x3D; new Person(); alert(p1.Say &#x3D;&#x3D; p2.Say); p1.name &#x3D; &#39;wang&#39;; p1.Say(); 由于this始终和执行上下文相关，p1和p2实例中的Say方法中会正确地返回对应实例的name属性。但是，使用此方式有违面向对象的思想，也失去了类型密封的原则。还会造成大量的全局函数。 为了解决这些缺点，Javascript引出了原型的概念，简单理解，原型可以看成是类型的共享区，原型本身是一个对象，而对象中的属性对于类型来说是共享的。Javascript中每个类型通过prototype属性来表示原型，通过这个属性可指定共享方法： &gt;&gt; function Person()&#123; &#125; Person.prototype.name &#x3D; &#39;xfrog&#39;; Person.prototype.Say &#x3D; function()&#123; alert(this.name); &#125;; var p1 &#x3D; new Person(); var p2 &#x3D; new Person(); alert(p1.Say &#x3D;&#x3D; p2.Say); &#x2F;&#x2F;返回true 为什么这里可以通过p1.Say来访问Say方法呢？这是因为ECMAScript标准规定了类型属性的查找顺序：先在类型的实例上查找，如果没有则继续在类型原型上查找，这一查找路径采用短路算法，即找到首个后即返回，考虑如下代码： &gt;&gt; function Person()&#123; this.name &#x3D; &#39;wang&#39;; &#125; Person.prototype.name &#x3D; &#39;xfrog&#39;; Person.prototype.Say &#x3D; function()&#123; alert(this.name); &#125; var p1 &#x3D; new Person(); p1.Say(); &#x2F;&#x2F;将返回wang 上面提到prototype实际上是一个对象，那么我们是否可以直接访问呢？ 在一些浏览器实现（如Chrome、Fixfox等）的确可通过实例的proto属性来访问内部的prototype对象，这种特征表明Javascript引擎在每个对象的内部都是通过一个变量来保存对prototype的引用，这保证了prototype对应整个类型的实例来说是共享的，例如，你可在Chrome浏览器内使用如下方式来访问Say方法： p1.__proto__[&quot;Say&quot;](); 由于原型是一个对象，我们可以直接将一个对象赋值给prototype： &gt;&gt; function Person()&#123; &#125; Person.prototype &#x3D; &#123;name:&#39;xfrog&#39;, Say:function()&#123; alert(this.name); &#125;&#125;; 注意这个方式下，实际上是完全替换了Person的prototype，这与上面Person.prototype.name方式还是有细微差异的，这是因为任何类型，Javascript引擎都会添加默认的prototype，在这个prototype中包含一个对构造函数的引用，即原型对象属性constructor，所以通常使用替代prototype方式时，我们需要手动加上constructor属性： &gt;&gt; Person.prototype &#x3D; &#123; constructor: Person, name :&#39;xfrog&#39;, Say:function()&#123; alert(this.name); &#125; &#125; 注意，由于prototype对于整个类型是共享的，那么在prototype中的引用类型可能会存在问题，前面的Say函数作为一个对象，也是引用类型，所以每个实例中的Say都指向原型对象中的同一个函数，这本身没有问题，也是我们使用原型的初衷，但对于其他引用对象，可能结果并不是我们想要的： &gt;&gt; function Person()&#123; &#125; Person.prototype &#x3D; &#123; name: &#39;xfrog&#39;, obj : &#123; age: 18 &#125;, Say : function()&#123; alert(this.obj.age); &#125; &#125;; var p1 &#x3D; new Person(); var p2 &#x3D; new Person(); p1.obj.age &#x3D; 20; p1.Say(); p2.Say(); p2.Say返回的是20，这是因为obj属性作为原型属性是共享的，在内存中只存在一个实例，所以通过p1修改后，p2只能得到修改后的状态。如果要避免此情况，可将obj属性放到实例中： function Person()&#123; this.obj &#x3D; &#123; age: 18 &#125;; &#125;","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[]},{"title":"CSS扼要-2","slug":"程序语言/CSS扼要-2","date":"2016-10-03T08:32:55.000Z","updated":"2019-04-03T05:03:55.000Z","comments":true,"path":"程序语言/CSS扼要-2/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/CSS%E6%89%BC%E8%A6%81-2/","excerpt":"六、超链接样式 CSS: a:link&#123; &lt;!–此为默认情况–&gt; text-decoration:none; &lt;!–去掉下划线–&gt; &#125;②访问后样式 a:visited{ &lt;!–链接被访问（点击）过之后–&gt; }","text":"六、超链接样式 CSS: a:link&#123; &lt;!–此为默认情况–&gt; text-decoration:none; &lt;!–去掉下划线–&gt; &#125;②访问后样式 a:visited{ &lt;!–链接被访问（点击）过之后–&gt; } 兼容性问题：非IE会继承默认属性而IE不继承，故第一段未访问情况改为这样 ①未访问样式 a:link,a:visited{ } ③鼠标移动到上面的时候的样式 a:hover{ } 注意 :hover不只运用于超链接 对于任何元素均可设置hover的属性,表示当鼠标移动到上面的时候的样式 xxx:hovor{} 类超链接控制器 eg: a.xxx:link&#123;&#125; a.xxx:visited&#123;&#125; a.xxx:hover&#123;&#125; — HTML: &lt;a href=”#”&gt;xxx&lt;/a&gt; 注意CSS样式表的优先级问题 被包含的处理优先级要高（先加载它）一些，也就是先处理，所以实际套用的是优先级低（后加载的）的包含者的属性 比如&lt;ul&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;p&gt;&lt;/p&gt;&lt;/ui&gt; ul{} ul p{} p被包含于ul中，所以实际上先处理了第二条 再处理了第一条，所以第二条的属性被第一条覆盖了 当使用了包含的操作符之后，它的加载时间比使用class的加载时间低，此时再来定义一个class的样式，就不会把使用包含的样式覆盖掉 七、CSS HACK 加 使得不同浏览器读出不同的语句 加语句该浏览器能识别就读 不能识别就跳过 八、错误总结出的经验： 1、float是设置给所有需要浮动的元素的属性 而不是表格整体 2、不能忽视[ul]和[div块]的宽度！！ul与div本身是有宽度属性的！！！ img文件一般放在css文件夹中（或其中的子目录） 方便background url设置等 两个点 ..访问上一级目录 cursor:pointer; hovor中的样式 使得鼠标移动上去变成手指 九、布局设计/流派 布局一： 一整块div网页的写法 这种大DIV一块的方式是以前的网站的常用布局 现在的布局一般不采用 布局二： &lt;div id&#x3D;“head”&gt; &lt;div id&#x3D;“c_head”&gt;顶部图片&lt;&#x2F;div&gt; &#x2F;*c center*&#x2F; &lt;&#x2F;div&gt; &lt;div id&#x3D;“nav”&gt; &lt;div id&#x3D;“c_nav”&gt;导航内容&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;“content”&gt; &lt;div id&#x3D;“c_content”&gt;内容&lt;&#x2F;div&gt; &lt;&#x2F;div&gt; &lt;div id&#x3D;“bottom”&gt; &lt;div id&#x3D;“c_bottom”&gt;底部内容&lt;&#x2F;div&gt; &lt;&#x2F;div&gt;c_xxx也要用到div的居中对齐方法，见文章 CSS扼要-1 这样就使得页面很宽 内容全铺在屏幕上 但实际上显示的内容还是在中间一部分 布局三：瀑布流布局 以专门看图片为主 仅CSS无法实现 十、display属性 display:none; 不显示 display:block; 显示 导航菜单的伸缩实现：为菜单首先加上class=”a”; 但点击后使其class=”a”变成class=”b”（通过javascript实现） –样式表：class=”a”{不显示} class=”b”{显示}","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[]},{"title":"bandwagon迁移digitalocean 大成功","slug":"博客/bandwagon迁移digitalocean 大成功","date":"2016-10-01T11:39:19.000Z","updated":"2019-04-03T04:58:03.000Z","comments":true,"path":"博客/bandwagon迁移digitalocean 大成功/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/bandwagon%E8%BF%81%E7%A7%BBdigitalocean%20%E5%A4%A7%E6%88%90%E5%8A%9F/","excerpt":"","text":"centos6.5无可用php5.5源真是折腾死我了 ……………","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"CSS扼要-1","slug":"程序语言/CSS扼要-1","date":"2016-09-29T07:26:03.000Z","updated":"2019-04-03T05:03:48.000Z","comments":true,"path":"程序语言/CSS扼要-1/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/CSS%E6%89%BC%E8%A6%81-1/","excerpt":"一、HTML仅用于页面内容的显示而CSS是修饰可查阅CSS手册查看大量的CSS样式 CSS难点在于在什么情况应该用什么手段解决问题 参考书籍 Zen Garden 引入样式表&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;xxx.css&quot;&gt; px像素 标题和文章一般用12px/14px","text":"一、HTML仅用于页面内容的显示而CSS是修饰可查阅CSS手册查看大量的CSS样式 CSS难点在于在什么情况应该用什么手段解决问题 参考书籍 Zen Garden 引入样式表&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;xxx.css&quot;&gt; px像素 标题和文章一般用12px/14px ATT注意编码问题，win10纪事本默认ANSI编码 如果meta里设置UTF-8则txt文档在保存的时候应该储存为UTF-8编码！否则会出现乱码，中文字体读不出来等情况 background:url(“xxx.xxx”) no-repeat; background-position:5px 10px;第一个值为左右 第二个值为上下 插入图片有三种方式：①img标签src属性②设置background background更快，因为backgrond会把图片存入缓存中，故除非该图片会变化，则一律用background插入图片(可设置为一个div的样式） max-width:100%; 宽度自适应屏幕，高度同理,max-height:; 二、选择器p{} 标签选择器#xx{} id选择器 id=”xx”x.xx{} 类（class）选择器 class=”xx” 可以选择【一组】标签 p.xx{} 标签为p中的class为xx的标签，表示p标签的所有xx类，类不可单独拿出来选择 必须要【标签.类名】 格式（W3C标准规定，在同一个页面内，不允许有相同名字的id对象出现，但是允许相同名字的class）p.#xx{} 标签为p中id为xx的* {} *表示所有的标签 div span{} 包含选择符 指p标签中的所有span标签都来设置这个信息(eg:&lt;div&gt;..&lt;span&gt;&lt;/span&gt;..&lt;/div&gt; div &gt;h2{} 子对象选择符 (eg:&lt;div&gt;…….&lt;h2&gt;….&lt;/h2&gt;….&lt;h2&gt;…..&lt;/h2&gt;…&lt;p&gt;..&lt;/p&gt;..&lt;div&gt;注意区别：子对象选择符(&gt;)仅仅只针对第一级子对象，而包含选择符(空格)则针对一切子对象 xx,xx,#xx,#xx{} 分组选择符，用逗号同时设定多个标签，使他们都遵循下面样式 三、盒子模型（代替HTML中的表格布局 但不能完全替代框架）对于每一层盒其margin和padding属性margin:对外（上一级）padding:对内（下一级）不加left right top button则是四个方向统一设置(若加则单独设置margin-left,padding-right,etc）也可以 margin:12px,10px,20px,20px 表示从top开始顺时针转的各方向 千万不要使用padding来进行对齐操作。对于IE padding的值会算在width中，而对于其他浏览器，padding的值不算入width中！ 不兼容问题 但若没有设置width则可以，但最建议还是用position方式 (如主菜单 每一个都是一个span 共存一个div中；或者文章列表，每一个标题都是一个span 存于一块div中)但主菜单，文章列表等等 一般用表格 ul dl等 那么如何方便居中呢 也一般使用表格ul dl （补充：去掉ul的点 list-style-type:none;） 有些标签比如h3 body标签自身margin和padding属性不为0，若需要要自己改，可以直接*{margin:0; padding:0;} css文件第一句话要写这个！一般都不用自身的margin和padding 在html，有一些标签仅仅是用来设置文本，诸如a和span，对于这两个标签而言，在W3C标准中默认是不能进行width等样式进行修饰的，所以为这些标签设置width是没有作用的，需要display:block;（写入样式表）之后才有作用。但对于IE是有作用的（IE的标准与W3C不一样 微软强无敌= =）在开发中，一般对span加width是没有意义的，（一般不用为span加width），若果需要可能是设计有问题.. 四、定位 position样式 然后就可以设置top/bottom/right/left的值(eg : left:40px) 1、position:absolute; 绝对定位 针对浏览器而言的（此话是有误的，但很多时候是这样，见下一段）。当设置之后，该容器就不会再占用相应的空间，原有的空间会被其它元素占用 （实际上，绝对定位会针对父级标签中进行了absolute定位的标签来进行left/right等设置，如果父级标签都没有这样的定位方式，则根据body来定位） 2、position:relative;相对定位 针对父级元素进行定位，而且空间会一直占用，哪怕这个元素已经移动到其它位置 默认的定位方式为static，这种定位不能设置top/bottom/right/left 使用经验：经常会使用relative来实现文本位置的移动。所以如果要为某个容器设置里面的文本位置，可以按照如下方式来处理abscd 经验：内容一般都存在或里。 所以做居中对齐的时候，把内容放在span里，加position:relative;然后设置top/bottom/right/left 这是对齐的唯一方式！不能用padding,width！ 居中一个div的方法（重要！），text-align:center;只有IE可以居中，margin:auto;只有IE之外的浏览器可以居中，所以推荐的居中方式就是position定位的方法！见下：eg #container{ width:1100px; &lt;!–宽度设为1100px–&gt; border:1px solid #229; &lt;!–别给contain div（整块的主div设高度），不设高度就让元素把它撑下来 有多少高多少–&gt; position:absolute; &lt;!—-&gt; left:50%; &lt;!–左边框对齐页面中央–&gt; margin-left:-550px; &lt;!–向左回一半–&gt; } 当然也可两个居中方式都写..（orz这样IE和非IE都管用了，简单粗暴..）但推荐还是用以上的方式（因为如果设了margin：auto后其子类全部都继承这个属性） 3、position:fixed; 固定在页面上，不随滚动条滚动而改变位置 五、float float:left;左飘，第一个放最左边 float:right;右飘，第一个放最右边 float可使得表格等横向浮动 （表格中在样式里设置） 兼容性：对于IE，设置float后该标签依然占用空间，而其他浏览器不占用，故必须要再添加一个属性 clear:both; 将两段的float清除！否则对于IE外的浏览器设置了float的元素不再占用空间，下面的元素会飘上来！ border-bottom:1px solid red; 只设置底部边框那条 ，etc 加线","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[]},{"title":"HTML扼要","slug":"程序语言/html","date":"2016-09-29T05:24:15.000Z","updated":"2019-04-03T05:04:12.000Z","comments":true,"path":"程序语言/html/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/html/","excerpt":"一、每个块的标题 全用h 搜索引擎会搜索hul无序 （li） 诸如导航 文章列表等dl 数据列表块 （dt标题 dd元素） ul dl非常重要 表格&lt;table&gt; &lt;tr&gt; &#x2F;*第一行*&#x2F; &lt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt; &#x2F;*第一行里每一列*&#x2F; &lt;&#x2F;tr&gt; &lt;tr&gt; &#x2F;*第二行*&#x2F; &lt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt; &#x2F;*第二行里每一列*&#x2F; &lt;&#x2F;tr&gt; &lt;&#x2F;table&gt;","text":"一、每个块的标题 全用h 搜索引擎会搜索hul无序 （li） 诸如导航 文章列表等dl 数据列表块 （dt标题 dd元素） ul dl非常重要 表格&lt;table&gt; &lt;tr&gt; &#x2F;*第一行*&#x2F; &lt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt; &#x2F;*第一行里每一列*&#x2F; &lt;&#x2F;tr&gt; &lt;tr&gt; &#x2F;*第二行*&#x2F; &lt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt;td&gt;&lt;&#x2F;td&gt; &#x2F;*第二行里每一列*&#x2F; &lt;&#x2F;tr&gt; &lt;&#x2F;table&gt; 表格的样式属性 网上查 ol不常用&amp;nbsp 页面空格a超链接href&lt;!– –&gt;&lt;br/&gt;每个标签都要有/结束 如果只有一个不是一组则自结束frame input br等都可自结束&lt;pre&gt; 格式显现出来的文本 二、常用布局标签div于span用于进行容器控制div 一般设定一个容器，这个容器中可以放置大量的内容span 一般用于放置最后的文本数据，用来进行简单的控制 补充href属性和src属性的区别 href 表示超文本引用（hypertext reference），在 link和a 等元素上使用。src 表示来源地址，在 img、script、iframe 等元素上。 src 的内容，是页面必不可少的一部分，是引入。href 的内容，是与该页面有关联，是引用。区别就是，引入和引用。 三、表单常用的表单标签原则上都要放在form标签中input标签可以用来设置文本框密码框等数据submit表示提交，提交的时候会链接到指定页面去处理button是按钮，如果没有进行控制则不会发生反应radio单选框 name用来分组 使得其变成单选框，当name一样表示这几个radio都在一个组中，点击其中一个会取消其他的选中checkbox多选框 用法同radio 不用分组下拉列表框 select 不用input 用法见下textarea文本框 不用input 用法见下 &lt;form action&#x3D;”01.html”&gt; 用户名：&lt;input type&#x3D;”text”&#x2F;&gt;&lt;br&#x2F;&gt; 密码：&lt;input type&#x3D;”password”&#x2F;&gt;&lt;br&#x2F;&gt; 性别：&lt;input type&#x3D;”radio” value&#x3D;”男” name&#x3D;”sex”&#x2F;&gt;男&lt;input type&#x3D;”radio” value&#x3D;”女” name&#x3D;”sex”&#x2F;&gt;女&lt;br&#x2F;&gt; 兴趣：&lt;input type&#x3D;”checkbox”&#x2F;&gt;足球&lt;input type&#x3D;”checkbox”&#x2F;&gt;羽毛球&lt;input type&#x3D;”checkbox”&#x2F;&gt;篮球&lt;input type&#x3D;”checkbox”&#x2F;&gt;乒乓球&amp;ltbr&#x2F;&gt; 籍贯：&lt;select&gt; &lt;option&gt;北京&lt;&#x2F;option&gt; &lt;option&gt;上海&lt;&#x2F;option&gt; &lt;option&gt;广州&lt;&#x2F;option&gt; &lt;&#x2F;select&gt; &lt;textarea cols&#x3D;”50″ rows&#x3D;”10″ &gt;&lt;&#x2F;textarea&gt;&lt;br&#x2F;&gt; &lt;input type&#x3D;”submit” value&#x3D;”用户注册”&#x2F;&gt; &lt;input type&#x3D;”button” value&#x3D;”点一下试试”&#x2F;&gt; &lt;&#x2F;form&gt; 四、frameset 框架 布局 框架并不是完全被CSS布局替代，比如说在设计管理界面等页面框架的时候 局部刷新等的时候就需要框架 （当然建议也可以用div+css方式完成）不能在body中设置，其上级为html标签cols/rows表示让这个框架基于横/纵向方式切分，cols，rows可同时使用以平均拆分（像表格一样），每行每列达到要求。如果不想全部平均拆分（有些地方分有些地方部分），则使用frame嵌套的方法（多个框架文件嵌套）。多使用frame嵌套方法实现较好的布局 3个框架大小依次列出150 *（剩下） 150norisize使得边框不能移动；frameborder值为0表示没有边框 如果有边框则为1 border设置边框厚度框架不能src属性不能为其自身文件 &lt;frameset cols&#x3D;&quot;150,*,150&gt; (&lt;frameset cols&#x3D;&quot;150,*,150 rows&#x3D;&quot;150,*,150″&#x2F;&gt;) &lt;frame src&#x3D;&quot;01.html&quot; noresize frameborder&#x3D;0 border&#x3D;3&#x2F;&gt; &lt;frame src&#x3D;&quot;02.html&quot; target&#x3D;&quot;content&quot;&#x2F;&gt; &lt;frame name&#x3D;&quot;content&quot; src&#x3D;&quot;03.html&quot;&#x2F;&gt; &lt;&#x2F;frameset&gt; 局部刷新的方法：在超链接的时候增加属性target=”content”，这个链接就会在content这个frame（href必须链接到该页面）中显示（当然，需要先把一个frame的名字设置为content） 如果要将整个框架居中 则需要在框架外再嵌套一层框架 使其分为左中右三栏，左右留为空白 如何通过css+div实现局部刷新？ 参考http://zhidao.baidu.com/link?url=ZuP0aA_mv4coT4zCflt3_wwuj9d2G-6kAgD9W22P_6sBdgWtp0iFRvZAcmb7XU0C7L35aO7VoqRH2tHhTlc8H_ 五、通过&lt;input type=&quot;xxx&quot;&gt;&lt;/input&gt;标签 等来插入按钮等 然后可以添加事件 比如xxx可以为button，则为添加一个按钮","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"}],"tags":[]},{"title":"提前进入国庆状态","slug":"日记/提前进入国庆状态","date":"2016-09-29T03:23:28.000Z","updated":"2019-12-22T23:16:33.000Z","comments":true,"path":"日记/提前进入国庆状态/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E6%8F%90%E5%89%8D%E8%BF%9B%E5%85%A5%E5%9B%BD%E5%BA%86%E7%8A%B6%E6%80%81/","excerpt":"","text":"","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"172","slug":"Anime/172","date":"2016-09-21T01:27:23.000Z","updated":"2019-04-03T04:57:20.000Z","comments":true,"path":"Anime/172/","link":"","permalink":"https://aisaka.cloud/Anime/172/","excerpt":"","text":"——你是日向同学吧… ——你是说以前的我吗 ——…果然…你不记得了啊……已经…想不起来了吗… ——做不到.我以前的记忆已经完全被消除了 ——什么都…能做到哦…日向同学的话……你看，去做的话总有办法… ………. ——果然…还是不行啊… ………. ——没能救…日向同学…对不起… ——就算成了这种状况，你还是想着保护别人啊 ——因为…我喜欢大家啊………不要…不想死…我还有…想做的事…还想继续和大家做同学…还想再一次和日向同学…一起打游戏啊… --- 我才是…谢谢你。 大家的事…我不会忘记哦… 永远永远…不会忘记哦… 从今以后…我也会在某处给大家加油哦。 因为…我们永远都是同伴嘛。 --- 你的愿望最终实现了哟","categories":[{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"}],"tags":[]},{"title":"今年成都的夏天真热","slug":"日记/今年成都的夏天真热","date":"2016-08-28T16:02:18.000Z","updated":"2019-04-03T04:58:38.000Z","comments":true,"path":"日记/今年成都的夏天真热/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%BB%8A%E5%B9%B4%E6%88%90%E9%83%BD%E7%9A%84%E5%A4%8F%E5%A4%A9%E7%9C%9F%E7%83%AD/","excerpt":"","text":"终于降温了~","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"iOS-1","slug":"开发/ios-1","date":"2016-08-12T14:38:54.000Z","updated":"2019-04-03T05:05:53.000Z","comments":true,"path":"开发/ios-1/","link":"","permalink":"https://aisaka.cloud/%E5%BC%80%E5%8F%91/ios-1/","excerpt":"1、获取UIApplication代理： AppDelegate* appDelegate = [UIApplication shareApplication].delegate 应用程序代理是整个iOS应用的通讯中心，其他应用程序组件都可以通过该对象进行数据交换，同时ios应用代理还负责处理用用程序执行中的事件循环 应用程序代理需要满足两个规则：继承UIResponder基类和遵守UIApplicationDelegate协议（UIResponder是iOS应用提供的一个基类，所有需要向用户提供响应的对象都需要继承UIResponder基类）","text":"1、获取UIApplication代理： AppDelegate* appDelegate = [UIApplication shareApplication].delegate 应用程序代理是整个iOS应用的通讯中心，其他应用程序组件都可以通过该对象进行数据交换，同时ios应用代理还负责处理用用程序执行中的事件循环 应用程序代理需要满足两个规则：继承UIResponder基类和遵守UIApplicationDelegate协议（UIResponder是iOS应用提供的一个基类，所有需要向用户提供响应的对象都需要继承UIResponder基类） 2、MVC模式 百度百科： MVC全名是Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写，一种软件设计典范，用于组织代码用一种业务逻辑和数据显示分离的方法，这个方法的假设前提是如果业务逻辑被聚集到一个部件里面，而且界面和用户围绕数据的交互能被改进和个性化定制而不需要重新编写业务逻辑MVC被独特的发展起来用于映射传统的输入、处理和输出功能在一个逻辑的图形化用户界面的结构中。 个人观点部分：MVC也可以说是一个架构，无论架构还是设计模式也就离不开灵活性、重用性跟扩展性Model-View-Control，可以看到，他的原则就是把一个项目分成三个部分，分别对项目中的三种元素进行拆解Model：用于保存实体部分，保存了关于这个实体的某些算法功能、读写资料的功能Control：顾名思义。控制器就是将由View传来的任务分配给特定的Model去处理，再将处理完的结果返回到目地View。View：用来将结果做显示。这是展现给用户看的一面所以可以看到，只要遵循约定，Mdoel层中某个实体的输入输出算法需要改变或扩展的时候并不影响到Control跟View。而Control就像一个导航指针，作为Model跟View的中间桥梁，View则是象征着输出的部分。 另外还要遵循设计模式中的原则之一：要面向接口编程。这样才能谈得上其中一个元素的更改不会影响到另外两个元素。 最后再次引用百度百科：MVC使开发和维护用户接口的技术含量降低。 分离视图层和业务逻辑层也使得WEB应用更易于维护和修改。 原来以前做java大作业的时候，为了更好地设计程序架构，我自己无意间就实现了MVC模式..不过因为那时不知道，我把M叫底层，V叫表层，C叫数据传输 考虑到iOS， View组件：*.stroyboard等 Controller组件：View组件由ViewController来负责加载管理 Model组件：『数据，底层』","categories":[{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"},{"name":"IOS开发","slug":"开发/IOS开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/IOS%E5%BC%80%E5%8F%91/"}],"tags":[]},{"title":"OC-4","slug":"程序语言/oc-4","date":"2016-08-12T04:02:30.000Z","updated":"2019-04-03T05:02:53.000Z","comments":true,"path":"程序语言/oc-4/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/oc-4/","excerpt":"OC学习过程中的笔记 1、 NSString *str = @”Hello OC~~~”; NSLog(@”%@”,str); 只要输出一个字符串，则必须在””前加@。（只输出一个格式控制符也叫一个字符串 两个双引号出现就是一个字符串） NSString的格式标识符为%@ 故如此输出 2、应该这么理解方法定义： -(void) setWord1:(NSString ) word1 setWord2:(NSString ) word2","text":"OC学习过程中的笔记 1、 NSString *str = @”Hello OC~~~”; NSLog(@”%@”,str); 只要输出一个字符串，则必须在””前加@。（只输出一个格式控制符也叫一个字符串 两个双引号出现就是一个字符串） NSString的格式标识符为%@ 故如此输出 2、应该这么理解方法定义： -(void) setWord1:(NSString ) word1 setWord2:(NSString ) word2 “setWord1:setWord2:”是方法名，word1和word2是参数名。你所谓的参数2的名称（setWord2）其实是方法名的一部分，而不是参数名。objective-c的发明者希望方法名读起来像一个通顺的句子，结合这点来理解方法定义，就不会对objective-c怪异的语法感到困惑了。 例如，定义一个求两个数的和的方法， -(float) addNumber1:(float)num1 toNumber2:(float)num2; 方法名“addNumber1:toNumber2:”读起来就像一个通顺的句子。 3、OC中self 类似于 java中的this ①OC没有私有成员，而是通过接口与实现两部分的方式来实现封装，在实现中定义接口没有的成员即为私有成员（仅供该类使用 不提供给子类及外部使用） ②使用interface声明的成员变量是只能在自己类和子类使用的（oc的默认访问权限是protected），而不能在类的外部使用，（就是通过类名. 点的方式是显示不出来的），pproperty则相反，它可以在类的外部访问，在类的内部可以通过下划线+变量名或者self.变量名的方式来访问。 ③@property给默认访问权限的成员变量提供了一套getter和setter给外界 并且可以使用点语法 ④另可使用访问控制符 但注意myWorld是指向对象的该对象的类的类型的引用，在使用的时候不能用点语法 而是用-&gt; eg:myWORLD-&gt;cc 而对property定义的变量 外部调用只能用点语法不能用-&gt; -&gt;是直接调用改成员 （因为property定义的是私有变量，所以不能直接调用），而点语法是调用getter setter方法 OC是不推荐成员变量即使是用公共访问控制符访问的，所以在其它语言中很常用的.语法 ，在OC中只给@property定义的变量提供 （property定义的变量可以使用点语法 默认调用setter getter方法） 这体现了oc良好的封装性，需要与外界交互的变量全权由property负责定义 等。 property 字面意思—属性 理解之 【注意property不只是可以定义基本类型，还可以定义对象，声明委托等等】 对于通过property与interface定义变量的两种定义方法的理解 见我的个人网站OC1文章 ，详细解释@interface @property两种定义变量的方法 当然 也可以用访问控制符来实现 @private 本类 @public @protected 本类及子类 @package 当然也有getter setter oc为了简便，提供了合成存取方法 @property @synthesize 注意 @property int abc 后 实际上的成员变量为_abc 自动加了下划线请注意 （但是 在外部运用点语法的时候，依然使用xxx.abc而不是xxx.底层成员变量，相当于套了一层引用，我觉得可以叫表层成员变量） 可以通过synthesize的参数来修改 若@synthesize name 则默认等效于@synthesize name=name 此时 就可以直接运用点语法了 以下资料来自百度 『当定义了一系列的变量时，需要写很多的getter和setter方法，而且它们的形式都是差不多的，所以Xcode提供了@property和@synthesize属性，@property用在 .h 头文件中用作声明，@synthesize用在.m 文件中用于实现。 在X-code4.5以前，在.h中声明完属性之后，如： @property（nonatomic，assign) int age; @property（nonatomic，assign) NSString *name; 需要在.m中写上 @synthesize int age; @synthesize NSString *name; 系统会自动去实现setter和getter方法 而在X-code4.5之后，@synthesize就不需要再写了，系统会直接去实现setter和getter方法。 【补充：但是 若要自己重写setter 或getter方法 则必须在实现部分声明@synthesize 注意 若@synthesize name则等效于把name的底层变量从_name修改成了name要注意】 另外，声明完property属性之后，会自动生成下划线，如_age、_name；如果不想要下划线，那么就可以使用@synthesize去修饰，例如，在.m中写@synthesize age；那么_age就会变成age』 4、一些习俗 接口部分和实现部分通常放到两个文件中（接口.h 实现.m） 成员变量通常加一个下划线用_a 参数用a 库前两个大写字母加特殊标识 一般表公司 5、@interface helloworld:NSObject 任何类都继承于NSObject 在没有其它父类的时候必须标明 6、OC中不存在类变量，但存在类方法，可以定义一个全局变量（static）（在实现部分）然后通过类似于getMethod 定义一个类方法返回该变量，称之为模拟类变量 7、OC须手动装箱 NSNumber 方法：numberWithXxx initWithXxx xxxValue 自动装箱不支持ARC 【补充：装箱的意义：将基本类型装箱成对象， 便于将『基本类型元素』储存在像集合这种只能储存对象的结构】 8、只要涉及对象 都要@ 而且是建立一个引用指向对象 故 ABC q = xxx 要打 是一个指针 9、（A）oc中也有类似于java中的toString方法———description 该方法为NSObject的方法 重写该方法以实现功能（打印对象） 直接输出该对象等于调用该方法 一般重写该方法用于告诉外界该对象所具有的状态信息 该方法返回值为NSString* （B）oc中也有java中字符串的一些特性 比如 常量池保证相同的字符串直接量只有一个，不会产生多个副本，即两个指针指向同一个常量池中的对象，而可以用stringWithFormat方法（类似于java中的stringBuffer）将字符串对象创建在运行时内存区（堆内存）中。 [NSString stringWithFormat:”abc”] （C）同java一样，==可以判断基本类型相等和指针地址相等（包括指向对象的引用 故判断字符串相等的时候要注意，需要用isEqualToString方法，注意NSObject的isEqual和==是等价的，经常需要重写） 10、nil相当于其它语言的NULL 11、OC中的『协议』相当于其它语言的接口 非正式协议通过类别和扩展实现 不强制实现所有方法 正式协议 @protocol 必须实现协议中所有方法 （但可以用@optional @required（默认）来改变） 使用协议定义的方法只可调用该协议中声明的[方法]，且只有两种定义语法 [用此方法来限定只能调用该协议中声明的方法] NSObject* p; id p; p是指向对象的变量名 类可继承多个协议 协议可继承多个协议 定义方法 使用方法见书 @protocol XXX @end 对委托的理解 见OC-3 12、扩展即为匿名类别，但类别只能有方法，而扩展可以增加实例变量 用@property @synthesize等 13、NSString 是不可变类 字符串一旦生成则不可改变 可以用NSMutableString（NSString的子类） 该类定义的字符串可以改变（但需要用到方法如appendFormat insertString 等等）","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"OC/SWIFT","slug":"程序语言/OC-SWIFT","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-SWIFT/"}],"tags":[]},{"title":"OC-3 delegate","slug":"程序语言/OC-3 delegate","date":"2016-08-08T05:06:07.000Z","updated":"2019-04-03T05:03:02.000Z","comments":true,"path":"程序语言/OC-3 delegate/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-3%20delegate/","excerpt":"委托是协议的沿用，委托简单的理解就是某人委托某人去做某事，这个和java中的接口回调机制比较相似。委托在IOS开发中比较常用，比如我们不知道一个列表中的数据有多少，我们可以用委托的方式，将数据委托给其他类，让其他类去填充数据。委托的常用功能主要是传值和事件监听。 我们下面使用委托来实现2个类的委托，即老师委托学生去买本《OC开发》。 用来实现委托的协议(BuyBookDelegate.h) @protocol BuyBookDelegate//定义一个委托协议，协议中只有一个方法，用来买书-(void)buyBook:(NSString*)name;@end","text":"委托是协议的沿用，委托简单的理解就是某人委托某人去做某事，这个和java中的接口回调机制比较相似。委托在IOS开发中比较常用，比如我们不知道一个列表中的数据有多少，我们可以用委托的方式，将数据委托给其他类，让其他类去填充数据。委托的常用功能主要是传值和事件监听。 我们下面使用委托来实现2个类的委托，即老师委托学生去买本《OC开发》。 用来实现委托的协议(BuyBookDelegate.h) @protocol BuyBookDelegate//定义一个委托协议，协议中只有一个方法，用来买书-(void)buyBook:(NSString*)name;@end 老师类 import import “BuyBookDelegate.h”@interface Teacher : NSObject//定义一个委托协议@property (nonatomic,assign)id buyBookDele;//定义一个老师想让学生买书的方法-(void)willBuyBook:(NSString*)bookName;@end import “Teacher.h”@implementation Teacher-(void)willBuyBook:(NSString*)bookName{​ NSLog(@”老师想买本《%@》”,bookName);​ [_buyBookDele buyBook:bookName];}@end 学生类 import import “Teacher.h”@interface Student : NSObject @end import “Student.h”@implementation Student-(void)buyBook:(NSString *)name{​ NSLog(@”学生去买《%@》”,name);}@end 测试： import import “Teacher.h”import “Student.h”int main(int argc, const char argv[]) {​ @autoreleasepool {​ Teacher teacher = [[Teacher alloc]init];​ Student* student = [[Student alloc]init];​ //为老师设置委托的对象​ [teacher setBuyBookDele:student];​ //老师要买书了​ [teacher willBuyBook:@”OC开发”];​ }​ return 0;} 结果： 老师想买本《**OC**开发》 学生去买《**OC开发》** 转载自http://m.blog.csdn.net/article/details?id=41827599","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"OC/SWIFT","slug":"程序语言/OC-SWIFT","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-SWIFT/"}],"tags":[]},{"title":"OC-2 invalid operands to binary expression ('NSString *' and 'NSString *')q","slug":"程序语言/oc-2-invalid-operands-to-binary-expression-nsstring-and-nsstring-q","date":"2016-07-31T07:40:47.000Z","updated":"2019-04-03T05:03:08.000Z","comments":true,"path":"程序语言/oc-2-invalid-operands-to-binary-expression-nsstring-and-nsstring-q/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/oc-2-invalid-operands-to-binary-expression-nsstring-and-nsstring-q/","excerpt":"Q： I have the following code: NSString *String=TextField1.text + TextField2.text its giving the error: -invalid operands to binary expression (&#39;NSString *&#39; and &#39;NSString *&#39;) An:","text":"Q： I have the following code: NSString *String=TextField1.text + TextField2.text its giving the error: -invalid operands to binary expression (&#39;NSString *&#39; and &#39;NSString *&#39;) An: You cannot do it this way, because objective-c doesn’t use ‘+’ operator for concatenation This way should work: NSString *concat = [NSString stringWithFormat@&quot;%@%@&quot;, TextField1.text, TextField2.text]; or NSString *concat = [TextField1.text stringByAppendingString:TextField2.text]; Hope this works for you ;) from stackoverflow","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"OC/SWIFT","slug":"程序语言/OC-SWIFT","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-SWIFT/"}],"tags":[]},{"title":"OC 1","slug":"程序语言/oc-1","date":"2016-07-30T11:41:09.000Z","updated":"2019-04-03T05:03:15.000Z","comments":true,"path":"程序语言/oc-1/","link":"","permalink":"https://aisaka.cloud/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/oc-1/","excerpt":"**1、oc的默认访问权限：变量是protected，函数是public @property给默认访问权限的成员变量提供了一套getter和setter给外界 封装 2、 一直有疑问，在objective_C中声明变量会有 2种方式，今天有空和网友讨论了下，并且自己查了stackoverflew后算是稍微弄懂了一点。记录如下： 用了一段oc；会发现有2种定义变量的方式 1.在 @interface :NSObject{} 的括号中，当然NSObject 是指一个父类，可以是其他的。","text":"**1、oc的默认访问权限：变量是protected，函数是public @property给默认访问权限的成员变量提供了一套getter和setter给外界 封装 2、 一直有疑问，在objective_C中声明变量会有 2种方式，今天有空和网友讨论了下，并且自己查了stackoverflew后算是稍微弄懂了一点。记录如下： 用了一段oc；会发现有2种定义变量的方式 1.在 @interface :NSObject{} 的括号中，当然NSObject 是指一个父类，可以是其他的。 形式如下： 1 @interface GCTurnBasedMatchHelper : NSObject &#123; 2 BOOL gameCenterAvailable; 3 BOOL userAuthenticated; 4 &#125; 2.另外一种是直接在 @interface : NSObject{}括号之后，用 @property 去定义一个变量。 1 @property (assign, readonly) BOOL gameCenterAvailable; 你会发现，有人会再@interface中定义了变量后，又在 @property中重复定义相同的变量，而且很常见。 结果可能是这样： 1 @interface GCTurnBasedMatchHelper : NSObject &#123; 2 BOOL gameCenterAvailable; 3 BOOL userAuthenticated; 4 &#125; 5 6 @property (assign, readonly) BOOL gameCenterAvailable; 而且你可以单独在@interface中定义变量，而不用@property定义；也可以只用@property去定义，而不在@interface中定义，当然用了@property去定义，一般要在.m文件中用@synthsize去合成相应的setter，getter方法。否则会得到一个警告。当然@synthsize是可选的，但是是Apple推荐的，不用会有什么后果，我没试过，有兴趣的童鞋可以试一下。 那这两种方式有什么区别呢。 \\1. 只在@interface中定义变量的话，你所定义的变量只能在当前的类中访问，在其他类中是访问不了的；而用@property声明的变量可以在外部访问。 2.用了@property去声明的变量，可以使用“self.变量名”的方式去读写变量。而用@interface的方式就不可以。 \\3. 这里给出一个链接：http://stackoverflow.com/questions/9702258/difference-between-properties-and-variables-in-ios-header-file 里面讲到： 我英语菜，简单翻一下： Defining the variables in the brackets simply declares them instance variables. 在括号中定义一个变量只是简单的声明了一个实例变量（实例变量应该指的成员变量）。 博主注：老外对variable 和instance variable是有不同理解的。所以下文中 用了一个模糊的词 ivar。 Declaring (and synthesizing) a property generates getters and setters for the instance variable, according to the criteria within the parenthesis. This is particularly important in Objective-C because it is often by way of getters and setters that memory is managed (e.g., when a value is assigned to an ivar, it is by way of the setter that the object assigned is retained and ultimately released). Beyond a memory management strategy, the practice also promotes encapsulation and reduces the amount of trivial code that would otherwise be required. 声明（和 @synthsize）一个属性会为成员变量生成 getter 和setter方法，根据括号内的标准,在oc中经常用setter和getter 做内存管理，这是很重要的。（例如： 当一个值被赋给这个变量，对象是通过setter函数去分配，修改计数器，并最后释放的）。更高一个层次来说，这种做法也促进了封装，减少了一些不必要的代码。 It is very common to declare an ivar in brackets and then an associated property (as in your example), but that isn’t strictly necessary. Defining the property and synthesizing is all that’s required, because synthesizing the property implicitly also creates an ivar. 在@interface括号中定义一个变量并用@property 重复定义一次是很普遍的，实际上不是必要的。用@property和@synthszie就够了，因为在用@synthsize合成这个属性的读写方法时就会创建一个变量。 The approach currently suggested by Apple (in templates) is: 目前苹果（在模板中）建议的方法是这样的： -Define property in header file, e.g.: 先在头文件中定义一个属性 1 @property int gameCenter; Then synthesize &amp; declare ivar in implementation: 然后在实现文件中 synthsize和declare成这样： 1 @synthesize gameCenter &#x3D; __ gameCenter; The last line synthesizes the gameCenter property and asserts that whatever value is assigned to the property will be stored in the __gameCenter ivar. Again, this isn’t necessary, but by defining the ivar next to the synthesizer, you are reducing the locations where you have to type the name of the ivar while still explicitly naming it. 最后一行synthsize gameCenter 属性并说明了不管什么值被分配给这个属性，都会存储到_gameCenter这个变量中。 再次说明，这不是必要的，但是，这样写了之后，你能减少输入已经明确命名的变量名。 最后一句的意思you are reducing the locations where you have to type the name of the ivar while still explicitly naming it .不好翻。 据千锋的第2节语法课课程的讲解，这样写之后可以使得 @synthsize 时内部getter方法会展成 1 -(int)gameCenter 2 &#123; 3 return _gameCenter; 4 &#125; 而直接写 @synthsize gameCenter； setter函数会在内部展开成 1 -(int)gameCenter 2 &#123; 3 return gameCenter; 4 &#125; 注意到：函数名和变量名是一样的。在斯坦福的课程中，白胡子教授也模糊的说道这样的同名有可能带来bug，具体什么bug他没说，我也没见过，所以还是养成这样写的习惯为好。其他语言的getter函数 一般会在变量前加 get；但oc没有，可能是为了与其他语言做区分，算是oc的特色，结果却带来这么个麻烦。 转载自http://www.cnblogs.com/letmefly/archive/2012/07/20/2601338.html","categories":[{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"OC/SWIFT","slug":"程序语言/OC-SWIFT","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-SWIFT/"}],"tags":[]},{"title":"终于考完了 进入苦逼的小学期","slug":"日记/终于考完了 进入苦逼的小学期","date":"2016-07-05T12:04:26.000Z","updated":"2019-04-01T15:38:25.000Z","comments":true,"path":"日记/终于考完了 进入苦逼的小学期/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E7%BB%88%E4%BA%8E%E8%80%83%E5%AE%8C%E4%BA%86%20%E8%BF%9B%E5%85%A5%E8%8B%A6%E9%80%BC%E7%9A%84%E5%B0%8F%E5%AD%A6%E6%9C%9F/","excerpt":"","text":"先来局屁股","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"...","slug":"日记/113","date":"2016-05-17T23:55:19.000Z","updated":"2019-04-03T04:57:29.000Z","comments":true,"path":"日记/113/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/113/","excerpt":"","text":"","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"不要让你的生命留下太多遗憾","slug":"日记/不要让你的生命留下太多遗憾","date":"2016-05-09T15:58:15.000Z","updated":"2019-04-03T04:58:23.000Z","comments":true,"path":"日记/不要让你的生命留下太多遗憾/","link":"","permalink":"https://aisaka.cloud/%E6%97%A5%E8%AE%B0/%E4%B8%8D%E8%A6%81%E8%AE%A9%E4%BD%A0%E7%9A%84%E7%94%9F%E5%91%BD%E7%95%99%E4%B8%8B%E5%A4%AA%E5%A4%9A%E9%81%97%E6%86%BE/","excerpt":"","text":"","categories":[{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"}],"tags":[]},{"title":"TestMovie","slug":"博客/TestMovie","date":"2016-05-09T15:46:31.000Z","updated":"2019-04-01T15:39:13.000Z","comments":true,"path":"博客/TestMovie/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/TestMovie/","excerpt":"","text":"","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"链表，栈，队列、树四种结构的构建方式的简单理解","slug":"算法与数据结构/链表，栈，队列、树四种结构的构建方式的简单理解","date":"2016-05-07T03:56:59.000Z","updated":"2018-11-06T05:33:12.000Z","comments":true,"path":"算法与数据结构/链表，栈，队列、树四种结构的构建方式的简单理解/","link":"","permalink":"https://aisaka.cloud/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8%EF%BC%8C%E6%A0%88%EF%BC%8C%E9%98%9F%E5%88%97%E3%80%81%E6%A0%91%E5%9B%9B%E7%A7%8D%E7%BB%93%E6%9E%84%E7%9A%84%E6%9E%84%E5%BB%BA%E6%96%B9%E5%BC%8F%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/","excerpt":"开个坑，有空填，方便自己考前速看一下 两种储存结构 链式和顺式 比较一下链表的链式储存结构、栈和队列的顺式储存结构（不代表他们只有链式/顺式，只是着重强调） 假设所有的储存数据都是int型 顺序栈的结构构建 两个参数：初始容量、每次增加的容量 struct stack { int base,top; int length; };","text":"开个坑，有空填，方便自己考前速看一下 两种储存结构 链式和顺式 比较一下链表的链式储存结构、栈和队列的顺式储存结构（不代表他们只有链式/顺式，只是着重强调） 假设所有的储存数据都是int型 顺序栈的结构构建 两个参数：初始容量、每次增加的容量 struct stack { int base,top; int length; }; base指向栈底，top指向栈顶 length表明现在栈的容量 初始化的时候，需要初始化一个初始容量大小的空间。base指向第一个位置，top指向顶位置 base和top是指针，代表指向的位置，要储存的数据储存在『top指针当时指向的那一个位置』 当到达栈顶，开辟新空间 循环队列的结构构建 参数： 最大容量 struct queen { int *base; int front,rear; }; 其实顺序结构实际上是个数组。数组和指针在用法上有非常多的相似，这里用指针的操作方式建立了一个数组， base是指向数组头的指针；base手动开辟一段最大容量大小的空间 front和rear是数组的下标，front在第一位数，rear在最后一个存放数据的位置的后一位 要储存的内容即存放在该数组中 这里，可以使用数组操作了。 比如base[a] front-base即为队列长度 但是对于普通的一长列，可以用后-前来算长度，但由于这是循环的队列，所以有一些数学上的东西要修正： 若为不循环的表，b在a后面，那么b-a即可 若为一个循环列表 a到b中间空了多少格？ 1、假设b在a前面，那么这就尴尬了。b-a为负数，这时候求个补，即加一个总长，b-a+length，这时候假设2-4=-2 ，那么就变成了-2+6（总长）=4，这即为他们之间的距离（注意：距离是朝顺方向的距离）。但是如果b-a&gt;0的话，这tm就又尴尬了，4-2+6=8了，再结合2、处理 2、若为一个循环链表，一个数到达顶端了要跳回第一个数怎么处理？ 对它加一然后求余即可，故在循环链表中，表示一个数进一位用（a+1）%length表示。对于循环列表中的数，下标%length即为其该在的位置 链表 struct linknode { int data; int *next; }; 链表的内容储存在每一个节点中，每一个节点都是一个struct，而栈和队列都只有一个struct，即为栈、队列本身。 串珠子，很容易理解 {对所有数据结构}一个易错点，struct sim;在主函数创建一个 sim a 还是 sim* a 要注意，两者皆可以但用法不同 建议链式结构 sim*a 顺式结构 sim a 二叉树 栈的递归运用之–二叉树 注意这里和链表的感觉很像，实则不然，创建方式和遍历方式是不同的，栈的创建需要至少两个指针p，q，像爬梯子一样创建。而二叉树的创建只需要一个根，然后递归创建 TBC","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]},{"title":"VMware虚拟机ping不通主机","slug":"博客/VMware虚拟机ping不通主机","date":"2016-05-03T14:36:20.000Z","updated":"2019-04-03T04:56:48.000Z","comments":true,"path":"博客/VMware虚拟机ping不通主机/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/VMware%E8%99%9A%E6%8B%9F%E6%9C%BAping%E4%B8%8D%E9%80%9A%E4%B8%BB%E6%9C%BA/","excerpt":"","text":"待解决 5月4日更新 问题解决了 使用桥接模式需要dhclient自动获取IP地址………..","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"Test image","slug":"博客/test-image","date":"2016-05-01T07:21:43.000Z","updated":"2019-04-01T15:39:31.000Z","comments":true,"path":"博客/test-image/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/test-image/","excerpt":"","text":"一脸懵逼","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"Sever.","slug":"博客/sever","date":"2016-04-30T15:10:05.000Z","updated":"2019-04-01T15:39:22.000Z","comments":true,"path":"博客/sever/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/sever/","excerpt":"","text":"","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]},{"title":"hello world","slug":"博客/hello-world-2","date":"2016-04-30T10:11:27.000Z","updated":"2019-04-01T15:39:01.000Z","comments":true,"path":"博客/hello-world-2/","link":"","permalink":"https://aisaka.cloud/%E5%8D%9A%E5%AE%A2/hello-world-2/","excerpt":"","text":"from aisaka","categories":[{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[]}],"categories":[{"name":"存储","slug":"存储","permalink":"https://aisaka.cloud/categories/%E5%AD%98%E5%82%A8/"},{"name":"日记","slug":"日记","permalink":"https://aisaka.cloud/categories/%E6%97%A5%E8%AE%B0/"},{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/categories/%E9%98%85%E8%AF%BB/"},{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://aisaka.cloud/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Music","slug":"Music","permalink":"https://aisaka.cloud/categories/Music/"},{"name":"Anime","slug":"Anime","permalink":"https://aisaka.cloud/categories/Anime/"},{"name":"硬件","slug":"硬件","permalink":"https://aisaka.cloud/categories/%E7%A1%AC%E4%BB%B6/"},{"name":"网络与云","slug":"网络与云","permalink":"https://aisaka.cloud/categories/%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BA%91/"},{"name":"Game","slug":"Game","permalink":"https://aisaka.cloud/categories/Game/"},{"name":"工具","slug":"工具","permalink":"https://aisaka.cloud/categories/%E5%B7%A5%E5%85%B7/"},{"name":"人工智能","slug":"人工智能","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"人工智能/神经网络","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"机器学习与统计学习","slug":"人工智能/机器学习与统计学习","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"},{"name":"程序语言","slug":"程序语言","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"},{"name":"JAVA","slug":"程序语言/JAVA","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/JAVA/"},{"name":"计算机理论","slug":"计算机理论","permalink":"https://aisaka.cloud/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"},{"name":"数据库与中间件","slug":"数据库与中间件","permalink":"https://aisaka.cloud/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"C","slug":"程序语言/C","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/C/"},{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/categories/%E9%9A%8F%E7%AC%94/"},{"name":"HTML/JS/CSS","slug":"程序语言/HTML-JS-CSS","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/HTML-JS-CSS/"},{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/categories/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"},{"name":"大数据","slug":"人工智能/大数据","permalink":"https://aisaka.cloud/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"开发","slug":"开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/"},{"name":"Unity","slug":"开发/Unity","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/Unity/"},{"name":"论文阅读笔记","slug":"论文阅读笔记","permalink":"https://aisaka.cloud/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"IOS开发","slug":"开发/IOS开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/IOS%E5%BC%80%E5%8F%91/"},{"name":"博客","slug":"博客","permalink":"https://aisaka.cloud/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"PYTHON","slug":"程序语言/PYTHON","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/PYTHON/"},{"name":"andoird开发","slug":"开发/andoird开发","permalink":"https://aisaka.cloud/categories/%E5%BC%80%E5%8F%91/andoird%E5%BC%80%E5%8F%91/"},{"name":"C#","slug":"程序语言/C","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/C/"},{"name":"OC/SWIFT","slug":"程序语言/OC-SWIFT","permalink":"https://aisaka.cloud/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/OC-SWIFT/"}],"tags":[{"name":"老婆","slug":"老婆","permalink":"https://aisaka.cloud/tags/%E8%80%81%E5%A9%86/"},{"name":"新番","slug":"新番","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E7%95%AA/"},{"name":"hanser","slug":"hanser","permalink":"https://aisaka.cloud/tags/hanser/"},{"name":"indie game","slug":"indie-game","permalink":"https://aisaka.cloud/tags/indie-game/"},{"name":"雪","slug":"雪","permalink":"https://aisaka.cloud/tags/%E9%9B%AA/"},{"name":"双笙","slug":"双笙","permalink":"https://aisaka.cloud/tags/%E5%8F%8C%E7%AC%99/"},{"name":"矩阵论","slug":"矩阵论","permalink":"https://aisaka.cloud/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"},{"name":"SVM","slug":"SVM","permalink":"https://aisaka.cloud/tags/SVM/"},{"name":"凸优化","slug":"凸优化","permalink":"https://aisaka.cloud/tags/%E5%87%B8%E4%BC%98%E5%8C%96/"},{"name":"新海诚","slug":"新海诚","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E6%B5%B7%E8%AF%9A/"},{"name":"3A","slug":"3A","permalink":"https://aisaka.cloud/tags/3A/"},{"name":"震惊","slug":"震惊","permalink":"https://aisaka.cloud/tags/%E9%9C%87%E6%83%8A/"},{"name":"暴力","slug":"暴力","permalink":"https://aisaka.cloud/tags/%E6%9A%B4%E5%8A%9B/"},{"name":"GAN","slug":"GAN","permalink":"https://aisaka.cloud/tags/GAN/"},{"name":"随笔","slug":"随笔","permalink":"https://aisaka.cloud/tags/%E9%9A%8F%E7%AC%94/"},{"name":"村上春树","slug":"村上春树","permalink":"https://aisaka.cloud/tags/%E6%9D%91%E4%B8%8A%E6%98%A5%E6%A0%91/"},{"name":"数学","slug":"数学","permalink":"https://aisaka.cloud/tags/%E6%95%B0%E5%AD%A6/"},{"name":"统计物理学","slug":"统计物理学","permalink":"https://aisaka.cloud/tags/%E7%BB%9F%E8%AE%A1%E7%89%A9%E7%90%86%E5%AD%A6/"},{"name":"青春","slug":"青春","permalink":"https://aisaka.cloud/tags/%E9%9D%92%E6%98%A5/"},{"name":"新海诚式","slug":"新海诚式","permalink":"https://aisaka.cloud/tags/%E6%96%B0%E6%B5%B7%E8%AF%9A%E5%BC%8F/"},{"name":"kb","slug":"kb","permalink":"https://aisaka.cloud/tags/kb/"},{"name":"秋","slug":"秋","permalink":"https://aisaka.cloud/tags/%E7%A7%8B/"},{"name":"游戏设计","slug":"游戏设计","permalink":"https://aisaka.cloud/tags/%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/"},{"name":"采样","slug":"采样","permalink":"https://aisaka.cloud/tags/%E9%87%87%E6%A0%B7/"},{"name":"统计数学","slug":"统计数学","permalink":"https://aisaka.cloud/tags/%E7%BB%9F%E8%AE%A1%E6%95%B0%E5%AD%A6/"},{"name":"马尔科夫链","slug":"马尔科夫链","permalink":"https://aisaka.cloud/tags/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE/"},{"name":"概率论","slug":"概率论","permalink":"https://aisaka.cloud/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"自编码器","slug":"自编码器","permalink":"https://aisaka.cloud/tags/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/"},{"name":"风格迁移","slug":"风格迁移","permalink":"https://aisaka.cloud/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"},{"name":"非线性优化","slug":"非线性优化","permalink":"https://aisaka.cloud/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96/"},{"name":"IOS","slug":"IOS","permalink":"https://aisaka.cloud/tags/IOS/"},{"name":"XCODE","slug":"XCODE","permalink":"https://aisaka.cloud/tags/XCODE/"},{"name":"神经网络","slug":"神经网络","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://aisaka.cloud/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"对抗样本","slug":"对抗样本","permalink":"https://aisaka.cloud/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"},{"name":"智能对抗","slug":"智能对抗","permalink":"https://aisaka.cloud/tags/%E6%99%BA%E8%83%BD%E5%AF%B9%E6%8A%97/"},{"name":"AE","slug":"AE","permalink":"https://aisaka.cloud/tags/AE/"},{"name":"model-security","slug":"model-security","permalink":"https://aisaka.cloud/tags/model-security/"},{"name":"NAS","slug":"NAS","permalink":"https://aisaka.cloud/tags/NAS/"},{"name":"夏天","slug":"夏天","permalink":"https://aisaka.cloud/tags/%E5%A4%8F%E5%A4%A9/"},{"name":"京阿尼","slug":"京阿尼","permalink":"https://aisaka.cloud/tags/%E4%BA%AC%E9%98%BF%E5%B0%BC/"},{"name":"mini-batch","slug":"mini-batch","permalink":"https://aisaka.cloud/tags/mini-batch/"},{"name":"RNN","slug":"RNN","permalink":"https://aisaka.cloud/tags/RNN/"},{"name":"pytorch","slug":"pytorch","permalink":"https://aisaka.cloud/tags/pytorch/"},{"name":"n-gram","slug":"n-gram","permalink":"https://aisaka.cloud/tags/n-gram/"},{"name":"NLP","slug":"NLP","permalink":"https://aisaka.cloud/tags/NLP/"},{"name":"CNN","slug":"CNN","permalink":"https://aisaka.cloud/tags/CNN/"},{"name":"Apple","slug":"Apple","permalink":"https://aisaka.cloud/tags/Apple/"},{"name":"天下第一","slug":"天下第一","permalink":"https://aisaka.cloud/tags/%E5%A4%A9%E4%B8%8B%E7%AC%AC%E4%B8%80/"},{"name":"川端康成","slug":"川端康成","permalink":"https://aisaka.cloud/tags/%E5%B7%9D%E7%AB%AF%E5%BA%B7%E6%88%90/"},{"name":"词向量","slug":"词向量","permalink":"https://aisaka.cloud/tags/%E8%AF%8D%E5%90%91%E9%87%8F/"},{"name":"word2vec","slug":"word2vec","permalink":"https://aisaka.cloud/tags/word2vec/"},{"name":"阅读","slug":"阅读","permalink":"https://aisaka.cloud/tags/%E9%98%85%E8%AF%BB/"},{"name":"数据","slug":"数据","permalink":"https://aisaka.cloud/tags/%E6%95%B0%E6%8D%AE/"},{"name":"HEXO","slug":"HEXO","permalink":"https://aisaka.cloud/tags/HEXO/"},{"name":"神说，要有光","slug":"神说，要有光","permalink":"https://aisaka.cloud/tags/%E7%A5%9E%E8%AF%B4%EF%BC%8C%E8%A6%81%E6%9C%89%E5%85%89/"},{"name":"图像处理","slug":"图像处理","permalink":"https://aisaka.cloud/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"炼丹","slug":"炼丹","permalink":"https://aisaka.cloud/tags/%E7%82%BC%E4%B8%B9/"},{"name":"显卡","slug":"显卡","permalink":"https://aisaka.cloud/tags/%E6%98%BE%E5%8D%A1/"},{"name":"BP","slug":"BP","permalink":"https://aisaka.cloud/tags/BP/"},{"name":"markdown","slug":"markdown","permalink":"https://aisaka.cloud/tags/markdown/"},{"name":"DNS","slug":"DNS","permalink":"https://aisaka.cloud/tags/DNS/"}]}